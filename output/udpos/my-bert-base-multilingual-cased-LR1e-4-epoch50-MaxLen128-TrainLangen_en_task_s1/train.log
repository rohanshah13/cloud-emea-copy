01/05/2022 21:41:00 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:41:00 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/05/2022 21:41:00 - INFO - __main__ -   Seed = 1
01/05/2022 21:41:00 - INFO - root -   save adapters
01/05/2022 21:41:00 - INFO - root -   True
01/05/2022 21:41:00 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:41:00 - INFO - __main__ -   Loading pretrained model and tokenizer
01/05/2022 21:41:03 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/05/2022 21:41:08 - INFO - __main__ -   Using lang2id = None
01/05/2022 21:41:08 - INFO - root -   Trying to decide if add adapter
01/05/2022 21:41:08 - INFO - root -   Adding task adapter
01/05/2022 21:41:08 - INFO - __main__ -   lang adapter names: 
01/05/2022 21:41:12 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_train_en_bert-base-multilingual-cased_128
01/05/2022 21:41:14 - INFO - root -   ['bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias', 'classifier.weight', 'classifier.bias']
01/05/2022 21:41:14 - INFO - __main__ -   ***** Running training *****
01/05/2022 21:41:14 - INFO - __main__ -     Num examples = 21798
01/05/2022 21:41:14 - INFO - __main__ -     Num Epochs = 50
01/05/2022 21:41:14 - INFO - __main__ -     Instantaneous batch size per GPU = 8
01/05/2022 21:41:14 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
01/05/2022 21:41:14 - INFO - __main__ -     Gradient Accumulation steps = 4
01/05/2022 21:41:14 - INFO - __main__ -     Total optimization steps = 34050
01/05/2022 21:41:14 - INFO - __main__ -   Seed = 1
01/05/2022 21:42:57 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:42:57 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/05/2022 21:42:57 - INFO - __main__ -   Seed = 1
01/05/2022 21:42:57 - INFO - root -   save adapters
01/05/2022 21:42:57 - INFO - root -   True
01/05/2022 21:42:57 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:42:57 - INFO - __main__ -   Loading pretrained model and tokenizer
01/05/2022 21:43:00 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/05/2022 21:43:05 - INFO - __main__ -   Using lang2id = None
01/05/2022 21:43:05 - INFO - __main__ -   bert.embeddings.word_embeddings.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.embeddings.position_embeddings.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.embeddings.token_type_embeddings.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.embeddings.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.embeddings.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.output.dense.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.output.dense.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   classifier.weight
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - __main__ -   classifier.bias
01/05/2022 21:43:05 - INFO - __main__ -   True
01/05/2022 21:43:05 - INFO - root -   Trying to decide if add adapter
01/05/2022 21:43:05 - INFO - root -   Adding task adapter
01/05/2022 21:43:05 - INFO - __main__ -   lang adapter names: 
01/05/2022 21:43:09 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_train_en_bert-base-multilingual-cased_128
01/05/2022 21:43:11 - INFO - root -   ['bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias', 'classifier.weight', 'classifier.bias']
01/05/2022 21:43:11 - INFO - __main__ -   ***** Running training *****
01/05/2022 21:43:11 - INFO - __main__ -     Num examples = 21798
01/05/2022 21:43:11 - INFO - __main__ -     Num Epochs = 50
01/05/2022 21:43:11 - INFO - __main__ -     Instantaneous batch size per GPU = 8
01/05/2022 21:43:11 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
01/05/2022 21:43:11 - INFO - __main__ -     Gradient Accumulation steps = 4
01/05/2022 21:43:11 - INFO - __main__ -     Total optimization steps = 34050
01/05/2022 21:43:11 - INFO - __main__ -   Seed = 1
01/05/2022 21:43:20 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 21:43:20 - INFO - __main__ -   ***** Running evaluation 1000 in en *****
01/05/2022 21:43:20 - INFO - __main__ -     Num examples = 3974
01/05/2022 21:43:20 - INFO - __main__ -     Batch size = 32
01/05/2022 21:43:20 - INFO - __main__ -   Batch number = 1
01/05/2022 21:43:20 - INFO - __main__ -   Batch number = 2
01/05/2022 21:43:20 - INFO - __main__ -   Batch number = 3
01/05/2022 21:43:20 - INFO - __main__ -   Batch number = 4
01/05/2022 21:43:20 - INFO - __main__ -   Batch number = 5
01/05/2022 21:43:20 - INFO - __main__ -   Batch number = 6
01/05/2022 21:43:20 - INFO - __main__ -   Batch number = 7
01/05/2022 21:43:20 - INFO - __main__ -   Batch number = 8
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 9
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 10
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 11
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 12
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 13
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 14
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 15
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 16
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 17
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 18
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 19
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 20
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 21
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 22
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 23
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 24
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 25
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 26
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 27
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 28
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 29
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 30
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 31
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 32
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 33
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 34
01/05/2022 21:43:21 - INFO - __main__ -   Batch number = 35
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 36
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 37
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 38
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 39
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 40
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 41
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 42
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 43
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 44
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 45
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 46
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 47
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 48
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 49
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 50
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 51
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 52
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 53
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 54
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 55
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 56
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 57
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 58
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 59
01/05/2022 21:43:22 - INFO - __main__ -   Batch number = 60
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 61
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 62
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 63
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 64
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 65
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 66
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 67
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 68
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 69
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 70
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 71
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 72
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 73
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 74
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 75
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 76
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 77
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 78
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 79
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 80
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 81
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 82
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 83
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 84
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 85
01/05/2022 21:43:23 - INFO - __main__ -   Batch number = 86
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 87
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 88
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 89
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 90
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 91
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 92
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 93
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 94
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 95
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 96
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 97
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 98
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 99
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 100
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 101
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 102
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 103
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 104
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 105
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 106
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 107
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 108
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 109
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 110
01/05/2022 21:43:24 - INFO - __main__ -   Batch number = 111
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 112
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 113
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 114
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 115
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 116
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 117
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 118
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 119
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 120
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 121
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 122
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 123
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 124
01/05/2022 21:43:25 - INFO - __main__ -   Batch number = 125
01/05/2022 21:43:39 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:43:39 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/05/2022 21:43:39 - INFO - __main__ -   Seed = 1
01/05/2022 21:43:39 - INFO - root -   save adapters
01/05/2022 21:43:39 - INFO - root -   True
01/05/2022 21:43:39 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:43:39 - INFO - __main__ -   Loading pretrained model and tokenizer
01/05/2022 21:43:42 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/05/2022 21:43:47 - INFO - __main__ -   Using lang2id = None
01/05/2022 21:43:47 - INFO - __main__ -   bert.embeddings.word_embeddings.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.embeddings.position_embeddings.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.embeddings.token_type_embeddings.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.embeddings.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.embeddings.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.output.dense.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.output.dense.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   classifier.weight
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - __main__ -   classifier.bias
01/05/2022 21:43:47 - INFO - __main__ -   True
01/05/2022 21:43:47 - INFO - root -   Trying to decide if add adapter
01/05/2022 21:43:47 - INFO - root -   Adding task adapter
01/05/2022 21:43:47 - INFO - __main__ -   lang adapter names: 
01/05/2022 21:43:50 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_train_en_bert-base-multilingual-cased_128
01/05/2022 21:43:52 - INFO - root -   ['bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias', 'classifier.weight', 'classifier.bias']
01/05/2022 21:43:52 - INFO - __main__ -   ***** Running training *****
01/05/2022 21:43:52 - INFO - __main__ -     Num examples = 21798
01/05/2022 21:43:52 - INFO - __main__ -     Num Epochs = 50
01/05/2022 21:43:52 - INFO - __main__ -     Instantaneous batch size per GPU = 8
01/05/2022 21:43:52 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
01/05/2022 21:43:52 - INFO - __main__ -     Gradient Accumulation steps = 4
01/05/2022 21:43:52 - INFO - __main__ -     Total optimization steps = 34050
01/05/2022 21:43:52 - INFO - __main__ -   Seed = 1
01/05/2022 21:46:27 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:46:27 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/05/2022 21:46:27 - INFO - __main__ -   Seed = 1
01/05/2022 21:46:27 - INFO - root -   save adapters
01/05/2022 21:46:27 - INFO - root -   True
01/05/2022 21:46:27 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:46:27 - INFO - __main__ -   Loading pretrained model and tokenizer
01/05/2022 21:46:29 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/05/2022 21:46:34 - INFO - __main__ -   Using lang2id = None
01/05/2022 21:46:34 - INFO - root -   Trying to decide if add adapter
01/05/2022 21:46:34 - INFO - root -   Adding task adapter
01/05/2022 21:46:34 - INFO - __main__ -   lang adapter names: 
01/05/2022 21:46:34 - INFO - __main__ -   bert.embeddings.word_embeddings.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.embeddings.position_embeddings.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.embeddings.token_type_embeddings.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.embeddings.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.embeddings.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.output.dense.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.output.dense.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.weight
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.bias
01/05/2022 21:46:34 - INFO - __main__ -   False
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   classifier.weight
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:34 - INFO - __main__ -   classifier.bias
01/05/2022 21:46:34 - INFO - __main__ -   True
01/05/2022 21:46:37 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_train_en_bert-base-multilingual-cased_128
01/05/2022 21:46:39 - INFO - root -   ['bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias', 'classifier.weight', 'classifier.bias']
01/05/2022 21:46:39 - INFO - __main__ -   ***** Running training *****
01/05/2022 21:46:39 - INFO - __main__ -     Num examples = 21798
01/05/2022 21:46:39 - INFO - __main__ -     Num Epochs = 50
01/05/2022 21:46:39 - INFO - __main__ -     Instantaneous batch size per GPU = 8
01/05/2022 21:46:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
01/05/2022 21:46:39 - INFO - __main__ -     Gradient Accumulation steps = 4
01/05/2022 21:46:39 - INFO - __main__ -     Total optimization steps = 34050
01/05/2022 21:46:39 - INFO - __main__ -   Seed = 1
01/05/2022 21:49:09 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 21:49:09 - INFO - __main__ -   ***** Running evaluation 1000 in en *****
01/05/2022 21:49:09 - INFO - __main__ -     Num examples = 3974
01/05/2022 21:49:09 - INFO - __main__ -     Batch size = 32
01/05/2022 21:49:09 - INFO - __main__ -   Batch number = 1
01/05/2022 21:49:09 - INFO - __main__ -   Batch number = 2
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 3
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 4
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 5
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 6
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 7
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 8
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 9
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 10
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 11
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 12
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 13
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 14
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 15
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 16
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 17
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 18
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 19
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 20
01/05/2022 21:49:10 - INFO - __main__ -   Batch number = 21
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 22
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 23
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 24
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 25
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 26
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 27
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 28
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 29
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 30
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 31
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 32
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 33
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 34
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 35
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 36
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 37
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 38
01/05/2022 21:49:11 - INFO - __main__ -   Batch number = 39
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 40
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 41
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 42
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 43
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 44
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 45
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 46
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 47
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 48
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 49
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 50
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 51
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 52
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 53
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 54
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 55
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 56
01/05/2022 21:49:12 - INFO - __main__ -   Batch number = 57
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 58
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 59
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 60
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 61
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 62
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 63
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 64
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 65
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 66
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 67
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 68
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 69
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 70
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 71
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 72
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 73
01/05/2022 21:49:13 - INFO - __main__ -   Batch number = 74
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 75
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 76
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 77
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 78
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 79
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 80
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 81
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 82
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 83
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 84
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 85
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 86
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 87
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 88
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 89
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 90
01/05/2022 21:49:14 - INFO - __main__ -   Batch number = 91
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 92
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 93
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 94
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 95
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 96
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 97
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 98
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 99
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 100
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 101
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 102
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 103
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 104
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 105
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 106
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 107
01/05/2022 21:49:15 - INFO - __main__ -   Batch number = 108
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 109
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 110
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 111
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 112
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 113
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 114
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 115
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 116
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 117
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 118
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 119
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 120
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 121
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 122
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 123
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 124
01/05/2022 21:49:16 - INFO - __main__ -   Batch number = 125
01/05/2022 21:49:18 - INFO - __main__ -   ***** Evaluation result 1000 in en *****
01/05/2022 21:49:18 - INFO - __main__ -     f1 = 0.9415200171269534
01/05/2022 21:49:18 - INFO - __main__ -     loss = 0.16703320011496545
01/05/2022 21:49:18 - INFO - __main__ -     precision = 0.9413829714363997
01/05/2022 21:49:18 - INFO - __main__ -     recall = 0.941657102725295
01/05/2022 21:49:18 - INFO - __main__ -   result['f1']=0.9415200171269534 > best_score=0.0
01/05/2022 21:49:18 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/checkpoint-best
01/05/2022 21:49:18 - INFO - __main__ -   Reset patience to 0
01/05/2022 21:51:51 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 21:51:51 - INFO - __main__ -   ***** Running evaluation 2000 in en *****
01/05/2022 21:51:51 - INFO - __main__ -     Num examples = 3974
01/05/2022 21:51:51 - INFO - __main__ -     Batch size = 32
01/05/2022 21:51:51 - INFO - __main__ -   Batch number = 1
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 2
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 3
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 4
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 5
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 6
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 7
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 8
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 9
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 10
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 11
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 12
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 13
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 14
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 15
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 16
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 17
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 18
01/05/2022 21:51:52 - INFO - __main__ -   Batch number = 19
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 20
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 21
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 22
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 23
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 24
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 25
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 26
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 27
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 28
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 29
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 30
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 31
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 32
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 33
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 34
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 35
01/05/2022 21:51:53 - INFO - __main__ -   Batch number = 36
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 37
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 38
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 39
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 40
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 41
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 42
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 43
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 44
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 45
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 46
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 47
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 48
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 49
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 50
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 51
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 52
01/05/2022 21:51:54 - INFO - __main__ -   Batch number = 53
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 54
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 55
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 56
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 57
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 58
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 59
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 60
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 61
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 62
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 63
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 64
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 65
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 66
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 67
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 68
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 69
01/05/2022 21:51:55 - INFO - __main__ -   Batch number = 70
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 71
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 72
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 73
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 74
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 75
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 76
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 77
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 78
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 79
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 80
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 81
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 82
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 83
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 84
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 85
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 86
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 87
01/05/2022 21:51:56 - INFO - __main__ -   Batch number = 88
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 89
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 90
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 91
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 92
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 93
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 94
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 95
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 96
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 97
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 98
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 99
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 100
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 101
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 102
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 103
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 104
01/05/2022 21:51:57 - INFO - __main__ -   Batch number = 105
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 106
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 107
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 108
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 109
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 110
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 111
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 112
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 113
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 114
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 115
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 116
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 117
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 118
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 119
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 120
01/05/2022 21:51:58 - INFO - __main__ -   Batch number = 121
01/05/2022 21:51:59 - INFO - __main__ -   Batch number = 122
01/05/2022 21:51:59 - INFO - __main__ -   Batch number = 123
01/05/2022 21:51:59 - INFO - __main__ -   Batch number = 124
01/05/2022 21:51:59 - INFO - __main__ -   Batch number = 125
01/05/2022 21:52:00 - INFO - __main__ -   ***** Evaluation result 2000 in en *****
01/05/2022 21:52:00 - INFO - __main__ -     f1 = 0.9454856947061846
01/05/2022 21:52:00 - INFO - __main__ -     loss = 0.1450874671638012
01/05/2022 21:52:00 - INFO - __main__ -     precision = 0.9456315004883398
01/05/2022 21:52:00 - INFO - __main__ -     recall = 0.9453399338803337
01/05/2022 21:52:00 - INFO - __main__ -   result['f1']=0.9454856947061846 > best_score=0.9415200171269534
01/05/2022 21:52:00 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/checkpoint-best
01/05/2022 21:52:00 - INFO - __main__ -   Reset patience to 0
01/05/2022 21:55:26 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 21:55:26 - INFO - __main__ -   ***** Running evaluation 3000 in en *****
01/05/2022 21:55:26 - INFO - __main__ -     Num examples = 3974
01/05/2022 21:55:26 - INFO - __main__ -     Batch size = 32
01/05/2022 21:55:26 - INFO - __main__ -   Batch number = 1
01/05/2022 21:55:26 - INFO - __main__ -   Batch number = 2
01/05/2022 21:55:26 - INFO - __main__ -   Batch number = 3
01/05/2022 21:55:26 - INFO - __main__ -   Batch number = 4
01/05/2022 21:55:26 - INFO - __main__ -   Batch number = 5
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 6
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 7
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 8
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 9
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 10
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 11
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 12
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 13
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 14
01/05/2022 21:55:27 - INFO - __main__ -   Batch number = 15
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 16
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 17
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 18
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 19
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 20
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 21
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 22
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 23
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 24
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 25
01/05/2022 21:55:28 - INFO - __main__ -   Batch number = 26
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 27
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 28
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 29
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 30
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 31
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 32
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 33
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 34
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 35
01/05/2022 21:55:29 - INFO - __main__ -   Batch number = 36
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 37
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 38
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 39
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 40
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 41
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 42
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 43
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 44
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 45
01/05/2022 21:55:30 - INFO - __main__ -   Batch number = 46
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 47
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 48
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 49
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 50
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 51
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 52
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 53
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 54
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 55
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 56
01/05/2022 21:55:31 - INFO - __main__ -   Batch number = 57
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 58
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 59
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 60
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 61
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 62
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 63
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 64
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 65
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 66
01/05/2022 21:55:32 - INFO - __main__ -   Batch number = 67
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 68
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 69
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 70
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 71
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 72
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 73
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 74
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 75
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 76
01/05/2022 21:55:33 - INFO - __main__ -   Batch number = 77
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 78
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 79
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 80
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 81
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 82
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 83
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 84
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 85
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 86
01/05/2022 21:55:34 - INFO - __main__ -   Batch number = 87
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 88
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 89
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 90
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 91
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 92
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 93
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 94
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 95
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 96
01/05/2022 21:55:35 - INFO - __main__ -   Batch number = 97
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 98
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 99
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 100
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 101
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 102
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 103
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 104
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 105
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 106
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 107
01/05/2022 21:55:36 - INFO - __main__ -   Batch number = 108
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 109
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 110
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 111
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 112
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 113
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 114
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 115
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 116
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 117
01/05/2022 21:55:37 - INFO - __main__ -   Batch number = 118
01/05/2022 21:55:38 - INFO - __main__ -   Batch number = 119
01/05/2022 21:55:38 - INFO - __main__ -   Batch number = 120
01/05/2022 21:55:38 - INFO - __main__ -   Batch number = 121
01/05/2022 21:55:38 - INFO - __main__ -   Batch number = 122
01/05/2022 21:55:38 - INFO - __main__ -   Batch number = 123
01/05/2022 21:55:38 - INFO - __main__ -   Batch number = 124
01/05/2022 21:55:38 - INFO - __main__ -   Batch number = 125
01/05/2022 21:55:39 - INFO - __main__ -   ***** Evaluation result 3000 in en *****
01/05/2022 21:55:39 - INFO - __main__ -     f1 = 0.947473848208324
01/05/2022 21:55:39 - INFO - __main__ -     loss = 0.13995608195662498
01/05/2022 21:55:39 - INFO - __main__ -     precision = 0.9469874570064511
01/05/2022 21:55:39 - INFO - __main__ -     recall = 0.9479607393069426
01/05/2022 21:55:39 - INFO - __main__ -   result['f1']=0.947473848208324 > best_score=0.9454856947061846
01/05/2022 21:55:39 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/checkpoint-best
01/05/2022 21:55:39 - INFO - __main__ -   Reset patience to 0
01/05/2022 22:01:23 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:01:23 - INFO - __main__ -   ***** Running evaluation 4000 in en *****
01/05/2022 22:01:23 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:01:23 - INFO - __main__ -     Batch size = 32
01/05/2022 22:01:23 - INFO - __main__ -   Batch number = 1
01/05/2022 22:01:23 - INFO - __main__ -   Batch number = 2
01/05/2022 22:01:23 - INFO - __main__ -   Batch number = 3
01/05/2022 22:01:23 - INFO - __main__ -   Batch number = 4
01/05/2022 22:01:23 - INFO - __main__ -   Batch number = 5
01/05/2022 22:01:24 - INFO - __main__ -   Batch number = 6
01/05/2022 22:01:24 - INFO - __main__ -   Batch number = 7
01/05/2022 22:01:24 - INFO - __main__ -   Batch number = 8
01/05/2022 22:01:24 - INFO - __main__ -   Batch number = 9
01/05/2022 22:01:24 - INFO - __main__ -   Batch number = 10
01/05/2022 22:01:24 - INFO - __main__ -   Batch number = 11
01/05/2022 22:01:24 - INFO - __main__ -   Batch number = 12
01/05/2022 22:01:24 - INFO - __main__ -   Batch number = 13
01/05/2022 22:01:25 - INFO - __main__ -   Batch number = 14
01/05/2022 22:01:25 - INFO - __main__ -   Batch number = 15
01/05/2022 22:01:25 - INFO - __main__ -   Batch number = 16
01/05/2022 22:01:25 - INFO - __main__ -   Batch number = 17
01/05/2022 22:01:25 - INFO - __main__ -   Batch number = 18
01/05/2022 22:01:25 - INFO - __main__ -   Batch number = 19
01/05/2022 22:01:25 - INFO - __main__ -   Batch number = 20
01/05/2022 22:01:25 - INFO - __main__ -   Batch number = 21
01/05/2022 22:01:26 - INFO - __main__ -   Batch number = 22
01/05/2022 22:01:26 - INFO - __main__ -   Batch number = 23
01/05/2022 22:01:26 - INFO - __main__ -   Batch number = 24
01/05/2022 22:01:26 - INFO - __main__ -   Batch number = 25
01/05/2022 22:01:26 - INFO - __main__ -   Batch number = 26
01/05/2022 22:01:26 - INFO - __main__ -   Batch number = 27
01/05/2022 22:01:26 - INFO - __main__ -   Batch number = 28
01/05/2022 22:01:26 - INFO - __main__ -   Batch number = 29
01/05/2022 22:01:27 - INFO - __main__ -   Batch number = 30
01/05/2022 22:01:27 - INFO - __main__ -   Batch number = 31
01/05/2022 22:01:27 - INFO - __main__ -   Batch number = 32
01/05/2022 22:01:27 - INFO - __main__ -   Batch number = 33
01/05/2022 22:01:27 - INFO - __main__ -   Batch number = 34
01/05/2022 22:01:27 - INFO - __main__ -   Batch number = 35
01/05/2022 22:01:27 - INFO - __main__ -   Batch number = 36
01/05/2022 22:01:27 - INFO - __main__ -   Batch number = 37
01/05/2022 22:01:28 - INFO - __main__ -   Batch number = 38
01/05/2022 22:01:28 - INFO - __main__ -   Batch number = 39
01/05/2022 22:01:28 - INFO - __main__ -   Batch number = 40
01/05/2022 22:01:28 - INFO - __main__ -   Batch number = 41
01/05/2022 22:01:28 - INFO - __main__ -   Batch number = 42
01/05/2022 22:01:28 - INFO - __main__ -   Batch number = 43
01/05/2022 22:01:28 - INFO - __main__ -   Batch number = 44
01/05/2022 22:01:28 - INFO - __main__ -   Batch number = 45
01/05/2022 22:01:29 - INFO - __main__ -   Batch number = 46
01/05/2022 22:01:29 - INFO - __main__ -   Batch number = 47
01/05/2022 22:01:29 - INFO - __main__ -   Batch number = 48
01/05/2022 22:01:29 - INFO - __main__ -   Batch number = 49
01/05/2022 22:01:29 - INFO - __main__ -   Batch number = 50
01/05/2022 22:01:29 - INFO - __main__ -   Batch number = 51
01/05/2022 22:01:29 - INFO - __main__ -   Batch number = 52
01/05/2022 22:01:29 - INFO - __main__ -   Batch number = 53
01/05/2022 22:01:30 - INFO - __main__ -   Batch number = 54
01/05/2022 22:01:30 - INFO - __main__ -   Batch number = 55
01/05/2022 22:01:30 - INFO - __main__ -   Batch number = 56
01/05/2022 22:01:30 - INFO - __main__ -   Batch number = 57
01/05/2022 22:01:30 - INFO - __main__ -   Batch number = 58
01/05/2022 22:01:30 - INFO - __main__ -   Batch number = 59
01/05/2022 22:01:30 - INFO - __main__ -   Batch number = 60
01/05/2022 22:01:30 - INFO - __main__ -   Batch number = 61
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 62
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 63
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 64
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 65
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 66
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 67
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 68
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 69
01/05/2022 22:01:31 - INFO - __main__ -   Batch number = 70
01/05/2022 22:01:32 - INFO - __main__ -   Batch number = 71
01/05/2022 22:01:32 - INFO - __main__ -   Batch number = 72
01/05/2022 22:01:32 - INFO - __main__ -   Batch number = 73
01/05/2022 22:01:32 - INFO - __main__ -   Batch number = 74
01/05/2022 22:01:32 - INFO - __main__ -   Batch number = 75
01/05/2022 22:01:32 - INFO - __main__ -   Batch number = 76
01/05/2022 22:01:32 - INFO - __main__ -   Batch number = 77
01/05/2022 22:01:32 - INFO - __main__ -   Batch number = 78
01/05/2022 22:01:33 - INFO - __main__ -   Batch number = 79
01/05/2022 22:01:33 - INFO - __main__ -   Batch number = 80
01/05/2022 22:01:33 - INFO - __main__ -   Batch number = 81
01/05/2022 22:01:33 - INFO - __main__ -   Batch number = 82
01/05/2022 22:01:33 - INFO - __main__ -   Batch number = 83
01/05/2022 22:01:33 - INFO - __main__ -   Batch number = 84
01/05/2022 22:01:33 - INFO - __main__ -   Batch number = 85
01/05/2022 22:01:33 - INFO - __main__ -   Batch number = 86
01/05/2022 22:01:34 - INFO - __main__ -   Batch number = 87
01/05/2022 22:01:34 - INFO - __main__ -   Batch number = 88
01/05/2022 22:01:34 - INFO - __main__ -   Batch number = 89
01/05/2022 22:01:34 - INFO - __main__ -   Batch number = 90
01/05/2022 22:01:34 - INFO - __main__ -   Batch number = 91
01/05/2022 22:01:34 - INFO - __main__ -   Batch number = 92
01/05/2022 22:01:34 - INFO - __main__ -   Batch number = 93
01/05/2022 22:01:34 - INFO - __main__ -   Batch number = 94
01/05/2022 22:01:35 - INFO - __main__ -   Batch number = 95
01/05/2022 22:01:35 - INFO - __main__ -   Batch number = 96
01/05/2022 22:01:35 - INFO - __main__ -   Batch number = 97
01/05/2022 22:01:35 - INFO - __main__ -   Batch number = 98
01/05/2022 22:01:35 - INFO - __main__ -   Batch number = 99
01/05/2022 22:01:35 - INFO - __main__ -   Batch number = 100
01/05/2022 22:01:35 - INFO - __main__ -   Batch number = 101
01/05/2022 22:01:35 - INFO - __main__ -   Batch number = 102
01/05/2022 22:01:36 - INFO - __main__ -   Batch number = 103
01/05/2022 22:01:36 - INFO - __main__ -   Batch number = 104
01/05/2022 22:01:36 - INFO - __main__ -   Batch number = 105
01/05/2022 22:01:36 - INFO - __main__ -   Batch number = 106
01/05/2022 22:01:36 - INFO - __main__ -   Batch number = 107
01/05/2022 22:01:36 - INFO - __main__ -   Batch number = 108
01/05/2022 22:01:36 - INFO - __main__ -   Batch number = 109
01/05/2022 22:01:36 - INFO - __main__ -   Batch number = 110
01/05/2022 22:01:37 - INFO - __main__ -   Batch number = 111
01/05/2022 22:01:37 - INFO - __main__ -   Batch number = 112
01/05/2022 22:01:37 - INFO - __main__ -   Batch number = 113
01/05/2022 22:01:37 - INFO - __main__ -   Batch number = 114
01/05/2022 22:01:37 - INFO - __main__ -   Batch number = 115
01/05/2022 22:01:37 - INFO - __main__ -   Batch number = 116
01/05/2022 22:01:37 - INFO - __main__ -   Batch number = 117
01/05/2022 22:01:37 - INFO - __main__ -   Batch number = 118
01/05/2022 22:01:38 - INFO - __main__ -   Batch number = 119
01/05/2022 22:01:38 - INFO - __main__ -   Batch number = 120
01/05/2022 22:01:38 - INFO - __main__ -   Batch number = 121
01/05/2022 22:01:38 - INFO - __main__ -   Batch number = 122
01/05/2022 22:01:38 - INFO - __main__ -   Batch number = 123
01/05/2022 22:01:38 - INFO - __main__ -   Batch number = 124
01/05/2022 22:01:38 - INFO - __main__ -   Batch number = 125
01/05/2022 22:01:40 - INFO - __main__ -   ***** Evaluation result 4000 in en *****
01/05/2022 22:01:40 - INFO - __main__ -     f1 = 0.9487752846531472
01/05/2022 22:01:40 - INFO - __main__ -     loss = 0.13880804696679117
01/05/2022 22:01:40 - INFO - __main__ -     precision = 0.9490761372596072
01/05/2022 22:01:40 - INFO - __main__ -     recall = 0.9484746227239247
01/05/2022 22:01:40 - INFO - __main__ -   result['f1']=0.9487752846531472 > best_score=0.947473848208324
01/05/2022 22:01:40 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/checkpoint-best
01/05/2022 22:01:40 - INFO - __main__ -   Reset patience to 0
01/05/2022 22:07:34 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:07:34 - INFO - __main__ -   ***** Running evaluation 5000 in en *****
01/05/2022 22:07:34 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:07:34 - INFO - __main__ -     Batch size = 32
01/05/2022 22:07:34 - INFO - __main__ -   Batch number = 1
01/05/2022 22:07:34 - INFO - __main__ -   Batch number = 2
01/05/2022 22:07:34 - INFO - __main__ -   Batch number = 3
01/05/2022 22:07:34 - INFO - __main__ -   Batch number = 4
01/05/2022 22:07:34 - INFO - __main__ -   Batch number = 5
01/05/2022 22:07:34 - INFO - __main__ -   Batch number = 6
01/05/2022 22:07:35 - INFO - __main__ -   Batch number = 7
01/05/2022 22:07:35 - INFO - __main__ -   Batch number = 8
01/05/2022 22:07:35 - INFO - __main__ -   Batch number = 9
01/05/2022 22:07:35 - INFO - __main__ -   Batch number = 10
01/05/2022 22:07:35 - INFO - __main__ -   Batch number = 11
01/05/2022 22:07:35 - INFO - __main__ -   Batch number = 12
01/05/2022 22:07:35 - INFO - __main__ -   Batch number = 13
01/05/2022 22:07:35 - INFO - __main__ -   Batch number = 14
01/05/2022 22:07:36 - INFO - __main__ -   Batch number = 15
01/05/2022 22:07:36 - INFO - __main__ -   Batch number = 16
01/05/2022 22:07:36 - INFO - __main__ -   Batch number = 17
01/05/2022 22:07:36 - INFO - __main__ -   Batch number = 18
01/05/2022 22:07:36 - INFO - __main__ -   Batch number = 19
01/05/2022 22:07:36 - INFO - __main__ -   Batch number = 20
01/05/2022 22:07:36 - INFO - __main__ -   Batch number = 21
01/05/2022 22:07:36 - INFO - __main__ -   Batch number = 22
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 23
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 24
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 25
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 26
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 27
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 28
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 29
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 30
01/05/2022 22:07:37 - INFO - __main__ -   Batch number = 31
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 32
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 33
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 34
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 35
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 36
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 37
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 38
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 39
01/05/2022 22:07:38 - INFO - __main__ -   Batch number = 40
01/05/2022 22:07:39 - INFO - __main__ -   Batch number = 41
01/05/2022 22:07:39 - INFO - __main__ -   Batch number = 42
01/05/2022 22:07:39 - INFO - __main__ -   Batch number = 43
01/05/2022 22:07:39 - INFO - __main__ -   Batch number = 44
01/05/2022 22:07:39 - INFO - __main__ -   Batch number = 45
01/05/2022 22:07:39 - INFO - __main__ -   Batch number = 46
01/05/2022 22:07:39 - INFO - __main__ -   Batch number = 47
01/05/2022 22:07:39 - INFO - __main__ -   Batch number = 48
01/05/2022 22:07:40 - INFO - __main__ -   Batch number = 49
01/05/2022 22:07:40 - INFO - __main__ -   Batch number = 50
01/05/2022 22:07:40 - INFO - __main__ -   Batch number = 51
01/05/2022 22:07:40 - INFO - __main__ -   Batch number = 52
01/05/2022 22:07:40 - INFO - __main__ -   Batch number = 53
01/05/2022 22:07:40 - INFO - __main__ -   Batch number = 54
01/05/2022 22:07:40 - INFO - __main__ -   Batch number = 55
01/05/2022 22:07:40 - INFO - __main__ -   Batch number = 56
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 57
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 58
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 59
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 60
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 61
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 62
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 63
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 64
01/05/2022 22:07:41 - INFO - __main__ -   Batch number = 65
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 66
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 67
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 68
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 69
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 70
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 71
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 72
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 73
01/05/2022 22:07:42 - INFO - __main__ -   Batch number = 74
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 75
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 76
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 77
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 78
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 79
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 80
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 81
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 82
01/05/2022 22:07:43 - INFO - __main__ -   Batch number = 83
01/05/2022 22:07:44 - INFO - __main__ -   Batch number = 84
01/05/2022 22:07:44 - INFO - __main__ -   Batch number = 85
01/05/2022 22:07:44 - INFO - __main__ -   Batch number = 86
01/05/2022 22:07:44 - INFO - __main__ -   Batch number = 87
01/05/2022 22:07:44 - INFO - __main__ -   Batch number = 88
01/05/2022 22:07:44 - INFO - __main__ -   Batch number = 89
01/05/2022 22:07:44 - INFO - __main__ -   Batch number = 90
01/05/2022 22:07:44 - INFO - __main__ -   Batch number = 91
01/05/2022 22:07:45 - INFO - __main__ -   Batch number = 92
01/05/2022 22:07:45 - INFO - __main__ -   Batch number = 93
01/05/2022 22:07:45 - INFO - __main__ -   Batch number = 94
01/05/2022 22:07:45 - INFO - __main__ -   Batch number = 95
01/05/2022 22:07:45 - INFO - __main__ -   Batch number = 96
01/05/2022 22:07:45 - INFO - __main__ -   Batch number = 97
01/05/2022 22:07:45 - INFO - __main__ -   Batch number = 98
01/05/2022 22:07:45 - INFO - __main__ -   Batch number = 99
01/05/2022 22:07:46 - INFO - __main__ -   Batch number = 100
01/05/2022 22:07:46 - INFO - __main__ -   Batch number = 101
01/05/2022 22:07:46 - INFO - __main__ -   Batch number = 102
01/05/2022 22:07:46 - INFO - __main__ -   Batch number = 103
01/05/2022 22:07:46 - INFO - __main__ -   Batch number = 104
01/05/2022 22:07:46 - INFO - __main__ -   Batch number = 105
01/05/2022 22:07:46 - INFO - __main__ -   Batch number = 106
01/05/2022 22:07:46 - INFO - __main__ -   Batch number = 107
01/05/2022 22:07:47 - INFO - __main__ -   Batch number = 108
01/05/2022 22:07:47 - INFO - __main__ -   Batch number = 109
01/05/2022 22:07:47 - INFO - __main__ -   Batch number = 110
01/05/2022 22:07:47 - INFO - __main__ -   Batch number = 111
01/05/2022 22:07:47 - INFO - __main__ -   Batch number = 112
01/05/2022 22:07:47 - INFO - __main__ -   Batch number = 113
01/05/2022 22:07:47 - INFO - __main__ -   Batch number = 114
01/05/2022 22:07:47 - INFO - __main__ -   Batch number = 115
01/05/2022 22:07:48 - INFO - __main__ -   Batch number = 116
01/05/2022 22:07:48 - INFO - __main__ -   Batch number = 117
01/05/2022 22:07:48 - INFO - __main__ -   Batch number = 118
01/05/2022 22:07:48 - INFO - __main__ -   Batch number = 119
01/05/2022 22:07:48 - INFO - __main__ -   Batch number = 120
01/05/2022 22:07:48 - INFO - __main__ -   Batch number = 121
01/05/2022 22:07:48 - INFO - __main__ -   Batch number = 122
01/05/2022 22:07:49 - INFO - __main__ -   Batch number = 123
01/05/2022 22:07:49 - INFO - __main__ -   Batch number = 124
01/05/2022 22:07:49 - INFO - __main__ -   Batch number = 125
01/05/2022 22:07:50 - INFO - __main__ -   ***** Evaluation result 5000 in en *****
01/05/2022 22:07:50 - INFO - __main__ -     f1 = 0.9457660513128026
01/05/2022 22:07:50 - INFO - __main__ -     loss = 0.1475219424068928
01/05/2022 22:07:50 - INFO - __main__ -     precision = 0.9459524299129481
01/05/2022 22:07:50 - INFO - __main__ -     recall = 0.945579746141592
01/05/2022 22:07:50 - INFO - __main__ -   Hit patience=1
01/05/2022 22:13:41 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:13:41 - INFO - __main__ -   ***** Running evaluation 6000 in en *****
01/05/2022 22:13:41 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:13:41 - INFO - __main__ -     Batch size = 32
01/05/2022 22:13:41 - INFO - __main__ -   Batch number = 1
01/05/2022 22:13:41 - INFO - __main__ -   Batch number = 2
01/05/2022 22:13:42 - INFO - __main__ -   Batch number = 3
01/05/2022 22:13:42 - INFO - __main__ -   Batch number = 4
01/05/2022 22:13:42 - INFO - __main__ -   Batch number = 5
01/05/2022 22:13:42 - INFO - __main__ -   Batch number = 6
01/05/2022 22:13:42 - INFO - __main__ -   Batch number = 7
01/05/2022 22:13:42 - INFO - __main__ -   Batch number = 8
01/05/2022 22:13:42 - INFO - __main__ -   Batch number = 9
01/05/2022 22:13:42 - INFO - __main__ -   Batch number = 10
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 11
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 12
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 13
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 14
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 15
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 16
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 17
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 18
01/05/2022 22:13:43 - INFO - __main__ -   Batch number = 19
01/05/2022 22:13:44 - INFO - __main__ -   Batch number = 20
01/05/2022 22:13:44 - INFO - __main__ -   Batch number = 21
01/05/2022 22:13:44 - INFO - __main__ -   Batch number = 22
01/05/2022 22:13:44 - INFO - __main__ -   Batch number = 23
01/05/2022 22:13:44 - INFO - __main__ -   Batch number = 24
01/05/2022 22:13:44 - INFO - __main__ -   Batch number = 25
01/05/2022 22:13:44 - INFO - __main__ -   Batch number = 26
01/05/2022 22:13:44 - INFO - __main__ -   Batch number = 27
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 28
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 29
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 30
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 31
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 32
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 33
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 34
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 35
01/05/2022 22:13:45 - INFO - __main__ -   Batch number = 36
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 37
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 38
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 39
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 40
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 41
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 42
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 43
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 44
01/05/2022 22:13:46 - INFO - __main__ -   Batch number = 45
01/05/2022 22:13:47 - INFO - __main__ -   Batch number = 46
01/05/2022 22:13:47 - INFO - __main__ -   Batch number = 47
01/05/2022 22:13:47 - INFO - __main__ -   Batch number = 48
01/05/2022 22:13:47 - INFO - __main__ -   Batch number = 49
01/05/2022 22:13:47 - INFO - __main__ -   Batch number = 50
01/05/2022 22:13:47 - INFO - __main__ -   Batch number = 51
01/05/2022 22:13:47 - INFO - __main__ -   Batch number = 52
01/05/2022 22:13:47 - INFO - __main__ -   Batch number = 53
01/05/2022 22:13:48 - INFO - __main__ -   Batch number = 54
01/05/2022 22:13:48 - INFO - __main__ -   Batch number = 55
01/05/2022 22:13:48 - INFO - __main__ -   Batch number = 56
01/05/2022 22:13:48 - INFO - __main__ -   Batch number = 57
01/05/2022 22:13:48 - INFO - __main__ -   Batch number = 58
01/05/2022 22:13:48 - INFO - __main__ -   Batch number = 59
01/05/2022 22:13:48 - INFO - __main__ -   Batch number = 60
01/05/2022 22:13:48 - INFO - __main__ -   Batch number = 61
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 62
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 63
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 64
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 65
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 66
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 67
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 68
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 69
01/05/2022 22:13:49 - INFO - __main__ -   Batch number = 70
01/05/2022 22:13:50 - INFO - __main__ -   Batch number = 71
01/05/2022 22:13:50 - INFO - __main__ -   Batch number = 72
01/05/2022 22:13:50 - INFO - __main__ -   Batch number = 73
01/05/2022 22:13:50 - INFO - __main__ -   Batch number = 74
01/05/2022 22:13:50 - INFO - __main__ -   Batch number = 75
01/05/2022 22:13:50 - INFO - __main__ -   Batch number = 76
01/05/2022 22:13:50 - INFO - __main__ -   Batch number = 77
01/05/2022 22:13:50 - INFO - __main__ -   Batch number = 78
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 79
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 80
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 81
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 82
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 83
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 84
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 85
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 86
01/05/2022 22:13:51 - INFO - __main__ -   Batch number = 87
01/05/2022 22:13:52 - INFO - __main__ -   Batch number = 88
01/05/2022 22:13:52 - INFO - __main__ -   Batch number = 89
01/05/2022 22:13:52 - INFO - __main__ -   Batch number = 90
01/05/2022 22:13:52 - INFO - __main__ -   Batch number = 91
01/05/2022 22:13:52 - INFO - __main__ -   Batch number = 92
01/05/2022 22:13:52 - INFO - __main__ -   Batch number = 93
01/05/2022 22:13:52 - INFO - __main__ -   Batch number = 94
01/05/2022 22:13:52 - INFO - __main__ -   Batch number = 95
01/05/2022 22:13:53 - INFO - __main__ -   Batch number = 96
01/05/2022 22:13:53 - INFO - __main__ -   Batch number = 97
01/05/2022 22:13:53 - INFO - __main__ -   Batch number = 98
01/05/2022 22:13:53 - INFO - __main__ -   Batch number = 99
01/05/2022 22:13:53 - INFO - __main__ -   Batch number = 100
01/05/2022 22:13:53 - INFO - __main__ -   Batch number = 101
01/05/2022 22:13:53 - INFO - __main__ -   Batch number = 102
01/05/2022 22:13:53 - INFO - __main__ -   Batch number = 103
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 104
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 105
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 106
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 107
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 108
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 109
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 110
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 111
01/05/2022 22:13:54 - INFO - __main__ -   Batch number = 112
01/05/2022 22:13:55 - INFO - __main__ -   Batch number = 113
01/05/2022 22:13:55 - INFO - __main__ -   Batch number = 114
01/05/2022 22:13:55 - INFO - __main__ -   Batch number = 115
01/05/2022 22:13:55 - INFO - __main__ -   Batch number = 116
01/05/2022 22:13:55 - INFO - __main__ -   Batch number = 117
01/05/2022 22:13:55 - INFO - __main__ -   Batch number = 118
01/05/2022 22:13:55 - INFO - __main__ -   Batch number = 119
01/05/2022 22:13:55 - INFO - __main__ -   Batch number = 120
01/05/2022 22:13:56 - INFO - __main__ -   Batch number = 121
01/05/2022 22:13:56 - INFO - __main__ -   Batch number = 122
01/05/2022 22:13:56 - INFO - __main__ -   Batch number = 123
01/05/2022 22:13:56 - INFO - __main__ -   Batch number = 124
01/05/2022 22:13:56 - INFO - __main__ -   Batch number = 125
01/05/2022 22:13:57 - INFO - __main__ -   ***** Evaluation result 6000 in en *****
01/05/2022 22:13:57 - INFO - __main__ -     f1 = 0.9488459726801696
01/05/2022 22:13:57 - INFO - __main__ -     loss = 0.14593491405248643
01/05/2022 22:13:57 - INFO - __main__ -     precision = 0.9487890932757853
01/05/2022 22:13:57 - INFO - __main__ -     recall = 0.9489028589047431
01/05/2022 22:13:57 - INFO - __main__ -   result['f1']=0.9488459726801696 > best_score=0.9487752846531472
01/05/2022 22:13:57 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/checkpoint-best
01/05/2022 22:13:57 - INFO - __main__ -   Reset patience to 0
01/05/2022 22:19:48 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:19:48 - INFO - __main__ -   ***** Running evaluation 7000 in en *****
01/05/2022 22:19:48 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:19:48 - INFO - __main__ -     Batch size = 32
01/05/2022 22:19:48 - INFO - __main__ -   Batch number = 1
01/05/2022 22:19:48 - INFO - __main__ -   Batch number = 2
01/05/2022 22:19:48 - INFO - __main__ -   Batch number = 3
01/05/2022 22:19:48 - INFO - __main__ -   Batch number = 4
01/05/2022 22:19:48 - INFO - __main__ -   Batch number = 5
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 6
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 7
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 8
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 9
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 10
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 11
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 12
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 13
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 14
01/05/2022 22:19:49 - INFO - __main__ -   Batch number = 15
01/05/2022 22:19:50 - INFO - __main__ -   Batch number = 16
01/05/2022 22:19:50 - INFO - __main__ -   Batch number = 17
01/05/2022 22:19:50 - INFO - __main__ -   Batch number = 18
01/05/2022 22:19:50 - INFO - __main__ -   Batch number = 19
01/05/2022 22:19:50 - INFO - __main__ -   Batch number = 20
01/05/2022 22:19:50 - INFO - __main__ -   Batch number = 21
01/05/2022 22:19:50 - INFO - __main__ -   Batch number = 22
01/05/2022 22:19:50 - INFO - __main__ -   Batch number = 23
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 24
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 25
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 26
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 27
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 28
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 29
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 30
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 31
01/05/2022 22:19:51 - INFO - __main__ -   Batch number = 32
01/05/2022 22:19:52 - INFO - __main__ -   Batch number = 33
01/05/2022 22:19:52 - INFO - __main__ -   Batch number = 34
01/05/2022 22:19:52 - INFO - __main__ -   Batch number = 35
01/05/2022 22:19:52 - INFO - __main__ -   Batch number = 36
01/05/2022 22:19:52 - INFO - __main__ -   Batch number = 37
01/05/2022 22:19:52 - INFO - __main__ -   Batch number = 38
01/05/2022 22:19:52 - INFO - __main__ -   Batch number = 39
01/05/2022 22:19:52 - INFO - __main__ -   Batch number = 40
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 41
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 42
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 43
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 44
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 45
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 46
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 47
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 48
01/05/2022 22:19:53 - INFO - __main__ -   Batch number = 49
01/05/2022 22:19:54 - INFO - __main__ -   Batch number = 50
01/05/2022 22:19:54 - INFO - __main__ -   Batch number = 51
01/05/2022 22:19:54 - INFO - __main__ -   Batch number = 52
01/05/2022 22:19:54 - INFO - __main__ -   Batch number = 53
01/05/2022 22:19:54 - INFO - __main__ -   Batch number = 54
01/05/2022 22:19:54 - INFO - __main__ -   Batch number = 55
01/05/2022 22:19:54 - INFO - __main__ -   Batch number = 56
01/05/2022 22:19:54 - INFO - __main__ -   Batch number = 57
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 58
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 59
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 60
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 61
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 62
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 63
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 64
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 65
01/05/2022 22:19:55 - INFO - __main__ -   Batch number = 66
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 67
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 68
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 69
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 70
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 71
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 72
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 73
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 74
01/05/2022 22:19:56 - INFO - __main__ -   Batch number = 75
01/05/2022 22:19:57 - INFO - __main__ -   Batch number = 76
01/05/2022 22:19:57 - INFO - __main__ -   Batch number = 77
01/05/2022 22:19:57 - INFO - __main__ -   Batch number = 78
01/05/2022 22:19:57 - INFO - __main__ -   Batch number = 79
01/05/2022 22:19:57 - INFO - __main__ -   Batch number = 80
01/05/2022 22:19:57 - INFO - __main__ -   Batch number = 81
01/05/2022 22:19:57 - INFO - __main__ -   Batch number = 82
01/05/2022 22:19:57 - INFO - __main__ -   Batch number = 83
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 84
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 85
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 86
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 87
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 88
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 89
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 90
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 91
01/05/2022 22:19:58 - INFO - __main__ -   Batch number = 92
01/05/2022 22:19:59 - INFO - __main__ -   Batch number = 93
01/05/2022 22:19:59 - INFO - __main__ -   Batch number = 94
01/05/2022 22:19:59 - INFO - __main__ -   Batch number = 95
01/05/2022 22:19:59 - INFO - __main__ -   Batch number = 96
01/05/2022 22:19:59 - INFO - __main__ -   Batch number = 97
01/05/2022 22:19:59 - INFO - __main__ -   Batch number = 98
01/05/2022 22:19:59 - INFO - __main__ -   Batch number = 99
01/05/2022 22:19:59 - INFO - __main__ -   Batch number = 100
01/05/2022 22:20:00 - INFO - __main__ -   Batch number = 101
01/05/2022 22:20:00 - INFO - __main__ -   Batch number = 102
01/05/2022 22:20:00 - INFO - __main__ -   Batch number = 103
01/05/2022 22:20:00 - INFO - __main__ -   Batch number = 104
01/05/2022 22:20:00 - INFO - __main__ -   Batch number = 105
01/05/2022 22:20:00 - INFO - __main__ -   Batch number = 106
01/05/2022 22:20:00 - INFO - __main__ -   Batch number = 107
01/05/2022 22:20:00 - INFO - __main__ -   Batch number = 108
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 109
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 110
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 111
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 112
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 113
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 114
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 115
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 116
01/05/2022 22:20:01 - INFO - __main__ -   Batch number = 117
01/05/2022 22:20:02 - INFO - __main__ -   Batch number = 118
01/05/2022 22:20:02 - INFO - __main__ -   Batch number = 119
01/05/2022 22:20:02 - INFO - __main__ -   Batch number = 120
01/05/2022 22:20:02 - INFO - __main__ -   Batch number = 121
01/05/2022 22:20:02 - INFO - __main__ -   Batch number = 122
01/05/2022 22:20:02 - INFO - __main__ -   Batch number = 123
01/05/2022 22:20:02 - INFO - __main__ -   Batch number = 124
01/05/2022 22:20:02 - INFO - __main__ -   Batch number = 125
01/05/2022 22:20:04 - INFO - __main__ -   ***** Evaluation result 7000 in en *****
01/05/2022 22:20:04 - INFO - __main__ -     f1 = 0.9485631076277357
01/05/2022 22:20:04 - INFO - __main__ -     loss = 0.15544613137841223
01/05/2022 22:20:04 - INFO - __main__ -     precision = 0.9486687455025186
01/05/2022 22:20:04 - INFO - __main__ -     recall = 0.9484574932766919
01/05/2022 22:20:04 - INFO - __main__ -   Hit patience=1
01/05/2022 22:25:55 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:25:56 - INFO - __main__ -   ***** Running evaluation 8000 in en *****
01/05/2022 22:25:56 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:25:56 - INFO - __main__ -     Batch size = 32
01/05/2022 22:25:56 - INFO - __main__ -   Batch number = 1
01/05/2022 22:25:56 - INFO - __main__ -   Batch number = 2
01/05/2022 22:25:56 - INFO - __main__ -   Batch number = 3
01/05/2022 22:25:56 - INFO - __main__ -   Batch number = 4
01/05/2022 22:25:56 - INFO - __main__ -   Batch number = 5
01/05/2022 22:25:56 - INFO - __main__ -   Batch number = 6
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 7
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 8
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 9
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 10
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 11
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 12
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 13
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 14
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 15
01/05/2022 22:25:57 - INFO - __main__ -   Batch number = 16
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 17
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 18
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 19
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 20
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 21
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 22
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 23
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 24
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 25
01/05/2022 22:25:58 - INFO - __main__ -   Batch number = 26
01/05/2022 22:25:59 - INFO - __main__ -   Batch number = 27
01/05/2022 22:25:59 - INFO - __main__ -   Batch number = 28
01/05/2022 22:25:59 - INFO - __main__ -   Batch number = 29
01/05/2022 22:25:59 - INFO - __main__ -   Batch number = 30
01/05/2022 22:25:59 - INFO - __main__ -   Batch number = 31
01/05/2022 22:25:59 - INFO - __main__ -   Batch number = 32
01/05/2022 22:25:59 - INFO - __main__ -   Batch number = 33
01/05/2022 22:25:59 - INFO - __main__ -   Batch number = 34
01/05/2022 22:26:00 - INFO - __main__ -   Batch number = 35
01/05/2022 22:26:00 - INFO - __main__ -   Batch number = 36
01/05/2022 22:26:00 - INFO - __main__ -   Batch number = 37
01/05/2022 22:26:00 - INFO - __main__ -   Batch number = 38
01/05/2022 22:26:00 - INFO - __main__ -   Batch number = 39
01/05/2022 22:26:00 - INFO - __main__ -   Batch number = 40
01/05/2022 22:26:00 - INFO - __main__ -   Batch number = 41
01/05/2022 22:26:00 - INFO - __main__ -   Batch number = 42
01/05/2022 22:26:01 - INFO - __main__ -   Batch number = 43
01/05/2022 22:26:01 - INFO - __main__ -   Batch number = 44
01/05/2022 22:26:01 - INFO - __main__ -   Batch number = 45
01/05/2022 22:26:01 - INFO - __main__ -   Batch number = 46
01/05/2022 22:26:01 - INFO - __main__ -   Batch number = 47
01/05/2022 22:26:01 - INFO - __main__ -   Batch number = 48
01/05/2022 22:26:01 - INFO - __main__ -   Batch number = 49
01/05/2022 22:26:01 - INFO - __main__ -   Batch number = 50
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 51
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 52
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 53
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 54
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 55
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 56
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 57
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 58
01/05/2022 22:26:02 - INFO - __main__ -   Batch number = 59
01/05/2022 22:26:03 - INFO - __main__ -   Batch number = 60
01/05/2022 22:26:03 - INFO - __main__ -   Batch number = 61
01/05/2022 22:26:03 - INFO - __main__ -   Batch number = 62
01/05/2022 22:26:03 - INFO - __main__ -   Batch number = 63
01/05/2022 22:26:03 - INFO - __main__ -   Batch number = 64
01/05/2022 22:26:03 - INFO - __main__ -   Batch number = 65
01/05/2022 22:26:03 - INFO - __main__ -   Batch number = 66
01/05/2022 22:26:03 - INFO - __main__ -   Batch number = 67
01/05/2022 22:26:04 - INFO - __main__ -   Batch number = 68
01/05/2022 22:26:04 - INFO - __main__ -   Batch number = 69
01/05/2022 22:26:04 - INFO - __main__ -   Batch number = 70
01/05/2022 22:26:04 - INFO - __main__ -   Batch number = 71
01/05/2022 22:26:04 - INFO - __main__ -   Batch number = 72
01/05/2022 22:26:04 - INFO - __main__ -   Batch number = 73
01/05/2022 22:26:04 - INFO - __main__ -   Batch number = 74
01/05/2022 22:26:04 - INFO - __main__ -   Batch number = 75
01/05/2022 22:26:05 - INFO - __main__ -   Batch number = 76
01/05/2022 22:26:05 - INFO - __main__ -   Batch number = 77
01/05/2022 22:26:05 - INFO - __main__ -   Batch number = 78
01/05/2022 22:26:05 - INFO - __main__ -   Batch number = 79
01/05/2022 22:26:05 - INFO - __main__ -   Batch number = 80
01/05/2022 22:26:05 - INFO - __main__ -   Batch number = 81
01/05/2022 22:26:05 - INFO - __main__ -   Batch number = 82
01/05/2022 22:26:05 - INFO - __main__ -   Batch number = 83
01/05/2022 22:26:06 - INFO - __main__ -   Batch number = 84
01/05/2022 22:26:06 - INFO - __main__ -   Batch number = 85
01/05/2022 22:26:06 - INFO - __main__ -   Batch number = 86
01/05/2022 22:26:06 - INFO - __main__ -   Batch number = 87
01/05/2022 22:26:06 - INFO - __main__ -   Batch number = 88
01/05/2022 22:26:06 - INFO - __main__ -   Batch number = 89
01/05/2022 22:26:06 - INFO - __main__ -   Batch number = 90
01/05/2022 22:26:06 - INFO - __main__ -   Batch number = 91
01/05/2022 22:26:07 - INFO - __main__ -   Batch number = 92
01/05/2022 22:26:07 - INFO - __main__ -   Batch number = 93
01/05/2022 22:26:07 - INFO - __main__ -   Batch number = 94
01/05/2022 22:26:07 - INFO - __main__ -   Batch number = 95
01/05/2022 22:26:07 - INFO - __main__ -   Batch number = 96
01/05/2022 22:26:07 - INFO - __main__ -   Batch number = 97
01/05/2022 22:26:07 - INFO - __main__ -   Batch number = 98
01/05/2022 22:26:07 - INFO - __main__ -   Batch number = 99
01/05/2022 22:26:08 - INFO - __main__ -   Batch number = 100
01/05/2022 22:26:08 - INFO - __main__ -   Batch number = 101
01/05/2022 22:26:08 - INFO - __main__ -   Batch number = 102
01/05/2022 22:26:08 - INFO - __main__ -   Batch number = 103
01/05/2022 22:26:08 - INFO - __main__ -   Batch number = 104
01/05/2022 22:26:08 - INFO - __main__ -   Batch number = 105
01/05/2022 22:26:08 - INFO - __main__ -   Batch number = 106
01/05/2022 22:26:08 - INFO - __main__ -   Batch number = 107
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 108
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 109
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 110
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 111
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 112
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 113
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 114
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 115
01/05/2022 22:26:09 - INFO - __main__ -   Batch number = 116
01/05/2022 22:26:10 - INFO - __main__ -   Batch number = 117
01/05/2022 22:26:10 - INFO - __main__ -   Batch number = 118
01/05/2022 22:26:10 - INFO - __main__ -   Batch number = 119
01/05/2022 22:26:10 - INFO - __main__ -   Batch number = 120
01/05/2022 22:26:10 - INFO - __main__ -   Batch number = 121
01/05/2022 22:26:10 - INFO - __main__ -   Batch number = 122
01/05/2022 22:26:10 - INFO - __main__ -   Batch number = 123
01/05/2022 22:26:10 - INFO - __main__ -   Batch number = 124
01/05/2022 22:26:11 - INFO - __main__ -   Batch number = 125
01/05/2022 22:26:12 - INFO - __main__ -   ***** Evaluation result 8000 in en *****
01/05/2022 22:26:12 - INFO - __main__ -     f1 = 0.9484511360619374
01/05/2022 22:26:12 - INFO - __main__ -     loss = 0.15868354004621504
01/05/2022 22:26:12 - INFO - __main__ -     precision = 0.948410523431077
01/05/2022 22:26:12 - INFO - __main__ -     recall = 0.9484917521711574
01/05/2022 22:26:12 - INFO - __main__ -   Hit patience=2
01/05/2022 22:32:07 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:32:07 - INFO - __main__ -   ***** Running evaluation 9000 in en *****
01/05/2022 22:32:07 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:32:07 - INFO - __main__ -     Batch size = 32
01/05/2022 22:32:07 - INFO - __main__ -   Batch number = 1
01/05/2022 22:32:07 - INFO - __main__ -   Batch number = 2
01/05/2022 22:32:07 - INFO - __main__ -   Batch number = 3
01/05/2022 22:32:07 - INFO - __main__ -   Batch number = 4
01/05/2022 22:32:07 - INFO - __main__ -   Batch number = 5
01/05/2022 22:32:08 - INFO - __main__ -   Batch number = 6
01/05/2022 22:32:08 - INFO - __main__ -   Batch number = 7
01/05/2022 22:32:08 - INFO - __main__ -   Batch number = 8
01/05/2022 22:32:08 - INFO - __main__ -   Batch number = 9
01/05/2022 22:32:08 - INFO - __main__ -   Batch number = 10
01/05/2022 22:32:08 - INFO - __main__ -   Batch number = 11
01/05/2022 22:32:08 - INFO - __main__ -   Batch number = 12
01/05/2022 22:32:08 - INFO - __main__ -   Batch number = 13
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 14
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 15
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 16
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 17
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 18
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 19
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 20
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 21
01/05/2022 22:32:09 - INFO - __main__ -   Batch number = 22
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 23
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 24
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 25
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 26
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 27
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 28
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 29
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 30
01/05/2022 22:32:10 - INFO - __main__ -   Batch number = 31
01/05/2022 22:32:11 - INFO - __main__ -   Batch number = 32
01/05/2022 22:32:11 - INFO - __main__ -   Batch number = 33
01/05/2022 22:32:11 - INFO - __main__ -   Batch number = 34
01/05/2022 22:32:11 - INFO - __main__ -   Batch number = 35
01/05/2022 22:32:11 - INFO - __main__ -   Batch number = 36
01/05/2022 22:32:11 - INFO - __main__ -   Batch number = 37
01/05/2022 22:32:11 - INFO - __main__ -   Batch number = 38
01/05/2022 22:32:11 - INFO - __main__ -   Batch number = 39
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 40
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 41
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 42
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 43
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 44
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 45
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 46
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 47
01/05/2022 22:32:12 - INFO - __main__ -   Batch number = 48
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 49
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 50
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 51
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 52
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 53
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 54
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 55
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 56
01/05/2022 22:32:13 - INFO - __main__ -   Batch number = 57
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 58
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 59
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 60
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 61
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 62
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 63
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 64
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 65
01/05/2022 22:32:14 - INFO - __main__ -   Batch number = 66
01/05/2022 22:32:15 - INFO - __main__ -   Batch number = 67
01/05/2022 22:32:15 - INFO - __main__ -   Batch number = 68
01/05/2022 22:32:15 - INFO - __main__ -   Batch number = 69
01/05/2022 22:32:15 - INFO - __main__ -   Batch number = 70
01/05/2022 22:32:15 - INFO - __main__ -   Batch number = 71
01/05/2022 22:32:15 - INFO - __main__ -   Batch number = 72
01/05/2022 22:32:15 - INFO - __main__ -   Batch number = 73
01/05/2022 22:32:15 - INFO - __main__ -   Batch number = 74
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 75
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 76
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 77
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 78
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 79
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 80
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 81
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 82
01/05/2022 22:32:16 - INFO - __main__ -   Batch number = 83
01/05/2022 22:32:17 - INFO - __main__ -   Batch number = 84
01/05/2022 22:32:17 - INFO - __main__ -   Batch number = 85
01/05/2022 22:32:17 - INFO - __main__ -   Batch number = 86
01/05/2022 22:32:17 - INFO - __main__ -   Batch number = 87
01/05/2022 22:32:17 - INFO - __main__ -   Batch number = 88
01/05/2022 22:32:17 - INFO - __main__ -   Batch number = 89
01/05/2022 22:32:17 - INFO - __main__ -   Batch number = 90
01/05/2022 22:32:17 - INFO - __main__ -   Batch number = 91
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 92
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 93
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 94
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 95
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 96
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 97
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 98
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 99
01/05/2022 22:32:18 - INFO - __main__ -   Batch number = 100
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 101
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 102
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 103
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 104
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 105
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 106
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 107
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 108
01/05/2022 22:32:19 - INFO - __main__ -   Batch number = 109
01/05/2022 22:32:20 - INFO - __main__ -   Batch number = 110
01/05/2022 22:32:20 - INFO - __main__ -   Batch number = 111
01/05/2022 22:32:20 - INFO - __main__ -   Batch number = 112
01/05/2022 22:32:20 - INFO - __main__ -   Batch number = 113
01/05/2022 22:32:20 - INFO - __main__ -   Batch number = 114
01/05/2022 22:32:20 - INFO - __main__ -   Batch number = 115
01/05/2022 22:32:20 - INFO - __main__ -   Batch number = 116
01/05/2022 22:32:20 - INFO - __main__ -   Batch number = 117
01/05/2022 22:32:21 - INFO - __main__ -   Batch number = 118
01/05/2022 22:32:21 - INFO - __main__ -   Batch number = 119
01/05/2022 22:32:21 - INFO - __main__ -   Batch number = 120
01/05/2022 22:32:21 - INFO - __main__ -   Batch number = 121
01/05/2022 22:32:21 - INFO - __main__ -   Batch number = 122
01/05/2022 22:32:21 - INFO - __main__ -   Batch number = 123
01/05/2022 22:32:21 - INFO - __main__ -   Batch number = 124
01/05/2022 22:32:21 - INFO - __main__ -   Batch number = 125
01/05/2022 22:32:23 - INFO - __main__ -   ***** Evaluation result 9000 in en *****
01/05/2022 22:32:23 - INFO - __main__ -     f1 = 0.9468525357072477
01/05/2022 22:32:23 - INFO - __main__ -     loss = 0.17875667691230773
01/05/2022 22:32:23 - INFO - __main__ -     precision = 0.9472177460829019
01/05/2022 22:32:23 - INFO - __main__ -     recall = 0.9464876068449272
01/05/2022 22:32:23 - INFO - __main__ -   Hit patience=3
01/05/2022 22:38:29 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:38:30 - INFO - __main__ -   ***** Running evaluation 10000 in en *****
01/05/2022 22:38:30 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:38:30 - INFO - __main__ -     Batch size = 32
01/05/2022 22:38:30 - INFO - __main__ -   Batch number = 1
01/05/2022 22:38:30 - INFO - __main__ -   Batch number = 2
01/05/2022 22:38:30 - INFO - __main__ -   Batch number = 3
01/05/2022 22:38:30 - INFO - __main__ -   Batch number = 4
01/05/2022 22:38:30 - INFO - __main__ -   Batch number = 5
01/05/2022 22:38:30 - INFO - __main__ -   Batch number = 6
01/05/2022 22:38:30 - INFO - __main__ -   Batch number = 7
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 8
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 9
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 10
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 11
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 12
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 13
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 14
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 15
01/05/2022 22:38:31 - INFO - __main__ -   Batch number = 16
01/05/2022 22:38:32 - INFO - __main__ -   Batch number = 17
01/05/2022 22:38:32 - INFO - __main__ -   Batch number = 18
01/05/2022 22:38:32 - INFO - __main__ -   Batch number = 19
01/05/2022 22:38:32 - INFO - __main__ -   Batch number = 20
01/05/2022 22:38:32 - INFO - __main__ -   Batch number = 21
01/05/2022 22:38:32 - INFO - __main__ -   Batch number = 22
01/05/2022 22:38:32 - INFO - __main__ -   Batch number = 23
01/05/2022 22:38:32 - INFO - __main__ -   Batch number = 24
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 25
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 26
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 27
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 28
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 29
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 30
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 31
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 32
01/05/2022 22:38:33 - INFO - __main__ -   Batch number = 33
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 34
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 35
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 36
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 37
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 38
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 39
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 40
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 41
01/05/2022 22:38:34 - INFO - __main__ -   Batch number = 42
01/05/2022 22:38:35 - INFO - __main__ -   Batch number = 43
01/05/2022 22:38:35 - INFO - __main__ -   Batch number = 44
01/05/2022 22:38:35 - INFO - __main__ -   Batch number = 45
01/05/2022 22:38:35 - INFO - __main__ -   Batch number = 46
01/05/2022 22:38:35 - INFO - __main__ -   Batch number = 47
01/05/2022 22:38:35 - INFO - __main__ -   Batch number = 48
01/05/2022 22:38:35 - INFO - __main__ -   Batch number = 49
01/05/2022 22:38:35 - INFO - __main__ -   Batch number = 50
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 51
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 52
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 53
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 54
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 55
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 56
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 57
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 58
01/05/2022 22:38:36 - INFO - __main__ -   Batch number = 59
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 60
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 61
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 62
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 63
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 64
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 65
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 66
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 67
01/05/2022 22:38:37 - INFO - __main__ -   Batch number = 68
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 69
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 70
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 71
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 72
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 73
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 74
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 75
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 76
01/05/2022 22:38:38 - INFO - __main__ -   Batch number = 77
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 78
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 79
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 80
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 81
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 82
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 83
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 84
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 85
01/05/2022 22:38:39 - INFO - __main__ -   Batch number = 86
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 87
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 88
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 89
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 90
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 91
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 92
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 93
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 94
01/05/2022 22:38:40 - INFO - __main__ -   Batch number = 95
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 96
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 97
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 98
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 99
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 100
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 101
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 102
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 103
01/05/2022 22:38:41 - INFO - __main__ -   Batch number = 104
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 105
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 106
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 107
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 108
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 109
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 110
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 111
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 112
01/05/2022 22:38:42 - INFO - __main__ -   Batch number = 113
01/05/2022 22:38:43 - INFO - __main__ -   Batch number = 114
01/05/2022 22:38:43 - INFO - __main__ -   Batch number = 115
01/05/2022 22:38:43 - INFO - __main__ -   Batch number = 116
01/05/2022 22:38:43 - INFO - __main__ -   Batch number = 117
01/05/2022 22:38:43 - INFO - __main__ -   Batch number = 118
01/05/2022 22:38:43 - INFO - __main__ -   Batch number = 119
01/05/2022 22:38:43 - INFO - __main__ -   Batch number = 120
01/05/2022 22:38:43 - INFO - __main__ -   Batch number = 121
01/05/2022 22:38:44 - INFO - __main__ -   Batch number = 122
01/05/2022 22:38:44 - INFO - __main__ -   Batch number = 123
01/05/2022 22:38:44 - INFO - __main__ -   Batch number = 124
01/05/2022 22:38:44 - INFO - __main__ -   Batch number = 125
01/05/2022 22:38:45 - INFO - __main__ -   ***** Evaluation result 10000 in en *****
01/05/2022 22:38:45 - INFO - __main__ -     f1 = 0.9475081122269883
01/05/2022 22:38:45 - INFO - __main__ -     loss = 0.18827504116296767
01/05/2022 22:38:45 - INFO - __main__ -     precision = 0.9471756247860322
01/05/2022 22:38:45 - INFO - __main__ -     recall = 0.9478408331763134
01/05/2022 22:38:45 - INFO - __main__ -   Hit patience=4
01/05/2022 22:44:49 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:44:49 - INFO - __main__ -   ***** Running evaluation 11000 in en *****
01/05/2022 22:44:49 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:44:49 - INFO - __main__ -     Batch size = 32
01/05/2022 22:44:49 - INFO - __main__ -   Batch number = 1
01/05/2022 22:44:49 - INFO - __main__ -   Batch number = 2
01/05/2022 22:44:49 - INFO - __main__ -   Batch number = 3
01/05/2022 22:44:49 - INFO - __main__ -   Batch number = 4
01/05/2022 22:44:50 - INFO - __main__ -   Batch number = 5
01/05/2022 22:44:50 - INFO - __main__ -   Batch number = 6
01/05/2022 22:44:50 - INFO - __main__ -   Batch number = 7
01/05/2022 22:44:50 - INFO - __main__ -   Batch number = 8
01/05/2022 22:44:50 - INFO - __main__ -   Batch number = 9
01/05/2022 22:44:50 - INFO - __main__ -   Batch number = 10
01/05/2022 22:44:50 - INFO - __main__ -   Batch number = 11
01/05/2022 22:44:50 - INFO - __main__ -   Batch number = 12
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 13
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 14
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 15
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 16
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 17
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 18
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 19
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 20
01/05/2022 22:44:51 - INFO - __main__ -   Batch number = 21
01/05/2022 22:44:52 - INFO - __main__ -   Batch number = 22
01/05/2022 22:44:52 - INFO - __main__ -   Batch number = 23
01/05/2022 22:44:52 - INFO - __main__ -   Batch number = 24
01/05/2022 22:44:52 - INFO - __main__ -   Batch number = 25
01/05/2022 22:44:52 - INFO - __main__ -   Batch number = 26
01/05/2022 22:44:52 - INFO - __main__ -   Batch number = 27
01/05/2022 22:44:52 - INFO - __main__ -   Batch number = 28
01/05/2022 22:44:52 - INFO - __main__ -   Batch number = 29
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 30
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 31
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 32
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 33
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 34
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 35
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 36
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 37
01/05/2022 22:44:53 - INFO - __main__ -   Batch number = 38
01/05/2022 22:44:54 - INFO - __main__ -   Batch number = 39
01/05/2022 22:44:54 - INFO - __main__ -   Batch number = 40
01/05/2022 22:44:54 - INFO - __main__ -   Batch number = 41
01/05/2022 22:44:54 - INFO - __main__ -   Batch number = 42
01/05/2022 22:44:54 - INFO - __main__ -   Batch number = 43
01/05/2022 22:44:54 - INFO - __main__ -   Batch number = 44
01/05/2022 22:44:54 - INFO - __main__ -   Batch number = 45
01/05/2022 22:44:54 - INFO - __main__ -   Batch number = 46
01/05/2022 22:44:55 - INFO - __main__ -   Batch number = 47
01/05/2022 22:44:55 - INFO - __main__ -   Batch number = 48
01/05/2022 22:44:55 - INFO - __main__ -   Batch number = 49
01/05/2022 22:44:55 - INFO - __main__ -   Batch number = 50
01/05/2022 22:44:55 - INFO - __main__ -   Batch number = 51
01/05/2022 22:44:55 - INFO - __main__ -   Batch number = 52
01/05/2022 22:44:55 - INFO - __main__ -   Batch number = 53
01/05/2022 22:44:55 - INFO - __main__ -   Batch number = 54
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 55
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 56
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 57
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 58
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 59
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 60
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 61
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 62
01/05/2022 22:44:56 - INFO - __main__ -   Batch number = 63
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 64
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 65
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 66
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 67
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 68
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 69
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 70
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 71
01/05/2022 22:44:57 - INFO - __main__ -   Batch number = 72
01/05/2022 22:44:58 - INFO - __main__ -   Batch number = 73
01/05/2022 22:44:58 - INFO - __main__ -   Batch number = 74
01/05/2022 22:44:58 - INFO - __main__ -   Batch number = 75
01/05/2022 22:44:58 - INFO - __main__ -   Batch number = 76
01/05/2022 22:44:58 - INFO - __main__ -   Batch number = 77
01/05/2022 22:44:58 - INFO - __main__ -   Batch number = 78
01/05/2022 22:44:58 - INFO - __main__ -   Batch number = 79
01/05/2022 22:44:58 - INFO - __main__ -   Batch number = 80
01/05/2022 22:44:59 - INFO - __main__ -   Batch number = 81
01/05/2022 22:44:59 - INFO - __main__ -   Batch number = 82
01/05/2022 22:44:59 - INFO - __main__ -   Batch number = 83
01/05/2022 22:44:59 - INFO - __main__ -   Batch number = 84
01/05/2022 22:44:59 - INFO - __main__ -   Batch number = 85
01/05/2022 22:44:59 - INFO - __main__ -   Batch number = 86
01/05/2022 22:44:59 - INFO - __main__ -   Batch number = 87
01/05/2022 22:44:59 - INFO - __main__ -   Batch number = 88
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 89
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 90
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 91
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 92
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 93
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 94
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 95
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 96
01/05/2022 22:45:00 - INFO - __main__ -   Batch number = 97
01/05/2022 22:45:01 - INFO - __main__ -   Batch number = 98
01/05/2022 22:45:01 - INFO - __main__ -   Batch number = 99
01/05/2022 22:45:01 - INFO - __main__ -   Batch number = 100
01/05/2022 22:45:01 - INFO - __main__ -   Batch number = 101
01/05/2022 22:45:01 - INFO - __main__ -   Batch number = 102
01/05/2022 22:45:01 - INFO - __main__ -   Batch number = 103
01/05/2022 22:45:01 - INFO - __main__ -   Batch number = 104
01/05/2022 22:45:01 - INFO - __main__ -   Batch number = 105
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 106
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 107
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 108
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 109
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 110
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 111
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 112
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 113
01/05/2022 22:45:02 - INFO - __main__ -   Batch number = 114
01/05/2022 22:45:03 - INFO - __main__ -   Batch number = 115
01/05/2022 22:45:03 - INFO - __main__ -   Batch number = 116
01/05/2022 22:45:03 - INFO - __main__ -   Batch number = 117
01/05/2022 22:45:03 - INFO - __main__ -   Batch number = 118
01/05/2022 22:45:03 - INFO - __main__ -   Batch number = 119
01/05/2022 22:45:03 - INFO - __main__ -   Batch number = 120
01/05/2022 22:45:03 - INFO - __main__ -   Batch number = 121
01/05/2022 22:45:03 - INFO - __main__ -   Batch number = 122
01/05/2022 22:45:04 - INFO - __main__ -   Batch number = 123
01/05/2022 22:45:04 - INFO - __main__ -   Batch number = 124
01/05/2022 22:45:04 - INFO - __main__ -   Batch number = 125
01/05/2022 22:45:05 - INFO - __main__ -   ***** Evaluation result 11000 in en *****
01/05/2022 22:45:05 - INFO - __main__ -     f1 = 0.9463161411353533
01/05/2022 22:45:05 - INFO - __main__ -     loss = 0.2074487331211567
01/05/2022 22:45:05 - INFO - __main__ -     precision = 0.9464701850582591
01/05/2022 22:45:05 - INFO - __main__ -     recall = 0.9461621473475051
01/05/2022 22:45:05 - INFO - __main__ -   Hit patience=5
01/05/2022 22:50:58 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:50:59 - INFO - __main__ -   ***** Running evaluation 12000 in en *****
01/05/2022 22:50:59 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:50:59 - INFO - __main__ -     Batch size = 32
01/05/2022 22:50:59 - INFO - __main__ -   Batch number = 1
01/05/2022 22:50:59 - INFO - __main__ -   Batch number = 2
01/05/2022 22:50:59 - INFO - __main__ -   Batch number = 3
01/05/2022 22:50:59 - INFO - __main__ -   Batch number = 4
01/05/2022 22:50:59 - INFO - __main__ -   Batch number = 5
01/05/2022 22:50:59 - INFO - __main__ -   Batch number = 6
01/05/2022 22:50:59 - INFO - __main__ -   Batch number = 7
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 8
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 9
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 10
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 11
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 12
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 13
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 14
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 15
01/05/2022 22:51:00 - INFO - __main__ -   Batch number = 16
01/05/2022 22:51:01 - INFO - __main__ -   Batch number = 17
01/05/2022 22:51:01 - INFO - __main__ -   Batch number = 18
01/05/2022 22:51:01 - INFO - __main__ -   Batch number = 19
01/05/2022 22:51:01 - INFO - __main__ -   Batch number = 20
01/05/2022 22:51:01 - INFO - __main__ -   Batch number = 21
01/05/2022 22:51:01 - INFO - __main__ -   Batch number = 22
01/05/2022 22:51:01 - INFO - __main__ -   Batch number = 23
01/05/2022 22:51:01 - INFO - __main__ -   Batch number = 24
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 25
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 26
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 27
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 28
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 29
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 30
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 31
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 32
01/05/2022 22:51:02 - INFO - __main__ -   Batch number = 33
01/05/2022 22:51:03 - INFO - __main__ -   Batch number = 34
01/05/2022 22:51:03 - INFO - __main__ -   Batch number = 35
01/05/2022 22:51:03 - INFO - __main__ -   Batch number = 36
01/05/2022 22:51:03 - INFO - __main__ -   Batch number = 37
01/05/2022 22:51:03 - INFO - __main__ -   Batch number = 38
01/05/2022 22:51:03 - INFO - __main__ -   Batch number = 39
01/05/2022 22:51:03 - INFO - __main__ -   Batch number = 40
01/05/2022 22:51:03 - INFO - __main__ -   Batch number = 41
01/05/2022 22:51:04 - INFO - __main__ -   Batch number = 42
01/05/2022 22:51:04 - INFO - __main__ -   Batch number = 43
01/05/2022 22:51:04 - INFO - __main__ -   Batch number = 44
01/05/2022 22:51:04 - INFO - __main__ -   Batch number = 45
01/05/2022 22:51:04 - INFO - __main__ -   Batch number = 46
01/05/2022 22:51:04 - INFO - __main__ -   Batch number = 47
01/05/2022 22:51:04 - INFO - __main__ -   Batch number = 48
01/05/2022 22:51:04 - INFO - __main__ -   Batch number = 49
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 50
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 51
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 52
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 53
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 54
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 55
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 56
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 57
01/05/2022 22:51:05 - INFO - __main__ -   Batch number = 58
01/05/2022 22:51:06 - INFO - __main__ -   Batch number = 59
01/05/2022 22:51:06 - INFO - __main__ -   Batch number = 60
01/05/2022 22:51:06 - INFO - __main__ -   Batch number = 61
01/05/2022 22:51:06 - INFO - __main__ -   Batch number = 62
01/05/2022 22:51:06 - INFO - __main__ -   Batch number = 63
01/05/2022 22:51:06 - INFO - __main__ -   Batch number = 64
01/05/2022 22:51:06 - INFO - __main__ -   Batch number = 65
01/05/2022 22:51:06 - INFO - __main__ -   Batch number = 66
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 67
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 68
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 69
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 70
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 71
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 72
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 73
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 74
01/05/2022 22:51:07 - INFO - __main__ -   Batch number = 75
01/05/2022 22:51:08 - INFO - __main__ -   Batch number = 76
01/05/2022 22:51:08 - INFO - __main__ -   Batch number = 77
01/05/2022 22:51:08 - INFO - __main__ -   Batch number = 78
01/05/2022 22:51:08 - INFO - __main__ -   Batch number = 79
01/05/2022 22:51:08 - INFO - __main__ -   Batch number = 80
01/05/2022 22:51:08 - INFO - __main__ -   Batch number = 81
01/05/2022 22:51:08 - INFO - __main__ -   Batch number = 82
01/05/2022 22:51:08 - INFO - __main__ -   Batch number = 83
01/05/2022 22:51:09 - INFO - __main__ -   Batch number = 84
01/05/2022 22:51:09 - INFO - __main__ -   Batch number = 85
01/05/2022 22:51:09 - INFO - __main__ -   Batch number = 86
01/05/2022 22:51:09 - INFO - __main__ -   Batch number = 87
01/05/2022 22:51:09 - INFO - __main__ -   Batch number = 88
01/05/2022 22:51:09 - INFO - __main__ -   Batch number = 89
01/05/2022 22:51:09 - INFO - __main__ -   Batch number = 90
01/05/2022 22:51:09 - INFO - __main__ -   Batch number = 91
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 92
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 93
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 94
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 95
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 96
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 97
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 98
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 99
01/05/2022 22:51:10 - INFO - __main__ -   Batch number = 100
01/05/2022 22:51:11 - INFO - __main__ -   Batch number = 101
01/05/2022 22:51:11 - INFO - __main__ -   Batch number = 102
01/05/2022 22:51:11 - INFO - __main__ -   Batch number = 103
01/05/2022 22:51:11 - INFO - __main__ -   Batch number = 104
01/05/2022 22:51:11 - INFO - __main__ -   Batch number = 105
01/05/2022 22:51:11 - INFO - __main__ -   Batch number = 106
01/05/2022 22:51:11 - INFO - __main__ -   Batch number = 107
01/05/2022 22:51:11 - INFO - __main__ -   Batch number = 108
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 109
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 110
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 111
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 112
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 113
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 114
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 115
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 116
01/05/2022 22:51:12 - INFO - __main__ -   Batch number = 117
01/05/2022 22:51:13 - INFO - __main__ -   Batch number = 118
01/05/2022 22:51:13 - INFO - __main__ -   Batch number = 119
01/05/2022 22:51:13 - INFO - __main__ -   Batch number = 120
01/05/2022 22:51:13 - INFO - __main__ -   Batch number = 121
01/05/2022 22:51:13 - INFO - __main__ -   Batch number = 122
01/05/2022 22:51:13 - INFO - __main__ -   Batch number = 123
01/05/2022 22:51:13 - INFO - __main__ -   Batch number = 124
01/05/2022 22:51:13 - INFO - __main__ -   Batch number = 125
01/05/2022 22:51:15 - INFO - __main__ -   ***** Evaluation result 12000 in en *****
01/05/2022 22:51:15 - INFO - __main__ -     f1 = 0.94664348183617
01/05/2022 22:51:15 - INFO - __main__ -     loss = 0.2239720478951931
01/05/2022 22:51:15 - INFO - __main__ -     precision = 0.9467651291892263
01/05/2022 22:51:15 - INFO - __main__ -     recall = 0.9465218657393926
01/05/2022 22:51:15 - INFO - __main__ -   Hit patience=6
01/05/2022 22:57:09 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:57:09 - INFO - __main__ -   ***** Running evaluation 13000 in en *****
01/05/2022 22:57:09 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:57:09 - INFO - __main__ -     Batch size = 32
01/05/2022 22:57:09 - INFO - __main__ -   Batch number = 1
01/05/2022 22:57:09 - INFO - __main__ -   Batch number = 2
01/05/2022 22:57:09 - INFO - __main__ -   Batch number = 3
01/05/2022 22:57:09 - INFO - __main__ -   Batch number = 4
01/05/2022 22:57:09 - INFO - __main__ -   Batch number = 5
01/05/2022 22:57:09 - INFO - __main__ -   Batch number = 6
01/05/2022 22:57:10 - INFO - __main__ -   Batch number = 7
01/05/2022 22:57:10 - INFO - __main__ -   Batch number = 8
01/05/2022 22:57:10 - INFO - __main__ -   Batch number = 9
01/05/2022 22:57:10 - INFO - __main__ -   Batch number = 10
01/05/2022 22:57:10 - INFO - __main__ -   Batch number = 11
01/05/2022 22:57:10 - INFO - __main__ -   Batch number = 12
01/05/2022 22:57:10 - INFO - __main__ -   Batch number = 13
01/05/2022 22:57:10 - INFO - __main__ -   Batch number = 14
01/05/2022 22:57:11 - INFO - __main__ -   Batch number = 15
01/05/2022 22:57:11 - INFO - __main__ -   Batch number = 16
01/05/2022 22:57:11 - INFO - __main__ -   Batch number = 17
01/05/2022 22:57:11 - INFO - __main__ -   Batch number = 18
01/05/2022 22:57:11 - INFO - __main__ -   Batch number = 19
01/05/2022 22:57:11 - INFO - __main__ -   Batch number = 20
01/05/2022 22:57:11 - INFO - __main__ -   Batch number = 21
01/05/2022 22:57:11 - INFO - __main__ -   Batch number = 22
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 23
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 24
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 25
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 26
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 27
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 28
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 29
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 30
01/05/2022 22:57:12 - INFO - __main__ -   Batch number = 31
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 32
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 33
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 34
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 35
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 36
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 37
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 38
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 39
01/05/2022 22:57:13 - INFO - __main__ -   Batch number = 40
01/05/2022 22:57:14 - INFO - __main__ -   Batch number = 41
01/05/2022 22:57:14 - INFO - __main__ -   Batch number = 42
01/05/2022 22:57:14 - INFO - __main__ -   Batch number = 43
01/05/2022 22:57:14 - INFO - __main__ -   Batch number = 44
01/05/2022 22:57:14 - INFO - __main__ -   Batch number = 45
01/05/2022 22:57:14 - INFO - __main__ -   Batch number = 46
01/05/2022 22:57:14 - INFO - __main__ -   Batch number = 47
01/05/2022 22:57:14 - INFO - __main__ -   Batch number = 48
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 49
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 50
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 51
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 52
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 53
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 54
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 55
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 56
01/05/2022 22:57:15 - INFO - __main__ -   Batch number = 57
01/05/2022 22:57:16 - INFO - __main__ -   Batch number = 58
01/05/2022 22:57:16 - INFO - __main__ -   Batch number = 59
01/05/2022 22:57:16 - INFO - __main__ -   Batch number = 60
01/05/2022 22:57:16 - INFO - __main__ -   Batch number = 61
01/05/2022 22:57:16 - INFO - __main__ -   Batch number = 62
01/05/2022 22:57:16 - INFO - __main__ -   Batch number = 63
01/05/2022 22:57:16 - INFO - __main__ -   Batch number = 64
01/05/2022 22:57:16 - INFO - __main__ -   Batch number = 65
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 66
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 67
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 68
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 69
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 70
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 71
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 72
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 73
01/05/2022 22:57:17 - INFO - __main__ -   Batch number = 74
01/05/2022 22:57:18 - INFO - __main__ -   Batch number = 75
01/05/2022 22:57:18 - INFO - __main__ -   Batch number = 76
01/05/2022 22:57:18 - INFO - __main__ -   Batch number = 77
01/05/2022 22:57:18 - INFO - __main__ -   Batch number = 78
01/05/2022 22:57:18 - INFO - __main__ -   Batch number = 79
01/05/2022 22:57:18 - INFO - __main__ -   Batch number = 80
01/05/2022 22:57:18 - INFO - __main__ -   Batch number = 81
01/05/2022 22:57:18 - INFO - __main__ -   Batch number = 82
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 83
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 84
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 85
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 86
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 87
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 88
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 89
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 90
01/05/2022 22:57:19 - INFO - __main__ -   Batch number = 91
01/05/2022 22:57:20 - INFO - __main__ -   Batch number = 92
01/05/2022 22:57:20 - INFO - __main__ -   Batch number = 93
01/05/2022 22:57:20 - INFO - __main__ -   Batch number = 94
01/05/2022 22:57:20 - INFO - __main__ -   Batch number = 95
01/05/2022 22:57:20 - INFO - __main__ -   Batch number = 96
01/05/2022 22:57:20 - INFO - __main__ -   Batch number = 97
01/05/2022 22:57:20 - INFO - __main__ -   Batch number = 98
01/05/2022 22:57:20 - INFO - __main__ -   Batch number = 99
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 100
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 101
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 102
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 103
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 104
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 105
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 106
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 107
01/05/2022 22:57:21 - INFO - __main__ -   Batch number = 108
01/05/2022 22:57:22 - INFO - __main__ -   Batch number = 109
01/05/2022 22:57:22 - INFO - __main__ -   Batch number = 110
01/05/2022 22:57:22 - INFO - __main__ -   Batch number = 111
01/05/2022 22:57:22 - INFO - __main__ -   Batch number = 112
01/05/2022 22:57:22 - INFO - __main__ -   Batch number = 113
01/05/2022 22:57:22 - INFO - __main__ -   Batch number = 114
01/05/2022 22:57:22 - INFO - __main__ -   Batch number = 115
01/05/2022 22:57:22 - INFO - __main__ -   Batch number = 116
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 117
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 118
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 119
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 120
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 121
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 122
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 123
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 124
01/05/2022 22:57:23 - INFO - __main__ -   Batch number = 125
01/05/2022 22:57:25 - INFO - __main__ -   ***** Evaluation result 13000 in en *****
01/05/2022 22:57:25 - INFO - __main__ -     f1 = 0.9466309216893783
01/05/2022 22:57:25 - INFO - __main__ -     loss = 0.24445039254426956
01/05/2022 22:57:25 - INFO - __main__ -     precision = 0.9466714633227121
01/05/2022 22:57:25 - INFO - __main__ -     recall = 0.9465903835283236
01/05/2022 22:57:25 - INFO - __main__ -   Hit patience=7
01/05/2022 23:03:17 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:03:17 - INFO - __main__ -   ***** Running evaluation 14000 in en *****
01/05/2022 23:03:17 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:03:17 - INFO - __main__ -     Batch size = 32
01/05/2022 23:03:17 - INFO - __main__ -   Batch number = 1
01/05/2022 23:03:18 - INFO - __main__ -   Batch number = 2
01/05/2022 23:03:18 - INFO - __main__ -   Batch number = 3
01/05/2022 23:03:18 - INFO - __main__ -   Batch number = 4
01/05/2022 23:03:18 - INFO - __main__ -   Batch number = 5
01/05/2022 23:03:18 - INFO - __main__ -   Batch number = 6
01/05/2022 23:03:18 - INFO - __main__ -   Batch number = 7
01/05/2022 23:03:18 - INFO - __main__ -   Batch number = 8
01/05/2022 23:03:18 - INFO - __main__ -   Batch number = 9
01/05/2022 23:03:19 - INFO - __main__ -   Batch number = 10
01/05/2022 23:03:19 - INFO - __main__ -   Batch number = 11
01/05/2022 23:03:19 - INFO - __main__ -   Batch number = 12
01/05/2022 23:03:19 - INFO - __main__ -   Batch number = 13
01/05/2022 23:03:19 - INFO - __main__ -   Batch number = 14
01/05/2022 23:03:19 - INFO - __main__ -   Batch number = 15
01/05/2022 23:03:19 - INFO - __main__ -   Batch number = 16
01/05/2022 23:03:19 - INFO - __main__ -   Batch number = 17
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 18
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 19
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 20
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 21
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 22
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 23
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 24
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 25
01/05/2022 23:03:20 - INFO - __main__ -   Batch number = 26
01/05/2022 23:03:21 - INFO - __main__ -   Batch number = 27
01/05/2022 23:03:21 - INFO - __main__ -   Batch number = 28
01/05/2022 23:03:21 - INFO - __main__ -   Batch number = 29
01/05/2022 23:03:21 - INFO - __main__ -   Batch number = 30
01/05/2022 23:03:21 - INFO - __main__ -   Batch number = 31
01/05/2022 23:03:21 - INFO - __main__ -   Batch number = 32
01/05/2022 23:03:21 - INFO - __main__ -   Batch number = 33
01/05/2022 23:03:21 - INFO - __main__ -   Batch number = 34
01/05/2022 23:03:22 - INFO - __main__ -   Batch number = 35
01/05/2022 23:03:22 - INFO - __main__ -   Batch number = 36
01/05/2022 23:03:22 - INFO - __main__ -   Batch number = 37
01/05/2022 23:03:22 - INFO - __main__ -   Batch number = 38
01/05/2022 23:03:22 - INFO - __main__ -   Batch number = 39
01/05/2022 23:03:22 - INFO - __main__ -   Batch number = 40
01/05/2022 23:03:22 - INFO - __main__ -   Batch number = 41
01/05/2022 23:03:22 - INFO - __main__ -   Batch number = 42
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 43
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 44
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 45
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 46
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 47
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 48
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 49
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 50
01/05/2022 23:03:23 - INFO - __main__ -   Batch number = 51
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 52
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 53
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 54
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 55
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 56
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 57
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 58
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 59
01/05/2022 23:03:24 - INFO - __main__ -   Batch number = 60
01/05/2022 23:03:25 - INFO - __main__ -   Batch number = 61
01/05/2022 23:03:25 - INFO - __main__ -   Batch number = 62
01/05/2022 23:03:25 - INFO - __main__ -   Batch number = 63
01/05/2022 23:03:25 - INFO - __main__ -   Batch number = 64
01/05/2022 23:03:25 - INFO - __main__ -   Batch number = 65
01/05/2022 23:03:25 - INFO - __main__ -   Batch number = 66
01/05/2022 23:03:25 - INFO - __main__ -   Batch number = 67
01/05/2022 23:03:25 - INFO - __main__ -   Batch number = 68
01/05/2022 23:03:26 - INFO - __main__ -   Batch number = 69
01/05/2022 23:03:26 - INFO - __main__ -   Batch number = 70
01/05/2022 23:03:26 - INFO - __main__ -   Batch number = 71
01/05/2022 23:03:26 - INFO - __main__ -   Batch number = 72
01/05/2022 23:03:26 - INFO - __main__ -   Batch number = 73
01/05/2022 23:03:26 - INFO - __main__ -   Batch number = 74
01/05/2022 23:03:26 - INFO - __main__ -   Batch number = 75
01/05/2022 23:03:26 - INFO - __main__ -   Batch number = 76
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 77
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 78
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 79
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 80
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 81
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 82
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 83
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 84
01/05/2022 23:03:27 - INFO - __main__ -   Batch number = 85
01/05/2022 23:03:28 - INFO - __main__ -   Batch number = 86
01/05/2022 23:03:28 - INFO - __main__ -   Batch number = 87
01/05/2022 23:03:28 - INFO - __main__ -   Batch number = 88
01/05/2022 23:03:28 - INFO - __main__ -   Batch number = 89
01/05/2022 23:03:28 - INFO - __main__ -   Batch number = 90
01/05/2022 23:03:28 - INFO - __main__ -   Batch number = 91
01/05/2022 23:03:28 - INFO - __main__ -   Batch number = 92
01/05/2022 23:03:28 - INFO - __main__ -   Batch number = 93
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 94
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 95
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 96
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 97
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 98
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 99
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 100
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 101
01/05/2022 23:03:29 - INFO - __main__ -   Batch number = 102
01/05/2022 23:03:30 - INFO - __main__ -   Batch number = 103
01/05/2022 23:03:30 - INFO - __main__ -   Batch number = 104
01/05/2022 23:03:30 - INFO - __main__ -   Batch number = 105
01/05/2022 23:03:30 - INFO - __main__ -   Batch number = 106
01/05/2022 23:03:30 - INFO - __main__ -   Batch number = 107
01/05/2022 23:03:30 - INFO - __main__ -   Batch number = 108
01/05/2022 23:03:30 - INFO - __main__ -   Batch number = 109
01/05/2022 23:03:30 - INFO - __main__ -   Batch number = 110
01/05/2022 23:03:31 - INFO - __main__ -   Batch number = 111
01/05/2022 23:03:31 - INFO - __main__ -   Batch number = 112
01/05/2022 23:03:31 - INFO - __main__ -   Batch number = 113
01/05/2022 23:03:31 - INFO - __main__ -   Batch number = 114
01/05/2022 23:03:31 - INFO - __main__ -   Batch number = 115
01/05/2022 23:03:31 - INFO - __main__ -   Batch number = 116
01/05/2022 23:03:31 - INFO - __main__ -   Batch number = 117
01/05/2022 23:03:31 - INFO - __main__ -   Batch number = 118
01/05/2022 23:03:32 - INFO - __main__ -   Batch number = 119
01/05/2022 23:03:32 - INFO - __main__ -   Batch number = 120
01/05/2022 23:03:32 - INFO - __main__ -   Batch number = 121
01/05/2022 23:03:32 - INFO - __main__ -   Batch number = 122
01/05/2022 23:03:32 - INFO - __main__ -   Batch number = 123
01/05/2022 23:03:32 - INFO - __main__ -   Batch number = 124
01/05/2022 23:03:32 - INFO - __main__ -   Batch number = 125
01/05/2022 23:03:33 - INFO - __main__ -   ***** Evaluation result 14000 in en *****
01/05/2022 23:03:33 - INFO - __main__ -     f1 = 0.945840150068096
01/05/2022 23:03:33 - INFO - __main__ -     loss = 0.261722055375576
01/05/2022 23:03:33 - INFO - __main__ -     precision = 0.9459292763157895
01/05/2022 23:03:33 - INFO - __main__ -     recall = 0.9457510406139193
01/05/2022 23:03:33 - INFO - __main__ -   Hit patience=8
01/05/2022 23:09:26 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:09:26 - INFO - __main__ -   ***** Running evaluation 15000 in en *****
01/05/2022 23:09:26 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:09:26 - INFO - __main__ -     Batch size = 32
01/05/2022 23:09:26 - INFO - __main__ -   Batch number = 1
01/05/2022 23:09:26 - INFO - __main__ -   Batch number = 2
01/05/2022 23:09:26 - INFO - __main__ -   Batch number = 3
01/05/2022 23:09:27 - INFO - __main__ -   Batch number = 4
01/05/2022 23:09:27 - INFO - __main__ -   Batch number = 5
01/05/2022 23:09:27 - INFO - __main__ -   Batch number = 6
01/05/2022 23:09:27 - INFO - __main__ -   Batch number = 7
01/05/2022 23:09:27 - INFO - __main__ -   Batch number = 8
01/05/2022 23:09:27 - INFO - __main__ -   Batch number = 9
01/05/2022 23:09:27 - INFO - __main__ -   Batch number = 10
01/05/2022 23:09:27 - INFO - __main__ -   Batch number = 11
01/05/2022 23:09:28 - INFO - __main__ -   Batch number = 12
01/05/2022 23:09:28 - INFO - __main__ -   Batch number = 13
01/05/2022 23:09:28 - INFO - __main__ -   Batch number = 14
01/05/2022 23:09:28 - INFO - __main__ -   Batch number = 15
01/05/2022 23:09:28 - INFO - __main__ -   Batch number = 16
01/05/2022 23:09:28 - INFO - __main__ -   Batch number = 17
01/05/2022 23:09:28 - INFO - __main__ -   Batch number = 18
01/05/2022 23:09:28 - INFO - __main__ -   Batch number = 19
01/05/2022 23:09:29 - INFO - __main__ -   Batch number = 20
01/05/2022 23:09:29 - INFO - __main__ -   Batch number = 21
01/05/2022 23:09:29 - INFO - __main__ -   Batch number = 22
01/05/2022 23:09:29 - INFO - __main__ -   Batch number = 23
01/05/2022 23:09:29 - INFO - __main__ -   Batch number = 24
01/05/2022 23:09:29 - INFO - __main__ -   Batch number = 25
01/05/2022 23:09:29 - INFO - __main__ -   Batch number = 26
01/05/2022 23:09:29 - INFO - __main__ -   Batch number = 27
01/05/2022 23:09:30 - INFO - __main__ -   Batch number = 28
01/05/2022 23:09:30 - INFO - __main__ -   Batch number = 29
01/05/2022 23:09:30 - INFO - __main__ -   Batch number = 30
01/05/2022 23:09:30 - INFO - __main__ -   Batch number = 31
01/05/2022 23:09:30 - INFO - __main__ -   Batch number = 32
01/05/2022 23:09:30 - INFO - __main__ -   Batch number = 33
01/05/2022 23:09:30 - INFO - __main__ -   Batch number = 34
01/05/2022 23:09:30 - INFO - __main__ -   Batch number = 35
01/05/2022 23:09:31 - INFO - __main__ -   Batch number = 36
01/05/2022 23:09:31 - INFO - __main__ -   Batch number = 37
01/05/2022 23:09:31 - INFO - __main__ -   Batch number = 38
01/05/2022 23:09:31 - INFO - __main__ -   Batch number = 39
01/05/2022 23:09:31 - INFO - __main__ -   Batch number = 40
01/05/2022 23:09:31 - INFO - __main__ -   Batch number = 41
01/05/2022 23:09:31 - INFO - __main__ -   Batch number = 42
01/05/2022 23:09:31 - INFO - __main__ -   Batch number = 43
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 44
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 45
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 46
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 47
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 48
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 49
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 50
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 51
01/05/2022 23:09:32 - INFO - __main__ -   Batch number = 52
01/05/2022 23:09:33 - INFO - __main__ -   Batch number = 53
01/05/2022 23:09:33 - INFO - __main__ -   Batch number = 54
01/05/2022 23:09:33 - INFO - __main__ -   Batch number = 55
01/05/2022 23:09:33 - INFO - __main__ -   Batch number = 56
01/05/2022 23:09:33 - INFO - __main__ -   Batch number = 57
01/05/2022 23:09:33 - INFO - __main__ -   Batch number = 58
01/05/2022 23:09:33 - INFO - __main__ -   Batch number = 59
01/05/2022 23:09:33 - INFO - __main__ -   Batch number = 60
01/05/2022 23:09:34 - INFO - __main__ -   Batch number = 61
01/05/2022 23:09:34 - INFO - __main__ -   Batch number = 62
01/05/2022 23:09:34 - INFO - __main__ -   Batch number = 63
01/05/2022 23:09:34 - INFO - __main__ -   Batch number = 64
01/05/2022 23:09:34 - INFO - __main__ -   Batch number = 65
01/05/2022 23:09:34 - INFO - __main__ -   Batch number = 66
01/05/2022 23:09:34 - INFO - __main__ -   Batch number = 67
01/05/2022 23:09:34 - INFO - __main__ -   Batch number = 68
01/05/2022 23:09:35 - INFO - __main__ -   Batch number = 69
01/05/2022 23:09:35 - INFO - __main__ -   Batch number = 70
01/05/2022 23:09:35 - INFO - __main__ -   Batch number = 71
01/05/2022 23:09:35 - INFO - __main__ -   Batch number = 72
01/05/2022 23:09:35 - INFO - __main__ -   Batch number = 73
01/05/2022 23:09:35 - INFO - __main__ -   Batch number = 74
01/05/2022 23:09:35 - INFO - __main__ -   Batch number = 75
01/05/2022 23:09:35 - INFO - __main__ -   Batch number = 76
01/05/2022 23:09:36 - INFO - __main__ -   Batch number = 77
01/05/2022 23:09:36 - INFO - __main__ -   Batch number = 78
01/05/2022 23:09:36 - INFO - __main__ -   Batch number = 79
01/05/2022 23:09:36 - INFO - __main__ -   Batch number = 80
01/05/2022 23:09:36 - INFO - __main__ -   Batch number = 81
01/05/2022 23:09:36 - INFO - __main__ -   Batch number = 82
01/05/2022 23:09:36 - INFO - __main__ -   Batch number = 83
01/05/2022 23:09:36 - INFO - __main__ -   Batch number = 84
01/05/2022 23:09:37 - INFO - __main__ -   Batch number = 85
01/05/2022 23:09:37 - INFO - __main__ -   Batch number = 86
01/05/2022 23:09:37 - INFO - __main__ -   Batch number = 87
01/05/2022 23:09:37 - INFO - __main__ -   Batch number = 88
01/05/2022 23:09:37 - INFO - __main__ -   Batch number = 89
01/05/2022 23:09:37 - INFO - __main__ -   Batch number = 90
01/05/2022 23:09:37 - INFO - __main__ -   Batch number = 91
01/05/2022 23:09:37 - INFO - __main__ -   Batch number = 92
01/05/2022 23:09:38 - INFO - __main__ -   Batch number = 93
01/05/2022 23:09:38 - INFO - __main__ -   Batch number = 94
01/05/2022 23:09:38 - INFO - __main__ -   Batch number = 95
01/05/2022 23:09:38 - INFO - __main__ -   Batch number = 96
01/05/2022 23:09:38 - INFO - __main__ -   Batch number = 97
01/05/2022 23:09:38 - INFO - __main__ -   Batch number = 98
01/05/2022 23:09:38 - INFO - __main__ -   Batch number = 99
01/05/2022 23:09:38 - INFO - __main__ -   Batch number = 100
01/05/2022 23:09:39 - INFO - __main__ -   Batch number = 101
01/05/2022 23:09:39 - INFO - __main__ -   Batch number = 102
01/05/2022 23:09:39 - INFO - __main__ -   Batch number = 103
01/05/2022 23:09:39 - INFO - __main__ -   Batch number = 104
01/05/2022 23:09:39 - INFO - __main__ -   Batch number = 105
01/05/2022 23:09:39 - INFO - __main__ -   Batch number = 106
01/05/2022 23:09:39 - INFO - __main__ -   Batch number = 107
01/05/2022 23:09:39 - INFO - __main__ -   Batch number = 108
01/05/2022 23:09:40 - INFO - __main__ -   Batch number = 109
01/05/2022 23:09:40 - INFO - __main__ -   Batch number = 110
01/05/2022 23:09:40 - INFO - __main__ -   Batch number = 111
01/05/2022 23:09:40 - INFO - __main__ -   Batch number = 112
01/05/2022 23:09:40 - INFO - __main__ -   Batch number = 113
01/05/2022 23:09:40 - INFO - __main__ -   Batch number = 114
01/05/2022 23:09:40 - INFO - __main__ -   Batch number = 115
01/05/2022 23:09:40 - INFO - __main__ -   Batch number = 116
01/05/2022 23:09:41 - INFO - __main__ -   Batch number = 117
01/05/2022 23:09:41 - INFO - __main__ -   Batch number = 118
01/05/2022 23:09:41 - INFO - __main__ -   Batch number = 119
01/05/2022 23:09:41 - INFO - __main__ -   Batch number = 120
01/05/2022 23:09:41 - INFO - __main__ -   Batch number = 121
01/05/2022 23:09:41 - INFO - __main__ -   Batch number = 122
01/05/2022 23:09:41 - INFO - __main__ -   Batch number = 123
01/05/2022 23:09:41 - INFO - __main__ -   Batch number = 124
01/05/2022 23:09:42 - INFO - __main__ -   Batch number = 125
01/05/2022 23:09:43 - INFO - __main__ -   ***** Evaluation result 15000 in en *****
01/05/2022 23:09:43 - INFO - __main__ -     f1 = 0.9453545829015767
01/05/2022 23:09:43 - INFO - __main__ -     loss = 0.28894881224632263
01/05/2022 23:09:43 - INFO - __main__ -     precision = 0.9452493492259214
01/05/2022 23:09:43 - INFO - __main__ -     recall = 0.9454598400109628
01/05/2022 23:09:43 - INFO - __main__ -   Hit patience=9
01/05/2022 23:15:36 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:15:37 - INFO - __main__ -   ***** Running evaluation 16000 in en *****
01/05/2022 23:15:37 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:15:37 - INFO - __main__ -     Batch size = 32
01/05/2022 23:15:37 - INFO - __main__ -   Batch number = 1
01/05/2022 23:15:37 - INFO - __main__ -   Batch number = 2
01/05/2022 23:15:37 - INFO - __main__ -   Batch number = 3
01/05/2022 23:15:37 - INFO - __main__ -   Batch number = 4
01/05/2022 23:15:37 - INFO - __main__ -   Batch number = 5
01/05/2022 23:15:37 - INFO - __main__ -   Batch number = 6
01/05/2022 23:15:37 - INFO - __main__ -   Batch number = 7
01/05/2022 23:15:37 - INFO - __main__ -   Batch number = 8
01/05/2022 23:15:38 - INFO - __main__ -   Batch number = 9
01/05/2022 23:15:38 - INFO - __main__ -   Batch number = 10
01/05/2022 23:15:38 - INFO - __main__ -   Batch number = 11
01/05/2022 23:15:38 - INFO - __main__ -   Batch number = 12
01/05/2022 23:15:38 - INFO - __main__ -   Batch number = 13
01/05/2022 23:15:38 - INFO - __main__ -   Batch number = 14
01/05/2022 23:15:38 - INFO - __main__ -   Batch number = 15
01/05/2022 23:15:38 - INFO - __main__ -   Batch number = 16
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 17
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 18
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 19
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 20
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 21
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 22
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 23
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 24
01/05/2022 23:15:39 - INFO - __main__ -   Batch number = 25
01/05/2022 23:15:40 - INFO - __main__ -   Batch number = 26
01/05/2022 23:15:40 - INFO - __main__ -   Batch number = 27
01/05/2022 23:15:40 - INFO - __main__ -   Batch number = 28
01/05/2022 23:15:40 - INFO - __main__ -   Batch number = 29
01/05/2022 23:15:40 - INFO - __main__ -   Batch number = 30
01/05/2022 23:15:40 - INFO - __main__ -   Batch number = 31
01/05/2022 23:15:40 - INFO - __main__ -   Batch number = 32
01/05/2022 23:15:40 - INFO - __main__ -   Batch number = 33
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 34
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 35
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 36
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 37
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 38
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 39
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 40
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 41
01/05/2022 23:15:41 - INFO - __main__ -   Batch number = 42
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 43
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 44
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 45
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 46
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 47
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 48
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 49
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 50
01/05/2022 23:15:42 - INFO - __main__ -   Batch number = 51
01/05/2022 23:15:43 - INFO - __main__ -   Batch number = 52
01/05/2022 23:15:43 - INFO - __main__ -   Batch number = 53
01/05/2022 23:15:43 - INFO - __main__ -   Batch number = 54
01/05/2022 23:15:43 - INFO - __main__ -   Batch number = 55
01/05/2022 23:15:43 - INFO - __main__ -   Batch number = 56
01/05/2022 23:15:43 - INFO - __main__ -   Batch number = 57
01/05/2022 23:15:43 - INFO - __main__ -   Batch number = 58
01/05/2022 23:15:43 - INFO - __main__ -   Batch number = 59
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 60
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 61
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 62
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 63
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 64
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 65
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 66
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 67
01/05/2022 23:15:44 - INFO - __main__ -   Batch number = 68
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 69
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 70
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 71
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 72
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 73
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 74
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 75
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 76
01/05/2022 23:15:45 - INFO - __main__ -   Batch number = 77
01/05/2022 23:15:46 - INFO - __main__ -   Batch number = 78
01/05/2022 23:15:46 - INFO - __main__ -   Batch number = 79
01/05/2022 23:15:46 - INFO - __main__ -   Batch number = 80
01/05/2022 23:15:46 - INFO - __main__ -   Batch number = 81
01/05/2022 23:15:46 - INFO - __main__ -   Batch number = 82
01/05/2022 23:15:46 - INFO - __main__ -   Batch number = 83
01/05/2022 23:15:46 - INFO - __main__ -   Batch number = 84
01/05/2022 23:15:46 - INFO - __main__ -   Batch number = 85
01/05/2022 23:15:47 - INFO - __main__ -   Batch number = 86
01/05/2022 23:15:47 - INFO - __main__ -   Batch number = 87
01/05/2022 23:15:47 - INFO - __main__ -   Batch number = 88
01/05/2022 23:15:47 - INFO - __main__ -   Batch number = 89
01/05/2022 23:15:47 - INFO - __main__ -   Batch number = 90
01/05/2022 23:15:47 - INFO - __main__ -   Batch number = 91
01/05/2022 23:15:47 - INFO - __main__ -   Batch number = 92
01/05/2022 23:15:47 - INFO - __main__ -   Batch number = 93
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 94
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 95
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 96
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 97
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 98
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 99
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 100
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 101
01/05/2022 23:15:48 - INFO - __main__ -   Batch number = 102
01/05/2022 23:15:49 - INFO - __main__ -   Batch number = 103
01/05/2022 23:15:49 - INFO - __main__ -   Batch number = 104
01/05/2022 23:15:49 - INFO - __main__ -   Batch number = 105
01/05/2022 23:15:49 - INFO - __main__ -   Batch number = 106
01/05/2022 23:15:49 - INFO - __main__ -   Batch number = 107
01/05/2022 23:15:49 - INFO - __main__ -   Batch number = 108
01/05/2022 23:15:49 - INFO - __main__ -   Batch number = 109
01/05/2022 23:15:49 - INFO - __main__ -   Batch number = 110
01/05/2022 23:15:50 - INFO - __main__ -   Batch number = 111
01/05/2022 23:15:50 - INFO - __main__ -   Batch number = 112
01/05/2022 23:15:50 - INFO - __main__ -   Batch number = 113
01/05/2022 23:15:50 - INFO - __main__ -   Batch number = 114
01/05/2022 23:15:50 - INFO - __main__ -   Batch number = 115
01/05/2022 23:15:50 - INFO - __main__ -   Batch number = 116
01/05/2022 23:15:50 - INFO - __main__ -   Batch number = 117
01/05/2022 23:15:50 - INFO - __main__ -   Batch number = 118
01/05/2022 23:15:51 - INFO - __main__ -   Batch number = 119
01/05/2022 23:15:51 - INFO - __main__ -   Batch number = 120
01/05/2022 23:15:51 - INFO - __main__ -   Batch number = 121
01/05/2022 23:15:51 - INFO - __main__ -   Batch number = 122
01/05/2022 23:15:51 - INFO - __main__ -   Batch number = 123
01/05/2022 23:15:51 - INFO - __main__ -   Batch number = 124
01/05/2022 23:15:51 - INFO - __main__ -   Batch number = 125
01/05/2022 23:15:52 - INFO - __main__ -   ***** Evaluation result 16000 in en *****
01/05/2022 23:15:52 - INFO - __main__ -     f1 = 0.9453302961275626
01/05/2022 23:15:52 - INFO - __main__ -     loss = 0.30874761801958084
01/05/2022 23:15:52 - INFO - __main__ -     precision = 0.9452007877386762
01/05/2022 23:15:52 - INFO - __main__ -     recall = 0.9454598400109628
01/05/2022 23:15:52 - INFO - __main__ -   Hit patience=10
01/05/2022 23:21:43 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:21:43 - INFO - __main__ -   ***** Running evaluation 17000 in en *****
01/05/2022 23:21:43 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:21:43 - INFO - __main__ -     Batch size = 32
01/05/2022 23:21:43 - INFO - __main__ -   Batch number = 1
01/05/2022 23:21:44 - INFO - __main__ -   Batch number = 2
01/05/2022 23:21:44 - INFO - __main__ -   Batch number = 3
01/05/2022 23:21:44 - INFO - __main__ -   Batch number = 4
01/05/2022 23:21:44 - INFO - __main__ -   Batch number = 5
01/05/2022 23:21:44 - INFO - __main__ -   Batch number = 6
01/05/2022 23:21:44 - INFO - __main__ -   Batch number = 7
01/05/2022 23:21:44 - INFO - __main__ -   Batch number = 8
01/05/2022 23:21:44 - INFO - __main__ -   Batch number = 9
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 10
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 11
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 12
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 13
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 14
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 15
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 16
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 17
01/05/2022 23:21:45 - INFO - __main__ -   Batch number = 18
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 19
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 20
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 21
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 22
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 23
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 24
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 25
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 26
01/05/2022 23:21:46 - INFO - __main__ -   Batch number = 27
01/05/2022 23:21:47 - INFO - __main__ -   Batch number = 28
01/05/2022 23:21:47 - INFO - __main__ -   Batch number = 29
01/05/2022 23:21:47 - INFO - __main__ -   Batch number = 30
01/05/2022 23:21:47 - INFO - __main__ -   Batch number = 31
01/05/2022 23:21:47 - INFO - __main__ -   Batch number = 32
01/05/2022 23:21:47 - INFO - __main__ -   Batch number = 33
01/05/2022 23:21:47 - INFO - __main__ -   Batch number = 34
01/05/2022 23:21:47 - INFO - __main__ -   Batch number = 35
01/05/2022 23:21:48 - INFO - __main__ -   Batch number = 36
01/05/2022 23:21:48 - INFO - __main__ -   Batch number = 37
01/05/2022 23:21:48 - INFO - __main__ -   Batch number = 38
01/05/2022 23:21:48 - INFO - __main__ -   Batch number = 39
01/05/2022 23:21:48 - INFO - __main__ -   Batch number = 40
01/05/2022 23:21:48 - INFO - __main__ -   Batch number = 41
01/05/2022 23:21:48 - INFO - __main__ -   Batch number = 42
01/05/2022 23:21:48 - INFO - __main__ -   Batch number = 43
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 44
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 45
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 46
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 47
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 48
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 49
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 50
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 51
01/05/2022 23:21:49 - INFO - __main__ -   Batch number = 52
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 53
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 54
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 55
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 56
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 57
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 58
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 59
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 60
01/05/2022 23:21:50 - INFO - __main__ -   Batch number = 61
01/05/2022 23:21:51 - INFO - __main__ -   Batch number = 62
01/05/2022 23:21:51 - INFO - __main__ -   Batch number = 63
01/05/2022 23:21:51 - INFO - __main__ -   Batch number = 64
01/05/2022 23:21:51 - INFO - __main__ -   Batch number = 65
01/05/2022 23:21:51 - INFO - __main__ -   Batch number = 66
01/05/2022 23:21:51 - INFO - __main__ -   Batch number = 67
01/05/2022 23:21:51 - INFO - __main__ -   Batch number = 68
01/05/2022 23:21:51 - INFO - __main__ -   Batch number = 69
01/05/2022 23:21:52 - INFO - __main__ -   Batch number = 70
01/05/2022 23:21:52 - INFO - __main__ -   Batch number = 71
01/05/2022 23:21:52 - INFO - __main__ -   Batch number = 72
01/05/2022 23:21:52 - INFO - __main__ -   Batch number = 73
01/05/2022 23:21:52 - INFO - __main__ -   Batch number = 74
01/05/2022 23:21:52 - INFO - __main__ -   Batch number = 75
01/05/2022 23:21:52 - INFO - __main__ -   Batch number = 76
01/05/2022 23:21:52 - INFO - __main__ -   Batch number = 77
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 78
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 79
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 80
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 81
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 82
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 83
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 84
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 85
01/05/2022 23:21:53 - INFO - __main__ -   Batch number = 86
01/05/2022 23:21:54 - INFO - __main__ -   Batch number = 87
01/05/2022 23:21:54 - INFO - __main__ -   Batch number = 88
01/05/2022 23:21:54 - INFO - __main__ -   Batch number = 89
01/05/2022 23:21:54 - INFO - __main__ -   Batch number = 90
01/05/2022 23:21:54 - INFO - __main__ -   Batch number = 91
01/05/2022 23:21:54 - INFO - __main__ -   Batch number = 92
01/05/2022 23:21:54 - INFO - __main__ -   Batch number = 93
01/05/2022 23:21:54 - INFO - __main__ -   Batch number = 94
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 95
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 96
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 97
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 98
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 99
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 100
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 101
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 102
01/05/2022 23:21:55 - INFO - __main__ -   Batch number = 103
01/05/2022 23:21:56 - INFO - __main__ -   Batch number = 104
01/05/2022 23:21:56 - INFO - __main__ -   Batch number = 105
01/05/2022 23:21:56 - INFO - __main__ -   Batch number = 106
01/05/2022 23:21:56 - INFO - __main__ -   Batch number = 107
01/05/2022 23:21:56 - INFO - __main__ -   Batch number = 108
01/05/2022 23:21:56 - INFO - __main__ -   Batch number = 109
01/05/2022 23:21:56 - INFO - __main__ -   Batch number = 110
01/05/2022 23:21:56 - INFO - __main__ -   Batch number = 111
01/05/2022 23:21:57 - INFO - __main__ -   Batch number = 112
01/05/2022 23:21:57 - INFO - __main__ -   Batch number = 113
01/05/2022 23:21:57 - INFO - __main__ -   Batch number = 114
01/05/2022 23:21:57 - INFO - __main__ -   Batch number = 115
01/05/2022 23:21:57 - INFO - __main__ -   Batch number = 116
01/05/2022 23:21:57 - INFO - __main__ -   Batch number = 117
01/05/2022 23:21:57 - INFO - __main__ -   Batch number = 118
01/05/2022 23:21:57 - INFO - __main__ -   Batch number = 119
01/05/2022 23:21:58 - INFO - __main__ -   Batch number = 120
01/05/2022 23:21:58 - INFO - __main__ -   Batch number = 121
01/05/2022 23:21:58 - INFO - __main__ -   Batch number = 122
01/05/2022 23:21:58 - INFO - __main__ -   Batch number = 123
01/05/2022 23:21:58 - INFO - __main__ -   Batch number = 124
01/05/2022 23:21:58 - INFO - __main__ -   Batch number = 125
01/05/2022 23:21:59 - INFO - __main__ -   ***** Evaluation result 17000 in en *****
01/05/2022 23:21:59 - INFO - __main__ -     f1 = 0.9447265441031657
01/05/2022 23:21:59 - INFO - __main__ -     loss = 0.3198302927017212
01/05/2022 23:21:59 - INFO - __main__ -     precision = 0.9445243476474214
01/05/2022 23:21:59 - INFO - __main__ -     recall = 0.944928827146748
01/05/2022 23:21:59 - INFO - __main__ -   Hit patience=11
01/05/2022 23:27:50 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:27:50 - INFO - __main__ -   ***** Running evaluation 18000 in en *****
01/05/2022 23:27:50 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:27:50 - INFO - __main__ -     Batch size = 32
01/05/2022 23:27:50 - INFO - __main__ -   Batch number = 1
01/05/2022 23:27:50 - INFO - __main__ -   Batch number = 2
01/05/2022 23:27:50 - INFO - __main__ -   Batch number = 3
01/05/2022 23:27:50 - INFO - __main__ -   Batch number = 4
01/05/2022 23:27:50 - INFO - __main__ -   Batch number = 5
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 6
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 7
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 8
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 9
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 10
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 11
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 12
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 13
01/05/2022 23:27:51 - INFO - __main__ -   Batch number = 14
01/05/2022 23:27:52 - INFO - __main__ -   Batch number = 15
01/05/2022 23:27:52 - INFO - __main__ -   Batch number = 16
01/05/2022 23:27:52 - INFO - __main__ -   Batch number = 17
01/05/2022 23:27:52 - INFO - __main__ -   Batch number = 18
01/05/2022 23:27:52 - INFO - __main__ -   Batch number = 19
01/05/2022 23:27:52 - INFO - __main__ -   Batch number = 20
01/05/2022 23:27:52 - INFO - __main__ -   Batch number = 21
01/05/2022 23:27:52 - INFO - __main__ -   Batch number = 22
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 23
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 24
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 25
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 26
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 27
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 28
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 29
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 30
01/05/2022 23:27:53 - INFO - __main__ -   Batch number = 31
01/05/2022 23:27:54 - INFO - __main__ -   Batch number = 32
01/05/2022 23:27:54 - INFO - __main__ -   Batch number = 33
01/05/2022 23:27:54 - INFO - __main__ -   Batch number = 34
01/05/2022 23:27:54 - INFO - __main__ -   Batch number = 35
01/05/2022 23:27:54 - INFO - __main__ -   Batch number = 36
01/05/2022 23:27:54 - INFO - __main__ -   Batch number = 37
01/05/2022 23:27:54 - INFO - __main__ -   Batch number = 38
01/05/2022 23:27:54 - INFO - __main__ -   Batch number = 39
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 40
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 41
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 42
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 43
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 44
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 45
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 46
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 47
01/05/2022 23:27:55 - INFO - __main__ -   Batch number = 48
01/05/2022 23:27:56 - INFO - __main__ -   Batch number = 49
01/05/2022 23:27:56 - INFO - __main__ -   Batch number = 50
01/05/2022 23:27:56 - INFO - __main__ -   Batch number = 51
01/05/2022 23:27:56 - INFO - __main__ -   Batch number = 52
01/05/2022 23:27:56 - INFO - __main__ -   Batch number = 53
01/05/2022 23:27:56 - INFO - __main__ -   Batch number = 54
01/05/2022 23:27:56 - INFO - __main__ -   Batch number = 55
01/05/2022 23:27:56 - INFO - __main__ -   Batch number = 56
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 57
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 58
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 59
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 60
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 61
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 62
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 63
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 64
01/05/2022 23:27:57 - INFO - __main__ -   Batch number = 65
01/05/2022 23:27:58 - INFO - __main__ -   Batch number = 66
01/05/2022 23:27:58 - INFO - __main__ -   Batch number = 67
01/05/2022 23:27:58 - INFO - __main__ -   Batch number = 68
01/05/2022 23:27:58 - INFO - __main__ -   Batch number = 69
01/05/2022 23:27:58 - INFO - __main__ -   Batch number = 70
01/05/2022 23:27:58 - INFO - __main__ -   Batch number = 71
01/05/2022 23:27:58 - INFO - __main__ -   Batch number = 72
01/05/2022 23:27:58 - INFO - __main__ -   Batch number = 73
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 74
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 75
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 76
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 77
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 78
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 79
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 80
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 81
01/05/2022 23:27:59 - INFO - __main__ -   Batch number = 82
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 83
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 84
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 85
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 86
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 87
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 88
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 89
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 90
01/05/2022 23:28:00 - INFO - __main__ -   Batch number = 91
01/05/2022 23:28:01 - INFO - __main__ -   Batch number = 92
01/05/2022 23:28:01 - INFO - __main__ -   Batch number = 93
01/05/2022 23:28:01 - INFO - __main__ -   Batch number = 94
01/05/2022 23:28:01 - INFO - __main__ -   Batch number = 95
01/05/2022 23:28:01 - INFO - __main__ -   Batch number = 96
01/05/2022 23:28:01 - INFO - __main__ -   Batch number = 97
01/05/2022 23:28:01 - INFO - __main__ -   Batch number = 98
01/05/2022 23:28:01 - INFO - __main__ -   Batch number = 99
01/05/2022 23:28:02 - INFO - __main__ -   Batch number = 100
01/05/2022 23:28:02 - INFO - __main__ -   Batch number = 101
01/05/2022 23:28:02 - INFO - __main__ -   Batch number = 102
01/05/2022 23:28:02 - INFO - __main__ -   Batch number = 103
01/05/2022 23:28:02 - INFO - __main__ -   Batch number = 104
01/05/2022 23:28:02 - INFO - __main__ -   Batch number = 105
01/05/2022 23:28:02 - INFO - __main__ -   Batch number = 106
01/05/2022 23:28:02 - INFO - __main__ -   Batch number = 107
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 108
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 109
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 110
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 111
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 112
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 113
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 114
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 115
01/05/2022 23:28:03 - INFO - __main__ -   Batch number = 116
01/05/2022 23:28:04 - INFO - __main__ -   Batch number = 117
01/05/2022 23:28:04 - INFO - __main__ -   Batch number = 118
01/05/2022 23:28:04 - INFO - __main__ -   Batch number = 119
01/05/2022 23:28:04 - INFO - __main__ -   Batch number = 120
01/05/2022 23:28:04 - INFO - __main__ -   Batch number = 121
01/05/2022 23:28:04 - INFO - __main__ -   Batch number = 122
01/05/2022 23:28:04 - INFO - __main__ -   Batch number = 123
01/05/2022 23:28:04 - INFO - __main__ -   Batch number = 124
01/05/2022 23:28:05 - INFO - __main__ -   Batch number = 125
01/05/2022 23:28:06 - INFO - __main__ -   ***** Evaluation result 18000 in en *****
01/05/2022 23:28:06 - INFO - __main__ -     f1 = 0.9444477737160665
01/05/2022 23:28:06 - INFO - __main__ -     loss = 0.3447964727282524
01/05/2022 23:28:06 - INFO - __main__ -     precision = 0.9440355981516344
01/05/2022 23:28:06 - INFO - __main__ -     recall = 0.9448603093578171
01/05/2022 23:28:06 - INFO - __main__ -   Hit patience=12
01/05/2022 23:33:55 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:33:56 - INFO - __main__ -   ***** Running evaluation 19000 in en *****
01/05/2022 23:33:56 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:33:56 - INFO - __main__ -     Batch size = 32
01/05/2022 23:33:56 - INFO - __main__ -   Batch number = 1
01/05/2022 23:33:56 - INFO - __main__ -   Batch number = 2
01/05/2022 23:33:56 - INFO - __main__ -   Batch number = 3
01/05/2022 23:33:56 - INFO - __main__ -   Batch number = 4
01/05/2022 23:33:56 - INFO - __main__ -   Batch number = 5
01/05/2022 23:33:56 - INFO - __main__ -   Batch number = 6
01/05/2022 23:33:56 - INFO - __main__ -   Batch number = 7
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 8
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 9
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 10
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 11
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 12
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 13
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 14
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 15
01/05/2022 23:33:57 - INFO - __main__ -   Batch number = 16
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 17
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 18
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 19
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 20
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 21
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 22
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 23
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 24
01/05/2022 23:33:58 - INFO - __main__ -   Batch number = 25
01/05/2022 23:33:59 - INFO - __main__ -   Batch number = 26
01/05/2022 23:33:59 - INFO - __main__ -   Batch number = 27
01/05/2022 23:33:59 - INFO - __main__ -   Batch number = 28
01/05/2022 23:33:59 - INFO - __main__ -   Batch number = 29
01/05/2022 23:33:59 - INFO - __main__ -   Batch number = 30
01/05/2022 23:33:59 - INFO - __main__ -   Batch number = 31
01/05/2022 23:33:59 - INFO - __main__ -   Batch number = 32
01/05/2022 23:33:59 - INFO - __main__ -   Batch number = 33
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 34
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 35
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 36
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 37
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 38
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 39
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 40
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 41
01/05/2022 23:34:00 - INFO - __main__ -   Batch number = 42
01/05/2022 23:34:01 - INFO - __main__ -   Batch number = 43
01/05/2022 23:34:01 - INFO - __main__ -   Batch number = 44
01/05/2022 23:34:01 - INFO - __main__ -   Batch number = 45
01/05/2022 23:34:01 - INFO - __main__ -   Batch number = 46
01/05/2022 23:34:01 - INFO - __main__ -   Batch number = 47
01/05/2022 23:34:01 - INFO - __main__ -   Batch number = 48
01/05/2022 23:34:01 - INFO - __main__ -   Batch number = 49
01/05/2022 23:34:01 - INFO - __main__ -   Batch number = 50
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 51
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 52
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 53
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 54
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 55
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 56
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 57
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 58
01/05/2022 23:34:02 - INFO - __main__ -   Batch number = 59
01/05/2022 23:34:03 - INFO - __main__ -   Batch number = 60
01/05/2022 23:34:03 - INFO - __main__ -   Batch number = 61
01/05/2022 23:34:03 - INFO - __main__ -   Batch number = 62
01/05/2022 23:34:03 - INFO - __main__ -   Batch number = 63
01/05/2022 23:34:03 - INFO - __main__ -   Batch number = 64
01/05/2022 23:34:03 - INFO - __main__ -   Batch number = 65
01/05/2022 23:34:03 - INFO - __main__ -   Batch number = 66
01/05/2022 23:34:03 - INFO - __main__ -   Batch number = 67
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 68
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 69
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 70
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 71
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 72
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 73
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 74
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 75
01/05/2022 23:34:04 - INFO - __main__ -   Batch number = 76
01/05/2022 23:34:05 - INFO - __main__ -   Batch number = 77
01/05/2022 23:34:05 - INFO - __main__ -   Batch number = 78
01/05/2022 23:34:05 - INFO - __main__ -   Batch number = 79
01/05/2022 23:34:05 - INFO - __main__ -   Batch number = 80
01/05/2022 23:34:05 - INFO - __main__ -   Batch number = 81
01/05/2022 23:34:05 - INFO - __main__ -   Batch number = 82
01/05/2022 23:34:05 - INFO - __main__ -   Batch number = 83
01/05/2022 23:34:05 - INFO - __main__ -   Batch number = 84
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 85
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 86
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 87
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 88
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 89
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 90
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 91
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 92
01/05/2022 23:34:06 - INFO - __main__ -   Batch number = 93
01/05/2022 23:34:07 - INFO - __main__ -   Batch number = 94
01/05/2022 23:34:07 - INFO - __main__ -   Batch number = 95
01/05/2022 23:34:07 - INFO - __main__ -   Batch number = 96
01/05/2022 23:34:07 - INFO - __main__ -   Batch number = 97
01/05/2022 23:34:07 - INFO - __main__ -   Batch number = 98
01/05/2022 23:34:07 - INFO - __main__ -   Batch number = 99
01/05/2022 23:34:07 - INFO - __main__ -   Batch number = 100
01/05/2022 23:34:07 - INFO - __main__ -   Batch number = 101
01/05/2022 23:34:08 - INFO - __main__ -   Batch number = 102
01/05/2022 23:34:08 - INFO - __main__ -   Batch number = 103
01/05/2022 23:34:08 - INFO - __main__ -   Batch number = 104
01/05/2022 23:34:08 - INFO - __main__ -   Batch number = 105
01/05/2022 23:34:08 - INFO - __main__ -   Batch number = 106
01/05/2022 23:34:08 - INFO - __main__ -   Batch number = 107
01/05/2022 23:34:08 - INFO - __main__ -   Batch number = 108
01/05/2022 23:34:08 - INFO - __main__ -   Batch number = 109
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 110
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 111
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 112
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 113
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 114
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 115
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 116
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 117
01/05/2022 23:34:09 - INFO - __main__ -   Batch number = 118
01/05/2022 23:34:10 - INFO - __main__ -   Batch number = 119
01/05/2022 23:34:10 - INFO - __main__ -   Batch number = 120
01/05/2022 23:34:10 - INFO - __main__ -   Batch number = 121
01/05/2022 23:34:10 - INFO - __main__ -   Batch number = 122
01/05/2022 23:34:10 - INFO - __main__ -   Batch number = 123
01/05/2022 23:34:10 - INFO - __main__ -   Batch number = 124
01/05/2022 23:34:10 - INFO - __main__ -   Batch number = 125
01/05/2022 23:34:12 - INFO - __main__ -   ***** Evaluation result 19000 in en *****
01/05/2022 23:34:12 - INFO - __main__ -     f1 = 0.9441738222226027
01/05/2022 23:34:12 - INFO - __main__ -     loss = 0.3603077927827835
01/05/2022 23:34:12 - INFO - __main__ -     precision = 0.943761766215985
01/05/2022 23:34:12 - INFO - __main__ -     recall = 0.9445862382020932
01/05/2022 23:34:12 - INFO - __main__ -   Hit patience=13
01/05/2022 23:40:05 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:40:05 - INFO - __main__ -   ***** Running evaluation 20000 in en *****
01/05/2022 23:40:05 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:40:05 - INFO - __main__ -     Batch size = 32
01/05/2022 23:40:05 - INFO - __main__ -   Batch number = 1
01/05/2022 23:40:05 - INFO - __main__ -   Batch number = 2
01/05/2022 23:40:05 - INFO - __main__ -   Batch number = 3
01/05/2022 23:40:05 - INFO - __main__ -   Batch number = 4
01/05/2022 23:40:05 - INFO - __main__ -   Batch number = 5
01/05/2022 23:40:05 - INFO - __main__ -   Batch number = 6
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 7
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 8
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 9
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 10
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 11
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 12
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 13
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 14
01/05/2022 23:40:06 - INFO - __main__ -   Batch number = 15
01/05/2022 23:40:07 - INFO - __main__ -   Batch number = 16
01/05/2022 23:40:07 - INFO - __main__ -   Batch number = 17
01/05/2022 23:40:07 - INFO - __main__ -   Batch number = 18
01/05/2022 23:40:07 - INFO - __main__ -   Batch number = 19
01/05/2022 23:40:07 - INFO - __main__ -   Batch number = 20
01/05/2022 23:40:07 - INFO - __main__ -   Batch number = 21
01/05/2022 23:40:07 - INFO - __main__ -   Batch number = 22
01/05/2022 23:40:07 - INFO - __main__ -   Batch number = 23
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 24
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 25
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 26
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 27
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 28
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 29
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 30
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 31
01/05/2022 23:40:08 - INFO - __main__ -   Batch number = 32
01/05/2022 23:40:09 - INFO - __main__ -   Batch number = 33
01/05/2022 23:40:09 - INFO - __main__ -   Batch number = 34
01/05/2022 23:40:09 - INFO - __main__ -   Batch number = 35
01/05/2022 23:40:09 - INFO - __main__ -   Batch number = 36
01/05/2022 23:40:09 - INFO - __main__ -   Batch number = 37
01/05/2022 23:40:09 - INFO - __main__ -   Batch number = 38
01/05/2022 23:40:09 - INFO - __main__ -   Batch number = 39
01/05/2022 23:40:09 - INFO - __main__ -   Batch number = 40
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 41
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 42
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 43
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 44
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 45
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 46
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 47
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 48
01/05/2022 23:40:10 - INFO - __main__ -   Batch number = 49
01/05/2022 23:40:11 - INFO - __main__ -   Batch number = 50
01/05/2022 23:40:11 - INFO - __main__ -   Batch number = 51
01/05/2022 23:40:11 - INFO - __main__ -   Batch number = 52
01/05/2022 23:40:11 - INFO - __main__ -   Batch number = 53
01/05/2022 23:40:11 - INFO - __main__ -   Batch number = 54
01/05/2022 23:40:11 - INFO - __main__ -   Batch number = 55
01/05/2022 23:40:11 - INFO - __main__ -   Batch number = 56
01/05/2022 23:40:11 - INFO - __main__ -   Batch number = 57
01/05/2022 23:40:12 - INFO - __main__ -   Batch number = 58
01/05/2022 23:40:12 - INFO - __main__ -   Batch number = 59
01/05/2022 23:40:12 - INFO - __main__ -   Batch number = 60
01/05/2022 23:40:12 - INFO - __main__ -   Batch number = 61
01/05/2022 23:40:12 - INFO - __main__ -   Batch number = 62
01/05/2022 23:40:12 - INFO - __main__ -   Batch number = 63
01/05/2022 23:40:12 - INFO - __main__ -   Batch number = 64
01/05/2022 23:40:12 - INFO - __main__ -   Batch number = 65
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 66
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 67
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 68
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 69
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 70
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 71
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 72
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 73
01/05/2022 23:40:13 - INFO - __main__ -   Batch number = 74
01/05/2022 23:40:14 - INFO - __main__ -   Batch number = 75
01/05/2022 23:40:14 - INFO - __main__ -   Batch number = 76
01/05/2022 23:40:14 - INFO - __main__ -   Batch number = 77
01/05/2022 23:40:14 - INFO - __main__ -   Batch number = 78
01/05/2022 23:40:14 - INFO - __main__ -   Batch number = 79
01/05/2022 23:40:14 - INFO - __main__ -   Batch number = 80
01/05/2022 23:40:14 - INFO - __main__ -   Batch number = 81
01/05/2022 23:40:14 - INFO - __main__ -   Batch number = 82
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 83
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 84
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 85
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 86
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 87
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 88
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 89
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 90
01/05/2022 23:40:15 - INFO - __main__ -   Batch number = 91
01/05/2022 23:40:16 - INFO - __main__ -   Batch number = 92
01/05/2022 23:40:16 - INFO - __main__ -   Batch number = 93
01/05/2022 23:40:16 - INFO - __main__ -   Batch number = 94
01/05/2022 23:40:16 - INFO - __main__ -   Batch number = 95
01/05/2022 23:40:16 - INFO - __main__ -   Batch number = 96
01/05/2022 23:40:16 - INFO - __main__ -   Batch number = 97
01/05/2022 23:40:16 - INFO - __main__ -   Batch number = 98
01/05/2022 23:40:16 - INFO - __main__ -   Batch number = 99
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 100
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 101
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 102
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 103
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 104
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 105
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 106
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 107
01/05/2022 23:40:17 - INFO - __main__ -   Batch number = 108
01/05/2022 23:40:18 - INFO - __main__ -   Batch number = 109
01/05/2022 23:40:18 - INFO - __main__ -   Batch number = 110
01/05/2022 23:40:18 - INFO - __main__ -   Batch number = 111
01/05/2022 23:40:18 - INFO - __main__ -   Batch number = 112
01/05/2022 23:40:18 - INFO - __main__ -   Batch number = 113
01/05/2022 23:40:18 - INFO - __main__ -   Batch number = 114
01/05/2022 23:40:18 - INFO - __main__ -   Batch number = 115
01/05/2022 23:40:18 - INFO - __main__ -   Batch number = 116
01/05/2022 23:40:19 - INFO - __main__ -   Batch number = 117
01/05/2022 23:40:19 - INFO - __main__ -   Batch number = 118
01/05/2022 23:40:19 - INFO - __main__ -   Batch number = 119
01/05/2022 23:40:19 - INFO - __main__ -   Batch number = 120
01/05/2022 23:40:19 - INFO - __main__ -   Batch number = 121
01/05/2022 23:40:19 - INFO - __main__ -   Batch number = 122
01/05/2022 23:40:19 - INFO - __main__ -   Batch number = 123
01/05/2022 23:40:19 - INFO - __main__ -   Batch number = 124
01/05/2022 23:40:20 - INFO - __main__ -   Batch number = 125
01/05/2022 23:40:21 - INFO - __main__ -   ***** Evaluation result 20000 in en *****
01/05/2022 23:40:21 - INFO - __main__ -     f1 = 0.9445319724629242
01/05/2022 23:40:21 - INFO - __main__ -     loss = 0.37099861168861387
01/05/2022 23:40:21 - INFO - __main__ -     precision = 0.9442894074543307
01/05/2022 23:40:21 - INFO - __main__ -     recall = 0.9447746621216533
01/05/2022 23:40:21 - INFO - __main__ -   Hit patience=14
01/05/2022 23:46:24 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:46:25 - INFO - __main__ -   ***** Running evaluation 21000 in en *****
01/05/2022 23:46:25 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:46:25 - INFO - __main__ -     Batch size = 32
01/05/2022 23:46:25 - INFO - __main__ -   Batch number = 1
01/05/2022 23:46:25 - INFO - __main__ -   Batch number = 2
01/05/2022 23:46:25 - INFO - __main__ -   Batch number = 3
01/05/2022 23:46:25 - INFO - __main__ -   Batch number = 4
01/05/2022 23:46:25 - INFO - __main__ -   Batch number = 5
01/05/2022 23:46:25 - INFO - __main__ -   Batch number = 6
01/05/2022 23:46:25 - INFO - __main__ -   Batch number = 7
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 8
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 9
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 10
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 11
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 12
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 13
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 14
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 15
01/05/2022 23:46:26 - INFO - __main__ -   Batch number = 16
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 17
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 18
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 19
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 20
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 21
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 22
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 23
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 24
01/05/2022 23:46:27 - INFO - __main__ -   Batch number = 25
01/05/2022 23:46:28 - INFO - __main__ -   Batch number = 26
01/05/2022 23:46:28 - INFO - __main__ -   Batch number = 27
01/05/2022 23:46:28 - INFO - __main__ -   Batch number = 28
01/05/2022 23:46:28 - INFO - __main__ -   Batch number = 29
01/05/2022 23:46:28 - INFO - __main__ -   Batch number = 30
01/05/2022 23:46:28 - INFO - __main__ -   Batch number = 31
01/05/2022 23:46:28 - INFO - __main__ -   Batch number = 32
01/05/2022 23:46:28 - INFO - __main__ -   Batch number = 33
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 34
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 35
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 36
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 37
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 38
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 39
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 40
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 41
01/05/2022 23:46:29 - INFO - __main__ -   Batch number = 42
01/05/2022 23:46:30 - INFO - __main__ -   Batch number = 43
01/05/2022 23:46:30 - INFO - __main__ -   Batch number = 44
01/05/2022 23:46:30 - INFO - __main__ -   Batch number = 45
01/05/2022 23:46:30 - INFO - __main__ -   Batch number = 46
01/05/2022 23:46:30 - INFO - __main__ -   Batch number = 47
01/05/2022 23:46:30 - INFO - __main__ -   Batch number = 48
01/05/2022 23:46:30 - INFO - __main__ -   Batch number = 49
01/05/2022 23:46:30 - INFO - __main__ -   Batch number = 50
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 51
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 52
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 53
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 54
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 55
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 56
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 57
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 58
01/05/2022 23:46:31 - INFO - __main__ -   Batch number = 59
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 60
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 61
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 62
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 63
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 64
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 65
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 66
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 67
01/05/2022 23:46:32 - INFO - __main__ -   Batch number = 68
01/05/2022 23:46:33 - INFO - __main__ -   Batch number = 69
01/05/2022 23:46:33 - INFO - __main__ -   Batch number = 70
01/05/2022 23:46:33 - INFO - __main__ -   Batch number = 71
01/05/2022 23:46:33 - INFO - __main__ -   Batch number = 72
01/05/2022 23:46:33 - INFO - __main__ -   Batch number = 73
01/05/2022 23:46:33 - INFO - __main__ -   Batch number = 74
01/05/2022 23:46:33 - INFO - __main__ -   Batch number = 75
01/05/2022 23:46:33 - INFO - __main__ -   Batch number = 76
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 77
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 78
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 79
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 80
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 81
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 82
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 83
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 84
01/05/2022 23:46:34 - INFO - __main__ -   Batch number = 85
01/05/2022 23:46:35 - INFO - __main__ -   Batch number = 86
01/05/2022 23:46:35 - INFO - __main__ -   Batch number = 87
01/05/2022 23:46:35 - INFO - __main__ -   Batch number = 88
01/05/2022 23:46:35 - INFO - __main__ -   Batch number = 89
01/05/2022 23:46:35 - INFO - __main__ -   Batch number = 90
01/05/2022 23:46:35 - INFO - __main__ -   Batch number = 91
01/05/2022 23:46:35 - INFO - __main__ -   Batch number = 92
01/05/2022 23:46:35 - INFO - __main__ -   Batch number = 93
01/05/2022 23:46:36 - INFO - __main__ -   Batch number = 94
01/05/2022 23:46:36 - INFO - __main__ -   Batch number = 95
01/05/2022 23:46:36 - INFO - __main__ -   Batch number = 96
01/05/2022 23:46:36 - INFO - __main__ -   Batch number = 97
01/05/2022 23:46:36 - INFO - __main__ -   Batch number = 98
01/05/2022 23:46:36 - INFO - __main__ -   Batch number = 99
01/05/2022 23:46:36 - INFO - __main__ -   Batch number = 100
01/05/2022 23:46:36 - INFO - __main__ -   Batch number = 101
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 102
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 103
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 104
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 105
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 106
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 107
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 108
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 109
01/05/2022 23:46:37 - INFO - __main__ -   Batch number = 110
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 111
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 112
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 113
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 114
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 115
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 116
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 117
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 118
01/05/2022 23:46:38 - INFO - __main__ -   Batch number = 119
01/05/2022 23:46:39 - INFO - __main__ -   Batch number = 120
01/05/2022 23:46:39 - INFO - __main__ -   Batch number = 121
01/05/2022 23:46:39 - INFO - __main__ -   Batch number = 122
01/05/2022 23:46:39 - INFO - __main__ -   Batch number = 123
01/05/2022 23:46:39 - INFO - __main__ -   Batch number = 124
01/05/2022 23:46:39 - INFO - __main__ -   Batch number = 125
01/05/2022 23:46:41 - INFO - __main__ -   ***** Evaluation result 21000 in en *****
01/05/2022 23:46:41 - INFO - __main__ -     f1 = 0.9441578252746687
01/05/2022 23:46:41 - INFO - __main__ -     loss = 0.39200635159015657
01/05/2022 23:46:41 - INFO - __main__ -     precision = 0.9447407686898657
01/05/2022 23:46:41 - INFO - __main__ -     recall = 0.9435756008153617
01/05/2022 23:46:41 - INFO - __main__ -   Hit patience=15
01/05/2022 23:52:45 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:52:46 - INFO - __main__ -   ***** Running evaluation 22000 in en *****
01/05/2022 23:52:46 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:52:46 - INFO - __main__ -     Batch size = 32
01/05/2022 23:52:46 - INFO - __main__ -   Batch number = 1
01/05/2022 23:52:46 - INFO - __main__ -   Batch number = 2
01/05/2022 23:52:46 - INFO - __main__ -   Batch number = 3
01/05/2022 23:52:46 - INFO - __main__ -   Batch number = 4
01/05/2022 23:52:46 - INFO - __main__ -   Batch number = 5
01/05/2022 23:52:46 - INFO - __main__ -   Batch number = 6
01/05/2022 23:52:46 - INFO - __main__ -   Batch number = 7
01/05/2022 23:52:46 - INFO - __main__ -   Batch number = 8
01/05/2022 23:52:47 - INFO - __main__ -   Batch number = 9
01/05/2022 23:52:47 - INFO - __main__ -   Batch number = 10
01/05/2022 23:52:47 - INFO - __main__ -   Batch number = 11
01/05/2022 23:52:47 - INFO - __main__ -   Batch number = 12
01/05/2022 23:52:47 - INFO - __main__ -   Batch number = 13
01/05/2022 23:52:47 - INFO - __main__ -   Batch number = 14
01/05/2022 23:52:47 - INFO - __main__ -   Batch number = 15
01/05/2022 23:52:47 - INFO - __main__ -   Batch number = 16
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 17
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 18
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 19
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 20
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 21
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 22
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 23
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 24
01/05/2022 23:52:48 - INFO - __main__ -   Batch number = 25
01/05/2022 23:52:49 - INFO - __main__ -   Batch number = 26
01/05/2022 23:52:49 - INFO - __main__ -   Batch number = 27
01/05/2022 23:52:49 - INFO - __main__ -   Batch number = 28
01/05/2022 23:52:49 - INFO - __main__ -   Batch number = 29
01/05/2022 23:52:49 - INFO - __main__ -   Batch number = 30
01/05/2022 23:52:49 - INFO - __main__ -   Batch number = 31
01/05/2022 23:52:49 - INFO - __main__ -   Batch number = 32
01/05/2022 23:52:49 - INFO - __main__ -   Batch number = 33
01/05/2022 23:52:50 - INFO - __main__ -   Batch number = 34
01/05/2022 23:52:50 - INFO - __main__ -   Batch number = 35
01/05/2022 23:52:50 - INFO - __main__ -   Batch number = 36
01/05/2022 23:52:50 - INFO - __main__ -   Batch number = 37
01/05/2022 23:52:50 - INFO - __main__ -   Batch number = 38
01/05/2022 23:52:50 - INFO - __main__ -   Batch number = 39
01/05/2022 23:52:50 - INFO - __main__ -   Batch number = 40
01/05/2022 23:52:50 - INFO - __main__ -   Batch number = 41
01/05/2022 23:52:51 - INFO - __main__ -   Batch number = 42
01/05/2022 23:52:51 - INFO - __main__ -   Batch number = 43
01/05/2022 23:52:51 - INFO - __main__ -   Batch number = 44
01/05/2022 23:52:51 - INFO - __main__ -   Batch number = 45
01/05/2022 23:52:51 - INFO - __main__ -   Batch number = 46
01/05/2022 23:52:51 - INFO - __main__ -   Batch number = 47
01/05/2022 23:52:51 - INFO - __main__ -   Batch number = 48
01/05/2022 23:52:51 - INFO - __main__ -   Batch number = 49
01/05/2022 23:52:52 - INFO - __main__ -   Batch number = 50
01/05/2022 23:52:52 - INFO - __main__ -   Batch number = 51
01/05/2022 23:52:52 - INFO - __main__ -   Batch number = 52
01/05/2022 23:52:52 - INFO - __main__ -   Batch number = 53
01/05/2022 23:52:52 - INFO - __main__ -   Batch number = 54
01/05/2022 23:52:52 - INFO - __main__ -   Batch number = 55
01/05/2022 23:52:52 - INFO - __main__ -   Batch number = 56
01/05/2022 23:52:52 - INFO - __main__ -   Batch number = 57
01/05/2022 23:52:53 - INFO - __main__ -   Batch number = 58
01/05/2022 23:52:53 - INFO - __main__ -   Batch number = 59
01/05/2022 23:52:53 - INFO - __main__ -   Batch number = 60
01/05/2022 23:52:53 - INFO - __main__ -   Batch number = 61
01/05/2022 23:52:53 - INFO - __main__ -   Batch number = 62
01/05/2022 23:52:53 - INFO - __main__ -   Batch number = 63
01/05/2022 23:52:53 - INFO - __main__ -   Batch number = 64
01/05/2022 23:52:53 - INFO - __main__ -   Batch number = 65
01/05/2022 23:52:54 - INFO - __main__ -   Batch number = 66
01/05/2022 23:52:54 - INFO - __main__ -   Batch number = 67
01/05/2022 23:52:54 - INFO - __main__ -   Batch number = 68
01/05/2022 23:52:54 - INFO - __main__ -   Batch number = 69
01/05/2022 23:52:54 - INFO - __main__ -   Batch number = 70
01/05/2022 23:52:54 - INFO - __main__ -   Batch number = 71
01/05/2022 23:52:54 - INFO - __main__ -   Batch number = 72
01/05/2022 23:52:54 - INFO - __main__ -   Batch number = 73
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 74
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 75
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 76
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 77
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 78
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 79
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 80
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 81
01/05/2022 23:52:55 - INFO - __main__ -   Batch number = 82
01/05/2022 23:52:56 - INFO - __main__ -   Batch number = 83
01/05/2022 23:52:56 - INFO - __main__ -   Batch number = 84
01/05/2022 23:52:56 - INFO - __main__ -   Batch number = 85
01/05/2022 23:52:56 - INFO - __main__ -   Batch number = 86
01/05/2022 23:52:56 - INFO - __main__ -   Batch number = 87
01/05/2022 23:52:56 - INFO - __main__ -   Batch number = 88
01/05/2022 23:52:56 - INFO - __main__ -   Batch number = 89
01/05/2022 23:52:56 - INFO - __main__ -   Batch number = 90
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 91
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 92
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 93
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 94
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 95
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 96
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 97
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 98
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 99
01/05/2022 23:52:57 - INFO - __main__ -   Batch number = 100
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 101
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 102
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 103
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 104
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 105
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 106
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 107
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 108
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 109
01/05/2022 23:52:58 - INFO - __main__ -   Batch number = 110
01/05/2022 23:52:59 - INFO - __main__ -   Batch number = 111
01/05/2022 23:52:59 - INFO - __main__ -   Batch number = 112
01/05/2022 23:52:59 - INFO - __main__ -   Batch number = 113
01/05/2022 23:52:59 - INFO - __main__ -   Batch number = 114
01/05/2022 23:52:59 - INFO - __main__ -   Batch number = 115
01/05/2022 23:52:59 - INFO - __main__ -   Batch number = 116
01/05/2022 23:52:59 - INFO - __main__ -   Batch number = 117
01/05/2022 23:52:59 - INFO - __main__ -   Batch number = 118
01/05/2022 23:53:00 - INFO - __main__ -   Batch number = 119
01/05/2022 23:53:00 - INFO - __main__ -   Batch number = 120
01/05/2022 23:53:00 - INFO - __main__ -   Batch number = 121
01/05/2022 23:53:00 - INFO - __main__ -   Batch number = 122
01/05/2022 23:53:00 - INFO - __main__ -   Batch number = 123
01/05/2022 23:53:00 - INFO - __main__ -   Batch number = 124
01/05/2022 23:53:00 - INFO - __main__ -   Batch number = 125
01/05/2022 23:53:02 - INFO - __main__ -   ***** Evaluation result 22000 in en *****
01/05/2022 23:53:02 - INFO - __main__ -     f1 = 0.9442898128720079
01/05/2022 23:53:02 - INFO - __main__ -     loss = 0.40010334891080857
01/05/2022 23:53:02 - INFO - __main__ -     precision = 0.944233206590621
01/05/2022 23:53:02 - INFO - __main__ -     recall = 0.9443464259408348
01/05/2022 23:53:02 - INFO - __main__ -   Hit patience=16
01/05/2022 23:58:59 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:58:59 - INFO - __main__ -   ***** Running evaluation 23000 in en *****
01/05/2022 23:58:59 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:58:59 - INFO - __main__ -     Batch size = 32
01/05/2022 23:58:59 - INFO - __main__ -   Batch number = 1
01/05/2022 23:58:59 - INFO - __main__ -   Batch number = 2
01/05/2022 23:58:59 - INFO - __main__ -   Batch number = 3
01/05/2022 23:58:59 - INFO - __main__ -   Batch number = 4
01/05/2022 23:58:59 - INFO - __main__ -   Batch number = 5
01/05/2022 23:59:00 - INFO - __main__ -   Batch number = 6
01/05/2022 23:59:00 - INFO - __main__ -   Batch number = 7
01/05/2022 23:59:00 - INFO - __main__ -   Batch number = 8
01/05/2022 23:59:00 - INFO - __main__ -   Batch number = 9
01/05/2022 23:59:00 - INFO - __main__ -   Batch number = 10
01/05/2022 23:59:00 - INFO - __main__ -   Batch number = 11
01/05/2022 23:59:00 - INFO - __main__ -   Batch number = 12
01/05/2022 23:59:00 - INFO - __main__ -   Batch number = 13
01/05/2022 23:59:01 - INFO - __main__ -   Batch number = 14
01/05/2022 23:59:01 - INFO - __main__ -   Batch number = 15
01/05/2022 23:59:01 - INFO - __main__ -   Batch number = 16
01/05/2022 23:59:01 - INFO - __main__ -   Batch number = 17
01/05/2022 23:59:01 - INFO - __main__ -   Batch number = 18
01/05/2022 23:59:01 - INFO - __main__ -   Batch number = 19
01/05/2022 23:59:01 - INFO - __main__ -   Batch number = 20
01/05/2022 23:59:01 - INFO - __main__ -   Batch number = 21
01/05/2022 23:59:02 - INFO - __main__ -   Batch number = 22
01/05/2022 23:59:02 - INFO - __main__ -   Batch number = 23
01/05/2022 23:59:02 - INFO - __main__ -   Batch number = 24
01/05/2022 23:59:02 - INFO - __main__ -   Batch number = 25
01/05/2022 23:59:02 - INFO - __main__ -   Batch number = 26
01/05/2022 23:59:02 - INFO - __main__ -   Batch number = 27
01/05/2022 23:59:02 - INFO - __main__ -   Batch number = 28
01/05/2022 23:59:02 - INFO - __main__ -   Batch number = 29
01/05/2022 23:59:03 - INFO - __main__ -   Batch number = 30
01/05/2022 23:59:03 - INFO - __main__ -   Batch number = 31
01/05/2022 23:59:03 - INFO - __main__ -   Batch number = 32
01/05/2022 23:59:03 - INFO - __main__ -   Batch number = 33
01/05/2022 23:59:03 - INFO - __main__ -   Batch number = 34
01/05/2022 23:59:03 - INFO - __main__ -   Batch number = 35
01/05/2022 23:59:03 - INFO - __main__ -   Batch number = 36
01/05/2022 23:59:03 - INFO - __main__ -   Batch number = 37
01/05/2022 23:59:04 - INFO - __main__ -   Batch number = 38
01/05/2022 23:59:04 - INFO - __main__ -   Batch number = 39
01/05/2022 23:59:04 - INFO - __main__ -   Batch number = 40
01/05/2022 23:59:04 - INFO - __main__ -   Batch number = 41
01/05/2022 23:59:04 - INFO - __main__ -   Batch number = 42
01/05/2022 23:59:04 - INFO - __main__ -   Batch number = 43
01/05/2022 23:59:04 - INFO - __main__ -   Batch number = 44
01/05/2022 23:59:04 - INFO - __main__ -   Batch number = 45
01/05/2022 23:59:05 - INFO - __main__ -   Batch number = 46
01/05/2022 23:59:05 - INFO - __main__ -   Batch number = 47
01/05/2022 23:59:05 - INFO - __main__ -   Batch number = 48
01/05/2022 23:59:05 - INFO - __main__ -   Batch number = 49
01/05/2022 23:59:05 - INFO - __main__ -   Batch number = 50
01/05/2022 23:59:05 - INFO - __main__ -   Batch number = 51
01/05/2022 23:59:05 - INFO - __main__ -   Batch number = 52
01/05/2022 23:59:05 - INFO - __main__ -   Batch number = 53
01/05/2022 23:59:06 - INFO - __main__ -   Batch number = 54
01/05/2022 23:59:06 - INFO - __main__ -   Batch number = 55
01/05/2022 23:59:06 - INFO - __main__ -   Batch number = 56
01/05/2022 23:59:06 - INFO - __main__ -   Batch number = 57
01/05/2022 23:59:06 - INFO - __main__ -   Batch number = 58
01/05/2022 23:59:06 - INFO - __main__ -   Batch number = 59
01/05/2022 23:59:06 - INFO - __main__ -   Batch number = 60
01/05/2022 23:59:06 - INFO - __main__ -   Batch number = 61
01/05/2022 23:59:07 - INFO - __main__ -   Batch number = 62
01/05/2022 23:59:07 - INFO - __main__ -   Batch number = 63
01/05/2022 23:59:07 - INFO - __main__ -   Batch number = 64
01/05/2022 23:59:07 - INFO - __main__ -   Batch number = 65
01/05/2022 23:59:07 - INFO - __main__ -   Batch number = 66
01/05/2022 23:59:07 - INFO - __main__ -   Batch number = 67
01/05/2022 23:59:07 - INFO - __main__ -   Batch number = 68
01/05/2022 23:59:07 - INFO - __main__ -   Batch number = 69
01/05/2022 23:59:08 - INFO - __main__ -   Batch number = 70
01/05/2022 23:59:08 - INFO - __main__ -   Batch number = 71
01/05/2022 23:59:08 - INFO - __main__ -   Batch number = 72
01/05/2022 23:59:08 - INFO - __main__ -   Batch number = 73
01/05/2022 23:59:08 - INFO - __main__ -   Batch number = 74
01/05/2022 23:59:08 - INFO - __main__ -   Batch number = 75
01/05/2022 23:59:08 - INFO - __main__ -   Batch number = 76
01/05/2022 23:59:08 - INFO - __main__ -   Batch number = 77
01/05/2022 23:59:09 - INFO - __main__ -   Batch number = 78
01/05/2022 23:59:09 - INFO - __main__ -   Batch number = 79
01/05/2022 23:59:09 - INFO - __main__ -   Batch number = 80
01/05/2022 23:59:09 - INFO - __main__ -   Batch number = 81
01/05/2022 23:59:09 - INFO - __main__ -   Batch number = 82
01/05/2022 23:59:09 - INFO - __main__ -   Batch number = 83
01/05/2022 23:59:09 - INFO - __main__ -   Batch number = 84
01/05/2022 23:59:09 - INFO - __main__ -   Batch number = 85
01/05/2022 23:59:10 - INFO - __main__ -   Batch number = 86
01/05/2022 23:59:10 - INFO - __main__ -   Batch number = 87
01/05/2022 23:59:10 - INFO - __main__ -   Batch number = 88
01/05/2022 23:59:10 - INFO - __main__ -   Batch number = 89
01/05/2022 23:59:10 - INFO - __main__ -   Batch number = 90
01/05/2022 23:59:10 - INFO - __main__ -   Batch number = 91
01/05/2022 23:59:10 - INFO - __main__ -   Batch number = 92
01/05/2022 23:59:10 - INFO - __main__ -   Batch number = 93
01/05/2022 23:59:11 - INFO - __main__ -   Batch number = 94
01/05/2022 23:59:11 - INFO - __main__ -   Batch number = 95
01/05/2022 23:59:11 - INFO - __main__ -   Batch number = 96
01/05/2022 23:59:11 - INFO - __main__ -   Batch number = 97
01/05/2022 23:59:11 - INFO - __main__ -   Batch number = 98
01/05/2022 23:59:11 - INFO - __main__ -   Batch number = 99
01/05/2022 23:59:11 - INFO - __main__ -   Batch number = 100
01/05/2022 23:59:11 - INFO - __main__ -   Batch number = 101
01/05/2022 23:59:12 - INFO - __main__ -   Batch number = 102
01/05/2022 23:59:12 - INFO - __main__ -   Batch number = 103
01/05/2022 23:59:12 - INFO - __main__ -   Batch number = 104
01/05/2022 23:59:12 - INFO - __main__ -   Batch number = 105
01/05/2022 23:59:12 - INFO - __main__ -   Batch number = 106
01/05/2022 23:59:12 - INFO - __main__ -   Batch number = 107
01/05/2022 23:59:12 - INFO - __main__ -   Batch number = 108
01/05/2022 23:59:12 - INFO - __main__ -   Batch number = 109
01/05/2022 23:59:13 - INFO - __main__ -   Batch number = 110
01/05/2022 23:59:13 - INFO - __main__ -   Batch number = 111
01/05/2022 23:59:13 - INFO - __main__ -   Batch number = 112
01/05/2022 23:59:13 - INFO - __main__ -   Batch number = 113
01/05/2022 23:59:13 - INFO - __main__ -   Batch number = 114
01/05/2022 23:59:13 - INFO - __main__ -   Batch number = 115
01/05/2022 23:59:13 - INFO - __main__ -   Batch number = 116
01/05/2022 23:59:14 - INFO - __main__ -   Batch number = 117
01/05/2022 23:59:14 - INFO - __main__ -   Batch number = 118
01/05/2022 23:59:14 - INFO - __main__ -   Batch number = 119
01/05/2022 23:59:14 - INFO - __main__ -   Batch number = 120
01/05/2022 23:59:14 - INFO - __main__ -   Batch number = 121
01/05/2022 23:59:14 - INFO - __main__ -   Batch number = 122
01/05/2022 23:59:14 - INFO - __main__ -   Batch number = 123
01/05/2022 23:59:14 - INFO - __main__ -   Batch number = 124
01/05/2022 23:59:15 - INFO - __main__ -   Batch number = 125
01/05/2022 23:59:16 - INFO - __main__ -   ***** Evaluation result 23000 in en *****
01/05/2022 23:59:16 - INFO - __main__ -     f1 = 0.9446813612152974
01/05/2022 23:59:16 - INFO - __main__ -     loss = 0.4045876771211624
01/05/2022 23:59:16 - INFO - __main__ -     precision = 0.9445195979383209
01/05/2022 23:59:16 - INFO - __main__ -     recall = 0.9448431799105843
01/05/2022 23:59:16 - INFO - __main__ -   Hit patience=17
01/06/2022 00:05:10 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:05:11 - INFO - __main__ -   ***** Running evaluation 24000 in en *****
01/06/2022 00:05:11 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:05:11 - INFO - __main__ -     Batch size = 32
01/06/2022 00:05:11 - INFO - __main__ -   Batch number = 1
01/06/2022 00:05:11 - INFO - __main__ -   Batch number = 2
01/06/2022 00:05:11 - INFO - __main__ -   Batch number = 3
01/06/2022 00:05:11 - INFO - __main__ -   Batch number = 4
01/06/2022 00:05:11 - INFO - __main__ -   Batch number = 5
01/06/2022 00:05:11 - INFO - __main__ -   Batch number = 6
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 7
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 8
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 9
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 10
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 11
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 12
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 13
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 14
01/06/2022 00:05:12 - INFO - __main__ -   Batch number = 15
01/06/2022 00:05:13 - INFO - __main__ -   Batch number = 16
01/06/2022 00:05:13 - INFO - __main__ -   Batch number = 17
01/06/2022 00:05:13 - INFO - __main__ -   Batch number = 18
01/06/2022 00:05:13 - INFO - __main__ -   Batch number = 19
01/06/2022 00:05:13 - INFO - __main__ -   Batch number = 20
01/06/2022 00:05:13 - INFO - __main__ -   Batch number = 21
01/06/2022 00:05:13 - INFO - __main__ -   Batch number = 22
01/06/2022 00:05:13 - INFO - __main__ -   Batch number = 23
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 24
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 25
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 26
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 27
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 28
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 29
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 30
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 31
01/06/2022 00:05:14 - INFO - __main__ -   Batch number = 32
01/06/2022 00:05:15 - INFO - __main__ -   Batch number = 33
01/06/2022 00:05:15 - INFO - __main__ -   Batch number = 34
01/06/2022 00:05:15 - INFO - __main__ -   Batch number = 35
01/06/2022 00:05:15 - INFO - __main__ -   Batch number = 36
01/06/2022 00:05:15 - INFO - __main__ -   Batch number = 37
01/06/2022 00:05:15 - INFO - __main__ -   Batch number = 38
01/06/2022 00:05:15 - INFO - __main__ -   Batch number = 39
01/06/2022 00:05:15 - INFO - __main__ -   Batch number = 40
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 41
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 42
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 43
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 44
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 45
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 46
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 47
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 48
01/06/2022 00:05:16 - INFO - __main__ -   Batch number = 49
01/06/2022 00:05:17 - INFO - __main__ -   Batch number = 50
01/06/2022 00:05:17 - INFO - __main__ -   Batch number = 51
01/06/2022 00:05:17 - INFO - __main__ -   Batch number = 52
01/06/2022 00:05:17 - INFO - __main__ -   Batch number = 53
01/06/2022 00:05:17 - INFO - __main__ -   Batch number = 54
01/06/2022 00:05:17 - INFO - __main__ -   Batch number = 55
01/06/2022 00:05:17 - INFO - __main__ -   Batch number = 56
01/06/2022 00:05:17 - INFO - __main__ -   Batch number = 57
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 58
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 59
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 60
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 61
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 62
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 63
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 64
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 65
01/06/2022 00:05:18 - INFO - __main__ -   Batch number = 66
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 67
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 68
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 69
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 70
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 71
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 72
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 73
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 74
01/06/2022 00:05:19 - INFO - __main__ -   Batch number = 75
01/06/2022 00:05:20 - INFO - __main__ -   Batch number = 76
01/06/2022 00:05:20 - INFO - __main__ -   Batch number = 77
01/06/2022 00:05:20 - INFO - __main__ -   Batch number = 78
01/06/2022 00:05:20 - INFO - __main__ -   Batch number = 79
01/06/2022 00:05:20 - INFO - __main__ -   Batch number = 80
01/06/2022 00:05:20 - INFO - __main__ -   Batch number = 81
01/06/2022 00:05:20 - INFO - __main__ -   Batch number = 82
01/06/2022 00:05:20 - INFO - __main__ -   Batch number = 83
01/06/2022 00:05:21 - INFO - __main__ -   Batch number = 84
01/06/2022 00:05:21 - INFO - __main__ -   Batch number = 85
01/06/2022 00:05:21 - INFO - __main__ -   Batch number = 86
01/06/2022 00:05:21 - INFO - __main__ -   Batch number = 87
01/06/2022 00:05:21 - INFO - __main__ -   Batch number = 88
01/06/2022 00:05:21 - INFO - __main__ -   Batch number = 89
01/06/2022 00:05:21 - INFO - __main__ -   Batch number = 90
01/06/2022 00:05:21 - INFO - __main__ -   Batch number = 91
01/06/2022 00:05:22 - INFO - __main__ -   Batch number = 92
01/06/2022 00:05:22 - INFO - __main__ -   Batch number = 93
01/06/2022 00:05:22 - INFO - __main__ -   Batch number = 94
01/06/2022 00:05:22 - INFO - __main__ -   Batch number = 95
01/06/2022 00:05:22 - INFO - __main__ -   Batch number = 96
01/06/2022 00:05:22 - INFO - __main__ -   Batch number = 97
01/06/2022 00:05:22 - INFO - __main__ -   Batch number = 98
01/06/2022 00:05:22 - INFO - __main__ -   Batch number = 99
01/06/2022 00:05:23 - INFO - __main__ -   Batch number = 100
01/06/2022 00:05:23 - INFO - __main__ -   Batch number = 101
01/06/2022 00:05:23 - INFO - __main__ -   Batch number = 102
01/06/2022 00:05:23 - INFO - __main__ -   Batch number = 103
01/06/2022 00:05:23 - INFO - __main__ -   Batch number = 104
01/06/2022 00:05:23 - INFO - __main__ -   Batch number = 105
01/06/2022 00:05:23 - INFO - __main__ -   Batch number = 106
01/06/2022 00:05:23 - INFO - __main__ -   Batch number = 107
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 108
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 109
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 110
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 111
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 112
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 113
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 114
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 115
01/06/2022 00:05:24 - INFO - __main__ -   Batch number = 116
01/06/2022 00:05:25 - INFO - __main__ -   Batch number = 117
01/06/2022 00:05:25 - INFO - __main__ -   Batch number = 118
01/06/2022 00:05:25 - INFO - __main__ -   Batch number = 119
01/06/2022 00:05:25 - INFO - __main__ -   Batch number = 120
01/06/2022 00:05:25 - INFO - __main__ -   Batch number = 121
01/06/2022 00:05:25 - INFO - __main__ -   Batch number = 122
01/06/2022 00:05:25 - INFO - __main__ -   Batch number = 123
01/06/2022 00:05:26 - INFO - __main__ -   Batch number = 124
01/06/2022 00:05:26 - INFO - __main__ -   Batch number = 125
01/06/2022 00:05:27 - INFO - __main__ -   ***** Evaluation result 24000 in en *****
01/06/2022 00:05:27 - INFO - __main__ -     f1 = 0.9446908337471532
01/06/2022 00:05:27 - INFO - __main__ -     loss = 0.41114771378040316
01/06/2022 00:05:27 - INFO - __main__ -     precision = 0.9443674147109673
01/06/2022 00:05:27 - INFO - __main__ -     recall = 0.9450144743829116
01/06/2022 00:05:27 - INFO - __main__ -   Hit patience=18
01/06/2022 00:11:20 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:11:20 - INFO - __main__ -   ***** Running evaluation 25000 in en *****
01/06/2022 00:11:20 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:11:20 - INFO - __main__ -     Batch size = 32
01/06/2022 00:11:20 - INFO - __main__ -   Batch number = 1
01/06/2022 00:11:20 - INFO - __main__ -   Batch number = 2
01/06/2022 00:11:20 - INFO - __main__ -   Batch number = 3
01/06/2022 00:11:20 - INFO - __main__ -   Batch number = 4
01/06/2022 00:11:21 - INFO - __main__ -   Batch number = 5
01/06/2022 00:11:21 - INFO - __main__ -   Batch number = 6
01/06/2022 00:11:21 - INFO - __main__ -   Batch number = 7
01/06/2022 00:11:21 - INFO - __main__ -   Batch number = 8
01/06/2022 00:11:21 - INFO - __main__ -   Batch number = 9
01/06/2022 00:11:21 - INFO - __main__ -   Batch number = 10
01/06/2022 00:11:21 - INFO - __main__ -   Batch number = 11
01/06/2022 00:11:21 - INFO - __main__ -   Batch number = 12
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 13
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 14
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 15
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 16
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 17
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 18
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 19
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 20
01/06/2022 00:11:22 - INFO - __main__ -   Batch number = 21
01/06/2022 00:11:23 - INFO - __main__ -   Batch number = 22
01/06/2022 00:11:23 - INFO - __main__ -   Batch number = 23
01/06/2022 00:11:23 - INFO - __main__ -   Batch number = 24
01/06/2022 00:11:23 - INFO - __main__ -   Batch number = 25
01/06/2022 00:11:23 - INFO - __main__ -   Batch number = 26
01/06/2022 00:11:23 - INFO - __main__ -   Batch number = 27
01/06/2022 00:11:23 - INFO - __main__ -   Batch number = 28
01/06/2022 00:11:23 - INFO - __main__ -   Batch number = 29
01/06/2022 00:11:24 - INFO - __main__ -   Batch number = 30
01/06/2022 00:11:24 - INFO - __main__ -   Batch number = 31
01/06/2022 00:11:24 - INFO - __main__ -   Batch number = 32
01/06/2022 00:11:24 - INFO - __main__ -   Batch number = 33
01/06/2022 00:11:24 - INFO - __main__ -   Batch number = 34
01/06/2022 00:11:24 - INFO - __main__ -   Batch number = 35
01/06/2022 00:11:24 - INFO - __main__ -   Batch number = 36
01/06/2022 00:11:24 - INFO - __main__ -   Batch number = 37
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 38
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 39
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 40
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 41
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 42
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 43
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 44
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 45
01/06/2022 00:11:25 - INFO - __main__ -   Batch number = 46
01/06/2022 00:11:26 - INFO - __main__ -   Batch number = 47
01/06/2022 00:11:26 - INFO - __main__ -   Batch number = 48
01/06/2022 00:11:26 - INFO - __main__ -   Batch number = 49
01/06/2022 00:11:26 - INFO - __main__ -   Batch number = 50
01/06/2022 00:11:26 - INFO - __main__ -   Batch number = 51
01/06/2022 00:11:26 - INFO - __main__ -   Batch number = 52
01/06/2022 00:11:26 - INFO - __main__ -   Batch number = 53
01/06/2022 00:11:26 - INFO - __main__ -   Batch number = 54
01/06/2022 00:11:27 - INFO - __main__ -   Batch number = 55
01/06/2022 00:11:27 - INFO - __main__ -   Batch number = 56
01/06/2022 00:11:27 - INFO - __main__ -   Batch number = 57
01/06/2022 00:11:27 - INFO - __main__ -   Batch number = 58
01/06/2022 00:11:27 - INFO - __main__ -   Batch number = 59
01/06/2022 00:11:27 - INFO - __main__ -   Batch number = 60
01/06/2022 00:11:27 - INFO - __main__ -   Batch number = 61
01/06/2022 00:11:27 - INFO - __main__ -   Batch number = 62
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 63
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 64
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 65
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 66
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 67
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 68
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 69
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 70
01/06/2022 00:11:28 - INFO - __main__ -   Batch number = 71
01/06/2022 00:11:29 - INFO - __main__ -   Batch number = 72
01/06/2022 00:11:29 - INFO - __main__ -   Batch number = 73
01/06/2022 00:11:29 - INFO - __main__ -   Batch number = 74
01/06/2022 00:11:29 - INFO - __main__ -   Batch number = 75
01/06/2022 00:11:29 - INFO - __main__ -   Batch number = 76
01/06/2022 00:11:29 - INFO - __main__ -   Batch number = 77
01/06/2022 00:11:29 - INFO - __main__ -   Batch number = 78
01/06/2022 00:11:29 - INFO - __main__ -   Batch number = 79
01/06/2022 00:11:30 - INFO - __main__ -   Batch number = 80
01/06/2022 00:11:30 - INFO - __main__ -   Batch number = 81
01/06/2022 00:11:30 - INFO - __main__ -   Batch number = 82
01/06/2022 00:11:30 - INFO - __main__ -   Batch number = 83
01/06/2022 00:11:30 - INFO - __main__ -   Batch number = 84
01/06/2022 00:11:30 - INFO - __main__ -   Batch number = 85
01/06/2022 00:11:30 - INFO - __main__ -   Batch number = 86
01/06/2022 00:11:30 - INFO - __main__ -   Batch number = 87
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 88
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 89
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 90
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 91
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 92
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 93
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 94
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 95
01/06/2022 00:11:31 - INFO - __main__ -   Batch number = 96
01/06/2022 00:11:32 - INFO - __main__ -   Batch number = 97
01/06/2022 00:11:32 - INFO - __main__ -   Batch number = 98
01/06/2022 00:11:32 - INFO - __main__ -   Batch number = 99
01/06/2022 00:11:32 - INFO - __main__ -   Batch number = 100
01/06/2022 00:11:32 - INFO - __main__ -   Batch number = 101
01/06/2022 00:11:32 - INFO - __main__ -   Batch number = 102
01/06/2022 00:11:32 - INFO - __main__ -   Batch number = 103
01/06/2022 00:11:32 - INFO - __main__ -   Batch number = 104
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 105
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 106
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 107
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 108
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 109
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 110
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 111
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 112
01/06/2022 00:11:33 - INFO - __main__ -   Batch number = 113
01/06/2022 00:11:34 - INFO - __main__ -   Batch number = 114
01/06/2022 00:11:34 - INFO - __main__ -   Batch number = 115
01/06/2022 00:11:34 - INFO - __main__ -   Batch number = 116
01/06/2022 00:11:34 - INFO - __main__ -   Batch number = 117
01/06/2022 00:11:34 - INFO - __main__ -   Batch number = 118
01/06/2022 00:11:34 - INFO - __main__ -   Batch number = 119
01/06/2022 00:11:34 - INFO - __main__ -   Batch number = 120
01/06/2022 00:11:34 - INFO - __main__ -   Batch number = 121
01/06/2022 00:11:35 - INFO - __main__ -   Batch number = 122
01/06/2022 00:11:35 - INFO - __main__ -   Batch number = 123
01/06/2022 00:11:35 - INFO - __main__ -   Batch number = 124
01/06/2022 00:11:35 - INFO - __main__ -   Batch number = 125
01/06/2022 00:11:36 - INFO - __main__ -   ***** Evaluation result 25000 in en *****
01/06/2022 00:11:36 - INFO - __main__ -     f1 = 0.9447736146311391
01/06/2022 00:11:36 - INFO - __main__ -     loss = 0.4198463537395
01/06/2022 00:11:36 - INFO - __main__ -     precision = 0.944498656121069
01/06/2022 00:11:36 - INFO - __main__ -     recall = 0.9450487332773772
01/06/2022 00:11:36 - INFO - __main__ -   Hit patience=19
01/06/2022 00:17:39 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:17:39 - INFO - __main__ -   ***** Running evaluation 26000 in en *****
01/06/2022 00:17:39 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:17:39 - INFO - __main__ -     Batch size = 32
01/06/2022 00:17:39 - INFO - __main__ -   Batch number = 1
01/06/2022 00:17:39 - INFO - __main__ -   Batch number = 2
01/06/2022 00:17:39 - INFO - __main__ -   Batch number = 3
01/06/2022 00:17:39 - INFO - __main__ -   Batch number = 4
01/06/2022 00:17:39 - INFO - __main__ -   Batch number = 5
01/06/2022 00:17:39 - INFO - __main__ -   Batch number = 6
01/06/2022 00:17:40 - INFO - __main__ -   Batch number = 7
01/06/2022 00:17:40 - INFO - __main__ -   Batch number = 8
01/06/2022 00:17:40 - INFO - __main__ -   Batch number = 9
01/06/2022 00:17:40 - INFO - __main__ -   Batch number = 10
01/06/2022 00:17:40 - INFO - __main__ -   Batch number = 11
01/06/2022 00:17:40 - INFO - __main__ -   Batch number = 12
01/06/2022 00:17:40 - INFO - __main__ -   Batch number = 13
01/06/2022 00:17:40 - INFO - __main__ -   Batch number = 14
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 15
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 16
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 17
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 18
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 19
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 20
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 21
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 22
01/06/2022 00:17:41 - INFO - __main__ -   Batch number = 23
01/06/2022 00:17:42 - INFO - __main__ -   Batch number = 24
01/06/2022 00:17:42 - INFO - __main__ -   Batch number = 25
01/06/2022 00:17:42 - INFO - __main__ -   Batch number = 26
01/06/2022 00:17:42 - INFO - __main__ -   Batch number = 27
01/06/2022 00:17:42 - INFO - __main__ -   Batch number = 28
01/06/2022 00:17:42 - INFO - __main__ -   Batch number = 29
01/06/2022 00:17:42 - INFO - __main__ -   Batch number = 30
01/06/2022 00:17:42 - INFO - __main__ -   Batch number = 31
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 32
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 33
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 34
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 35
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 36
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 37
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 38
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 39
01/06/2022 00:17:43 - INFO - __main__ -   Batch number = 40
01/06/2022 00:17:44 - INFO - __main__ -   Batch number = 41
01/06/2022 00:17:44 - INFO - __main__ -   Batch number = 42
01/06/2022 00:17:44 - INFO - __main__ -   Batch number = 43
01/06/2022 00:17:44 - INFO - __main__ -   Batch number = 44
01/06/2022 00:17:44 - INFO - __main__ -   Batch number = 45
01/06/2022 00:17:44 - INFO - __main__ -   Batch number = 46
01/06/2022 00:17:44 - INFO - __main__ -   Batch number = 47
01/06/2022 00:17:44 - INFO - __main__ -   Batch number = 48
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 49
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 50
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 51
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 52
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 53
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 54
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 55
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 56
01/06/2022 00:17:45 - INFO - __main__ -   Batch number = 57
01/06/2022 00:17:46 - INFO - __main__ -   Batch number = 58
01/06/2022 00:17:46 - INFO - __main__ -   Batch number = 59
01/06/2022 00:17:46 - INFO - __main__ -   Batch number = 60
01/06/2022 00:17:46 - INFO - __main__ -   Batch number = 61
01/06/2022 00:17:46 - INFO - __main__ -   Batch number = 62
01/06/2022 00:17:46 - INFO - __main__ -   Batch number = 63
01/06/2022 00:17:46 - INFO - __main__ -   Batch number = 64
01/06/2022 00:17:46 - INFO - __main__ -   Batch number = 65
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 66
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 67
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 68
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 69
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 70
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 71
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 72
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 73
01/06/2022 00:17:47 - INFO - __main__ -   Batch number = 74
01/06/2022 00:17:48 - INFO - __main__ -   Batch number = 75
01/06/2022 00:17:48 - INFO - __main__ -   Batch number = 76
01/06/2022 00:17:48 - INFO - __main__ -   Batch number = 77
01/06/2022 00:17:48 - INFO - __main__ -   Batch number = 78
01/06/2022 00:17:48 - INFO - __main__ -   Batch number = 79
01/06/2022 00:17:48 - INFO - __main__ -   Batch number = 80
01/06/2022 00:17:48 - INFO - __main__ -   Batch number = 81
01/06/2022 00:17:48 - INFO - __main__ -   Batch number = 82
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 83
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 84
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 85
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 86
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 87
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 88
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 89
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 90
01/06/2022 00:17:49 - INFO - __main__ -   Batch number = 91
01/06/2022 00:17:50 - INFO - __main__ -   Batch number = 92
01/06/2022 00:17:50 - INFO - __main__ -   Batch number = 93
01/06/2022 00:17:50 - INFO - __main__ -   Batch number = 94
01/06/2022 00:17:50 - INFO - __main__ -   Batch number = 95
01/06/2022 00:17:50 - INFO - __main__ -   Batch number = 96
01/06/2022 00:17:50 - INFO - __main__ -   Batch number = 97
01/06/2022 00:17:50 - INFO - __main__ -   Batch number = 98
01/06/2022 00:17:50 - INFO - __main__ -   Batch number = 99
01/06/2022 00:17:51 - INFO - __main__ -   Batch number = 100
01/06/2022 00:17:51 - INFO - __main__ -   Batch number = 101
01/06/2022 00:17:51 - INFO - __main__ -   Batch number = 102
01/06/2022 00:17:51 - INFO - __main__ -   Batch number = 103
01/06/2022 00:17:51 - INFO - __main__ -   Batch number = 104
01/06/2022 00:17:51 - INFO - __main__ -   Batch number = 105
01/06/2022 00:17:51 - INFO - __main__ -   Batch number = 106
01/06/2022 00:17:51 - INFO - __main__ -   Batch number = 107
01/06/2022 00:17:52 - INFO - __main__ -   Batch number = 108
01/06/2022 00:17:52 - INFO - __main__ -   Batch number = 109
01/06/2022 00:17:52 - INFO - __main__ -   Batch number = 110
01/06/2022 00:17:52 - INFO - __main__ -   Batch number = 111
01/06/2022 00:17:52 - INFO - __main__ -   Batch number = 112
01/06/2022 00:17:52 - INFO - __main__ -   Batch number = 113
01/06/2022 00:17:52 - INFO - __main__ -   Batch number = 114
01/06/2022 00:17:52 - INFO - __main__ -   Batch number = 115
01/06/2022 00:17:53 - INFO - __main__ -   Batch number = 116
01/06/2022 00:17:53 - INFO - __main__ -   Batch number = 117
01/06/2022 00:17:53 - INFO - __main__ -   Batch number = 118
01/06/2022 00:17:53 - INFO - __main__ -   Batch number = 119
01/06/2022 00:17:53 - INFO - __main__ -   Batch number = 120
01/06/2022 00:17:53 - INFO - __main__ -   Batch number = 121
01/06/2022 00:17:53 - INFO - __main__ -   Batch number = 122
01/06/2022 00:17:53 - INFO - __main__ -   Batch number = 123
01/06/2022 00:17:54 - INFO - __main__ -   Batch number = 124
01/06/2022 00:17:54 - INFO - __main__ -   Batch number = 125
01/06/2022 00:17:55 - INFO - __main__ -   ***** Evaluation result 26000 in en *****
01/06/2022 00:17:55 - INFO - __main__ -     f1 = 0.9447641557907718
01/06/2022 00:17:55 - INFO - __main__ -     loss = 0.4273519796133041
01/06/2022 00:17:55 - INFO - __main__ -     precision = 0.9446508999366362
01/06/2022 00:17:55 - INFO - __main__ -     recall = 0.9448774388050497
01/06/2022 00:17:55 - INFO - __main__ -   Hit patience=20
01/06/2022 00:24:01 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:24:01 - INFO - __main__ -   ***** Running evaluation 27000 in en *****
01/06/2022 00:24:01 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:24:01 - INFO - __main__ -     Batch size = 32
01/06/2022 00:24:01 - INFO - __main__ -   Batch number = 1
01/06/2022 00:24:01 - INFO - __main__ -   Batch number = 2
01/06/2022 00:24:01 - INFO - __main__ -   Batch number = 3
01/06/2022 00:24:01 - INFO - __main__ -   Batch number = 4
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 5
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 6
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 7
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 8
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 9
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 10
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 11
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 12
01/06/2022 00:24:02 - INFO - __main__ -   Batch number = 13
01/06/2022 00:24:03 - INFO - __main__ -   Batch number = 14
01/06/2022 00:24:03 - INFO - __main__ -   Batch number = 15
01/06/2022 00:24:03 - INFO - __main__ -   Batch number = 16
01/06/2022 00:24:03 - INFO - __main__ -   Batch number = 17
01/06/2022 00:24:03 - INFO - __main__ -   Batch number = 18
01/06/2022 00:24:03 - INFO - __main__ -   Batch number = 19
01/06/2022 00:24:03 - INFO - __main__ -   Batch number = 20
01/06/2022 00:24:03 - INFO - __main__ -   Batch number = 21
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 22
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 23
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 24
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 25
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 26
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 27
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 28
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 29
01/06/2022 00:24:04 - INFO - __main__ -   Batch number = 30
01/06/2022 00:24:05 - INFO - __main__ -   Batch number = 31
01/06/2022 00:24:05 - INFO - __main__ -   Batch number = 32
01/06/2022 00:24:05 - INFO - __main__ -   Batch number = 33
01/06/2022 00:24:05 - INFO - __main__ -   Batch number = 34
01/06/2022 00:24:05 - INFO - __main__ -   Batch number = 35
01/06/2022 00:24:05 - INFO - __main__ -   Batch number = 36
01/06/2022 00:24:05 - INFO - __main__ -   Batch number = 37
01/06/2022 00:24:05 - INFO - __main__ -   Batch number = 38
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 39
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 40
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 41
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 42
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 43
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 44
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 45
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 46
01/06/2022 00:24:06 - INFO - __main__ -   Batch number = 47
01/06/2022 00:24:07 - INFO - __main__ -   Batch number = 48
01/06/2022 00:24:07 - INFO - __main__ -   Batch number = 49
01/06/2022 00:24:07 - INFO - __main__ -   Batch number = 50
01/06/2022 00:24:07 - INFO - __main__ -   Batch number = 51
01/06/2022 00:24:07 - INFO - __main__ -   Batch number = 52
01/06/2022 00:24:07 - INFO - __main__ -   Batch number = 53
01/06/2022 00:24:07 - INFO - __main__ -   Batch number = 54
01/06/2022 00:24:07 - INFO - __main__ -   Batch number = 55
01/06/2022 00:24:08 - INFO - __main__ -   Batch number = 56
01/06/2022 00:24:08 - INFO - __main__ -   Batch number = 57
01/06/2022 00:24:08 - INFO - __main__ -   Batch number = 58
01/06/2022 00:24:08 - INFO - __main__ -   Batch number = 59
01/06/2022 00:24:08 - INFO - __main__ -   Batch number = 60
01/06/2022 00:24:08 - INFO - __main__ -   Batch number = 61
01/06/2022 00:24:08 - INFO - __main__ -   Batch number = 62
01/06/2022 00:24:08 - INFO - __main__ -   Batch number = 63
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 64
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 65
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 66
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 67
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 68
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 69
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 70
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 71
01/06/2022 00:24:09 - INFO - __main__ -   Batch number = 72
01/06/2022 00:24:10 - INFO - __main__ -   Batch number = 73
01/06/2022 00:24:10 - INFO - __main__ -   Batch number = 74
01/06/2022 00:24:10 - INFO - __main__ -   Batch number = 75
01/06/2022 00:24:10 - INFO - __main__ -   Batch number = 76
01/06/2022 00:24:10 - INFO - __main__ -   Batch number = 77
01/06/2022 00:24:10 - INFO - __main__ -   Batch number = 78
01/06/2022 00:24:10 - INFO - __main__ -   Batch number = 79
01/06/2022 00:24:10 - INFO - __main__ -   Batch number = 80
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 81
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 82
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 83
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 84
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 85
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 86
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 87
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 88
01/06/2022 00:24:11 - INFO - __main__ -   Batch number = 89
01/06/2022 00:24:12 - INFO - __main__ -   Batch number = 90
01/06/2022 00:24:12 - INFO - __main__ -   Batch number = 91
01/06/2022 00:24:12 - INFO - __main__ -   Batch number = 92
01/06/2022 00:24:12 - INFO - __main__ -   Batch number = 93
01/06/2022 00:24:12 - INFO - __main__ -   Batch number = 94
01/06/2022 00:24:12 - INFO - __main__ -   Batch number = 95
01/06/2022 00:24:12 - INFO - __main__ -   Batch number = 96
01/06/2022 00:24:12 - INFO - __main__ -   Batch number = 97
01/06/2022 00:24:13 - INFO - __main__ -   Batch number = 98
01/06/2022 00:24:13 - INFO - __main__ -   Batch number = 99
01/06/2022 00:24:13 - INFO - __main__ -   Batch number = 100
01/06/2022 00:24:13 - INFO - __main__ -   Batch number = 101
01/06/2022 00:24:13 - INFO - __main__ -   Batch number = 102
01/06/2022 00:24:13 - INFO - __main__ -   Batch number = 103
01/06/2022 00:24:13 - INFO - __main__ -   Batch number = 104
01/06/2022 00:24:13 - INFO - __main__ -   Batch number = 105
01/06/2022 00:24:14 - INFO - __main__ -   Batch number = 106
01/06/2022 00:24:14 - INFO - __main__ -   Batch number = 107
01/06/2022 00:24:14 - INFO - __main__ -   Batch number = 108
01/06/2022 00:24:14 - INFO - __main__ -   Batch number = 109
01/06/2022 00:24:14 - INFO - __main__ -   Batch number = 110
01/06/2022 00:24:14 - INFO - __main__ -   Batch number = 111
01/06/2022 00:24:14 - INFO - __main__ -   Batch number = 112
01/06/2022 00:24:14 - INFO - __main__ -   Batch number = 113
01/06/2022 00:24:15 - INFO - __main__ -   Batch number = 114
01/06/2022 00:24:15 - INFO - __main__ -   Batch number = 115
01/06/2022 00:24:15 - INFO - __main__ -   Batch number = 116
01/06/2022 00:24:15 - INFO - __main__ -   Batch number = 117
01/06/2022 00:24:15 - INFO - __main__ -   Batch number = 118
01/06/2022 00:24:15 - INFO - __main__ -   Batch number = 119
01/06/2022 00:24:15 - INFO - __main__ -   Batch number = 120
01/06/2022 00:24:15 - INFO - __main__ -   Batch number = 121
01/06/2022 00:24:16 - INFO - __main__ -   Batch number = 122
01/06/2022 00:24:16 - INFO - __main__ -   Batch number = 123
01/06/2022 00:24:16 - INFO - __main__ -   Batch number = 124
01/06/2022 00:24:16 - INFO - __main__ -   Batch number = 125
01/06/2022 00:24:17 - INFO - __main__ -   ***** Evaluation result 27000 in en *****
01/06/2022 00:24:17 - INFO - __main__ -     f1 = 0.9451898788371795
01/06/2022 00:24:17 - INFO - __main__ -     loss = 0.43415765672922135
01/06/2022 00:24:17 - INFO - __main__ -     precision = 0.9449714070472212
01/06/2022 00:24:17 - INFO - __main__ -     recall = 0.9454084516692647
01/06/2022 00:24:17 - INFO - __main__ -   Hit patience=21
01/06/2022 00:30:08 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:30:08 - INFO - __main__ -   ***** Running evaluation 28000 in en *****
01/06/2022 00:30:08 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:30:08 - INFO - __main__ -     Batch size = 32
01/06/2022 00:30:08 - INFO - __main__ -   Batch number = 1
01/06/2022 00:30:08 - INFO - __main__ -   Batch number = 2
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 3
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 4
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 5
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 6
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 7
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 8
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 9
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 10
01/06/2022 00:30:09 - INFO - __main__ -   Batch number = 11
01/06/2022 00:30:10 - INFO - __main__ -   Batch number = 12
01/06/2022 00:30:10 - INFO - __main__ -   Batch number = 13
01/06/2022 00:30:10 - INFO - __main__ -   Batch number = 14
01/06/2022 00:30:10 - INFO - __main__ -   Batch number = 15
01/06/2022 00:30:10 - INFO - __main__ -   Batch number = 16
01/06/2022 00:30:10 - INFO - __main__ -   Batch number = 17
01/06/2022 00:30:10 - INFO - __main__ -   Batch number = 18
01/06/2022 00:30:10 - INFO - __main__ -   Batch number = 19
01/06/2022 00:30:11 - INFO - __main__ -   Batch number = 20
01/06/2022 00:30:11 - INFO - __main__ -   Batch number = 21
01/06/2022 00:30:11 - INFO - __main__ -   Batch number = 22
01/06/2022 00:30:11 - INFO - __main__ -   Batch number = 23
01/06/2022 00:30:11 - INFO - __main__ -   Batch number = 24
01/06/2022 00:30:11 - INFO - __main__ -   Batch number = 25
01/06/2022 00:30:11 - INFO - __main__ -   Batch number = 26
01/06/2022 00:30:11 - INFO - __main__ -   Batch number = 27
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 28
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 29
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 30
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 31
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 32
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 33
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 34
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 35
01/06/2022 00:30:12 - INFO - __main__ -   Batch number = 36
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 37
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 38
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 39
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 40
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 41
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 42
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 43
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 44
01/06/2022 00:30:13 - INFO - __main__ -   Batch number = 45
01/06/2022 00:30:14 - INFO - __main__ -   Batch number = 46
01/06/2022 00:30:14 - INFO - __main__ -   Batch number = 47
01/06/2022 00:30:14 - INFO - __main__ -   Batch number = 48
01/06/2022 00:30:14 - INFO - __main__ -   Batch number = 49
01/06/2022 00:30:14 - INFO - __main__ -   Batch number = 50
01/06/2022 00:30:14 - INFO - __main__ -   Batch number = 51
01/06/2022 00:30:14 - INFO - __main__ -   Batch number = 52
01/06/2022 00:30:14 - INFO - __main__ -   Batch number = 53
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 54
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 55
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 56
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 57
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 58
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 59
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 60
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 61
01/06/2022 00:30:15 - INFO - __main__ -   Batch number = 62
01/06/2022 00:30:16 - INFO - __main__ -   Batch number = 63
01/06/2022 00:30:16 - INFO - __main__ -   Batch number = 64
01/06/2022 00:30:16 - INFO - __main__ -   Batch number = 65
01/06/2022 00:30:16 - INFO - __main__ -   Batch number = 66
01/06/2022 00:30:16 - INFO - __main__ -   Batch number = 67
01/06/2022 00:30:16 - INFO - __main__ -   Batch number = 68
01/06/2022 00:30:16 - INFO - __main__ -   Batch number = 69
01/06/2022 00:30:16 - INFO - __main__ -   Batch number = 70
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 71
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 72
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 73
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 74
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 75
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 76
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 77
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 78
01/06/2022 00:30:17 - INFO - __main__ -   Batch number = 79
01/06/2022 00:30:18 - INFO - __main__ -   Batch number = 80
01/06/2022 00:30:18 - INFO - __main__ -   Batch number = 81
01/06/2022 00:30:18 - INFO - __main__ -   Batch number = 82
01/06/2022 00:30:18 - INFO - __main__ -   Batch number = 83
01/06/2022 00:30:18 - INFO - __main__ -   Batch number = 84
01/06/2022 00:30:18 - INFO - __main__ -   Batch number = 85
01/06/2022 00:30:18 - INFO - __main__ -   Batch number = 86
01/06/2022 00:30:18 - INFO - __main__ -   Batch number = 87
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 88
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 89
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 90
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 91
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 92
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 93
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 94
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 95
01/06/2022 00:30:19 - INFO - __main__ -   Batch number = 96
01/06/2022 00:30:20 - INFO - __main__ -   Batch number = 97
01/06/2022 00:30:20 - INFO - __main__ -   Batch number = 98
01/06/2022 00:30:20 - INFO - __main__ -   Batch number = 99
01/06/2022 00:30:20 - INFO - __main__ -   Batch number = 100
01/06/2022 00:30:20 - INFO - __main__ -   Batch number = 101
01/06/2022 00:30:20 - INFO - __main__ -   Batch number = 102
01/06/2022 00:30:20 - INFO - __main__ -   Batch number = 103
01/06/2022 00:30:20 - INFO - __main__ -   Batch number = 104
01/06/2022 00:30:21 - INFO - __main__ -   Batch number = 105
01/06/2022 00:30:21 - INFO - __main__ -   Batch number = 106
01/06/2022 00:30:21 - INFO - __main__ -   Batch number = 107
01/06/2022 00:30:21 - INFO - __main__ -   Batch number = 108
01/06/2022 00:30:21 - INFO - __main__ -   Batch number = 109
01/06/2022 00:30:21 - INFO - __main__ -   Batch number = 110
01/06/2022 00:30:21 - INFO - __main__ -   Batch number = 111
01/06/2022 00:30:21 - INFO - __main__ -   Batch number = 112
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 113
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 114
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 115
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 116
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 117
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 118
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 119
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 120
01/06/2022 00:30:22 - INFO - __main__ -   Batch number = 121
01/06/2022 00:30:23 - INFO - __main__ -   Batch number = 122
01/06/2022 00:30:23 - INFO - __main__ -   Batch number = 123
01/06/2022 00:30:23 - INFO - __main__ -   Batch number = 124
01/06/2022 00:30:23 - INFO - __main__ -   Batch number = 125
01/06/2022 00:30:24 - INFO - __main__ -   ***** Evaluation result 28000 in en *****
01/06/2022 00:30:24 - INFO - __main__ -     f1 = 0.9454947087229015
01/06/2022 00:30:24 - INFO - __main__ -     loss = 0.4372801317572594
01/06/2022 00:30:24 - INFO - __main__ -     precision = 0.9451871886608351
01/06/2022 00:30:24 - INFO - __main__ -     recall = 0.9458024289556176
01/06/2022 00:30:24 - INFO - __main__ -   Hit patience=22
01/06/2022 00:36:19 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:36:19 - INFO - __main__ -   ***** Running evaluation 29000 in en *****
01/06/2022 00:36:19 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:36:19 - INFO - __main__ -     Batch size = 32
01/06/2022 00:36:19 - INFO - __main__ -   Batch number = 1
01/06/2022 00:36:19 - INFO - __main__ -   Batch number = 2
01/06/2022 00:36:19 - INFO - __main__ -   Batch number = 3
01/06/2022 00:36:20 - INFO - __main__ -   Batch number = 4
01/06/2022 00:36:20 - INFO - __main__ -   Batch number = 5
01/06/2022 00:36:20 - INFO - __main__ -   Batch number = 6
01/06/2022 00:36:20 - INFO - __main__ -   Batch number = 7
01/06/2022 00:36:20 - INFO - __main__ -   Batch number = 8
01/06/2022 00:36:20 - INFO - __main__ -   Batch number = 9
01/06/2022 00:36:20 - INFO - __main__ -   Batch number = 10
01/06/2022 00:36:20 - INFO - __main__ -   Batch number = 11
01/06/2022 00:36:21 - INFO - __main__ -   Batch number = 12
01/06/2022 00:36:21 - INFO - __main__ -   Batch number = 13
01/06/2022 00:36:21 - INFO - __main__ -   Batch number = 14
01/06/2022 00:36:21 - INFO - __main__ -   Batch number = 15
01/06/2022 00:36:21 - INFO - __main__ -   Batch number = 16
01/06/2022 00:36:21 - INFO - __main__ -   Batch number = 17
01/06/2022 00:36:21 - INFO - __main__ -   Batch number = 18
01/06/2022 00:36:21 - INFO - __main__ -   Batch number = 19
01/06/2022 00:36:22 - INFO - __main__ -   Batch number = 20
01/06/2022 00:36:22 - INFO - __main__ -   Batch number = 21
01/06/2022 00:36:22 - INFO - __main__ -   Batch number = 22
01/06/2022 00:36:22 - INFO - __main__ -   Batch number = 23
01/06/2022 00:36:22 - INFO - __main__ -   Batch number = 24
01/06/2022 00:36:22 - INFO - __main__ -   Batch number = 25
01/06/2022 00:36:22 - INFO - __main__ -   Batch number = 26
01/06/2022 00:36:22 - INFO - __main__ -   Batch number = 27
01/06/2022 00:36:23 - INFO - __main__ -   Batch number = 28
01/06/2022 00:36:23 - INFO - __main__ -   Batch number = 29
01/06/2022 00:36:23 - INFO - __main__ -   Batch number = 30
01/06/2022 00:36:23 - INFO - __main__ -   Batch number = 31
01/06/2022 00:36:23 - INFO - __main__ -   Batch number = 32
01/06/2022 00:36:23 - INFO - __main__ -   Batch number = 33
01/06/2022 00:36:23 - INFO - __main__ -   Batch number = 34
01/06/2022 00:36:23 - INFO - __main__ -   Batch number = 35
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 36
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 37
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 38
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 39
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 40
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 41
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 42
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 43
01/06/2022 00:36:24 - INFO - __main__ -   Batch number = 44
01/06/2022 00:36:25 - INFO - __main__ -   Batch number = 45
01/06/2022 00:36:25 - INFO - __main__ -   Batch number = 46
01/06/2022 00:36:25 - INFO - __main__ -   Batch number = 47
01/06/2022 00:36:25 - INFO - __main__ -   Batch number = 48
01/06/2022 00:36:25 - INFO - __main__ -   Batch number = 49
01/06/2022 00:36:25 - INFO - __main__ -   Batch number = 50
01/06/2022 00:36:25 - INFO - __main__ -   Batch number = 51
01/06/2022 00:36:25 - INFO - __main__ -   Batch number = 52
01/06/2022 00:36:26 - INFO - __main__ -   Batch number = 53
01/06/2022 00:36:26 - INFO - __main__ -   Batch number = 54
01/06/2022 00:36:26 - INFO - __main__ -   Batch number = 55
01/06/2022 00:36:26 - INFO - __main__ -   Batch number = 56
01/06/2022 00:36:26 - INFO - __main__ -   Batch number = 57
01/06/2022 00:36:26 - INFO - __main__ -   Batch number = 58
01/06/2022 00:36:26 - INFO - __main__ -   Batch number = 59
01/06/2022 00:36:26 - INFO - __main__ -   Batch number = 60
01/06/2022 00:36:27 - INFO - __main__ -   Batch number = 61
01/06/2022 00:36:27 - INFO - __main__ -   Batch number = 62
01/06/2022 00:36:27 - INFO - __main__ -   Batch number = 63
01/06/2022 00:36:27 - INFO - __main__ -   Batch number = 64
01/06/2022 00:36:27 - INFO - __main__ -   Batch number = 65
01/06/2022 00:36:27 - INFO - __main__ -   Batch number = 66
01/06/2022 00:36:27 - INFO - __main__ -   Batch number = 67
01/06/2022 00:36:27 - INFO - __main__ -   Batch number = 68
01/06/2022 00:36:28 - INFO - __main__ -   Batch number = 69
01/06/2022 00:36:28 - INFO - __main__ -   Batch number = 70
01/06/2022 00:36:28 - INFO - __main__ -   Batch number = 71
01/06/2022 00:36:28 - INFO - __main__ -   Batch number = 72
01/06/2022 00:36:28 - INFO - __main__ -   Batch number = 73
01/06/2022 00:36:28 - INFO - __main__ -   Batch number = 74
01/06/2022 00:36:28 - INFO - __main__ -   Batch number = 75
01/06/2022 00:36:28 - INFO - __main__ -   Batch number = 76
01/06/2022 00:36:29 - INFO - __main__ -   Batch number = 77
01/06/2022 00:36:29 - INFO - __main__ -   Batch number = 78
01/06/2022 00:36:29 - INFO - __main__ -   Batch number = 79
01/06/2022 00:36:29 - INFO - __main__ -   Batch number = 80
01/06/2022 00:36:29 - INFO - __main__ -   Batch number = 81
01/06/2022 00:36:29 - INFO - __main__ -   Batch number = 82
01/06/2022 00:36:29 - INFO - __main__ -   Batch number = 83
01/06/2022 00:36:29 - INFO - __main__ -   Batch number = 84
01/06/2022 00:36:30 - INFO - __main__ -   Batch number = 85
01/06/2022 00:36:30 - INFO - __main__ -   Batch number = 86
01/06/2022 00:36:30 - INFO - __main__ -   Batch number = 87
01/06/2022 00:36:30 - INFO - __main__ -   Batch number = 88
01/06/2022 00:36:30 - INFO - __main__ -   Batch number = 89
01/06/2022 00:36:30 - INFO - __main__ -   Batch number = 90
01/06/2022 00:36:30 - INFO - __main__ -   Batch number = 91
01/06/2022 00:36:30 - INFO - __main__ -   Batch number = 92
01/06/2022 00:36:31 - INFO - __main__ -   Batch number = 93
01/06/2022 00:36:31 - INFO - __main__ -   Batch number = 94
01/06/2022 00:36:31 - INFO - __main__ -   Batch number = 95
01/06/2022 00:36:31 - INFO - __main__ -   Batch number = 96
01/06/2022 00:36:31 - INFO - __main__ -   Batch number = 97
01/06/2022 00:36:31 - INFO - __main__ -   Batch number = 98
01/06/2022 00:36:31 - INFO - __main__ -   Batch number = 99
01/06/2022 00:36:31 - INFO - __main__ -   Batch number = 100
01/06/2022 00:36:32 - INFO - __main__ -   Batch number = 101
01/06/2022 00:36:32 - INFO - __main__ -   Batch number = 102
01/06/2022 00:36:32 - INFO - __main__ -   Batch number = 103
01/06/2022 00:36:32 - INFO - __main__ -   Batch number = 104
01/06/2022 00:36:32 - INFO - __main__ -   Batch number = 105
01/06/2022 00:36:32 - INFO - __main__ -   Batch number = 106
01/06/2022 00:36:32 - INFO - __main__ -   Batch number = 107
01/06/2022 00:36:32 - INFO - __main__ -   Batch number = 108
01/06/2022 00:36:33 - INFO - __main__ -   Batch number = 109
01/06/2022 00:36:33 - INFO - __main__ -   Batch number = 110
01/06/2022 00:36:33 - INFO - __main__ -   Batch number = 111
01/06/2022 00:36:33 - INFO - __main__ -   Batch number = 112
01/06/2022 00:36:33 - INFO - __main__ -   Batch number = 113
01/06/2022 00:36:33 - INFO - __main__ -   Batch number = 114
01/06/2022 00:36:33 - INFO - __main__ -   Batch number = 115
01/06/2022 00:36:33 - INFO - __main__ -   Batch number = 116
01/06/2022 00:36:34 - INFO - __main__ -   Batch number = 117
01/06/2022 00:36:34 - INFO - __main__ -   Batch number = 118
01/06/2022 00:36:34 - INFO - __main__ -   Batch number = 119
01/06/2022 00:36:34 - INFO - __main__ -   Batch number = 120
01/06/2022 00:36:34 - INFO - __main__ -   Batch number = 121
01/06/2022 00:36:34 - INFO - __main__ -   Batch number = 122
01/06/2022 00:36:34 - INFO - __main__ -   Batch number = 123
01/06/2022 00:36:34 - INFO - __main__ -   Batch number = 124
01/06/2022 00:36:35 - INFO - __main__ -   Batch number = 125
01/06/2022 00:36:36 - INFO - __main__ -   ***** Evaluation result 29000 in en *****
01/06/2022 00:36:36 - INFO - __main__ -     f1 = 0.9447713006020433
01/06/2022 00:36:36 - INFO - __main__ -     loss = 0.43870828753709795
01/06/2022 00:36:36 - INFO - __main__ -     precision = 0.9446823086144888
01/06/2022 00:36:36 - INFO - __main__ -     recall = 0.9448603093578171
01/06/2022 00:36:36 - INFO - __main__ -   Hit patience=23
01/06/2022 00:42:27 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:42:27 - INFO - __main__ -   ***** Running evaluation 30000 in en *****
01/06/2022 00:42:27 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:42:27 - INFO - __main__ -     Batch size = 32
01/06/2022 00:42:27 - INFO - __main__ -   Batch number = 1
01/06/2022 00:42:27 - INFO - __main__ -   Batch number = 2
01/06/2022 00:42:27 - INFO - __main__ -   Batch number = 3
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 4
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 5
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 6
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 7
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 8
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 9
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 10
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 11
01/06/2022 00:42:28 - INFO - __main__ -   Batch number = 12
01/06/2022 00:42:29 - INFO - __main__ -   Batch number = 13
01/06/2022 00:42:29 - INFO - __main__ -   Batch number = 14
01/06/2022 00:42:29 - INFO - __main__ -   Batch number = 15
01/06/2022 00:42:29 - INFO - __main__ -   Batch number = 16
01/06/2022 00:42:29 - INFO - __main__ -   Batch number = 17
01/06/2022 00:42:29 - INFO - __main__ -   Batch number = 18
01/06/2022 00:42:29 - INFO - __main__ -   Batch number = 19
01/06/2022 00:42:29 - INFO - __main__ -   Batch number = 20
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 21
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 22
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 23
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 24
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 25
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 26
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 27
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 28
01/06/2022 00:42:30 - INFO - __main__ -   Batch number = 29
01/06/2022 00:42:31 - INFO - __main__ -   Batch number = 30
01/06/2022 00:42:31 - INFO - __main__ -   Batch number = 31
01/06/2022 00:42:31 - INFO - __main__ -   Batch number = 32
01/06/2022 00:42:31 - INFO - __main__ -   Batch number = 33
01/06/2022 00:42:31 - INFO - __main__ -   Batch number = 34
01/06/2022 00:42:31 - INFO - __main__ -   Batch number = 35
01/06/2022 00:42:31 - INFO - __main__ -   Batch number = 36
01/06/2022 00:42:31 - INFO - __main__ -   Batch number = 37
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 38
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 39
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 40
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 41
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 42
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 43
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 44
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 45
01/06/2022 00:42:32 - INFO - __main__ -   Batch number = 46
01/06/2022 00:42:33 - INFO - __main__ -   Batch number = 47
01/06/2022 00:42:33 - INFO - __main__ -   Batch number = 48
01/06/2022 00:42:33 - INFO - __main__ -   Batch number = 49
01/06/2022 00:42:33 - INFO - __main__ -   Batch number = 50
01/06/2022 00:42:33 - INFO - __main__ -   Batch number = 51
01/06/2022 00:42:33 - INFO - __main__ -   Batch number = 52
01/06/2022 00:42:33 - INFO - __main__ -   Batch number = 53
01/06/2022 00:42:33 - INFO - __main__ -   Batch number = 54
01/06/2022 00:42:34 - INFO - __main__ -   Batch number = 55
01/06/2022 00:42:34 - INFO - __main__ -   Batch number = 56
01/06/2022 00:42:34 - INFO - __main__ -   Batch number = 57
01/06/2022 00:42:34 - INFO - __main__ -   Batch number = 58
01/06/2022 00:42:34 - INFO - __main__ -   Batch number = 59
01/06/2022 00:42:34 - INFO - __main__ -   Batch number = 60
01/06/2022 00:42:34 - INFO - __main__ -   Batch number = 61
01/06/2022 00:42:34 - INFO - __main__ -   Batch number = 62
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 63
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 64
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 65
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 66
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 67
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 68
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 69
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 70
01/06/2022 00:42:35 - INFO - __main__ -   Batch number = 71
01/06/2022 00:42:36 - INFO - __main__ -   Batch number = 72
01/06/2022 00:42:36 - INFO - __main__ -   Batch number = 73
01/06/2022 00:42:36 - INFO - __main__ -   Batch number = 74
01/06/2022 00:42:36 - INFO - __main__ -   Batch number = 75
01/06/2022 00:42:36 - INFO - __main__ -   Batch number = 76
01/06/2022 00:42:36 - INFO - __main__ -   Batch number = 77
01/06/2022 00:42:36 - INFO - __main__ -   Batch number = 78
01/06/2022 00:42:36 - INFO - __main__ -   Batch number = 79
01/06/2022 00:42:37 - INFO - __main__ -   Batch number = 80
01/06/2022 00:42:37 - INFO - __main__ -   Batch number = 81
01/06/2022 00:42:37 - INFO - __main__ -   Batch number = 82
01/06/2022 00:42:37 - INFO - __main__ -   Batch number = 83
01/06/2022 00:42:37 - INFO - __main__ -   Batch number = 84
01/06/2022 00:42:37 - INFO - __main__ -   Batch number = 85
01/06/2022 00:42:37 - INFO - __main__ -   Batch number = 86
01/06/2022 00:42:37 - INFO - __main__ -   Batch number = 87
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 88
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 89
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 90
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 91
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 92
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 93
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 94
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 95
01/06/2022 00:42:38 - INFO - __main__ -   Batch number = 96
01/06/2022 00:42:39 - INFO - __main__ -   Batch number = 97
01/06/2022 00:42:39 - INFO - __main__ -   Batch number = 98
01/06/2022 00:42:39 - INFO - __main__ -   Batch number = 99
01/06/2022 00:42:39 - INFO - __main__ -   Batch number = 100
01/06/2022 00:42:39 - INFO - __main__ -   Batch number = 101
01/06/2022 00:42:39 - INFO - __main__ -   Batch number = 102
01/06/2022 00:42:39 - INFO - __main__ -   Batch number = 103
01/06/2022 00:42:39 - INFO - __main__ -   Batch number = 104
01/06/2022 00:42:40 - INFO - __main__ -   Batch number = 105
01/06/2022 00:42:40 - INFO - __main__ -   Batch number = 106
01/06/2022 00:42:40 - INFO - __main__ -   Batch number = 107
01/06/2022 00:42:40 - INFO - __main__ -   Batch number = 108
01/06/2022 00:42:40 - INFO - __main__ -   Batch number = 109
01/06/2022 00:42:40 - INFO - __main__ -   Batch number = 110
01/06/2022 00:42:40 - INFO - __main__ -   Batch number = 111
01/06/2022 00:42:40 - INFO - __main__ -   Batch number = 112
01/06/2022 00:42:41 - INFO - __main__ -   Batch number = 113
01/06/2022 00:42:41 - INFO - __main__ -   Batch number = 114
01/06/2022 00:42:41 - INFO - __main__ -   Batch number = 115
01/06/2022 00:42:41 - INFO - __main__ -   Batch number = 116
01/06/2022 00:42:41 - INFO - __main__ -   Batch number = 117
01/06/2022 00:42:41 - INFO - __main__ -   Batch number = 118
01/06/2022 00:42:41 - INFO - __main__ -   Batch number = 119
01/06/2022 00:42:41 - INFO - __main__ -   Batch number = 120
01/06/2022 00:42:42 - INFO - __main__ -   Batch number = 121
01/06/2022 00:42:42 - INFO - __main__ -   Batch number = 122
01/06/2022 00:42:42 - INFO - __main__ -   Batch number = 123
01/06/2022 00:42:42 - INFO - __main__ -   Batch number = 124
01/06/2022 00:42:42 - INFO - __main__ -   Batch number = 125
01/06/2022 00:42:43 - INFO - __main__ -   ***** Evaluation result 30000 in en *****
01/06/2022 00:42:43 - INFO - __main__ -     f1 = 0.94453911033095
01/06/2022 00:42:43 - INFO - __main__ -     loss = 0.4417617728114128
01/06/2022 00:42:43 - INFO - __main__ -     precision = 0.9443207889600383
01/06/2022 00:42:43 - INFO - __main__ -     recall = 0.9447575326744206
01/06/2022 00:42:43 - INFO - __main__ -   Hit patience=24
01/06/2022 00:48:39 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:48:39 - INFO - __main__ -   ***** Running evaluation 31000 in en *****
01/06/2022 00:48:39 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:48:39 - INFO - __main__ -     Batch size = 32
01/06/2022 00:48:39 - INFO - __main__ -   Batch number = 1
01/06/2022 00:48:39 - INFO - __main__ -   Batch number = 2
01/06/2022 00:48:39 - INFO - __main__ -   Batch number = 3
01/06/2022 00:48:39 - INFO - __main__ -   Batch number = 4
01/06/2022 00:48:39 - INFO - __main__ -   Batch number = 5
01/06/2022 00:48:40 - INFO - __main__ -   Batch number = 6
01/06/2022 00:48:40 - INFO - __main__ -   Batch number = 7
01/06/2022 00:48:40 - INFO - __main__ -   Batch number = 8
01/06/2022 00:48:40 - INFO - __main__ -   Batch number = 9
01/06/2022 00:48:40 - INFO - __main__ -   Batch number = 10
01/06/2022 00:48:40 - INFO - __main__ -   Batch number = 11
01/06/2022 00:48:40 - INFO - __main__ -   Batch number = 12
01/06/2022 00:48:40 - INFO - __main__ -   Batch number = 13
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 14
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 15
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 16
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 17
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 18
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 19
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 20
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 21
01/06/2022 00:48:41 - INFO - __main__ -   Batch number = 22
01/06/2022 00:48:42 - INFO - __main__ -   Batch number = 23
01/06/2022 00:48:42 - INFO - __main__ -   Batch number = 24
01/06/2022 00:48:42 - INFO - __main__ -   Batch number = 25
01/06/2022 00:48:42 - INFO - __main__ -   Batch number = 26
01/06/2022 00:48:42 - INFO - __main__ -   Batch number = 27
01/06/2022 00:48:42 - INFO - __main__ -   Batch number = 28
01/06/2022 00:48:42 - INFO - __main__ -   Batch number = 29
01/06/2022 00:48:42 - INFO - __main__ -   Batch number = 30
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 31
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 32
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 33
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 34
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 35
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 36
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 37
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 38
01/06/2022 00:48:43 - INFO - __main__ -   Batch number = 39
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 40
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 41
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 42
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 43
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 44
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 45
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 46
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 47
01/06/2022 00:48:44 - INFO - __main__ -   Batch number = 48
01/06/2022 00:48:45 - INFO - __main__ -   Batch number = 49
01/06/2022 00:48:45 - INFO - __main__ -   Batch number = 50
01/06/2022 00:48:45 - INFO - __main__ -   Batch number = 51
01/06/2022 00:48:45 - INFO - __main__ -   Batch number = 52
01/06/2022 00:48:45 - INFO - __main__ -   Batch number = 53
01/06/2022 00:48:45 - INFO - __main__ -   Batch number = 54
01/06/2022 00:48:45 - INFO - __main__ -   Batch number = 55
01/06/2022 00:48:45 - INFO - __main__ -   Batch number = 56
01/06/2022 00:48:46 - INFO - __main__ -   Batch number = 57
01/06/2022 00:48:46 - INFO - __main__ -   Batch number = 58
01/06/2022 00:48:46 - INFO - __main__ -   Batch number = 59
01/06/2022 00:48:46 - INFO - __main__ -   Batch number = 60
01/06/2022 00:48:46 - INFO - __main__ -   Batch number = 61
01/06/2022 00:48:46 - INFO - __main__ -   Batch number = 62
01/06/2022 00:48:46 - INFO - __main__ -   Batch number = 63
01/06/2022 00:48:46 - INFO - __main__ -   Batch number = 64
01/06/2022 00:48:47 - INFO - __main__ -   Batch number = 65
01/06/2022 00:48:47 - INFO - __main__ -   Batch number = 66
01/06/2022 00:48:47 - INFO - __main__ -   Batch number = 67
01/06/2022 00:48:47 - INFO - __main__ -   Batch number = 68
01/06/2022 00:48:47 - INFO - __main__ -   Batch number = 69
01/06/2022 00:48:47 - INFO - __main__ -   Batch number = 70
01/06/2022 00:48:47 - INFO - __main__ -   Batch number = 71
01/06/2022 00:48:47 - INFO - __main__ -   Batch number = 72
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 73
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 74
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 75
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 76
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 77
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 78
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 79
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 80
01/06/2022 00:48:48 - INFO - __main__ -   Batch number = 81
01/06/2022 00:48:49 - INFO - __main__ -   Batch number = 82
01/06/2022 00:48:49 - INFO - __main__ -   Batch number = 83
01/06/2022 00:48:49 - INFO - __main__ -   Batch number = 84
01/06/2022 00:48:49 - INFO - __main__ -   Batch number = 85
01/06/2022 00:48:49 - INFO - __main__ -   Batch number = 86
01/06/2022 00:48:49 - INFO - __main__ -   Batch number = 87
01/06/2022 00:48:49 - INFO - __main__ -   Batch number = 88
01/06/2022 00:48:49 - INFO - __main__ -   Batch number = 89
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 90
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 91
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 92
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 93
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 94
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 95
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 96
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 97
01/06/2022 00:48:50 - INFO - __main__ -   Batch number = 98
01/06/2022 00:48:51 - INFO - __main__ -   Batch number = 99
01/06/2022 00:48:51 - INFO - __main__ -   Batch number = 100
01/06/2022 00:48:51 - INFO - __main__ -   Batch number = 101
01/06/2022 00:48:51 - INFO - __main__ -   Batch number = 102
01/06/2022 00:48:51 - INFO - __main__ -   Batch number = 103
01/06/2022 00:48:51 - INFO - __main__ -   Batch number = 104
01/06/2022 00:48:51 - INFO - __main__ -   Batch number = 105
01/06/2022 00:48:51 - INFO - __main__ -   Batch number = 106
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 107
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 108
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 109
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 110
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 111
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 112
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 113
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 114
01/06/2022 00:48:52 - INFO - __main__ -   Batch number = 115
01/06/2022 00:48:53 - INFO - __main__ -   Batch number = 116
01/06/2022 00:48:53 - INFO - __main__ -   Batch number = 117
01/06/2022 00:48:53 - INFO - __main__ -   Batch number = 118
01/06/2022 00:48:53 - INFO - __main__ -   Batch number = 119
01/06/2022 00:48:53 - INFO - __main__ -   Batch number = 120
01/06/2022 00:48:53 - INFO - __main__ -   Batch number = 121
01/06/2022 00:48:53 - INFO - __main__ -   Batch number = 122
01/06/2022 00:48:53 - INFO - __main__ -   Batch number = 123
01/06/2022 00:48:54 - INFO - __main__ -   Batch number = 124
01/06/2022 00:48:54 - INFO - __main__ -   Batch number = 125
01/06/2022 00:48:55 - INFO - __main__ -   ***** Evaluation result 31000 in en *****
01/06/2022 00:48:55 - INFO - __main__ -     f1 = 0.9445681592380691
01/06/2022 00:48:55 - INFO - __main__ -     loss = 0.450191448867321
01/06/2022 00:48:55 - INFO - __main__ -     precision = 0.9445843397228361
01/06/2022 00:48:55 - INFO - __main__ -     recall = 0.9445519793076278
01/06/2022 00:48:55 - INFO - __main__ -   Hit patience=25
01/06/2022 00:54:56 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:54:56 - INFO - __main__ -   ***** Running evaluation 32000 in en *****
01/06/2022 00:54:56 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:54:56 - INFO - __main__ -     Batch size = 32
01/06/2022 00:54:56 - INFO - __main__ -   Batch number = 1
01/06/2022 00:54:56 - INFO - __main__ -   Batch number = 2
01/06/2022 00:54:56 - INFO - __main__ -   Batch number = 3
01/06/2022 00:54:56 - INFO - __main__ -   Batch number = 4
01/06/2022 00:54:57 - INFO - __main__ -   Batch number = 5
01/06/2022 00:54:57 - INFO - __main__ -   Batch number = 6
01/06/2022 00:54:57 - INFO - __main__ -   Batch number = 7
01/06/2022 00:54:57 - INFO - __main__ -   Batch number = 8
01/06/2022 00:54:57 - INFO - __main__ -   Batch number = 9
01/06/2022 00:54:57 - INFO - __main__ -   Batch number = 10
01/06/2022 00:54:57 - INFO - __main__ -   Batch number = 11
01/06/2022 00:54:57 - INFO - __main__ -   Batch number = 12
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 13
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 14
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 15
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 16
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 17
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 18
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 19
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 20
01/06/2022 00:54:58 - INFO - __main__ -   Batch number = 21
01/06/2022 00:54:59 - INFO - __main__ -   Batch number = 22
01/06/2022 00:54:59 - INFO - __main__ -   Batch number = 23
01/06/2022 00:54:59 - INFO - __main__ -   Batch number = 24
01/06/2022 00:54:59 - INFO - __main__ -   Batch number = 25
01/06/2022 00:54:59 - INFO - __main__ -   Batch number = 26
01/06/2022 00:54:59 - INFO - __main__ -   Batch number = 27
01/06/2022 00:54:59 - INFO - __main__ -   Batch number = 28
01/06/2022 00:54:59 - INFO - __main__ -   Batch number = 29
01/06/2022 00:55:00 - INFO - __main__ -   Batch number = 30
01/06/2022 00:55:00 - INFO - __main__ -   Batch number = 31
01/06/2022 00:55:00 - INFO - __main__ -   Batch number = 32
01/06/2022 00:55:00 - INFO - __main__ -   Batch number = 33
01/06/2022 00:55:00 - INFO - __main__ -   Batch number = 34
01/06/2022 00:55:00 - INFO - __main__ -   Batch number = 35
01/06/2022 00:55:00 - INFO - __main__ -   Batch number = 36
01/06/2022 00:55:00 - INFO - __main__ -   Batch number = 37
01/06/2022 00:55:01 - INFO - __main__ -   Batch number = 38
01/06/2022 00:55:01 - INFO - __main__ -   Batch number = 39
01/06/2022 00:55:01 - INFO - __main__ -   Batch number = 40
01/06/2022 00:55:01 - INFO - __main__ -   Batch number = 41
01/06/2022 00:55:01 - INFO - __main__ -   Batch number = 42
01/06/2022 00:55:01 - INFO - __main__ -   Batch number = 43
01/06/2022 00:55:01 - INFO - __main__ -   Batch number = 44
01/06/2022 00:55:01 - INFO - __main__ -   Batch number = 45
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 46
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 47
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 48
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 49
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 50
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 51
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 52
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 53
01/06/2022 00:55:02 - INFO - __main__ -   Batch number = 54
01/06/2022 00:55:03 - INFO - __main__ -   Batch number = 55
01/06/2022 00:55:03 - INFO - __main__ -   Batch number = 56
01/06/2022 00:55:03 - INFO - __main__ -   Batch number = 57
01/06/2022 00:55:03 - INFO - __main__ -   Batch number = 58
01/06/2022 00:55:03 - INFO - __main__ -   Batch number = 59
01/06/2022 00:55:03 - INFO - __main__ -   Batch number = 60
01/06/2022 00:55:03 - INFO - __main__ -   Batch number = 61
01/06/2022 00:55:03 - INFO - __main__ -   Batch number = 62
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 63
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 64
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 65
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 66
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 67
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 68
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 69
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 70
01/06/2022 00:55:04 - INFO - __main__ -   Batch number = 71
01/06/2022 00:55:05 - INFO - __main__ -   Batch number = 72
01/06/2022 00:55:05 - INFO - __main__ -   Batch number = 73
01/06/2022 00:55:05 - INFO - __main__ -   Batch number = 74
01/06/2022 00:55:05 - INFO - __main__ -   Batch number = 75
01/06/2022 00:55:05 - INFO - __main__ -   Batch number = 76
01/06/2022 00:55:05 - INFO - __main__ -   Batch number = 77
01/06/2022 00:55:05 - INFO - __main__ -   Batch number = 78
01/06/2022 00:55:05 - INFO - __main__ -   Batch number = 79
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 80
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 81
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 82
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 83
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 84
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 85
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 86
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 87
01/06/2022 00:55:06 - INFO - __main__ -   Batch number = 88
01/06/2022 00:55:07 - INFO - __main__ -   Batch number = 89
01/06/2022 00:55:07 - INFO - __main__ -   Batch number = 90
01/06/2022 00:55:07 - INFO - __main__ -   Batch number = 91
01/06/2022 00:55:07 - INFO - __main__ -   Batch number = 92
01/06/2022 00:55:07 - INFO - __main__ -   Batch number = 93
01/06/2022 00:55:07 - INFO - __main__ -   Batch number = 94
01/06/2022 00:55:07 - INFO - __main__ -   Batch number = 95
01/06/2022 00:55:07 - INFO - __main__ -   Batch number = 96
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 97
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 98
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 99
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 100
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 101
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 102
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 103
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 104
01/06/2022 00:55:08 - INFO - __main__ -   Batch number = 105
01/06/2022 00:55:09 - INFO - __main__ -   Batch number = 106
01/06/2022 00:55:09 - INFO - __main__ -   Batch number = 107
01/06/2022 00:55:09 - INFO - __main__ -   Batch number = 108
01/06/2022 00:55:09 - INFO - __main__ -   Batch number = 109
01/06/2022 00:55:09 - INFO - __main__ -   Batch number = 110
01/06/2022 00:55:09 - INFO - __main__ -   Batch number = 111
01/06/2022 00:55:09 - INFO - __main__ -   Batch number = 112
01/06/2022 00:55:09 - INFO - __main__ -   Batch number = 113
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 114
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 115
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 116
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 117
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 118
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 119
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 120
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 121
01/06/2022 00:55:10 - INFO - __main__ -   Batch number = 122
01/06/2022 00:55:11 - INFO - __main__ -   Batch number = 123
01/06/2022 00:55:11 - INFO - __main__ -   Batch number = 124
01/06/2022 00:55:11 - INFO - __main__ -   Batch number = 125
01/06/2022 00:55:12 - INFO - __main__ -   ***** Evaluation result 32000 in en *****
01/06/2022 00:55:12 - INFO - __main__ -     f1 = 0.9450058231143386
01/06/2022 00:55:12 - INFO - __main__ -     loss = 0.4491509857773781
01/06/2022 00:55:12 - INFO - __main__ -     precision = 0.9448601811736904
01/06/2022 00:55:12 - INFO - __main__ -     recall = 0.9451515099607736
01/06/2022 00:55:12 - INFO - __main__ -   Hit patience=26
01/06/2022 01:01:17 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 01:01:18 - INFO - __main__ -   ***** Running evaluation 33000 in en *****
01/06/2022 01:01:18 - INFO - __main__ -     Num examples = 3974
01/06/2022 01:01:18 - INFO - __main__ -     Batch size = 32
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 1
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 2
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 3
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 4
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 5
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 6
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 7
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 8
01/06/2022 01:01:18 - INFO - __main__ -   Batch number = 9
01/06/2022 01:01:19 - INFO - __main__ -   Batch number = 10
01/06/2022 01:01:19 - INFO - __main__ -   Batch number = 11
01/06/2022 01:01:19 - INFO - __main__ -   Batch number = 12
01/06/2022 01:01:19 - INFO - __main__ -   Batch number = 13
01/06/2022 01:01:19 - INFO - __main__ -   Batch number = 14
01/06/2022 01:01:19 - INFO - __main__ -   Batch number = 15
01/06/2022 01:01:19 - INFO - __main__ -   Batch number = 16
01/06/2022 01:01:19 - INFO - __main__ -   Batch number = 17
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 18
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 19
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 20
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 21
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 22
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 23
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 24
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 25
01/06/2022 01:01:20 - INFO - __main__ -   Batch number = 26
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 27
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 28
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 29
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 30
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 31
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 32
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 33
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 34
01/06/2022 01:01:21 - INFO - __main__ -   Batch number = 35
01/06/2022 01:01:22 - INFO - __main__ -   Batch number = 36
01/06/2022 01:01:22 - INFO - __main__ -   Batch number = 37
01/06/2022 01:01:22 - INFO - __main__ -   Batch number = 38
01/06/2022 01:01:22 - INFO - __main__ -   Batch number = 39
01/06/2022 01:01:22 - INFO - __main__ -   Batch number = 40
01/06/2022 01:01:22 - INFO - __main__ -   Batch number = 41
01/06/2022 01:01:22 - INFO - __main__ -   Batch number = 42
01/06/2022 01:01:22 - INFO - __main__ -   Batch number = 43
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 44
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 45
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 46
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 47
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 48
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 49
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 50
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 51
01/06/2022 01:01:23 - INFO - __main__ -   Batch number = 52
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 53
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 54
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 55
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 56
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 57
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 58
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 59
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 60
01/06/2022 01:01:24 - INFO - __main__ -   Batch number = 61
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 62
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 63
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 64
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 65
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 66
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 67
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 68
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 69
01/06/2022 01:01:25 - INFO - __main__ -   Batch number = 70
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 71
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 72
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 73
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 74
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 75
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 76
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 77
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 78
01/06/2022 01:01:26 - INFO - __main__ -   Batch number = 79
01/06/2022 01:01:27 - INFO - __main__ -   Batch number = 80
01/06/2022 01:01:27 - INFO - __main__ -   Batch number = 81
01/06/2022 01:01:27 - INFO - __main__ -   Batch number = 82
01/06/2022 01:01:27 - INFO - __main__ -   Batch number = 83
01/06/2022 01:01:27 - INFO - __main__ -   Batch number = 84
01/06/2022 01:01:27 - INFO - __main__ -   Batch number = 85
01/06/2022 01:01:27 - INFO - __main__ -   Batch number = 86
01/06/2022 01:01:27 - INFO - __main__ -   Batch number = 87
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 88
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 89
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 90
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 91
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 92
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 93
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 94
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 95
01/06/2022 01:01:28 - INFO - __main__ -   Batch number = 96
01/06/2022 01:01:29 - INFO - __main__ -   Batch number = 97
01/06/2022 01:01:29 - INFO - __main__ -   Batch number = 98
01/06/2022 01:01:29 - INFO - __main__ -   Batch number = 99
01/06/2022 01:01:29 - INFO - __main__ -   Batch number = 100
01/06/2022 01:01:29 - INFO - __main__ -   Batch number = 101
01/06/2022 01:01:29 - INFO - __main__ -   Batch number = 102
01/06/2022 01:01:29 - INFO - __main__ -   Batch number = 103
01/06/2022 01:01:29 - INFO - __main__ -   Batch number = 104
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 105
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 106
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 107
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 108
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 109
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 110
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 111
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 112
01/06/2022 01:01:30 - INFO - __main__ -   Batch number = 113
01/06/2022 01:01:31 - INFO - __main__ -   Batch number = 114
01/06/2022 01:01:31 - INFO - __main__ -   Batch number = 115
01/06/2022 01:01:31 - INFO - __main__ -   Batch number = 116
01/06/2022 01:01:31 - INFO - __main__ -   Batch number = 117
01/06/2022 01:01:31 - INFO - __main__ -   Batch number = 118
01/06/2022 01:01:31 - INFO - __main__ -   Batch number = 119
01/06/2022 01:01:31 - INFO - __main__ -   Batch number = 120
01/06/2022 01:01:31 - INFO - __main__ -   Batch number = 121
01/06/2022 01:01:32 - INFO - __main__ -   Batch number = 122
01/06/2022 01:01:32 - INFO - __main__ -   Batch number = 123
01/06/2022 01:01:32 - INFO - __main__ -   Batch number = 124
01/06/2022 01:01:32 - INFO - __main__ -   Batch number = 125
01/06/2022 01:01:33 - INFO - __main__ -   ***** Evaluation result 33000 in en *****
01/06/2022 01:01:33 - INFO - __main__ -     f1 = 0.9449130408720746
01/06/2022 01:01:33 - INFO - __main__ -     loss = 0.4492238638997078
01/06/2022 01:01:33 - INFO - __main__ -     precision = 0.9447431506849315
01/06/2022 01:01:33 - INFO - __main__ -     recall = 0.9450829921718427
01/06/2022 01:01:33 - INFO - __main__ -   Hit patience=27
01/06/2022 01:07:34 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 01:07:35 - INFO - __main__ -   ***** Running evaluation 34000 in en *****
01/06/2022 01:07:35 - INFO - __main__ -     Num examples = 3974
01/06/2022 01:07:35 - INFO - __main__ -     Batch size = 32
01/06/2022 01:07:35 - INFO - __main__ -   Batch number = 1
01/06/2022 01:07:35 - INFO - __main__ -   Batch number = 2
01/06/2022 01:07:35 - INFO - __main__ -   Batch number = 3
01/06/2022 01:07:35 - INFO - __main__ -   Batch number = 4
01/06/2022 01:07:35 - INFO - __main__ -   Batch number = 5
01/06/2022 01:07:35 - INFO - __main__ -   Batch number = 6
01/06/2022 01:07:35 - INFO - __main__ -   Batch number = 7
01/06/2022 01:07:35 - INFO - __main__ -   Batch number = 8
01/06/2022 01:07:36 - INFO - __main__ -   Batch number = 9
01/06/2022 01:07:36 - INFO - __main__ -   Batch number = 10
01/06/2022 01:07:36 - INFO - __main__ -   Batch number = 11
01/06/2022 01:07:36 - INFO - __main__ -   Batch number = 12
01/06/2022 01:07:36 - INFO - __main__ -   Batch number = 13
01/06/2022 01:07:36 - INFO - __main__ -   Batch number = 14
01/06/2022 01:07:36 - INFO - __main__ -   Batch number = 15
01/06/2022 01:07:36 - INFO - __main__ -   Batch number = 16
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 17
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 18
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 19
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 20
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 21
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 22
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 23
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 24
01/06/2022 01:07:37 - INFO - __main__ -   Batch number = 25
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 26
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 27
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 28
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 29
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 30
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 31
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 32
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 33
01/06/2022 01:07:38 - INFO - __main__ -   Batch number = 34
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 35
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 36
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 37
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 38
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 39
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 40
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 41
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 42
01/06/2022 01:07:39 - INFO - __main__ -   Batch number = 43
01/06/2022 01:07:40 - INFO - __main__ -   Batch number = 44
01/06/2022 01:07:40 - INFO - __main__ -   Batch number = 45
01/06/2022 01:07:40 - INFO - __main__ -   Batch number = 46
01/06/2022 01:07:40 - INFO - __main__ -   Batch number = 47
01/06/2022 01:07:40 - INFO - __main__ -   Batch number = 48
01/06/2022 01:07:40 - INFO - __main__ -   Batch number = 49
01/06/2022 01:07:40 - INFO - __main__ -   Batch number = 50
01/06/2022 01:07:40 - INFO - __main__ -   Batch number = 51
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 52
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 53
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 54
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 55
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 56
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 57
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 58
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 59
01/06/2022 01:07:41 - INFO - __main__ -   Batch number = 60
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 61
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 62
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 63
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 64
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 65
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 66
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 67
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 68
01/06/2022 01:07:42 - INFO - __main__ -   Batch number = 69
01/06/2022 01:07:43 - INFO - __main__ -   Batch number = 70
01/06/2022 01:07:43 - INFO - __main__ -   Batch number = 71
01/06/2022 01:07:43 - INFO - __main__ -   Batch number = 72
01/06/2022 01:07:43 - INFO - __main__ -   Batch number = 73
01/06/2022 01:07:43 - INFO - __main__ -   Batch number = 74
01/06/2022 01:07:43 - INFO - __main__ -   Batch number = 75
01/06/2022 01:07:43 - INFO - __main__ -   Batch number = 76
01/06/2022 01:07:43 - INFO - __main__ -   Batch number = 77
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 78
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 79
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 80
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 81
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 82
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 83
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 84
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 85
01/06/2022 01:07:44 - INFO - __main__ -   Batch number = 86
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 87
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 88
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 89
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 90
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 91
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 92
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 93
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 94
01/06/2022 01:07:45 - INFO - __main__ -   Batch number = 95
01/06/2022 01:07:46 - INFO - __main__ -   Batch number = 96
01/06/2022 01:07:46 - INFO - __main__ -   Batch number = 97
01/06/2022 01:07:46 - INFO - __main__ -   Batch number = 98
01/06/2022 01:07:46 - INFO - __main__ -   Batch number = 99
01/06/2022 01:07:46 - INFO - __main__ -   Batch number = 100
01/06/2022 01:07:46 - INFO - __main__ -   Batch number = 101
01/06/2022 01:07:46 - INFO - __main__ -   Batch number = 102
01/06/2022 01:07:46 - INFO - __main__ -   Batch number = 103
01/06/2022 01:07:47 - INFO - __main__ -   Batch number = 104
01/06/2022 01:07:47 - INFO - __main__ -   Batch number = 105
01/06/2022 01:07:47 - INFO - __main__ -   Batch number = 106
01/06/2022 01:07:47 - INFO - __main__ -   Batch number = 107
01/06/2022 01:07:47 - INFO - __main__ -   Batch number = 108
01/06/2022 01:07:47 - INFO - __main__ -   Batch number = 109
01/06/2022 01:07:47 - INFO - __main__ -   Batch number = 110
01/06/2022 01:07:47 - INFO - __main__ -   Batch number = 111
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 112
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 113
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 114
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 115
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 116
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 117
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 118
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 119
01/06/2022 01:07:48 - INFO - __main__ -   Batch number = 120
01/06/2022 01:07:49 - INFO - __main__ -   Batch number = 121
01/06/2022 01:07:49 - INFO - __main__ -   Batch number = 122
01/06/2022 01:07:49 - INFO - __main__ -   Batch number = 123
01/06/2022 01:07:49 - INFO - __main__ -   Batch number = 124
01/06/2022 01:07:49 - INFO - __main__ -   Batch number = 125
01/06/2022 01:07:51 - INFO - __main__ -   ***** Evaluation result 34000 in en *****
01/06/2022 01:07:51 - INFO - __main__ -     f1 = 0.9451403813715332
01/06/2022 01:07:51 - INFO - __main__ -     loss = 0.4512791564464569
01/06/2022 01:07:51 - INFO - __main__ -     precision = 0.944889573703133
01/06/2022 01:07:51 - INFO - __main__ -     recall = 0.9453913222220319
01/06/2022 01:07:51 - INFO - __main__ -   Hit patience=28
01/06/2022 01:08:10 - INFO - __main__ -    global_step = 34050, average loss = 0.033160172011133936
01/06/2022 01:08:10 - INFO - __main__ -   Saving model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/
01/06/2022 01:08:10 - INFO - root -   Save adapter
01/06/2022 01:08:10 - INFO - __main__ -   Loading pretrained model and tokenizer
01/06/2022 01:08:13 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/06/2022 01:08:19 - INFO - __main__ -   Using lang2id = None
01/06/2022 01:08:19 - INFO - __main__ -   Evaluating the model on dev set of training language(en)
01/06/2022 01:08:19 - INFO - __main__ -   Task Adapter will be loaded from this path /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s1/checkpoint-best/udpos
01/06/2022 01:08:19 - INFO - root -   Trying to decide if add adapter
01/06/2022 01:08:19 - INFO - root -   loading task adapter
01/06/2022 01:08:20 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 01:08:21 - INFO - __main__ -   ***** Running evaluation debugging in en *****
01/06/2022 01:08:21 - INFO - __main__ -     Num examples = 3974
01/06/2022 01:08:21 - INFO - __main__ -     Batch size = 32
01/06/2022 01:08:21 - INFO - __main__ -   Batch number = 1
01/06/2022 01:08:21 - INFO - __main__ -   Batch number = 2
01/06/2022 01:08:21 - INFO - __main__ -   Batch number = 3
01/06/2022 01:08:21 - INFO - __main__ -   Batch number = 4
01/06/2022 01:08:21 - INFO - __main__ -   Batch number = 5
01/06/2022 01:08:21 - INFO - __main__ -   Batch number = 6
01/06/2022 01:08:21 - INFO - __main__ -   Batch number = 7
01/06/2022 01:08:21 - INFO - __main__ -   Batch number = 8
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 9
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 10
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 11
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 12
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 13
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 14
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 15
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 16
01/06/2022 01:08:22 - INFO - __main__ -   Batch number = 17
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 18
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 19
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 20
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 21
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 22
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 23
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 24
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 25
01/06/2022 01:08:23 - INFO - __main__ -   Batch number = 26
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 27
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 28
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 29
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 30
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 31
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 32
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 33
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 34
01/06/2022 01:08:24 - INFO - __main__ -   Batch number = 35
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 36
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 37
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 38
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 39
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 40
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 41
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 42
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 43
01/06/2022 01:08:25 - INFO - __main__ -   Batch number = 44
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 45
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 46
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 47
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 48
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 49
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 50
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 51
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 52
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 53
01/06/2022 01:08:26 - INFO - __main__ -   Batch number = 54
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 55
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 56
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 57
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 58
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 59
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 60
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 61
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 62
01/06/2022 01:08:27 - INFO - __main__ -   Batch number = 63
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 64
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 65
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 66
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 67
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 68
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 69
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 70
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 71
01/06/2022 01:08:28 - INFO - __main__ -   Batch number = 72
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 73
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 74
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 75
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 76
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 77
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 78
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 79
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 80
01/06/2022 01:08:29 - INFO - __main__ -   Batch number = 81
01/06/2022 01:08:30 - INFO - __main__ -   Batch number = 82
01/06/2022 01:08:30 - INFO - __main__ -   Batch number = 83
01/06/2022 01:08:30 - INFO - __main__ -   Batch number = 84
01/06/2022 01:08:30 - INFO - __main__ -   Batch number = 85
01/06/2022 01:08:30 - INFO - __main__ -   Batch number = 86
01/06/2022 01:08:30 - INFO - __main__ -   Batch number = 87
01/06/2022 01:08:30 - INFO - __main__ -   Batch number = 88
01/06/2022 01:08:30 - INFO - __main__ -   Batch number = 89
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 90
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 91
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 92
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 93
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 94
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 95
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 96
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 97
01/06/2022 01:08:31 - INFO - __main__ -   Batch number = 98
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 99
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 100
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 101
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 102
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 103
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 104
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 105
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 106
01/06/2022 01:08:32 - INFO - __main__ -   Batch number = 107
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 108
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 109
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 110
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 111
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 112
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 113
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 114
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 115
01/06/2022 01:08:33 - INFO - __main__ -   Batch number = 116
01/06/2022 01:08:34 - INFO - __main__ -   Batch number = 117
01/06/2022 01:08:34 - INFO - __main__ -   Batch number = 118
01/06/2022 01:08:34 - INFO - __main__ -   Batch number = 119
01/06/2022 01:08:34 - INFO - __main__ -   Batch number = 120
01/06/2022 01:08:34 - INFO - __main__ -   Batch number = 121
01/06/2022 01:08:34 - INFO - __main__ -   Batch number = 122
01/06/2022 01:08:34 - INFO - __main__ -   Batch number = 123
01/06/2022 01:08:34 - INFO - __main__ -   Batch number = 124
01/06/2022 01:08:35 - INFO - __main__ -   Batch number = 125
01/06/2022 01:08:36 - INFO - __main__ -   ***** Evaluation result debugging in en *****
01/06/2022 01:08:36 - INFO - __main__ -     f1 = 0.9488459726801696
01/06/2022 01:08:36 - INFO - __main__ -     loss = 0.14593491405248643
01/06/2022 01:08:36 - INFO - __main__ -     precision = 0.9487890932757853
01/06/2022 01:08:36 - INFO - __main__ -     recall = 0.9489028589047431
