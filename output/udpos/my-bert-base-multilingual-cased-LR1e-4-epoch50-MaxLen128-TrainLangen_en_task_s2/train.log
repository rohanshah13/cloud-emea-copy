01/05/2022 21:47:49 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:47:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/05/2022 21:47:49 - INFO - __main__ -   Seed = 2
01/05/2022 21:47:49 - INFO - root -   save adapters
01/05/2022 21:47:49 - INFO - root -   True
01/05/2022 21:47:49 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:47:49 - INFO - __main__ -   Loading pretrained model and tokenizer
01/05/2022 21:47:52 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/05/2022 21:47:57 - INFO - __main__ -   Using lang2id = None
01/05/2022 21:47:57 - INFO - root -   Trying to decide if add adapter
01/05/2022 21:47:57 - INFO - root -   Adding task adapter
01/05/2022 21:47:57 - INFO - __main__ -   lang adapter names: 
01/05/2022 21:47:57 - INFO - __main__ -   bert.embeddings.word_embeddings.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.embeddings.position_embeddings.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.embeddings.token_type_embeddings.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.embeddings.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.embeddings.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.output.dense.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.output.dense.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.weight
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.bias
01/05/2022 21:47:57 - INFO - __main__ -   False
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   classifier.weight
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:47:57 - INFO - __main__ -   classifier.bias
01/05/2022 21:47:57 - INFO - __main__ -   True
01/05/2022 21:48:00 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_train_en_bert-base-multilingual-cased_128
01/05/2022 21:48:01 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:48:01 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/05/2022 21:48:01 - INFO - __main__ -   Seed = 2
01/05/2022 21:48:01 - INFO - root -   save adapters
01/05/2022 21:48:01 - INFO - root -   True
01/05/2022 21:48:01 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:48:01 - INFO - __main__ -   Loading pretrained model and tokenizer
01/05/2022 21:48:02 - INFO - root -   ['bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias', 'classifier.weight', 'classifier.bias']
01/05/2022 21:48:02 - INFO - __main__ -   ***** Running training *****
01/05/2022 21:48:02 - INFO - __main__ -     Num examples = 21798
01/05/2022 21:48:02 - INFO - __main__ -     Num Epochs = 50
01/05/2022 21:48:02 - INFO - __main__ -     Instantaneous batch size per GPU = 8
01/05/2022 21:48:02 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
01/05/2022 21:48:02 - INFO - __main__ -     Gradient Accumulation steps = 4
01/05/2022 21:48:02 - INFO - __main__ -     Total optimization steps = 34050
01/05/2022 21:48:02 - INFO - __main__ -   Seed = 2
01/05/2022 21:48:04 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/05/2022 21:48:09 - INFO - __main__ -   Using lang2id = None
01/05/2022 21:48:09 - INFO - root -   Trying to decide if add adapter
01/05/2022 21:48:09 - INFO - root -   Adding task adapter
01/05/2022 21:48:09 - INFO - __main__ -   lang adapter names: 
01/05/2022 21:48:09 - INFO - __main__ -   bert.embeddings.word_embeddings.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.embeddings.position_embeddings.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.embeddings.token_type_embeddings.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.embeddings.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.embeddings.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.output.dense.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.output.dense.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.weight
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.bias
01/05/2022 21:48:09 - INFO - __main__ -   False
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   classifier.weight
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:09 - INFO - __main__ -   classifier.bias
01/05/2022 21:48:09 - INFO - __main__ -   True
01/05/2022 21:48:14 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_train_en_bert-base-multilingual-cased_128
01/05/2022 21:48:16 - INFO - root -   ['bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias', 'classifier.weight', 'classifier.bias']
01/05/2022 21:48:16 - INFO - __main__ -   ***** Running training *****
01/05/2022 21:48:16 - INFO - __main__ -     Num examples = 21798
01/05/2022 21:48:16 - INFO - __main__ -     Num Epochs = 50
01/05/2022 21:48:16 - INFO - __main__ -     Instantaneous batch size per GPU = 8
01/05/2022 21:48:16 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
01/05/2022 21:48:16 - INFO - __main__ -     Gradient Accumulation steps = 4
01/05/2022 21:48:16 - INFO - __main__ -     Total optimization steps = 34050
01/05/2022 21:48:16 - INFO - __main__ -   Seed = 2
01/05/2022 21:50:09 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:50:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/05/2022 21:50:09 - INFO - __main__ -   Seed = 2
01/05/2022 21:50:09 - INFO - root -   save adapters
01/05/2022 21:50:09 - INFO - root -   True
01/05/2022 21:50:09 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/', max_seq_length=128, do_train=True, do_eval=True, do_predict=False, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=0.0001, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter=None, predict_lang_adapter=None, test_adapter=False, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix=None, en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/05/2022 21:50:09 - INFO - __main__ -   Loading pretrained model and tokenizer
01/05/2022 21:50:12 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/05/2022 21:50:16 - INFO - __main__ -   Using lang2id = None
01/05/2022 21:50:16 - INFO - root -   Trying to decide if add adapter
01/05/2022 21:50:16 - INFO - root -   Adding task adapter
01/05/2022 21:50:16 - INFO - __main__ -   lang adapter names: 
01/05/2022 21:50:16 - INFO - __main__ -   bert.embeddings.word_embeddings.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.embeddings.position_embeddings.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.embeddings.token_type_embeddings.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.embeddings.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.embeddings.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.self.query.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.self.key.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.self.value.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.attention.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.intermediate.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.output.dense.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.output.dense.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.weight
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.output.LayerNorm.bias
01/05/2022 21:50:16 - INFO - __main__ -   False
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   classifier.weight
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:16 - INFO - __main__ -   classifier.bias
01/05/2022 21:50:16 - INFO - __main__ -   True
01/05/2022 21:50:20 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_train_en_bert-base-multilingual-cased_128
01/05/2022 21:50:22 - INFO - root -   ['bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.0.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.1.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.2.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.3.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.4.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.5.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.6.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.7.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.8.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.9.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.10.output.layer_text_task_adapters.udpos.adapter_up.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_down.0.bias', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.weight', 'bert.encoder.layer.11.output.layer_text_task_adapters.udpos.adapter_up.bias', 'classifier.weight', 'classifier.bias']
01/05/2022 21:50:22 - INFO - __main__ -   ***** Running training *****
01/05/2022 21:50:22 - INFO - __main__ -     Num examples = 21798
01/05/2022 21:50:22 - INFO - __main__ -     Num Epochs = 50
01/05/2022 21:50:22 - INFO - __main__ -     Instantaneous batch size per GPU = 8
01/05/2022 21:50:22 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
01/05/2022 21:50:22 - INFO - __main__ -     Gradient Accumulation steps = 4
01/05/2022 21:50:22 - INFO - __main__ -     Total optimization steps = 34050
01/05/2022 21:50:22 - INFO - __main__ -   Seed = 2
01/05/2022 21:53:27 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 21:53:27 - INFO - __main__ -   ***** Running evaluation 1000 in en *****
01/05/2022 21:53:27 - INFO - __main__ -     Num examples = 3974
01/05/2022 21:53:27 - INFO - __main__ -     Batch size = 32
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 1
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 2
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 3
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 4
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 5
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 6
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 7
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 8
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 9
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 10
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 11
01/05/2022 21:53:27 - INFO - __main__ -   Batch number = 12
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 13
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 14
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 15
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 16
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 17
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 18
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 19
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 20
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 21
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 22
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 23
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 24
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 25
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 26
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 27
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 28
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 29
01/05/2022 21:53:28 - INFO - __main__ -   Batch number = 30
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 31
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 32
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 33
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 34
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 35
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 36
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 37
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 38
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 39
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 40
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 41
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 42
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 43
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 44
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 45
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 46
01/05/2022 21:53:29 - INFO - __main__ -   Batch number = 47
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 48
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 49
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 50
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 51
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 52
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 53
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 54
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 55
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 56
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 57
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 58
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 59
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 60
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 61
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 62
01/05/2022 21:53:30 - INFO - __main__ -   Batch number = 63
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 64
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 65
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 66
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 67
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 68
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 69
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 70
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 71
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 72
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 73
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 74
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 75
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 76
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 77
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 78
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 79
01/05/2022 21:53:31 - INFO - __main__ -   Batch number = 80
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 81
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 82
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 83
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 84
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 85
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 86
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 87
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 88
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 89
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 90
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 91
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 92
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 93
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 94
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 95
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 96
01/05/2022 21:53:32 - INFO - __main__ -   Batch number = 97
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 98
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 99
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 100
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 101
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 102
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 103
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 104
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 105
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 106
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 107
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 108
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 109
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 110
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 111
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 112
01/05/2022 21:53:33 - INFO - __main__ -   Batch number = 113
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 114
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 115
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 116
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 117
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 118
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 119
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 120
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 121
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 122
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 123
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 124
01/05/2022 21:53:34 - INFO - __main__ -   Batch number = 125
01/05/2022 21:53:36 - INFO - __main__ -   ***** Evaluation result 1000 in en *****
01/05/2022 21:53:36 - INFO - __main__ -     f1 = 0.9414272871270174
01/05/2022 21:53:36 - INFO - __main__ -     loss = 0.16562934836745263
01/05/2022 21:53:36 - INFO - __main__ -     precision = 0.94112914270063
01/05/2022 21:53:36 - INFO - __main__ -     recall = 0.941725620514226
01/05/2022 21:53:36 - INFO - __main__ -   result['f1']=0.9414272871270174 > best_score=0.0
01/05/2022 21:53:36 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/checkpoint-best
01/05/2022 21:53:36 - INFO - __main__ -   Reset patience to 0
01/05/2022 21:58:32 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 21:58:32 - INFO - __main__ -   ***** Running evaluation 2000 in en *****
01/05/2022 21:58:32 - INFO - __main__ -     Num examples = 3974
01/05/2022 21:58:32 - INFO - __main__ -     Batch size = 32
01/05/2022 21:58:32 - INFO - __main__ -   Batch number = 1
01/05/2022 21:58:32 - INFO - __main__ -   Batch number = 2
01/05/2022 21:58:32 - INFO - __main__ -   Batch number = 3
01/05/2022 21:58:32 - INFO - __main__ -   Batch number = 4
01/05/2022 21:58:33 - INFO - __main__ -   Batch number = 5
01/05/2022 21:58:33 - INFO - __main__ -   Batch number = 6
01/05/2022 21:58:33 - INFO - __main__ -   Batch number = 7
01/05/2022 21:58:33 - INFO - __main__ -   Batch number = 8
01/05/2022 21:58:33 - INFO - __main__ -   Batch number = 9
01/05/2022 21:58:33 - INFO - __main__ -   Batch number = 10
01/05/2022 21:58:33 - INFO - __main__ -   Batch number = 11
01/05/2022 21:58:33 - INFO - __main__ -   Batch number = 12
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 13
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 14
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 15
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 16
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 17
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 18
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 19
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 20
01/05/2022 21:58:34 - INFO - __main__ -   Batch number = 21
01/05/2022 21:58:35 - INFO - __main__ -   Batch number = 22
01/05/2022 21:58:35 - INFO - __main__ -   Batch number = 23
01/05/2022 21:58:35 - INFO - __main__ -   Batch number = 24
01/05/2022 21:58:35 - INFO - __main__ -   Batch number = 25
01/05/2022 21:58:35 - INFO - __main__ -   Batch number = 26
01/05/2022 21:58:35 - INFO - __main__ -   Batch number = 27
01/05/2022 21:58:35 - INFO - __main__ -   Batch number = 28
01/05/2022 21:58:35 - INFO - __main__ -   Batch number = 29
01/05/2022 21:58:36 - INFO - __main__ -   Batch number = 30
01/05/2022 21:58:36 - INFO - __main__ -   Batch number = 31
01/05/2022 21:58:36 - INFO - __main__ -   Batch number = 32
01/05/2022 21:58:36 - INFO - __main__ -   Batch number = 33
01/05/2022 21:58:36 - INFO - __main__ -   Batch number = 34
01/05/2022 21:58:36 - INFO - __main__ -   Batch number = 35
01/05/2022 21:58:36 - INFO - __main__ -   Batch number = 36
01/05/2022 21:58:36 - INFO - __main__ -   Batch number = 37
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 38
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 39
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 40
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 41
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 42
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 43
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 44
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 45
01/05/2022 21:58:37 - INFO - __main__ -   Batch number = 46
01/05/2022 21:58:38 - INFO - __main__ -   Batch number = 47
01/05/2022 21:58:38 - INFO - __main__ -   Batch number = 48
01/05/2022 21:58:38 - INFO - __main__ -   Batch number = 49
01/05/2022 21:58:38 - INFO - __main__ -   Batch number = 50
01/05/2022 21:58:38 - INFO - __main__ -   Batch number = 51
01/05/2022 21:58:38 - INFO - __main__ -   Batch number = 52
01/05/2022 21:58:38 - INFO - __main__ -   Batch number = 53
01/05/2022 21:58:38 - INFO - __main__ -   Batch number = 54
01/05/2022 21:58:39 - INFO - __main__ -   Batch number = 55
01/05/2022 21:58:39 - INFO - __main__ -   Batch number = 56
01/05/2022 21:58:39 - INFO - __main__ -   Batch number = 57
01/05/2022 21:58:39 - INFO - __main__ -   Batch number = 58
01/05/2022 21:58:39 - INFO - __main__ -   Batch number = 59
01/05/2022 21:58:39 - INFO - __main__ -   Batch number = 60
01/05/2022 21:58:39 - INFO - __main__ -   Batch number = 61
01/05/2022 21:58:39 - INFO - __main__ -   Batch number = 62
01/05/2022 21:58:40 - INFO - __main__ -   Batch number = 63
01/05/2022 21:58:40 - INFO - __main__ -   Batch number = 64
01/05/2022 21:58:40 - INFO - __main__ -   Batch number = 65
01/05/2022 21:58:40 - INFO - __main__ -   Batch number = 66
01/05/2022 21:58:40 - INFO - __main__ -   Batch number = 67
01/05/2022 21:58:40 - INFO - __main__ -   Batch number = 68
01/05/2022 21:58:40 - INFO - __main__ -   Batch number = 69
01/05/2022 21:58:40 - INFO - __main__ -   Batch number = 70
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 71
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 72
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 73
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 74
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 75
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 76
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 77
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 78
01/05/2022 21:58:41 - INFO - __main__ -   Batch number = 79
01/05/2022 21:58:42 - INFO - __main__ -   Batch number = 80
01/05/2022 21:58:42 - INFO - __main__ -   Batch number = 81
01/05/2022 21:58:42 - INFO - __main__ -   Batch number = 82
01/05/2022 21:58:42 - INFO - __main__ -   Batch number = 83
01/05/2022 21:58:42 - INFO - __main__ -   Batch number = 84
01/05/2022 21:58:42 - INFO - __main__ -   Batch number = 85
01/05/2022 21:58:42 - INFO - __main__ -   Batch number = 86
01/05/2022 21:58:42 - INFO - __main__ -   Batch number = 87
01/05/2022 21:58:43 - INFO - __main__ -   Batch number = 88
01/05/2022 21:58:43 - INFO - __main__ -   Batch number = 89
01/05/2022 21:58:43 - INFO - __main__ -   Batch number = 90
01/05/2022 21:58:43 - INFO - __main__ -   Batch number = 91
01/05/2022 21:58:43 - INFO - __main__ -   Batch number = 92
01/05/2022 21:58:43 - INFO - __main__ -   Batch number = 93
01/05/2022 21:58:43 - INFO - __main__ -   Batch number = 94
01/05/2022 21:58:43 - INFO - __main__ -   Batch number = 95
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 96
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 97
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 98
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 99
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 100
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 101
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 102
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 103
01/05/2022 21:58:44 - INFO - __main__ -   Batch number = 104
01/05/2022 21:58:45 - INFO - __main__ -   Batch number = 105
01/05/2022 21:58:45 - INFO - __main__ -   Batch number = 106
01/05/2022 21:58:45 - INFO - __main__ -   Batch number = 107
01/05/2022 21:58:45 - INFO - __main__ -   Batch number = 108
01/05/2022 21:58:45 - INFO - __main__ -   Batch number = 109
01/05/2022 21:58:45 - INFO - __main__ -   Batch number = 110
01/05/2022 21:58:45 - INFO - __main__ -   Batch number = 111
01/05/2022 21:58:45 - INFO - __main__ -   Batch number = 112
01/05/2022 21:58:46 - INFO - __main__ -   Batch number = 113
01/05/2022 21:58:46 - INFO - __main__ -   Batch number = 114
01/05/2022 21:58:46 - INFO - __main__ -   Batch number = 115
01/05/2022 21:58:46 - INFO - __main__ -   Batch number = 116
01/05/2022 21:58:46 - INFO - __main__ -   Batch number = 117
01/05/2022 21:58:46 - INFO - __main__ -   Batch number = 118
01/05/2022 21:58:46 - INFO - __main__ -   Batch number = 119
01/05/2022 21:58:46 - INFO - __main__ -   Batch number = 120
01/05/2022 21:58:47 - INFO - __main__ -   Batch number = 121
01/05/2022 21:58:47 - INFO - __main__ -   Batch number = 122
01/05/2022 21:58:47 - INFO - __main__ -   Batch number = 123
01/05/2022 21:58:47 - INFO - __main__ -   Batch number = 124
01/05/2022 21:58:47 - INFO - __main__ -   Batch number = 125
01/05/2022 21:58:48 - INFO - __main__ -   ***** Evaluation result 2000 in en *****
01/05/2022 21:58:48 - INFO - __main__ -     f1 = 0.946492963657699
01/05/2022 21:58:48 - INFO - __main__ -     loss = 0.14417749679088593
01/05/2022 21:58:48 - INFO - __main__ -     precision = 0.9465497156170767
01/05/2022 21:58:48 - INFO - __main__ -     recall = 0.9464362185032289
01/05/2022 21:58:48 - INFO - __main__ -   result['f1']=0.946492963657699 > best_score=0.9414272871270174
01/05/2022 21:58:48 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/checkpoint-best
01/05/2022 21:58:48 - INFO - __main__ -   Reset patience to 0
01/05/2022 22:04:44 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:04:44 - INFO - __main__ -   ***** Running evaluation 3000 in en *****
01/05/2022 22:04:44 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:04:44 - INFO - __main__ -     Batch size = 32
01/05/2022 22:04:44 - INFO - __main__ -   Batch number = 1
01/05/2022 22:04:44 - INFO - __main__ -   Batch number = 2
01/05/2022 22:04:44 - INFO - __main__ -   Batch number = 3
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 4
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 5
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 6
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 7
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 8
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 9
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 10
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 11
01/05/2022 22:04:45 - INFO - __main__ -   Batch number = 12
01/05/2022 22:04:46 - INFO - __main__ -   Batch number = 13
01/05/2022 22:04:46 - INFO - __main__ -   Batch number = 14
01/05/2022 22:04:46 - INFO - __main__ -   Batch number = 15
01/05/2022 22:04:46 - INFO - __main__ -   Batch number = 16
01/05/2022 22:04:46 - INFO - __main__ -   Batch number = 17
01/05/2022 22:04:46 - INFO - __main__ -   Batch number = 18
01/05/2022 22:04:46 - INFO - __main__ -   Batch number = 19
01/05/2022 22:04:46 - INFO - __main__ -   Batch number = 20
01/05/2022 22:04:47 - INFO - __main__ -   Batch number = 21
01/05/2022 22:04:47 - INFO - __main__ -   Batch number = 22
01/05/2022 22:04:47 - INFO - __main__ -   Batch number = 23
01/05/2022 22:04:47 - INFO - __main__ -   Batch number = 24
01/05/2022 22:04:47 - INFO - __main__ -   Batch number = 25
01/05/2022 22:04:47 - INFO - __main__ -   Batch number = 26
01/05/2022 22:04:47 - INFO - __main__ -   Batch number = 27
01/05/2022 22:04:47 - INFO - __main__ -   Batch number = 28
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 29
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 30
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 31
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 32
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 33
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 34
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 35
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 36
01/05/2022 22:04:48 - INFO - __main__ -   Batch number = 37
01/05/2022 22:04:49 - INFO - __main__ -   Batch number = 38
01/05/2022 22:04:49 - INFO - __main__ -   Batch number = 39
01/05/2022 22:04:49 - INFO - __main__ -   Batch number = 40
01/05/2022 22:04:49 - INFO - __main__ -   Batch number = 41
01/05/2022 22:04:49 - INFO - __main__ -   Batch number = 42
01/05/2022 22:04:49 - INFO - __main__ -   Batch number = 43
01/05/2022 22:04:49 - INFO - __main__ -   Batch number = 44
01/05/2022 22:04:49 - INFO - __main__ -   Batch number = 45
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 46
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 47
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 48
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 49
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 50
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 51
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 52
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 53
01/05/2022 22:04:50 - INFO - __main__ -   Batch number = 54
01/05/2022 22:04:51 - INFO - __main__ -   Batch number = 55
01/05/2022 22:04:51 - INFO - __main__ -   Batch number = 56
01/05/2022 22:04:51 - INFO - __main__ -   Batch number = 57
01/05/2022 22:04:51 - INFO - __main__ -   Batch number = 58
01/05/2022 22:04:51 - INFO - __main__ -   Batch number = 59
01/05/2022 22:04:51 - INFO - __main__ -   Batch number = 60
01/05/2022 22:04:51 - INFO - __main__ -   Batch number = 61
01/05/2022 22:04:51 - INFO - __main__ -   Batch number = 62
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 63
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 64
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 65
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 66
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 67
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 68
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 69
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 70
01/05/2022 22:04:52 - INFO - __main__ -   Batch number = 71
01/05/2022 22:04:53 - INFO - __main__ -   Batch number = 72
01/05/2022 22:04:53 - INFO - __main__ -   Batch number = 73
01/05/2022 22:04:53 - INFO - __main__ -   Batch number = 74
01/05/2022 22:04:53 - INFO - __main__ -   Batch number = 75
01/05/2022 22:04:53 - INFO - __main__ -   Batch number = 76
01/05/2022 22:04:53 - INFO - __main__ -   Batch number = 77
01/05/2022 22:04:53 - INFO - __main__ -   Batch number = 78
01/05/2022 22:04:53 - INFO - __main__ -   Batch number = 79
01/05/2022 22:04:54 - INFO - __main__ -   Batch number = 80
01/05/2022 22:04:54 - INFO - __main__ -   Batch number = 81
01/05/2022 22:04:54 - INFO - __main__ -   Batch number = 82
01/05/2022 22:04:54 - INFO - __main__ -   Batch number = 83
01/05/2022 22:04:54 - INFO - __main__ -   Batch number = 84
01/05/2022 22:04:54 - INFO - __main__ -   Batch number = 85
01/05/2022 22:04:54 - INFO - __main__ -   Batch number = 86
01/05/2022 22:04:54 - INFO - __main__ -   Batch number = 87
01/05/2022 22:04:55 - INFO - __main__ -   Batch number = 88
01/05/2022 22:04:55 - INFO - __main__ -   Batch number = 89
01/05/2022 22:04:55 - INFO - __main__ -   Batch number = 90
01/05/2022 22:04:55 - INFO - __main__ -   Batch number = 91
01/05/2022 22:04:55 - INFO - __main__ -   Batch number = 92
01/05/2022 22:04:55 - INFO - __main__ -   Batch number = 93
01/05/2022 22:04:55 - INFO - __main__ -   Batch number = 94
01/05/2022 22:04:55 - INFO - __main__ -   Batch number = 95
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 96
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 97
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 98
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 99
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 100
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 101
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 102
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 103
01/05/2022 22:04:56 - INFO - __main__ -   Batch number = 104
01/05/2022 22:04:57 - INFO - __main__ -   Batch number = 105
01/05/2022 22:04:57 - INFO - __main__ -   Batch number = 106
01/05/2022 22:04:57 - INFO - __main__ -   Batch number = 107
01/05/2022 22:04:57 - INFO - __main__ -   Batch number = 108
01/05/2022 22:04:57 - INFO - __main__ -   Batch number = 109
01/05/2022 22:04:57 - INFO - __main__ -   Batch number = 110
01/05/2022 22:04:57 - INFO - __main__ -   Batch number = 111
01/05/2022 22:04:57 - INFO - __main__ -   Batch number = 112
01/05/2022 22:04:58 - INFO - __main__ -   Batch number = 113
01/05/2022 22:04:58 - INFO - __main__ -   Batch number = 114
01/05/2022 22:04:58 - INFO - __main__ -   Batch number = 115
01/05/2022 22:04:58 - INFO - __main__ -   Batch number = 116
01/05/2022 22:04:58 - INFO - __main__ -   Batch number = 117
01/05/2022 22:04:58 - INFO - __main__ -   Batch number = 118
01/05/2022 22:04:58 - INFO - __main__ -   Batch number = 119
01/05/2022 22:04:58 - INFO - __main__ -   Batch number = 120
01/05/2022 22:04:59 - INFO - __main__ -   Batch number = 121
01/05/2022 22:04:59 - INFO - __main__ -   Batch number = 122
01/05/2022 22:04:59 - INFO - __main__ -   Batch number = 123
01/05/2022 22:04:59 - INFO - __main__ -   Batch number = 124
01/05/2022 22:04:59 - INFO - __main__ -   Batch number = 125
01/05/2022 22:05:00 - INFO - __main__ -   ***** Evaluation result 3000 in en *****
01/05/2022 22:05:00 - INFO - __main__ -     f1 = 0.947389169316205
01/05/2022 22:05:00 - INFO - __main__ -     loss = 0.14528289905190467
01/05/2022 22:05:00 - INFO - __main__ -     precision = 0.9479659737943336
01/05/2022 22:05:00 - INFO - __main__ -     recall = 0.9468130663423492
01/05/2022 22:05:00 - INFO - __main__ -   result['f1']=0.947389169316205 > best_score=0.946492963657699
01/05/2022 22:05:00 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/checkpoint-best
01/05/2022 22:05:00 - INFO - __main__ -   Reset patience to 0
01/05/2022 22:10:58 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:10:58 - INFO - __main__ -   ***** Running evaluation 4000 in en *****
01/05/2022 22:10:58 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:10:58 - INFO - __main__ -     Batch size = 32
01/05/2022 22:10:58 - INFO - __main__ -   Batch number = 1
01/05/2022 22:10:59 - INFO - __main__ -   Batch number = 2
01/05/2022 22:10:59 - INFO - __main__ -   Batch number = 3
01/05/2022 22:10:59 - INFO - __main__ -   Batch number = 4
01/05/2022 22:10:59 - INFO - __main__ -   Batch number = 5
01/05/2022 22:10:59 - INFO - __main__ -   Batch number = 6
01/05/2022 22:10:59 - INFO - __main__ -   Batch number = 7
01/05/2022 22:10:59 - INFO - __main__ -   Batch number = 8
01/05/2022 22:10:59 - INFO - __main__ -   Batch number = 9
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 10
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 11
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 12
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 13
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 14
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 15
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 16
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 17
01/05/2022 22:11:00 - INFO - __main__ -   Batch number = 18
01/05/2022 22:11:01 - INFO - __main__ -   Batch number = 19
01/05/2022 22:11:01 - INFO - __main__ -   Batch number = 20
01/05/2022 22:11:01 - INFO - __main__ -   Batch number = 21
01/05/2022 22:11:01 - INFO - __main__ -   Batch number = 22
01/05/2022 22:11:01 - INFO - __main__ -   Batch number = 23
01/05/2022 22:11:01 - INFO - __main__ -   Batch number = 24
01/05/2022 22:11:01 - INFO - __main__ -   Batch number = 25
01/05/2022 22:11:01 - INFO - __main__ -   Batch number = 26
01/05/2022 22:11:02 - INFO - __main__ -   Batch number = 27
01/05/2022 22:11:02 - INFO - __main__ -   Batch number = 28
01/05/2022 22:11:02 - INFO - __main__ -   Batch number = 29
01/05/2022 22:11:02 - INFO - __main__ -   Batch number = 30
01/05/2022 22:11:02 - INFO - __main__ -   Batch number = 31
01/05/2022 22:11:02 - INFO - __main__ -   Batch number = 32
01/05/2022 22:11:02 - INFO - __main__ -   Batch number = 33
01/05/2022 22:11:02 - INFO - __main__ -   Batch number = 34
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 35
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 36
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 37
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 38
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 39
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 40
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 41
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 42
01/05/2022 22:11:03 - INFO - __main__ -   Batch number = 43
01/05/2022 22:11:04 - INFO - __main__ -   Batch number = 44
01/05/2022 22:11:04 - INFO - __main__ -   Batch number = 45
01/05/2022 22:11:04 - INFO - __main__ -   Batch number = 46
01/05/2022 22:11:04 - INFO - __main__ -   Batch number = 47
01/05/2022 22:11:04 - INFO - __main__ -   Batch number = 48
01/05/2022 22:11:04 - INFO - __main__ -   Batch number = 49
01/05/2022 22:11:04 - INFO - __main__ -   Batch number = 50
01/05/2022 22:11:04 - INFO - __main__ -   Batch number = 51
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 52
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 53
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 54
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 55
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 56
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 57
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 58
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 59
01/05/2022 22:11:05 - INFO - __main__ -   Batch number = 60
01/05/2022 22:11:06 - INFO - __main__ -   Batch number = 61
01/05/2022 22:11:06 - INFO - __main__ -   Batch number = 62
01/05/2022 22:11:06 - INFO - __main__ -   Batch number = 63
01/05/2022 22:11:06 - INFO - __main__ -   Batch number = 64
01/05/2022 22:11:06 - INFO - __main__ -   Batch number = 65
01/05/2022 22:11:06 - INFO - __main__ -   Batch number = 66
01/05/2022 22:11:06 - INFO - __main__ -   Batch number = 67
01/05/2022 22:11:06 - INFO - __main__ -   Batch number = 68
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 69
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 70
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 71
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 72
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 73
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 74
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 75
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 76
01/05/2022 22:11:07 - INFO - __main__ -   Batch number = 77
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 78
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 79
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 80
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 81
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 82
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 83
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 84
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 85
01/05/2022 22:11:08 - INFO - __main__ -   Batch number = 86
01/05/2022 22:11:09 - INFO - __main__ -   Batch number = 87
01/05/2022 22:11:09 - INFO - __main__ -   Batch number = 88
01/05/2022 22:11:09 - INFO - __main__ -   Batch number = 89
01/05/2022 22:11:09 - INFO - __main__ -   Batch number = 90
01/05/2022 22:11:09 - INFO - __main__ -   Batch number = 91
01/05/2022 22:11:09 - INFO - __main__ -   Batch number = 92
01/05/2022 22:11:09 - INFO - __main__ -   Batch number = 93
01/05/2022 22:11:09 - INFO - __main__ -   Batch number = 94
01/05/2022 22:11:10 - INFO - __main__ -   Batch number = 95
01/05/2022 22:11:10 - INFO - __main__ -   Batch number = 96
01/05/2022 22:11:10 - INFO - __main__ -   Batch number = 97
01/05/2022 22:11:10 - INFO - __main__ -   Batch number = 98
01/05/2022 22:11:10 - INFO - __main__ -   Batch number = 99
01/05/2022 22:11:10 - INFO - __main__ -   Batch number = 100
01/05/2022 22:11:10 - INFO - __main__ -   Batch number = 101
01/05/2022 22:11:10 - INFO - __main__ -   Batch number = 102
01/05/2022 22:11:11 - INFO - __main__ -   Batch number = 103
01/05/2022 22:11:11 - INFO - __main__ -   Batch number = 104
01/05/2022 22:11:11 - INFO - __main__ -   Batch number = 105
01/05/2022 22:11:11 - INFO - __main__ -   Batch number = 106
01/05/2022 22:11:11 - INFO - __main__ -   Batch number = 107
01/05/2022 22:11:11 - INFO - __main__ -   Batch number = 108
01/05/2022 22:11:11 - INFO - __main__ -   Batch number = 109
01/05/2022 22:11:11 - INFO - __main__ -   Batch number = 110
01/05/2022 22:11:12 - INFO - __main__ -   Batch number = 111
01/05/2022 22:11:12 - INFO - __main__ -   Batch number = 112
01/05/2022 22:11:12 - INFO - __main__ -   Batch number = 113
01/05/2022 22:11:12 - INFO - __main__ -   Batch number = 114
01/05/2022 22:11:12 - INFO - __main__ -   Batch number = 115
01/05/2022 22:11:12 - INFO - __main__ -   Batch number = 116
01/05/2022 22:11:12 - INFO - __main__ -   Batch number = 117
01/05/2022 22:11:12 - INFO - __main__ -   Batch number = 118
01/05/2022 22:11:13 - INFO - __main__ -   Batch number = 119
01/05/2022 22:11:13 - INFO - __main__ -   Batch number = 120
01/05/2022 22:11:13 - INFO - __main__ -   Batch number = 121
01/05/2022 22:11:13 - INFO - __main__ -   Batch number = 122
01/05/2022 22:11:13 - INFO - __main__ -   Batch number = 123
01/05/2022 22:11:13 - INFO - __main__ -   Batch number = 124
01/05/2022 22:11:13 - INFO - __main__ -   Batch number = 125
01/05/2022 22:11:15 - INFO - __main__ -   ***** Evaluation result 4000 in en *****
01/05/2022 22:11:15 - INFO - __main__ -     f1 = 0.9490436585094263
01/05/2022 22:11:15 - INFO - __main__ -     loss = 0.1373485199511051
01/05/2022 22:11:15 - INFO - __main__ -     precision = 0.949133086622807
01/05/2022 22:11:15 - INFO - __main__ -     recall = 0.9489542472464414
01/05/2022 22:11:15 - INFO - __main__ -   result['f1']=0.9490436585094263 > best_score=0.947389169316205
01/05/2022 22:11:15 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/checkpoint-best
01/05/2022 22:11:15 - INFO - __main__ -   Reset patience to 0
01/05/2022 22:17:15 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:17:15 - INFO - __main__ -   ***** Running evaluation 5000 in en *****
01/05/2022 22:17:15 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:17:15 - INFO - __main__ -     Batch size = 32
01/05/2022 22:17:15 - INFO - __main__ -   Batch number = 1
01/05/2022 22:17:15 - INFO - __main__ -   Batch number = 2
01/05/2022 22:17:15 - INFO - __main__ -   Batch number = 3
01/05/2022 22:17:16 - INFO - __main__ -   Batch number = 4
01/05/2022 22:17:16 - INFO - __main__ -   Batch number = 5
01/05/2022 22:17:16 - INFO - __main__ -   Batch number = 6
01/05/2022 22:17:16 - INFO - __main__ -   Batch number = 7
01/05/2022 22:17:16 - INFO - __main__ -   Batch number = 8
01/05/2022 22:17:16 - INFO - __main__ -   Batch number = 9
01/05/2022 22:17:16 - INFO - __main__ -   Batch number = 10
01/05/2022 22:17:16 - INFO - __main__ -   Batch number = 11
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 12
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 13
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 14
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 15
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 16
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 17
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 18
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 19
01/05/2022 22:17:17 - INFO - __main__ -   Batch number = 20
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 21
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 22
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 23
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 24
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 25
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 26
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 27
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 28
01/05/2022 22:17:18 - INFO - __main__ -   Batch number = 29
01/05/2022 22:17:19 - INFO - __main__ -   Batch number = 30
01/05/2022 22:17:19 - INFO - __main__ -   Batch number = 31
01/05/2022 22:17:19 - INFO - __main__ -   Batch number = 32
01/05/2022 22:17:19 - INFO - __main__ -   Batch number = 33
01/05/2022 22:17:19 - INFO - __main__ -   Batch number = 34
01/05/2022 22:17:19 - INFO - __main__ -   Batch number = 35
01/05/2022 22:17:19 - INFO - __main__ -   Batch number = 36
01/05/2022 22:17:19 - INFO - __main__ -   Batch number = 37
01/05/2022 22:17:20 - INFO - __main__ -   Batch number = 38
01/05/2022 22:17:20 - INFO - __main__ -   Batch number = 39
01/05/2022 22:17:20 - INFO - __main__ -   Batch number = 40
01/05/2022 22:17:20 - INFO - __main__ -   Batch number = 41
01/05/2022 22:17:20 - INFO - __main__ -   Batch number = 42
01/05/2022 22:17:20 - INFO - __main__ -   Batch number = 43
01/05/2022 22:17:20 - INFO - __main__ -   Batch number = 44
01/05/2022 22:17:20 - INFO - __main__ -   Batch number = 45
01/05/2022 22:17:21 - INFO - __main__ -   Batch number = 46
01/05/2022 22:17:21 - INFO - __main__ -   Batch number = 47
01/05/2022 22:17:21 - INFO - __main__ -   Batch number = 48
01/05/2022 22:17:21 - INFO - __main__ -   Batch number = 49
01/05/2022 22:17:21 - INFO - __main__ -   Batch number = 50
01/05/2022 22:17:21 - INFO - __main__ -   Batch number = 51
01/05/2022 22:17:21 - INFO - __main__ -   Batch number = 52
01/05/2022 22:17:21 - INFO - __main__ -   Batch number = 53
01/05/2022 22:17:22 - INFO - __main__ -   Batch number = 54
01/05/2022 22:17:22 - INFO - __main__ -   Batch number = 55
01/05/2022 22:17:22 - INFO - __main__ -   Batch number = 56
01/05/2022 22:17:22 - INFO - __main__ -   Batch number = 57
01/05/2022 22:17:22 - INFO - __main__ -   Batch number = 58
01/05/2022 22:17:22 - INFO - __main__ -   Batch number = 59
01/05/2022 22:17:22 - INFO - __main__ -   Batch number = 60
01/05/2022 22:17:22 - INFO - __main__ -   Batch number = 61
01/05/2022 22:17:23 - INFO - __main__ -   Batch number = 62
01/05/2022 22:17:23 - INFO - __main__ -   Batch number = 63
01/05/2022 22:17:23 - INFO - __main__ -   Batch number = 64
01/05/2022 22:17:23 - INFO - __main__ -   Batch number = 65
01/05/2022 22:17:23 - INFO - __main__ -   Batch number = 66
01/05/2022 22:17:23 - INFO - __main__ -   Batch number = 67
01/05/2022 22:17:23 - INFO - __main__ -   Batch number = 68
01/05/2022 22:17:23 - INFO - __main__ -   Batch number = 69
01/05/2022 22:17:24 - INFO - __main__ -   Batch number = 70
01/05/2022 22:17:24 - INFO - __main__ -   Batch number = 71
01/05/2022 22:17:24 - INFO - __main__ -   Batch number = 72
01/05/2022 22:17:24 - INFO - __main__ -   Batch number = 73
01/05/2022 22:17:24 - INFO - __main__ -   Batch number = 74
01/05/2022 22:17:24 - INFO - __main__ -   Batch number = 75
01/05/2022 22:17:24 - INFO - __main__ -   Batch number = 76
01/05/2022 22:17:24 - INFO - __main__ -   Batch number = 77
01/05/2022 22:17:25 - INFO - __main__ -   Batch number = 78
01/05/2022 22:17:25 - INFO - __main__ -   Batch number = 79
01/05/2022 22:17:25 - INFO - __main__ -   Batch number = 80
01/05/2022 22:17:25 - INFO - __main__ -   Batch number = 81
01/05/2022 22:17:25 - INFO - __main__ -   Batch number = 82
01/05/2022 22:17:25 - INFO - __main__ -   Batch number = 83
01/05/2022 22:17:25 - INFO - __main__ -   Batch number = 84
01/05/2022 22:17:25 - INFO - __main__ -   Batch number = 85
01/05/2022 22:17:26 - INFO - __main__ -   Batch number = 86
01/05/2022 22:17:26 - INFO - __main__ -   Batch number = 87
01/05/2022 22:17:26 - INFO - __main__ -   Batch number = 88
01/05/2022 22:17:26 - INFO - __main__ -   Batch number = 89
01/05/2022 22:17:26 - INFO - __main__ -   Batch number = 90
01/05/2022 22:17:26 - INFO - __main__ -   Batch number = 91
01/05/2022 22:17:26 - INFO - __main__ -   Batch number = 92
01/05/2022 22:17:26 - INFO - __main__ -   Batch number = 93
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 94
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 95
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 96
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 97
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 98
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 99
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 100
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 101
01/05/2022 22:17:27 - INFO - __main__ -   Batch number = 102
01/05/2022 22:17:28 - INFO - __main__ -   Batch number = 103
01/05/2022 22:17:28 - INFO - __main__ -   Batch number = 104
01/05/2022 22:17:28 - INFO - __main__ -   Batch number = 105
01/05/2022 22:17:28 - INFO - __main__ -   Batch number = 106
01/05/2022 22:17:28 - INFO - __main__ -   Batch number = 107
01/05/2022 22:17:28 - INFO - __main__ -   Batch number = 108
01/05/2022 22:17:28 - INFO - __main__ -   Batch number = 109
01/05/2022 22:17:28 - INFO - __main__ -   Batch number = 110
01/05/2022 22:17:29 - INFO - __main__ -   Batch number = 111
01/05/2022 22:17:29 - INFO - __main__ -   Batch number = 112
01/05/2022 22:17:29 - INFO - __main__ -   Batch number = 113
01/05/2022 22:17:29 - INFO - __main__ -   Batch number = 114
01/05/2022 22:17:29 - INFO - __main__ -   Batch number = 115
01/05/2022 22:17:29 - INFO - __main__ -   Batch number = 116
01/05/2022 22:17:29 - INFO - __main__ -   Batch number = 117
01/05/2022 22:17:30 - INFO - __main__ -   Batch number = 118
01/05/2022 22:17:30 - INFO - __main__ -   Batch number = 119
01/05/2022 22:17:30 - INFO - __main__ -   Batch number = 120
01/05/2022 22:17:30 - INFO - __main__ -   Batch number = 121
01/05/2022 22:17:30 - INFO - __main__ -   Batch number = 122
01/05/2022 22:17:30 - INFO - __main__ -   Batch number = 123
01/05/2022 22:17:30 - INFO - __main__ -   Batch number = 124
01/05/2022 22:17:30 - INFO - __main__ -   Batch number = 125
01/05/2022 22:17:32 - INFO - __main__ -   ***** Evaluation result 5000 in en *****
01/05/2022 22:17:32 - INFO - __main__ -     f1 = 0.9482588853784044
01/05/2022 22:17:32 - INFO - __main__ -     loss = 0.1414506976157427
01/05/2022 22:17:32 - INFO - __main__ -     precision = 0.9479748005615092
01/05/2022 22:17:32 - INFO - __main__ -     recall = 0.9485431405128556
01/05/2022 22:17:32 - INFO - __main__ -   Hit patience=1
01/05/2022 22:23:29 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:23:29 - INFO - __main__ -   ***** Running evaluation 6000 in en *****
01/05/2022 22:23:29 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:23:29 - INFO - __main__ -     Batch size = 32
01/05/2022 22:23:29 - INFO - __main__ -   Batch number = 1
01/05/2022 22:23:29 - INFO - __main__ -   Batch number = 2
01/05/2022 22:23:30 - INFO - __main__ -   Batch number = 3
01/05/2022 22:23:30 - INFO - __main__ -   Batch number = 4
01/05/2022 22:23:30 - INFO - __main__ -   Batch number = 5
01/05/2022 22:23:30 - INFO - __main__ -   Batch number = 6
01/05/2022 22:23:30 - INFO - __main__ -   Batch number = 7
01/05/2022 22:23:30 - INFO - __main__ -   Batch number = 8
01/05/2022 22:23:30 - INFO - __main__ -   Batch number = 9
01/05/2022 22:23:30 - INFO - __main__ -   Batch number = 10
01/05/2022 22:23:31 - INFO - __main__ -   Batch number = 11
01/05/2022 22:23:31 - INFO - __main__ -   Batch number = 12
01/05/2022 22:23:31 - INFO - __main__ -   Batch number = 13
01/05/2022 22:23:31 - INFO - __main__ -   Batch number = 14
01/05/2022 22:23:31 - INFO - __main__ -   Batch number = 15
01/05/2022 22:23:31 - INFO - __main__ -   Batch number = 16
01/05/2022 22:23:31 - INFO - __main__ -   Batch number = 17
01/05/2022 22:23:31 - INFO - __main__ -   Batch number = 18
01/05/2022 22:23:32 - INFO - __main__ -   Batch number = 19
01/05/2022 22:23:32 - INFO - __main__ -   Batch number = 20
01/05/2022 22:23:32 - INFO - __main__ -   Batch number = 21
01/05/2022 22:23:32 - INFO - __main__ -   Batch number = 22
01/05/2022 22:23:32 - INFO - __main__ -   Batch number = 23
01/05/2022 22:23:32 - INFO - __main__ -   Batch number = 24
01/05/2022 22:23:32 - INFO - __main__ -   Batch number = 25
01/05/2022 22:23:32 - INFO - __main__ -   Batch number = 26
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 27
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 28
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 29
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 30
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 31
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 32
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 33
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 34
01/05/2022 22:23:33 - INFO - __main__ -   Batch number = 35
01/05/2022 22:23:34 - INFO - __main__ -   Batch number = 36
01/05/2022 22:23:34 - INFO - __main__ -   Batch number = 37
01/05/2022 22:23:34 - INFO - __main__ -   Batch number = 38
01/05/2022 22:23:34 - INFO - __main__ -   Batch number = 39
01/05/2022 22:23:34 - INFO - __main__ -   Batch number = 40
01/05/2022 22:23:34 - INFO - __main__ -   Batch number = 41
01/05/2022 22:23:34 - INFO - __main__ -   Batch number = 42
01/05/2022 22:23:34 - INFO - __main__ -   Batch number = 43
01/05/2022 22:23:35 - INFO - __main__ -   Batch number = 44
01/05/2022 22:23:35 - INFO - __main__ -   Batch number = 45
01/05/2022 22:23:35 - INFO - __main__ -   Batch number = 46
01/05/2022 22:23:35 - INFO - __main__ -   Batch number = 47
01/05/2022 22:23:35 - INFO - __main__ -   Batch number = 48
01/05/2022 22:23:35 - INFO - __main__ -   Batch number = 49
01/05/2022 22:23:35 - INFO - __main__ -   Batch number = 50
01/05/2022 22:23:35 - INFO - __main__ -   Batch number = 51
01/05/2022 22:23:36 - INFO - __main__ -   Batch number = 52
01/05/2022 22:23:36 - INFO - __main__ -   Batch number = 53
01/05/2022 22:23:36 - INFO - __main__ -   Batch number = 54
01/05/2022 22:23:36 - INFO - __main__ -   Batch number = 55
01/05/2022 22:23:36 - INFO - __main__ -   Batch number = 56
01/05/2022 22:23:36 - INFO - __main__ -   Batch number = 57
01/05/2022 22:23:36 - INFO - __main__ -   Batch number = 58
01/05/2022 22:23:36 - INFO - __main__ -   Batch number = 59
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 60
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 61
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 62
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 63
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 64
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 65
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 66
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 67
01/05/2022 22:23:37 - INFO - __main__ -   Batch number = 68
01/05/2022 22:23:38 - INFO - __main__ -   Batch number = 69
01/05/2022 22:23:38 - INFO - __main__ -   Batch number = 70
01/05/2022 22:23:38 - INFO - __main__ -   Batch number = 71
01/05/2022 22:23:38 - INFO - __main__ -   Batch number = 72
01/05/2022 22:23:38 - INFO - __main__ -   Batch number = 73
01/05/2022 22:23:38 - INFO - __main__ -   Batch number = 74
01/05/2022 22:23:38 - INFO - __main__ -   Batch number = 75
01/05/2022 22:23:38 - INFO - __main__ -   Batch number = 76
01/05/2022 22:23:39 - INFO - __main__ -   Batch number = 77
01/05/2022 22:23:39 - INFO - __main__ -   Batch number = 78
01/05/2022 22:23:39 - INFO - __main__ -   Batch number = 79
01/05/2022 22:23:39 - INFO - __main__ -   Batch number = 80
01/05/2022 22:23:39 - INFO - __main__ -   Batch number = 81
01/05/2022 22:23:39 - INFO - __main__ -   Batch number = 82
01/05/2022 22:23:39 - INFO - __main__ -   Batch number = 83
01/05/2022 22:23:39 - INFO - __main__ -   Batch number = 84
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 85
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 86
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 87
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 88
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 89
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 90
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 91
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 92
01/05/2022 22:23:40 - INFO - __main__ -   Batch number = 93
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 94
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 95
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 96
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 97
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 98
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 99
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 100
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 101
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 102
01/05/2022 22:23:41 - INFO - __main__ -   Batch number = 103
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 104
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 105
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 106
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 107
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 108
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 109
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 110
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 111
01/05/2022 22:23:42 - INFO - __main__ -   Batch number = 112
01/05/2022 22:23:43 - INFO - __main__ -   Batch number = 113
01/05/2022 22:23:43 - INFO - __main__ -   Batch number = 114
01/05/2022 22:23:43 - INFO - __main__ -   Batch number = 115
01/05/2022 22:23:43 - INFO - __main__ -   Batch number = 116
01/05/2022 22:23:43 - INFO - __main__ -   Batch number = 117
01/05/2022 22:23:43 - INFO - __main__ -   Batch number = 118
01/05/2022 22:23:43 - INFO - __main__ -   Batch number = 119
01/05/2022 22:23:43 - INFO - __main__ -   Batch number = 120
01/05/2022 22:23:44 - INFO - __main__ -   Batch number = 121
01/05/2022 22:23:44 - INFO - __main__ -   Batch number = 122
01/05/2022 22:23:44 - INFO - __main__ -   Batch number = 123
01/05/2022 22:23:44 - INFO - __main__ -   Batch number = 124
01/05/2022 22:23:44 - INFO - __main__ -   Batch number = 125
01/05/2022 22:23:45 - INFO - __main__ -   ***** Evaluation result 6000 in en *****
01/05/2022 22:23:45 - INFO - __main__ -     f1 = 0.9493291293246741
01/05/2022 22:23:45 - INFO - __main__ -     loss = 0.14065848419070243
01/05/2022 22:23:45 - INFO - __main__ -     precision = 0.949687151795663
01/05/2022 22:23:45 - INFO - __main__ -     recall = 0.948971376693674
01/05/2022 22:23:45 - INFO - __main__ -   result['f1']=0.9493291293246741 > best_score=0.9490436585094263
01/05/2022 22:23:45 - INFO - __main__ -   Saving the best model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/checkpoint-best
01/05/2022 22:23:45 - INFO - __main__ -   Reset patience to 0
01/05/2022 22:29:44 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:29:45 - INFO - __main__ -   ***** Running evaluation 7000 in en *****
01/05/2022 22:29:45 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:29:45 - INFO - __main__ -     Batch size = 32
01/05/2022 22:29:45 - INFO - __main__ -   Batch number = 1
01/05/2022 22:29:45 - INFO - __main__ -   Batch number = 2
01/05/2022 22:29:45 - INFO - __main__ -   Batch number = 3
01/05/2022 22:29:45 - INFO - __main__ -   Batch number = 4
01/05/2022 22:29:45 - INFO - __main__ -   Batch number = 5
01/05/2022 22:29:45 - INFO - __main__ -   Batch number = 6
01/05/2022 22:29:45 - INFO - __main__ -   Batch number = 7
01/05/2022 22:29:46 - INFO - __main__ -   Batch number = 8
01/05/2022 22:29:46 - INFO - __main__ -   Batch number = 9
01/05/2022 22:29:46 - INFO - __main__ -   Batch number = 10
01/05/2022 22:29:46 - INFO - __main__ -   Batch number = 11
01/05/2022 22:29:46 - INFO - __main__ -   Batch number = 12
01/05/2022 22:29:46 - INFO - __main__ -   Batch number = 13
01/05/2022 22:29:46 - INFO - __main__ -   Batch number = 14
01/05/2022 22:29:46 - INFO - __main__ -   Batch number = 15
01/05/2022 22:29:47 - INFO - __main__ -   Batch number = 16
01/05/2022 22:29:47 - INFO - __main__ -   Batch number = 17
01/05/2022 22:29:47 - INFO - __main__ -   Batch number = 18
01/05/2022 22:29:47 - INFO - __main__ -   Batch number = 19
01/05/2022 22:29:47 - INFO - __main__ -   Batch number = 20
01/05/2022 22:29:47 - INFO - __main__ -   Batch number = 21
01/05/2022 22:29:47 - INFO - __main__ -   Batch number = 22
01/05/2022 22:29:47 - INFO - __main__ -   Batch number = 23
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 24
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 25
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 26
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 27
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 28
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 29
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 30
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 31
01/05/2022 22:29:48 - INFO - __main__ -   Batch number = 32
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 33
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 34
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 35
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 36
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 37
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 38
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 39
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 40
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 41
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 42
01/05/2022 22:29:49 - INFO - __main__ -   Batch number = 43
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 44
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 45
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 46
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 47
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 48
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 49
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 50
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 51
01/05/2022 22:29:50 - INFO - __main__ -   Batch number = 52
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 53
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 54
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 55
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 56
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 57
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 58
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 59
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 60
01/05/2022 22:29:51 - INFO - __main__ -   Batch number = 61
01/05/2022 22:29:52 - INFO - __main__ -   Batch number = 62
01/05/2022 22:29:52 - INFO - __main__ -   Batch number = 63
01/05/2022 22:29:52 - INFO - __main__ -   Batch number = 64
01/05/2022 22:29:52 - INFO - __main__ -   Batch number = 65
01/05/2022 22:29:52 - INFO - __main__ -   Batch number = 66
01/05/2022 22:29:52 - INFO - __main__ -   Batch number = 67
01/05/2022 22:29:52 - INFO - __main__ -   Batch number = 68
01/05/2022 22:29:52 - INFO - __main__ -   Batch number = 69
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 70
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 71
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 72
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 73
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 74
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 75
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 76
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 77
01/05/2022 22:29:53 - INFO - __main__ -   Batch number = 78
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 79
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 80
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 81
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 82
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 83
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 84
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 85
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 86
01/05/2022 22:29:54 - INFO - __main__ -   Batch number = 87
01/05/2022 22:29:55 - INFO - __main__ -   Batch number = 88
01/05/2022 22:29:55 - INFO - __main__ -   Batch number = 89
01/05/2022 22:29:55 - INFO - __main__ -   Batch number = 90
01/05/2022 22:29:55 - INFO - __main__ -   Batch number = 91
01/05/2022 22:29:55 - INFO - __main__ -   Batch number = 92
01/05/2022 22:29:55 - INFO - __main__ -   Batch number = 93
01/05/2022 22:29:55 - INFO - __main__ -   Batch number = 94
01/05/2022 22:29:55 - INFO - __main__ -   Batch number = 95
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 96
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 97
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 98
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 99
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 100
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 101
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 102
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 103
01/05/2022 22:29:56 - INFO - __main__ -   Batch number = 104
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 105
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 106
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 107
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 108
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 109
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 110
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 111
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 112
01/05/2022 22:29:57 - INFO - __main__ -   Batch number = 113
01/05/2022 22:29:58 - INFO - __main__ -   Batch number = 114
01/05/2022 22:29:58 - INFO - __main__ -   Batch number = 115
01/05/2022 22:29:58 - INFO - __main__ -   Batch number = 116
01/05/2022 22:29:58 - INFO - __main__ -   Batch number = 117
01/05/2022 22:29:58 - INFO - __main__ -   Batch number = 118
01/05/2022 22:29:58 - INFO - __main__ -   Batch number = 119
01/05/2022 22:29:58 - INFO - __main__ -   Batch number = 120
01/05/2022 22:29:58 - INFO - __main__ -   Batch number = 121
01/05/2022 22:29:59 - INFO - __main__ -   Batch number = 122
01/05/2022 22:29:59 - INFO - __main__ -   Batch number = 123
01/05/2022 22:29:59 - INFO - __main__ -   Batch number = 124
01/05/2022 22:29:59 - INFO - __main__ -   Batch number = 125
01/05/2022 22:30:00 - INFO - __main__ -   ***** Evaluation result 7000 in en *****
01/05/2022 22:30:00 - INFO - __main__ -     f1 = 0.9482081955132049
01/05/2022 22:30:00 - INFO - __main__ -     loss = 0.14815029233694077
01/05/2022 22:30:00 - INFO - __main__ -     precision = 0.9486959652943294
01/05/2022 22:30:00 - INFO - __main__ -     recall = 0.9477209270456842
01/05/2022 22:30:00 - INFO - __main__ -   Hit patience=1
01/05/2022 22:36:04 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:36:04 - INFO - __main__ -   ***** Running evaluation 8000 in en *****
01/05/2022 22:36:04 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:36:04 - INFO - __main__ -     Batch size = 32
01/05/2022 22:36:04 - INFO - __main__ -   Batch number = 1
01/05/2022 22:36:04 - INFO - __main__ -   Batch number = 2
01/05/2022 22:36:04 - INFO - __main__ -   Batch number = 3
01/05/2022 22:36:04 - INFO - __main__ -   Batch number = 4
01/05/2022 22:36:05 - INFO - __main__ -   Batch number = 5
01/05/2022 22:36:05 - INFO - __main__ -   Batch number = 6
01/05/2022 22:36:05 - INFO - __main__ -   Batch number = 7
01/05/2022 22:36:05 - INFO - __main__ -   Batch number = 8
01/05/2022 22:36:05 - INFO - __main__ -   Batch number = 9
01/05/2022 22:36:05 - INFO - __main__ -   Batch number = 10
01/05/2022 22:36:05 - INFO - __main__ -   Batch number = 11
01/05/2022 22:36:05 - INFO - __main__ -   Batch number = 12
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 13
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 14
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 15
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 16
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 17
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 18
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 19
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 20
01/05/2022 22:36:06 - INFO - __main__ -   Batch number = 21
01/05/2022 22:36:07 - INFO - __main__ -   Batch number = 22
01/05/2022 22:36:07 - INFO - __main__ -   Batch number = 23
01/05/2022 22:36:07 - INFO - __main__ -   Batch number = 24
01/05/2022 22:36:07 - INFO - __main__ -   Batch number = 25
01/05/2022 22:36:07 - INFO - __main__ -   Batch number = 26
01/05/2022 22:36:07 - INFO - __main__ -   Batch number = 27
01/05/2022 22:36:07 - INFO - __main__ -   Batch number = 28
01/05/2022 22:36:07 - INFO - __main__ -   Batch number = 29
01/05/2022 22:36:08 - INFO - __main__ -   Batch number = 30
01/05/2022 22:36:08 - INFO - __main__ -   Batch number = 31
01/05/2022 22:36:08 - INFO - __main__ -   Batch number = 32
01/05/2022 22:36:08 - INFO - __main__ -   Batch number = 33
01/05/2022 22:36:08 - INFO - __main__ -   Batch number = 34
01/05/2022 22:36:08 - INFO - __main__ -   Batch number = 35
01/05/2022 22:36:08 - INFO - __main__ -   Batch number = 36
01/05/2022 22:36:08 - INFO - __main__ -   Batch number = 37
01/05/2022 22:36:09 - INFO - __main__ -   Batch number = 38
01/05/2022 22:36:09 - INFO - __main__ -   Batch number = 39
01/05/2022 22:36:09 - INFO - __main__ -   Batch number = 40
01/05/2022 22:36:09 - INFO - __main__ -   Batch number = 41
01/05/2022 22:36:09 - INFO - __main__ -   Batch number = 42
01/05/2022 22:36:09 - INFO - __main__ -   Batch number = 43
01/05/2022 22:36:09 - INFO - __main__ -   Batch number = 44
01/05/2022 22:36:09 - INFO - __main__ -   Batch number = 45
01/05/2022 22:36:10 - INFO - __main__ -   Batch number = 46
01/05/2022 22:36:10 - INFO - __main__ -   Batch number = 47
01/05/2022 22:36:10 - INFO - __main__ -   Batch number = 48
01/05/2022 22:36:10 - INFO - __main__ -   Batch number = 49
01/05/2022 22:36:10 - INFO - __main__ -   Batch number = 50
01/05/2022 22:36:10 - INFO - __main__ -   Batch number = 51
01/05/2022 22:36:10 - INFO - __main__ -   Batch number = 52
01/05/2022 22:36:10 - INFO - __main__ -   Batch number = 53
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 54
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 55
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 56
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 57
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 58
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 59
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 60
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 61
01/05/2022 22:36:11 - INFO - __main__ -   Batch number = 62
01/05/2022 22:36:12 - INFO - __main__ -   Batch number = 63
01/05/2022 22:36:12 - INFO - __main__ -   Batch number = 64
01/05/2022 22:36:12 - INFO - __main__ -   Batch number = 65
01/05/2022 22:36:12 - INFO - __main__ -   Batch number = 66
01/05/2022 22:36:12 - INFO - __main__ -   Batch number = 67
01/05/2022 22:36:12 - INFO - __main__ -   Batch number = 68
01/05/2022 22:36:12 - INFO - __main__ -   Batch number = 69
01/05/2022 22:36:12 - INFO - __main__ -   Batch number = 70
01/05/2022 22:36:13 - INFO - __main__ -   Batch number = 71
01/05/2022 22:36:13 - INFO - __main__ -   Batch number = 72
01/05/2022 22:36:13 - INFO - __main__ -   Batch number = 73
01/05/2022 22:36:13 - INFO - __main__ -   Batch number = 74
01/05/2022 22:36:13 - INFO - __main__ -   Batch number = 75
01/05/2022 22:36:13 - INFO - __main__ -   Batch number = 76
01/05/2022 22:36:13 - INFO - __main__ -   Batch number = 77
01/05/2022 22:36:13 - INFO - __main__ -   Batch number = 78
01/05/2022 22:36:14 - INFO - __main__ -   Batch number = 79
01/05/2022 22:36:14 - INFO - __main__ -   Batch number = 80
01/05/2022 22:36:14 - INFO - __main__ -   Batch number = 81
01/05/2022 22:36:14 - INFO - __main__ -   Batch number = 82
01/05/2022 22:36:14 - INFO - __main__ -   Batch number = 83
01/05/2022 22:36:14 - INFO - __main__ -   Batch number = 84
01/05/2022 22:36:14 - INFO - __main__ -   Batch number = 85
01/05/2022 22:36:14 - INFO - __main__ -   Batch number = 86
01/05/2022 22:36:15 - INFO - __main__ -   Batch number = 87
01/05/2022 22:36:15 - INFO - __main__ -   Batch number = 88
01/05/2022 22:36:15 - INFO - __main__ -   Batch number = 89
01/05/2022 22:36:15 - INFO - __main__ -   Batch number = 90
01/05/2022 22:36:15 - INFO - __main__ -   Batch number = 91
01/05/2022 22:36:15 - INFO - __main__ -   Batch number = 92
01/05/2022 22:36:15 - INFO - __main__ -   Batch number = 93
01/05/2022 22:36:15 - INFO - __main__ -   Batch number = 94
01/05/2022 22:36:16 - INFO - __main__ -   Batch number = 95
01/05/2022 22:36:16 - INFO - __main__ -   Batch number = 96
01/05/2022 22:36:16 - INFO - __main__ -   Batch number = 97
01/05/2022 22:36:16 - INFO - __main__ -   Batch number = 98
01/05/2022 22:36:16 - INFO - __main__ -   Batch number = 99
01/05/2022 22:36:16 - INFO - __main__ -   Batch number = 100
01/05/2022 22:36:16 - INFO - __main__ -   Batch number = 101
01/05/2022 22:36:16 - INFO - __main__ -   Batch number = 102
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 103
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 104
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 105
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 106
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 107
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 108
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 109
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 110
01/05/2022 22:36:17 - INFO - __main__ -   Batch number = 111
01/05/2022 22:36:18 - INFO - __main__ -   Batch number = 112
01/05/2022 22:36:18 - INFO - __main__ -   Batch number = 113
01/05/2022 22:36:18 - INFO - __main__ -   Batch number = 114
01/05/2022 22:36:18 - INFO - __main__ -   Batch number = 115
01/05/2022 22:36:18 - INFO - __main__ -   Batch number = 116
01/05/2022 22:36:18 - INFO - __main__ -   Batch number = 117
01/05/2022 22:36:18 - INFO - __main__ -   Batch number = 118
01/05/2022 22:36:18 - INFO - __main__ -   Batch number = 119
01/05/2022 22:36:19 - INFO - __main__ -   Batch number = 120
01/05/2022 22:36:19 - INFO - __main__ -   Batch number = 121
01/05/2022 22:36:19 - INFO - __main__ -   Batch number = 122
01/05/2022 22:36:19 - INFO - __main__ -   Batch number = 123
01/05/2022 22:36:19 - INFO - __main__ -   Batch number = 124
01/05/2022 22:36:19 - INFO - __main__ -   Batch number = 125
01/05/2022 22:36:21 - INFO - __main__ -   ***** Evaluation result 8000 in en *****
01/05/2022 22:36:21 - INFO - __main__ -     f1 = 0.9477902018870187
01/05/2022 22:36:21 - INFO - __main__ -     loss = 0.1585297313630581
01/05/2022 22:36:21 - INFO - __main__ -     precision = 0.9474657217686027
01/05/2022 22:36:21 - INFO - __main__ -     recall = 0.9481149043320372
01/05/2022 22:36:21 - INFO - __main__ -   Hit patience=2
01/05/2022 22:42:16 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:42:17 - INFO - __main__ -   ***** Running evaluation 9000 in en *****
01/05/2022 22:42:17 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:42:17 - INFO - __main__ -     Batch size = 32
01/05/2022 22:42:17 - INFO - __main__ -   Batch number = 1
01/05/2022 22:42:17 - INFO - __main__ -   Batch number = 2
01/05/2022 22:42:17 - INFO - __main__ -   Batch number = 3
01/05/2022 22:42:17 - INFO - __main__ -   Batch number = 4
01/05/2022 22:42:17 - INFO - __main__ -   Batch number = 5
01/05/2022 22:42:17 - INFO - __main__ -   Batch number = 6
01/05/2022 22:42:17 - INFO - __main__ -   Batch number = 7
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 8
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 9
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 10
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 11
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 12
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 13
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 14
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 15
01/05/2022 22:42:18 - INFO - __main__ -   Batch number = 16
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 17
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 18
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 19
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 20
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 21
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 22
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 23
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 24
01/05/2022 22:42:19 - INFO - __main__ -   Batch number = 25
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 26
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 27
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 28
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 29
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 30
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 31
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 32
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 33
01/05/2022 22:42:20 - INFO - __main__ -   Batch number = 34
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 35
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 36
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 37
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 38
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 39
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 40
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 41
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 42
01/05/2022 22:42:21 - INFO - __main__ -   Batch number = 43
01/05/2022 22:42:22 - INFO - __main__ -   Batch number = 44
01/05/2022 22:42:22 - INFO - __main__ -   Batch number = 45
01/05/2022 22:42:22 - INFO - __main__ -   Batch number = 46
01/05/2022 22:42:22 - INFO - __main__ -   Batch number = 47
01/05/2022 22:42:22 - INFO - __main__ -   Batch number = 48
01/05/2022 22:42:22 - INFO - __main__ -   Batch number = 49
01/05/2022 22:42:22 - INFO - __main__ -   Batch number = 50
01/05/2022 22:42:22 - INFO - __main__ -   Batch number = 51
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 52
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 53
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 54
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 55
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 56
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 57
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 58
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 59
01/05/2022 22:42:23 - INFO - __main__ -   Batch number = 60
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 61
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 62
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 63
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 64
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 65
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 66
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 67
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 68
01/05/2022 22:42:24 - INFO - __main__ -   Batch number = 69
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 70
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 71
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 72
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 73
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 74
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 75
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 76
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 77
01/05/2022 22:42:25 - INFO - __main__ -   Batch number = 78
01/05/2022 22:42:26 - INFO - __main__ -   Batch number = 79
01/05/2022 22:42:26 - INFO - __main__ -   Batch number = 80
01/05/2022 22:42:26 - INFO - __main__ -   Batch number = 81
01/05/2022 22:42:26 - INFO - __main__ -   Batch number = 82
01/05/2022 22:42:26 - INFO - __main__ -   Batch number = 83
01/05/2022 22:42:26 - INFO - __main__ -   Batch number = 84
01/05/2022 22:42:26 - INFO - __main__ -   Batch number = 85
01/05/2022 22:42:26 - INFO - __main__ -   Batch number = 86
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 87
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 88
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 89
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 90
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 91
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 92
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 93
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 94
01/05/2022 22:42:27 - INFO - __main__ -   Batch number = 95
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 96
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 97
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 98
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 99
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 100
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 101
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 102
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 103
01/05/2022 22:42:28 - INFO - __main__ -   Batch number = 104
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 105
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 106
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 107
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 108
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 109
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 110
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 111
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 112
01/05/2022 22:42:29 - INFO - __main__ -   Batch number = 113
01/05/2022 22:42:30 - INFO - __main__ -   Batch number = 114
01/05/2022 22:42:30 - INFO - __main__ -   Batch number = 115
01/05/2022 22:42:30 - INFO - __main__ -   Batch number = 116
01/05/2022 22:42:30 - INFO - __main__ -   Batch number = 117
01/05/2022 22:42:30 - INFO - __main__ -   Batch number = 118
01/05/2022 22:42:30 - INFO - __main__ -   Batch number = 119
01/05/2022 22:42:30 - INFO - __main__ -   Batch number = 120
01/05/2022 22:42:30 - INFO - __main__ -   Batch number = 121
01/05/2022 22:42:31 - INFO - __main__ -   Batch number = 122
01/05/2022 22:42:31 - INFO - __main__ -   Batch number = 123
01/05/2022 22:42:31 - INFO - __main__ -   Batch number = 124
01/05/2022 22:42:31 - INFO - __main__ -   Batch number = 125
01/05/2022 22:42:32 - INFO - __main__ -   ***** Evaluation result 9000 in en *****
01/05/2022 22:42:32 - INFO - __main__ -     f1 = 0.9480040082563228
01/05/2022 22:42:32 - INFO - __main__ -     loss = 0.16884111297130586
01/05/2022 22:42:32 - INFO - __main__ -     precision = 0.9479958890030833
01/05/2022 22:42:32 - INFO - __main__ -     recall = 0.9480121276486407
01/05/2022 22:42:32 - INFO - __main__ -   Hit patience=3
01/05/2022 22:48:44 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:48:44 - INFO - __main__ -   ***** Running evaluation 10000 in en *****
01/05/2022 22:48:44 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:48:44 - INFO - __main__ -     Batch size = 32
01/05/2022 22:48:44 - INFO - __main__ -   Batch number = 1
01/05/2022 22:48:44 - INFO - __main__ -   Batch number = 2
01/05/2022 22:48:44 - INFO - __main__ -   Batch number = 3
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 4
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 5
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 6
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 7
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 8
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 9
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 10
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 11
01/05/2022 22:48:45 - INFO - __main__ -   Batch number = 12
01/05/2022 22:48:46 - INFO - __main__ -   Batch number = 13
01/05/2022 22:48:46 - INFO - __main__ -   Batch number = 14
01/05/2022 22:48:46 - INFO - __main__ -   Batch number = 15
01/05/2022 22:48:46 - INFO - __main__ -   Batch number = 16
01/05/2022 22:48:46 - INFO - __main__ -   Batch number = 17
01/05/2022 22:48:46 - INFO - __main__ -   Batch number = 18
01/05/2022 22:48:46 - INFO - __main__ -   Batch number = 19
01/05/2022 22:48:46 - INFO - __main__ -   Batch number = 20
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 21
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 22
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 23
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 24
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 25
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 26
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 27
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 28
01/05/2022 22:48:47 - INFO - __main__ -   Batch number = 29
01/05/2022 22:48:48 - INFO - __main__ -   Batch number = 30
01/05/2022 22:48:48 - INFO - __main__ -   Batch number = 31
01/05/2022 22:48:48 - INFO - __main__ -   Batch number = 32
01/05/2022 22:48:48 - INFO - __main__ -   Batch number = 33
01/05/2022 22:48:48 - INFO - __main__ -   Batch number = 34
01/05/2022 22:48:48 - INFO - __main__ -   Batch number = 35
01/05/2022 22:48:48 - INFO - __main__ -   Batch number = 36
01/05/2022 22:48:48 - INFO - __main__ -   Batch number = 37
01/05/2022 22:48:49 - INFO - __main__ -   Batch number = 38
01/05/2022 22:48:49 - INFO - __main__ -   Batch number = 39
01/05/2022 22:48:49 - INFO - __main__ -   Batch number = 40
01/05/2022 22:48:49 - INFO - __main__ -   Batch number = 41
01/05/2022 22:48:49 - INFO - __main__ -   Batch number = 42
01/05/2022 22:48:49 - INFO - __main__ -   Batch number = 43
01/05/2022 22:48:49 - INFO - __main__ -   Batch number = 44
01/05/2022 22:48:49 - INFO - __main__ -   Batch number = 45
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 46
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 47
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 48
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 49
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 50
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 51
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 52
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 53
01/05/2022 22:48:50 - INFO - __main__ -   Batch number = 54
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 55
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 56
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 57
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 58
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 59
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 60
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 61
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 62
01/05/2022 22:48:51 - INFO - __main__ -   Batch number = 63
01/05/2022 22:48:52 - INFO - __main__ -   Batch number = 64
01/05/2022 22:48:52 - INFO - __main__ -   Batch number = 65
01/05/2022 22:48:52 - INFO - __main__ -   Batch number = 66
01/05/2022 22:48:52 - INFO - __main__ -   Batch number = 67
01/05/2022 22:48:52 - INFO - __main__ -   Batch number = 68
01/05/2022 22:48:52 - INFO - __main__ -   Batch number = 69
01/05/2022 22:48:52 - INFO - __main__ -   Batch number = 70
01/05/2022 22:48:52 - INFO - __main__ -   Batch number = 71
01/05/2022 22:48:53 - INFO - __main__ -   Batch number = 72
01/05/2022 22:48:53 - INFO - __main__ -   Batch number = 73
01/05/2022 22:48:53 - INFO - __main__ -   Batch number = 74
01/05/2022 22:48:53 - INFO - __main__ -   Batch number = 75
01/05/2022 22:48:53 - INFO - __main__ -   Batch number = 76
01/05/2022 22:48:53 - INFO - __main__ -   Batch number = 77
01/05/2022 22:48:53 - INFO - __main__ -   Batch number = 78
01/05/2022 22:48:53 - INFO - __main__ -   Batch number = 79
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 80
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 81
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 82
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 83
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 84
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 85
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 86
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 87
01/05/2022 22:48:54 - INFO - __main__ -   Batch number = 88
01/05/2022 22:48:55 - INFO - __main__ -   Batch number = 89
01/05/2022 22:48:55 - INFO - __main__ -   Batch number = 90
01/05/2022 22:48:55 - INFO - __main__ -   Batch number = 91
01/05/2022 22:48:55 - INFO - __main__ -   Batch number = 92
01/05/2022 22:48:55 - INFO - __main__ -   Batch number = 93
01/05/2022 22:48:55 - INFO - __main__ -   Batch number = 94
01/05/2022 22:48:55 - INFO - __main__ -   Batch number = 95
01/05/2022 22:48:55 - INFO - __main__ -   Batch number = 96
01/05/2022 22:48:56 - INFO - __main__ -   Batch number = 97
01/05/2022 22:48:56 - INFO - __main__ -   Batch number = 98
01/05/2022 22:48:56 - INFO - __main__ -   Batch number = 99
01/05/2022 22:48:56 - INFO - __main__ -   Batch number = 100
01/05/2022 22:48:56 - INFO - __main__ -   Batch number = 101
01/05/2022 22:48:56 - INFO - __main__ -   Batch number = 102
01/05/2022 22:48:56 - INFO - __main__ -   Batch number = 103
01/05/2022 22:48:56 - INFO - __main__ -   Batch number = 104
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 105
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 106
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 107
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 108
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 109
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 110
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 111
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 112
01/05/2022 22:48:57 - INFO - __main__ -   Batch number = 113
01/05/2022 22:48:58 - INFO - __main__ -   Batch number = 114
01/05/2022 22:48:58 - INFO - __main__ -   Batch number = 115
01/05/2022 22:48:58 - INFO - __main__ -   Batch number = 116
01/05/2022 22:48:58 - INFO - __main__ -   Batch number = 117
01/05/2022 22:48:58 - INFO - __main__ -   Batch number = 118
01/05/2022 22:48:58 - INFO - __main__ -   Batch number = 119
01/05/2022 22:48:58 - INFO - __main__ -   Batch number = 120
01/05/2022 22:48:58 - INFO - __main__ -   Batch number = 121
01/05/2022 22:48:59 - INFO - __main__ -   Batch number = 122
01/05/2022 22:48:59 - INFO - __main__ -   Batch number = 123
01/05/2022 22:48:59 - INFO - __main__ -   Batch number = 124
01/05/2022 22:48:59 - INFO - __main__ -   Batch number = 125
01/05/2022 22:49:00 - INFO - __main__ -   ***** Evaluation result 10000 in en *****
01/05/2022 22:49:00 - INFO - __main__ -     f1 = 0.9471881635728474
01/05/2022 22:49:00 - INFO - __main__ -     loss = 0.18689049729704857
01/05/2022 22:49:00 - INFO - __main__ -     precision = 0.9469125023539281
01/05/2022 22:49:00 - INFO - __main__ -     recall = 0.9474639853371931
01/05/2022 22:49:00 - INFO - __main__ -   Hit patience=4
01/05/2022 22:54:59 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 22:54:59 - INFO - __main__ -   ***** Running evaluation 11000 in en *****
01/05/2022 22:54:59 - INFO - __main__ -     Num examples = 3974
01/05/2022 22:54:59 - INFO - __main__ -     Batch size = 32
01/05/2022 22:54:59 - INFO - __main__ -   Batch number = 1
01/05/2022 22:54:59 - INFO - __main__ -   Batch number = 2
01/05/2022 22:54:59 - INFO - __main__ -   Batch number = 3
01/05/2022 22:54:59 - INFO - __main__ -   Batch number = 4
01/05/2022 22:54:59 - INFO - __main__ -   Batch number = 5
01/05/2022 22:54:59 - INFO - __main__ -   Batch number = 6
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 7
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 8
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 9
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 10
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 11
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 12
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 13
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 14
01/05/2022 22:55:00 - INFO - __main__ -   Batch number = 15
01/05/2022 22:55:01 - INFO - __main__ -   Batch number = 16
01/05/2022 22:55:01 - INFO - __main__ -   Batch number = 17
01/05/2022 22:55:01 - INFO - __main__ -   Batch number = 18
01/05/2022 22:55:01 - INFO - __main__ -   Batch number = 19
01/05/2022 22:55:01 - INFO - __main__ -   Batch number = 20
01/05/2022 22:55:01 - INFO - __main__ -   Batch number = 21
01/05/2022 22:55:01 - INFO - __main__ -   Batch number = 22
01/05/2022 22:55:01 - INFO - __main__ -   Batch number = 23
01/05/2022 22:55:02 - INFO - __main__ -   Batch number = 24
01/05/2022 22:55:02 - INFO - __main__ -   Batch number = 25
01/05/2022 22:55:02 - INFO - __main__ -   Batch number = 26
01/05/2022 22:55:02 - INFO - __main__ -   Batch number = 27
01/05/2022 22:55:02 - INFO - __main__ -   Batch number = 28
01/05/2022 22:55:02 - INFO - __main__ -   Batch number = 29
01/05/2022 22:55:02 - INFO - __main__ -   Batch number = 30
01/05/2022 22:55:02 - INFO - __main__ -   Batch number = 31
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 32
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 33
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 34
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 35
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 36
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 37
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 38
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 39
01/05/2022 22:55:03 - INFO - __main__ -   Batch number = 40
01/05/2022 22:55:04 - INFO - __main__ -   Batch number = 41
01/05/2022 22:55:04 - INFO - __main__ -   Batch number = 42
01/05/2022 22:55:04 - INFO - __main__ -   Batch number = 43
01/05/2022 22:55:04 - INFO - __main__ -   Batch number = 44
01/05/2022 22:55:04 - INFO - __main__ -   Batch number = 45
01/05/2022 22:55:04 - INFO - __main__ -   Batch number = 46
01/05/2022 22:55:04 - INFO - __main__ -   Batch number = 47
01/05/2022 22:55:04 - INFO - __main__ -   Batch number = 48
01/05/2022 22:55:05 - INFO - __main__ -   Batch number = 49
01/05/2022 22:55:05 - INFO - __main__ -   Batch number = 50
01/05/2022 22:55:05 - INFO - __main__ -   Batch number = 51
01/05/2022 22:55:05 - INFO - __main__ -   Batch number = 52
01/05/2022 22:55:05 - INFO - __main__ -   Batch number = 53
01/05/2022 22:55:05 - INFO - __main__ -   Batch number = 54
01/05/2022 22:55:05 - INFO - __main__ -   Batch number = 55
01/05/2022 22:55:05 - INFO - __main__ -   Batch number = 56
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 57
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 58
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 59
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 60
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 61
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 62
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 63
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 64
01/05/2022 22:55:06 - INFO - __main__ -   Batch number = 65
01/05/2022 22:55:07 - INFO - __main__ -   Batch number = 66
01/05/2022 22:55:07 - INFO - __main__ -   Batch number = 67
01/05/2022 22:55:07 - INFO - __main__ -   Batch number = 68
01/05/2022 22:55:07 - INFO - __main__ -   Batch number = 69
01/05/2022 22:55:07 - INFO - __main__ -   Batch number = 70
01/05/2022 22:55:07 - INFO - __main__ -   Batch number = 71
01/05/2022 22:55:07 - INFO - __main__ -   Batch number = 72
01/05/2022 22:55:07 - INFO - __main__ -   Batch number = 73
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 74
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 75
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 76
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 77
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 78
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 79
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 80
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 81
01/05/2022 22:55:08 - INFO - __main__ -   Batch number = 82
01/05/2022 22:55:09 - INFO - __main__ -   Batch number = 83
01/05/2022 22:55:09 - INFO - __main__ -   Batch number = 84
01/05/2022 22:55:09 - INFO - __main__ -   Batch number = 85
01/05/2022 22:55:09 - INFO - __main__ -   Batch number = 86
01/05/2022 22:55:09 - INFO - __main__ -   Batch number = 87
01/05/2022 22:55:09 - INFO - __main__ -   Batch number = 88
01/05/2022 22:55:09 - INFO - __main__ -   Batch number = 89
01/05/2022 22:55:09 - INFO - __main__ -   Batch number = 90
01/05/2022 22:55:10 - INFO - __main__ -   Batch number = 91
01/05/2022 22:55:10 - INFO - __main__ -   Batch number = 92
01/05/2022 22:55:10 - INFO - __main__ -   Batch number = 93
01/05/2022 22:55:10 - INFO - __main__ -   Batch number = 94
01/05/2022 22:55:10 - INFO - __main__ -   Batch number = 95
01/05/2022 22:55:10 - INFO - __main__ -   Batch number = 96
01/05/2022 22:55:10 - INFO - __main__ -   Batch number = 97
01/05/2022 22:55:10 - INFO - __main__ -   Batch number = 98
01/05/2022 22:55:11 - INFO - __main__ -   Batch number = 99
01/05/2022 22:55:11 - INFO - __main__ -   Batch number = 100
01/05/2022 22:55:11 - INFO - __main__ -   Batch number = 101
01/05/2022 22:55:11 - INFO - __main__ -   Batch number = 102
01/05/2022 22:55:11 - INFO - __main__ -   Batch number = 103
01/05/2022 22:55:11 - INFO - __main__ -   Batch number = 104
01/05/2022 22:55:11 - INFO - __main__ -   Batch number = 105
01/05/2022 22:55:11 - INFO - __main__ -   Batch number = 106
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 107
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 108
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 109
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 110
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 111
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 112
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 113
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 114
01/05/2022 22:55:12 - INFO - __main__ -   Batch number = 115
01/05/2022 22:55:13 - INFO - __main__ -   Batch number = 116
01/05/2022 22:55:13 - INFO - __main__ -   Batch number = 117
01/05/2022 22:55:13 - INFO - __main__ -   Batch number = 118
01/05/2022 22:55:13 - INFO - __main__ -   Batch number = 119
01/05/2022 22:55:13 - INFO - __main__ -   Batch number = 120
01/05/2022 22:55:13 - INFO - __main__ -   Batch number = 121
01/05/2022 22:55:13 - INFO - __main__ -   Batch number = 122
01/05/2022 22:55:13 - INFO - __main__ -   Batch number = 123
01/05/2022 22:55:14 - INFO - __main__ -   Batch number = 124
01/05/2022 22:55:14 - INFO - __main__ -   Batch number = 125
01/05/2022 22:55:15 - INFO - __main__ -   ***** Evaluation result 11000 in en *****
01/05/2022 22:55:15 - INFO - __main__ -     f1 = 0.9471763728404157
01/05/2022 22:55:15 - INFO - __main__ -     loss = 0.19524977910518646
01/05/2022 22:55:15 - INFO - __main__ -     precision = 0.947265625
01/05/2022 22:55:15 - INFO - __main__ -     recall = 0.9470871374980729
01/05/2022 22:55:15 - INFO - __main__ -   Hit patience=5
01/05/2022 23:01:12 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:01:13 - INFO - __main__ -   ***** Running evaluation 12000 in en *****
01/05/2022 23:01:13 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:01:13 - INFO - __main__ -     Batch size = 32
01/05/2022 23:01:13 - INFO - __main__ -   Batch number = 1
01/05/2022 23:01:13 - INFO - __main__ -   Batch number = 2
01/05/2022 23:01:13 - INFO - __main__ -   Batch number = 3
01/05/2022 23:01:13 - INFO - __main__ -   Batch number = 4
01/05/2022 23:01:13 - INFO - __main__ -   Batch number = 5
01/05/2022 23:01:13 - INFO - __main__ -   Batch number = 6
01/05/2022 23:01:13 - INFO - __main__ -   Batch number = 7
01/05/2022 23:01:14 - INFO - __main__ -   Batch number = 8
01/05/2022 23:01:14 - INFO - __main__ -   Batch number = 9
01/05/2022 23:01:14 - INFO - __main__ -   Batch number = 10
01/05/2022 23:01:14 - INFO - __main__ -   Batch number = 11
01/05/2022 23:01:14 - INFO - __main__ -   Batch number = 12
01/05/2022 23:01:14 - INFO - __main__ -   Batch number = 13
01/05/2022 23:01:14 - INFO - __main__ -   Batch number = 14
01/05/2022 23:01:14 - INFO - __main__ -   Batch number = 15
01/05/2022 23:01:15 - INFO - __main__ -   Batch number = 16
01/05/2022 23:01:15 - INFO - __main__ -   Batch number = 17
01/05/2022 23:01:15 - INFO - __main__ -   Batch number = 18
01/05/2022 23:01:15 - INFO - __main__ -   Batch number = 19
01/05/2022 23:01:15 - INFO - __main__ -   Batch number = 20
01/05/2022 23:01:15 - INFO - __main__ -   Batch number = 21
01/05/2022 23:01:15 - INFO - __main__ -   Batch number = 22
01/05/2022 23:01:15 - INFO - __main__ -   Batch number = 23
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 24
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 25
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 26
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 27
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 28
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 29
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 30
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 31
01/05/2022 23:01:16 - INFO - __main__ -   Batch number = 32
01/05/2022 23:01:17 - INFO - __main__ -   Batch number = 33
01/05/2022 23:01:17 - INFO - __main__ -   Batch number = 34
01/05/2022 23:01:17 - INFO - __main__ -   Batch number = 35
01/05/2022 23:01:17 - INFO - __main__ -   Batch number = 36
01/05/2022 23:01:17 - INFO - __main__ -   Batch number = 37
01/05/2022 23:01:17 - INFO - __main__ -   Batch number = 38
01/05/2022 23:01:17 - INFO - __main__ -   Batch number = 39
01/05/2022 23:01:17 - INFO - __main__ -   Batch number = 40
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 41
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 42
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 43
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 44
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 45
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 46
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 47
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 48
01/05/2022 23:01:18 - INFO - __main__ -   Batch number = 49
01/05/2022 23:01:19 - INFO - __main__ -   Batch number = 50
01/05/2022 23:01:19 - INFO - __main__ -   Batch number = 51
01/05/2022 23:01:19 - INFO - __main__ -   Batch number = 52
01/05/2022 23:01:19 - INFO - __main__ -   Batch number = 53
01/05/2022 23:01:19 - INFO - __main__ -   Batch number = 54
01/05/2022 23:01:19 - INFO - __main__ -   Batch number = 55
01/05/2022 23:01:19 - INFO - __main__ -   Batch number = 56
01/05/2022 23:01:19 - INFO - __main__ -   Batch number = 57
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 58
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 59
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 60
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 61
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 62
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 63
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 64
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 65
01/05/2022 23:01:20 - INFO - __main__ -   Batch number = 66
01/05/2022 23:01:21 - INFO - __main__ -   Batch number = 67
01/05/2022 23:01:21 - INFO - __main__ -   Batch number = 68
01/05/2022 23:01:21 - INFO - __main__ -   Batch number = 69
01/05/2022 23:01:21 - INFO - __main__ -   Batch number = 70
01/05/2022 23:01:21 - INFO - __main__ -   Batch number = 71
01/05/2022 23:01:21 - INFO - __main__ -   Batch number = 72
01/05/2022 23:01:21 - INFO - __main__ -   Batch number = 73
01/05/2022 23:01:21 - INFO - __main__ -   Batch number = 74
01/05/2022 23:01:22 - INFO - __main__ -   Batch number = 75
01/05/2022 23:01:22 - INFO - __main__ -   Batch number = 76
01/05/2022 23:01:22 - INFO - __main__ -   Batch number = 77
01/05/2022 23:01:22 - INFO - __main__ -   Batch number = 78
01/05/2022 23:01:22 - INFO - __main__ -   Batch number = 79
01/05/2022 23:01:22 - INFO - __main__ -   Batch number = 80
01/05/2022 23:01:22 - INFO - __main__ -   Batch number = 81
01/05/2022 23:01:22 - INFO - __main__ -   Batch number = 82
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 83
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 84
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 85
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 86
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 87
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 88
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 89
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 90
01/05/2022 23:01:23 - INFO - __main__ -   Batch number = 91
01/05/2022 23:01:24 - INFO - __main__ -   Batch number = 92
01/05/2022 23:01:24 - INFO - __main__ -   Batch number = 93
01/05/2022 23:01:24 - INFO - __main__ -   Batch number = 94
01/05/2022 23:01:24 - INFO - __main__ -   Batch number = 95
01/05/2022 23:01:24 - INFO - __main__ -   Batch number = 96
01/05/2022 23:01:24 - INFO - __main__ -   Batch number = 97
01/05/2022 23:01:24 - INFO - __main__ -   Batch number = 98
01/05/2022 23:01:24 - INFO - __main__ -   Batch number = 99
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 100
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 101
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 102
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 103
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 104
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 105
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 106
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 107
01/05/2022 23:01:25 - INFO - __main__ -   Batch number = 108
01/05/2022 23:01:26 - INFO - __main__ -   Batch number = 109
01/05/2022 23:01:26 - INFO - __main__ -   Batch number = 110
01/05/2022 23:01:26 - INFO - __main__ -   Batch number = 111
01/05/2022 23:01:26 - INFO - __main__ -   Batch number = 112
01/05/2022 23:01:26 - INFO - __main__ -   Batch number = 113
01/05/2022 23:01:26 - INFO - __main__ -   Batch number = 114
01/05/2022 23:01:26 - INFO - __main__ -   Batch number = 115
01/05/2022 23:01:26 - INFO - __main__ -   Batch number = 116
01/05/2022 23:01:27 - INFO - __main__ -   Batch number = 117
01/05/2022 23:01:27 - INFO - __main__ -   Batch number = 118
01/05/2022 23:01:27 - INFO - __main__ -   Batch number = 119
01/05/2022 23:01:27 - INFO - __main__ -   Batch number = 120
01/05/2022 23:01:27 - INFO - __main__ -   Batch number = 121
01/05/2022 23:01:27 - INFO - __main__ -   Batch number = 122
01/05/2022 23:01:27 - INFO - __main__ -   Batch number = 123
01/05/2022 23:01:27 - INFO - __main__ -   Batch number = 124
01/05/2022 23:01:28 - INFO - __main__ -   Batch number = 125
01/05/2022 23:01:29 - INFO - __main__ -   ***** Evaluation result 12000 in en *****
01/05/2022 23:01:29 - INFO - __main__ -     f1 = 0.9457839578053292
01/05/2022 23:01:29 - INFO - __main__ -     loss = 0.21701787945628165
01/05/2022 23:01:29 - INFO - __main__ -     precision = 0.9455087052539675
01/05/2022 23:01:29 - INFO - __main__ -     recall = 0.9460593706641087
01/05/2022 23:01:29 - INFO - __main__ -   Hit patience=6
01/05/2022 23:07:26 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:07:26 - INFO - __main__ -   ***** Running evaluation 13000 in en *****
01/05/2022 23:07:26 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:07:26 - INFO - __main__ -     Batch size = 32
01/05/2022 23:07:26 - INFO - __main__ -   Batch number = 1
01/05/2022 23:07:26 - INFO - __main__ -   Batch number = 2
01/05/2022 23:07:26 - INFO - __main__ -   Batch number = 3
01/05/2022 23:07:26 - INFO - __main__ -   Batch number = 4
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 5
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 6
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 7
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 8
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 9
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 10
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 11
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 12
01/05/2022 23:07:27 - INFO - __main__ -   Batch number = 13
01/05/2022 23:07:28 - INFO - __main__ -   Batch number = 14
01/05/2022 23:07:28 - INFO - __main__ -   Batch number = 15
01/05/2022 23:07:28 - INFO - __main__ -   Batch number = 16
01/05/2022 23:07:28 - INFO - __main__ -   Batch number = 17
01/05/2022 23:07:28 - INFO - __main__ -   Batch number = 18
01/05/2022 23:07:28 - INFO - __main__ -   Batch number = 19
01/05/2022 23:07:28 - INFO - __main__ -   Batch number = 20
01/05/2022 23:07:28 - INFO - __main__ -   Batch number = 21
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 22
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 23
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 24
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 25
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 26
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 27
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 28
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 29
01/05/2022 23:07:29 - INFO - __main__ -   Batch number = 30
01/05/2022 23:07:30 - INFO - __main__ -   Batch number = 31
01/05/2022 23:07:30 - INFO - __main__ -   Batch number = 32
01/05/2022 23:07:30 - INFO - __main__ -   Batch number = 33
01/05/2022 23:07:30 - INFO - __main__ -   Batch number = 34
01/05/2022 23:07:30 - INFO - __main__ -   Batch number = 35
01/05/2022 23:07:30 - INFO - __main__ -   Batch number = 36
01/05/2022 23:07:30 - INFO - __main__ -   Batch number = 37
01/05/2022 23:07:30 - INFO - __main__ -   Batch number = 38
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 39
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 40
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 41
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 42
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 43
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 44
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 45
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 46
01/05/2022 23:07:31 - INFO - __main__ -   Batch number = 47
01/05/2022 23:07:32 - INFO - __main__ -   Batch number = 48
01/05/2022 23:07:32 - INFO - __main__ -   Batch number = 49
01/05/2022 23:07:32 - INFO - __main__ -   Batch number = 50
01/05/2022 23:07:32 - INFO - __main__ -   Batch number = 51
01/05/2022 23:07:32 - INFO - __main__ -   Batch number = 52
01/05/2022 23:07:32 - INFO - __main__ -   Batch number = 53
01/05/2022 23:07:32 - INFO - __main__ -   Batch number = 54
01/05/2022 23:07:32 - INFO - __main__ -   Batch number = 55
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 56
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 57
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 58
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 59
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 60
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 61
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 62
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 63
01/05/2022 23:07:33 - INFO - __main__ -   Batch number = 64
01/05/2022 23:07:34 - INFO - __main__ -   Batch number = 65
01/05/2022 23:07:34 - INFO - __main__ -   Batch number = 66
01/05/2022 23:07:34 - INFO - __main__ -   Batch number = 67
01/05/2022 23:07:34 - INFO - __main__ -   Batch number = 68
01/05/2022 23:07:34 - INFO - __main__ -   Batch number = 69
01/05/2022 23:07:34 - INFO - __main__ -   Batch number = 70
01/05/2022 23:07:34 - INFO - __main__ -   Batch number = 71
01/05/2022 23:07:34 - INFO - __main__ -   Batch number = 72
01/05/2022 23:07:35 - INFO - __main__ -   Batch number = 73
01/05/2022 23:07:35 - INFO - __main__ -   Batch number = 74
01/05/2022 23:07:35 - INFO - __main__ -   Batch number = 75
01/05/2022 23:07:35 - INFO - __main__ -   Batch number = 76
01/05/2022 23:07:35 - INFO - __main__ -   Batch number = 77
01/05/2022 23:07:35 - INFO - __main__ -   Batch number = 78
01/05/2022 23:07:35 - INFO - __main__ -   Batch number = 79
01/05/2022 23:07:35 - INFO - __main__ -   Batch number = 80
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 81
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 82
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 83
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 84
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 85
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 86
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 87
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 88
01/05/2022 23:07:36 - INFO - __main__ -   Batch number = 89
01/05/2022 23:07:37 - INFO - __main__ -   Batch number = 90
01/05/2022 23:07:37 - INFO - __main__ -   Batch number = 91
01/05/2022 23:07:37 - INFO - __main__ -   Batch number = 92
01/05/2022 23:07:37 - INFO - __main__ -   Batch number = 93
01/05/2022 23:07:37 - INFO - __main__ -   Batch number = 94
01/05/2022 23:07:37 - INFO - __main__ -   Batch number = 95
01/05/2022 23:07:37 - INFO - __main__ -   Batch number = 96
01/05/2022 23:07:37 - INFO - __main__ -   Batch number = 97
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 98
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 99
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 100
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 101
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 102
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 103
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 104
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 105
01/05/2022 23:07:38 - INFO - __main__ -   Batch number = 106
01/05/2022 23:07:39 - INFO - __main__ -   Batch number = 107
01/05/2022 23:07:39 - INFO - __main__ -   Batch number = 108
01/05/2022 23:07:39 - INFO - __main__ -   Batch number = 109
01/05/2022 23:07:39 - INFO - __main__ -   Batch number = 110
01/05/2022 23:07:39 - INFO - __main__ -   Batch number = 111
01/05/2022 23:07:39 - INFO - __main__ -   Batch number = 112
01/05/2022 23:07:39 - INFO - __main__ -   Batch number = 113
01/05/2022 23:07:39 - INFO - __main__ -   Batch number = 114
01/05/2022 23:07:40 - INFO - __main__ -   Batch number = 115
01/05/2022 23:07:40 - INFO - __main__ -   Batch number = 116
01/05/2022 23:07:40 - INFO - __main__ -   Batch number = 117
01/05/2022 23:07:40 - INFO - __main__ -   Batch number = 118
01/05/2022 23:07:40 - INFO - __main__ -   Batch number = 119
01/05/2022 23:07:40 - INFO - __main__ -   Batch number = 120
01/05/2022 23:07:40 - INFO - __main__ -   Batch number = 121
01/05/2022 23:07:40 - INFO - __main__ -   Batch number = 122
01/05/2022 23:07:41 - INFO - __main__ -   Batch number = 123
01/05/2022 23:07:41 - INFO - __main__ -   Batch number = 124
01/05/2022 23:07:41 - INFO - __main__ -   Batch number = 125
01/05/2022 23:07:42 - INFO - __main__ -   ***** Evaluation result 13000 in en *****
01/05/2022 23:07:42 - INFO - __main__ -     f1 = 0.9457215562962138
01/05/2022 23:07:42 - INFO - __main__ -     loss = 0.2355309898853302
01/05/2022 23:07:42 - INFO - __main__ -     precision = 0.9460863304419378
01/05/2022 23:07:42 - INFO - __main__ -     recall = 0.9453570633275664
01/05/2022 23:07:42 - INFO - __main__ -   Hit patience=7
01/05/2022 23:13:40 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:13:40 - INFO - __main__ -   ***** Running evaluation 14000 in en *****
01/05/2022 23:13:40 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:13:40 - INFO - __main__ -     Batch size = 32
01/05/2022 23:13:40 - INFO - __main__ -   Batch number = 1
01/05/2022 23:13:40 - INFO - __main__ -   Batch number = 2
01/05/2022 23:13:40 - INFO - __main__ -   Batch number = 3
01/05/2022 23:13:40 - INFO - __main__ -   Batch number = 4
01/05/2022 23:13:40 - INFO - __main__ -   Batch number = 5
01/05/2022 23:13:40 - INFO - __main__ -   Batch number = 6
01/05/2022 23:13:41 - INFO - __main__ -   Batch number = 7
01/05/2022 23:13:41 - INFO - __main__ -   Batch number = 8
01/05/2022 23:13:41 - INFO - __main__ -   Batch number = 9
01/05/2022 23:13:41 - INFO - __main__ -   Batch number = 10
01/05/2022 23:13:41 - INFO - __main__ -   Batch number = 11
01/05/2022 23:13:41 - INFO - __main__ -   Batch number = 12
01/05/2022 23:13:41 - INFO - __main__ -   Batch number = 13
01/05/2022 23:13:41 - INFO - __main__ -   Batch number = 14
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 15
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 16
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 17
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 18
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 19
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 20
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 21
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 22
01/05/2022 23:13:42 - INFO - __main__ -   Batch number = 23
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 24
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 25
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 26
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 27
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 28
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 29
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 30
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 31
01/05/2022 23:13:43 - INFO - __main__ -   Batch number = 32
01/05/2022 23:13:44 - INFO - __main__ -   Batch number = 33
01/05/2022 23:13:44 - INFO - __main__ -   Batch number = 34
01/05/2022 23:13:44 - INFO - __main__ -   Batch number = 35
01/05/2022 23:13:44 - INFO - __main__ -   Batch number = 36
01/05/2022 23:13:44 - INFO - __main__ -   Batch number = 37
01/05/2022 23:13:44 - INFO - __main__ -   Batch number = 38
01/05/2022 23:13:44 - INFO - __main__ -   Batch number = 39
01/05/2022 23:13:44 - INFO - __main__ -   Batch number = 40
01/05/2022 23:13:45 - INFO - __main__ -   Batch number = 41
01/05/2022 23:13:45 - INFO - __main__ -   Batch number = 42
01/05/2022 23:13:45 - INFO - __main__ -   Batch number = 43
01/05/2022 23:13:45 - INFO - __main__ -   Batch number = 44
01/05/2022 23:13:45 - INFO - __main__ -   Batch number = 45
01/05/2022 23:13:45 - INFO - __main__ -   Batch number = 46
01/05/2022 23:13:45 - INFO - __main__ -   Batch number = 47
01/05/2022 23:13:45 - INFO - __main__ -   Batch number = 48
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 49
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 50
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 51
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 52
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 53
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 54
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 55
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 56
01/05/2022 23:13:46 - INFO - __main__ -   Batch number = 57
01/05/2022 23:13:47 - INFO - __main__ -   Batch number = 58
01/05/2022 23:13:47 - INFO - __main__ -   Batch number = 59
01/05/2022 23:13:47 - INFO - __main__ -   Batch number = 60
01/05/2022 23:13:47 - INFO - __main__ -   Batch number = 61
01/05/2022 23:13:47 - INFO - __main__ -   Batch number = 62
01/05/2022 23:13:47 - INFO - __main__ -   Batch number = 63
01/05/2022 23:13:47 - INFO - __main__ -   Batch number = 64
01/05/2022 23:13:47 - INFO - __main__ -   Batch number = 65
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 66
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 67
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 68
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 69
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 70
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 71
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 72
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 73
01/05/2022 23:13:48 - INFO - __main__ -   Batch number = 74
01/05/2022 23:13:49 - INFO - __main__ -   Batch number = 75
01/05/2022 23:13:49 - INFO - __main__ -   Batch number = 76
01/05/2022 23:13:49 - INFO - __main__ -   Batch number = 77
01/05/2022 23:13:49 - INFO - __main__ -   Batch number = 78
01/05/2022 23:13:49 - INFO - __main__ -   Batch number = 79
01/05/2022 23:13:49 - INFO - __main__ -   Batch number = 80
01/05/2022 23:13:49 - INFO - __main__ -   Batch number = 81
01/05/2022 23:13:49 - INFO - __main__ -   Batch number = 82
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 83
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 84
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 85
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 86
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 87
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 88
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 89
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 90
01/05/2022 23:13:50 - INFO - __main__ -   Batch number = 91
01/05/2022 23:13:51 - INFO - __main__ -   Batch number = 92
01/05/2022 23:13:51 - INFO - __main__ -   Batch number = 93
01/05/2022 23:13:51 - INFO - __main__ -   Batch number = 94
01/05/2022 23:13:51 - INFO - __main__ -   Batch number = 95
01/05/2022 23:13:51 - INFO - __main__ -   Batch number = 96
01/05/2022 23:13:51 - INFO - __main__ -   Batch number = 97
01/05/2022 23:13:51 - INFO - __main__ -   Batch number = 98
01/05/2022 23:13:51 - INFO - __main__ -   Batch number = 99
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 100
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 101
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 102
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 103
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 104
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 105
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 106
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 107
01/05/2022 23:13:52 - INFO - __main__ -   Batch number = 108
01/05/2022 23:13:53 - INFO - __main__ -   Batch number = 109
01/05/2022 23:13:53 - INFO - __main__ -   Batch number = 110
01/05/2022 23:13:53 - INFO - __main__ -   Batch number = 111
01/05/2022 23:13:53 - INFO - __main__ -   Batch number = 112
01/05/2022 23:13:53 - INFO - __main__ -   Batch number = 113
01/05/2022 23:13:53 - INFO - __main__ -   Batch number = 114
01/05/2022 23:13:53 - INFO - __main__ -   Batch number = 115
01/05/2022 23:13:53 - INFO - __main__ -   Batch number = 116
01/05/2022 23:13:54 - INFO - __main__ -   Batch number = 117
01/05/2022 23:13:54 - INFO - __main__ -   Batch number = 118
01/05/2022 23:13:54 - INFO - __main__ -   Batch number = 119
01/05/2022 23:13:54 - INFO - __main__ -   Batch number = 120
01/05/2022 23:13:54 - INFO - __main__ -   Batch number = 121
01/05/2022 23:13:54 - INFO - __main__ -   Batch number = 122
01/05/2022 23:13:54 - INFO - __main__ -   Batch number = 123
01/05/2022 23:13:54 - INFO - __main__ -   Batch number = 124
01/05/2022 23:13:55 - INFO - __main__ -   Batch number = 125
01/05/2022 23:13:56 - INFO - __main__ -   ***** Evaluation result 14000 in en *****
01/05/2022 23:13:56 - INFO - __main__ -     f1 = 0.9458142422815056
01/05/2022 23:13:56 - INFO - __main__ -     loss = 0.25864730206131936
01/05/2022 23:13:56 - INFO - __main__ -     precision = 0.9457575446168602
01/05/2022 23:13:56 - INFO - __main__ -     recall = 0.9458709467445485
01/05/2022 23:13:56 - INFO - __main__ -   Hit patience=8
01/05/2022 23:20:01 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:20:01 - INFO - __main__ -   ***** Running evaluation 15000 in en *****
01/05/2022 23:20:01 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:20:01 - INFO - __main__ -     Batch size = 32
01/05/2022 23:20:01 - INFO - __main__ -   Batch number = 1
01/05/2022 23:20:01 - INFO - __main__ -   Batch number = 2
01/05/2022 23:20:01 - INFO - __main__ -   Batch number = 3
01/05/2022 23:20:01 - INFO - __main__ -   Batch number = 4
01/05/2022 23:20:01 - INFO - __main__ -   Batch number = 5
01/05/2022 23:20:01 - INFO - __main__ -   Batch number = 6
01/05/2022 23:20:01 - INFO - __main__ -   Batch number = 7
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 8
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 9
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 10
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 11
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 12
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 13
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 14
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 15
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 16
01/05/2022 23:20:02 - INFO - __main__ -   Batch number = 17
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 18
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 19
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 20
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 21
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 22
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 23
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 24
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 25
01/05/2022 23:20:03 - INFO - __main__ -   Batch number = 26
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 27
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 28
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 29
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 30
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 31
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 32
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 33
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 34
01/05/2022 23:20:04 - INFO - __main__ -   Batch number = 35
01/05/2022 23:20:05 - INFO - __main__ -   Batch number = 36
01/05/2022 23:20:05 - INFO - __main__ -   Batch number = 37
01/05/2022 23:20:05 - INFO - __main__ -   Batch number = 38
01/05/2022 23:20:05 - INFO - __main__ -   Batch number = 39
01/05/2022 23:20:05 - INFO - __main__ -   Batch number = 40
01/05/2022 23:20:05 - INFO - __main__ -   Batch number = 41
01/05/2022 23:20:05 - INFO - __main__ -   Batch number = 42
01/05/2022 23:20:05 - INFO - __main__ -   Batch number = 43
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 44
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 45
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 46
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 47
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 48
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 49
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 50
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 51
01/05/2022 23:20:06 - INFO - __main__ -   Batch number = 52
01/05/2022 23:20:07 - INFO - __main__ -   Batch number = 53
01/05/2022 23:20:07 - INFO - __main__ -   Batch number = 54
01/05/2022 23:20:07 - INFO - __main__ -   Batch number = 55
01/05/2022 23:20:07 - INFO - __main__ -   Batch number = 56
01/05/2022 23:20:07 - INFO - __main__ -   Batch number = 57
01/05/2022 23:20:07 - INFO - __main__ -   Batch number = 58
01/05/2022 23:20:07 - INFO - __main__ -   Batch number = 59
01/05/2022 23:20:07 - INFO - __main__ -   Batch number = 60
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 61
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 62
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 63
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 64
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 65
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 66
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 67
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 68
01/05/2022 23:20:08 - INFO - __main__ -   Batch number = 69
01/05/2022 23:20:09 - INFO - __main__ -   Batch number = 70
01/05/2022 23:20:09 - INFO - __main__ -   Batch number = 71
01/05/2022 23:20:09 - INFO - __main__ -   Batch number = 72
01/05/2022 23:20:09 - INFO - __main__ -   Batch number = 73
01/05/2022 23:20:09 - INFO - __main__ -   Batch number = 74
01/05/2022 23:20:09 - INFO - __main__ -   Batch number = 75
01/05/2022 23:20:09 - INFO - __main__ -   Batch number = 76
01/05/2022 23:20:09 - INFO - __main__ -   Batch number = 77
01/05/2022 23:20:10 - INFO - __main__ -   Batch number = 78
01/05/2022 23:20:10 - INFO - __main__ -   Batch number = 79
01/05/2022 23:20:10 - INFO - __main__ -   Batch number = 80
01/05/2022 23:20:10 - INFO - __main__ -   Batch number = 81
01/05/2022 23:20:10 - INFO - __main__ -   Batch number = 82
01/05/2022 23:20:10 - INFO - __main__ -   Batch number = 83
01/05/2022 23:20:10 - INFO - __main__ -   Batch number = 84
01/05/2022 23:20:10 - INFO - __main__ -   Batch number = 85
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 86
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 87
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 88
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 89
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 90
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 91
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 92
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 93
01/05/2022 23:20:11 - INFO - __main__ -   Batch number = 94
01/05/2022 23:20:12 - INFO - __main__ -   Batch number = 95
01/05/2022 23:20:12 - INFO - __main__ -   Batch number = 96
01/05/2022 23:20:12 - INFO - __main__ -   Batch number = 97
01/05/2022 23:20:12 - INFO - __main__ -   Batch number = 98
01/05/2022 23:20:12 - INFO - __main__ -   Batch number = 99
01/05/2022 23:20:12 - INFO - __main__ -   Batch number = 100
01/05/2022 23:20:12 - INFO - __main__ -   Batch number = 101
01/05/2022 23:20:12 - INFO - __main__ -   Batch number = 102
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 103
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 104
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 105
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 106
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 107
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 108
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 109
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 110
01/05/2022 23:20:13 - INFO - __main__ -   Batch number = 111
01/05/2022 23:20:14 - INFO - __main__ -   Batch number = 112
01/05/2022 23:20:14 - INFO - __main__ -   Batch number = 113
01/05/2022 23:20:14 - INFO - __main__ -   Batch number = 114
01/05/2022 23:20:14 - INFO - __main__ -   Batch number = 115
01/05/2022 23:20:14 - INFO - __main__ -   Batch number = 116
01/05/2022 23:20:14 - INFO - __main__ -   Batch number = 117
01/05/2022 23:20:14 - INFO - __main__ -   Batch number = 118
01/05/2022 23:20:14 - INFO - __main__ -   Batch number = 119
01/05/2022 23:20:15 - INFO - __main__ -   Batch number = 120
01/05/2022 23:20:15 - INFO - __main__ -   Batch number = 121
01/05/2022 23:20:15 - INFO - __main__ -   Batch number = 122
01/05/2022 23:20:15 - INFO - __main__ -   Batch number = 123
01/05/2022 23:20:15 - INFO - __main__ -   Batch number = 124
01/05/2022 23:20:15 - INFO - __main__ -   Batch number = 125
01/05/2022 23:20:16 - INFO - __main__ -   ***** Evaluation result 15000 in en *****
01/05/2022 23:20:16 - INFO - __main__ -     f1 = 0.9453807419586887
01/05/2022 23:20:16 - INFO - __main__ -     loss = 0.2794348689764738
01/05/2022 23:20:16 - INFO - __main__ -     precision = 0.9452674121898172
01/05/2022 23:20:16 - INFO - __main__ -     recall = 0.9454940989054283
01/05/2022 23:20:16 - INFO - __main__ -   Hit patience=9
01/05/2022 23:26:13 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:26:13 - INFO - __main__ -   ***** Running evaluation 16000 in en *****
01/05/2022 23:26:13 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:26:13 - INFO - __main__ -     Batch size = 32
01/05/2022 23:26:13 - INFO - __main__ -   Batch number = 1
01/05/2022 23:26:13 - INFO - __main__ -   Batch number = 2
01/05/2022 23:26:13 - INFO - __main__ -   Batch number = 3
01/05/2022 23:26:14 - INFO - __main__ -   Batch number = 4
01/05/2022 23:26:14 - INFO - __main__ -   Batch number = 5
01/05/2022 23:26:14 - INFO - __main__ -   Batch number = 6
01/05/2022 23:26:14 - INFO - __main__ -   Batch number = 7
01/05/2022 23:26:14 - INFO - __main__ -   Batch number = 8
01/05/2022 23:26:14 - INFO - __main__ -   Batch number = 9
01/05/2022 23:26:14 - INFO - __main__ -   Batch number = 10
01/05/2022 23:26:14 - INFO - __main__ -   Batch number = 11
01/05/2022 23:26:15 - INFO - __main__ -   Batch number = 12
01/05/2022 23:26:15 - INFO - __main__ -   Batch number = 13
01/05/2022 23:26:15 - INFO - __main__ -   Batch number = 14
01/05/2022 23:26:15 - INFO - __main__ -   Batch number = 15
01/05/2022 23:26:15 - INFO - __main__ -   Batch number = 16
01/05/2022 23:26:15 - INFO - __main__ -   Batch number = 17
01/05/2022 23:26:15 - INFO - __main__ -   Batch number = 18
01/05/2022 23:26:15 - INFO - __main__ -   Batch number = 19
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 20
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 21
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 22
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 23
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 24
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 25
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 26
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 27
01/05/2022 23:26:16 - INFO - __main__ -   Batch number = 28
01/05/2022 23:26:17 - INFO - __main__ -   Batch number = 29
01/05/2022 23:26:17 - INFO - __main__ -   Batch number = 30
01/05/2022 23:26:17 - INFO - __main__ -   Batch number = 31
01/05/2022 23:26:17 - INFO - __main__ -   Batch number = 32
01/05/2022 23:26:17 - INFO - __main__ -   Batch number = 33
01/05/2022 23:26:17 - INFO - __main__ -   Batch number = 34
01/05/2022 23:26:17 - INFO - __main__ -   Batch number = 35
01/05/2022 23:26:17 - INFO - __main__ -   Batch number = 36
01/05/2022 23:26:18 - INFO - __main__ -   Batch number = 37
01/05/2022 23:26:18 - INFO - __main__ -   Batch number = 38
01/05/2022 23:26:18 - INFO - __main__ -   Batch number = 39
01/05/2022 23:26:18 - INFO - __main__ -   Batch number = 40
01/05/2022 23:26:18 - INFO - __main__ -   Batch number = 41
01/05/2022 23:26:18 - INFO - __main__ -   Batch number = 42
01/05/2022 23:26:18 - INFO - __main__ -   Batch number = 43
01/05/2022 23:26:18 - INFO - __main__ -   Batch number = 44
01/05/2022 23:26:19 - INFO - __main__ -   Batch number = 45
01/05/2022 23:26:19 - INFO - __main__ -   Batch number = 46
01/05/2022 23:26:19 - INFO - __main__ -   Batch number = 47
01/05/2022 23:26:19 - INFO - __main__ -   Batch number = 48
01/05/2022 23:26:19 - INFO - __main__ -   Batch number = 49
01/05/2022 23:26:19 - INFO - __main__ -   Batch number = 50
01/05/2022 23:26:19 - INFO - __main__ -   Batch number = 51
01/05/2022 23:26:19 - INFO - __main__ -   Batch number = 52
01/05/2022 23:26:20 - INFO - __main__ -   Batch number = 53
01/05/2022 23:26:20 - INFO - __main__ -   Batch number = 54
01/05/2022 23:26:20 - INFO - __main__ -   Batch number = 55
01/05/2022 23:26:20 - INFO - __main__ -   Batch number = 56
01/05/2022 23:26:20 - INFO - __main__ -   Batch number = 57
01/05/2022 23:26:20 - INFO - __main__ -   Batch number = 58
01/05/2022 23:26:20 - INFO - __main__ -   Batch number = 59
01/05/2022 23:26:20 - INFO - __main__ -   Batch number = 60
01/05/2022 23:26:21 - INFO - __main__ -   Batch number = 61
01/05/2022 23:26:21 - INFO - __main__ -   Batch number = 62
01/05/2022 23:26:21 - INFO - __main__ -   Batch number = 63
01/05/2022 23:26:21 - INFO - __main__ -   Batch number = 64
01/05/2022 23:26:21 - INFO - __main__ -   Batch number = 65
01/05/2022 23:26:21 - INFO - __main__ -   Batch number = 66
01/05/2022 23:26:21 - INFO - __main__ -   Batch number = 67
01/05/2022 23:26:21 - INFO - __main__ -   Batch number = 68
01/05/2022 23:26:22 - INFO - __main__ -   Batch number = 69
01/05/2022 23:26:22 - INFO - __main__ -   Batch number = 70
01/05/2022 23:26:22 - INFO - __main__ -   Batch number = 71
01/05/2022 23:26:22 - INFO - __main__ -   Batch number = 72
01/05/2022 23:26:22 - INFO - __main__ -   Batch number = 73
01/05/2022 23:26:22 - INFO - __main__ -   Batch number = 74
01/05/2022 23:26:22 - INFO - __main__ -   Batch number = 75
01/05/2022 23:26:22 - INFO - __main__ -   Batch number = 76
01/05/2022 23:26:23 - INFO - __main__ -   Batch number = 77
01/05/2022 23:26:23 - INFO - __main__ -   Batch number = 78
01/05/2022 23:26:23 - INFO - __main__ -   Batch number = 79
01/05/2022 23:26:23 - INFO - __main__ -   Batch number = 80
01/05/2022 23:26:23 - INFO - __main__ -   Batch number = 81
01/05/2022 23:26:23 - INFO - __main__ -   Batch number = 82
01/05/2022 23:26:23 - INFO - __main__ -   Batch number = 83
01/05/2022 23:26:23 - INFO - __main__ -   Batch number = 84
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 85
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 86
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 87
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 88
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 89
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 90
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 91
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 92
01/05/2022 23:26:24 - INFO - __main__ -   Batch number = 93
01/05/2022 23:26:25 - INFO - __main__ -   Batch number = 94
01/05/2022 23:26:25 - INFO - __main__ -   Batch number = 95
01/05/2022 23:26:25 - INFO - __main__ -   Batch number = 96
01/05/2022 23:26:25 - INFO - __main__ -   Batch number = 97
01/05/2022 23:26:25 - INFO - __main__ -   Batch number = 98
01/05/2022 23:26:25 - INFO - __main__ -   Batch number = 99
01/05/2022 23:26:25 - INFO - __main__ -   Batch number = 100
01/05/2022 23:26:25 - INFO - __main__ -   Batch number = 101
01/05/2022 23:26:26 - INFO - __main__ -   Batch number = 102
01/05/2022 23:26:26 - INFO - __main__ -   Batch number = 103
01/05/2022 23:26:26 - INFO - __main__ -   Batch number = 104
01/05/2022 23:26:26 - INFO - __main__ -   Batch number = 105
01/05/2022 23:26:26 - INFO - __main__ -   Batch number = 106
01/05/2022 23:26:26 - INFO - __main__ -   Batch number = 107
01/05/2022 23:26:26 - INFO - __main__ -   Batch number = 108
01/05/2022 23:26:26 - INFO - __main__ -   Batch number = 109
01/05/2022 23:26:27 - INFO - __main__ -   Batch number = 110
01/05/2022 23:26:27 - INFO - __main__ -   Batch number = 111
01/05/2022 23:26:27 - INFO - __main__ -   Batch number = 112
01/05/2022 23:26:27 - INFO - __main__ -   Batch number = 113
01/05/2022 23:26:27 - INFO - __main__ -   Batch number = 114
01/05/2022 23:26:27 - INFO - __main__ -   Batch number = 115
01/05/2022 23:26:27 - INFO - __main__ -   Batch number = 116
01/05/2022 23:26:27 - INFO - __main__ -   Batch number = 117
01/05/2022 23:26:28 - INFO - __main__ -   Batch number = 118
01/05/2022 23:26:28 - INFO - __main__ -   Batch number = 119
01/05/2022 23:26:28 - INFO - __main__ -   Batch number = 120
01/05/2022 23:26:28 - INFO - __main__ -   Batch number = 121
01/05/2022 23:26:28 - INFO - __main__ -   Batch number = 122
01/05/2022 23:26:28 - INFO - __main__ -   Batch number = 123
01/05/2022 23:26:28 - INFO - __main__ -   Batch number = 124
01/05/2022 23:26:28 - INFO - __main__ -   Batch number = 125
01/05/2022 23:26:30 - INFO - __main__ -   ***** Evaluation result 16000 in en *****
01/05/2022 23:26:30 - INFO - __main__ -     f1 = 0.9455881345481948
01/05/2022 23:26:30 - INFO - __main__ -     loss = 0.3020899246484041
01/05/2022 23:26:30 - INFO - __main__ -     precision = 0.9454424028631607
01/05/2022 23:26:30 - INFO - __main__ -     recall = 0.9457339111666867
01/05/2022 23:26:30 - INFO - __main__ -   Hit patience=10
01/05/2022 23:32:27 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:32:28 - INFO - __main__ -   ***** Running evaluation 17000 in en *****
01/05/2022 23:32:28 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:32:28 - INFO - __main__ -     Batch size = 32
01/05/2022 23:32:28 - INFO - __main__ -   Batch number = 1
01/05/2022 23:32:28 - INFO - __main__ -   Batch number = 2
01/05/2022 23:32:28 - INFO - __main__ -   Batch number = 3
01/05/2022 23:32:28 - INFO - __main__ -   Batch number = 4
01/05/2022 23:32:28 - INFO - __main__ -   Batch number = 5
01/05/2022 23:32:28 - INFO - __main__ -   Batch number = 6
01/05/2022 23:32:28 - INFO - __main__ -   Batch number = 7
01/05/2022 23:32:29 - INFO - __main__ -   Batch number = 8
01/05/2022 23:32:29 - INFO - __main__ -   Batch number = 9
01/05/2022 23:32:29 - INFO - __main__ -   Batch number = 10
01/05/2022 23:32:29 - INFO - __main__ -   Batch number = 11
01/05/2022 23:32:29 - INFO - __main__ -   Batch number = 12
01/05/2022 23:32:29 - INFO - __main__ -   Batch number = 13
01/05/2022 23:32:29 - INFO - __main__ -   Batch number = 14
01/05/2022 23:32:29 - INFO - __main__ -   Batch number = 15
01/05/2022 23:32:30 - INFO - __main__ -   Batch number = 16
01/05/2022 23:32:30 - INFO - __main__ -   Batch number = 17
01/05/2022 23:32:30 - INFO - __main__ -   Batch number = 18
01/05/2022 23:32:30 - INFO - __main__ -   Batch number = 19
01/05/2022 23:32:30 - INFO - __main__ -   Batch number = 20
01/05/2022 23:32:30 - INFO - __main__ -   Batch number = 21
01/05/2022 23:32:30 - INFO - __main__ -   Batch number = 22
01/05/2022 23:32:30 - INFO - __main__ -   Batch number = 23
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 24
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 25
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 26
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 27
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 28
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 29
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 30
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 31
01/05/2022 23:32:31 - INFO - __main__ -   Batch number = 32
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 33
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 34
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 35
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 36
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 37
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 38
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 39
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 40
01/05/2022 23:32:32 - INFO - __main__ -   Batch number = 41
01/05/2022 23:32:33 - INFO - __main__ -   Batch number = 42
01/05/2022 23:32:33 - INFO - __main__ -   Batch number = 43
01/05/2022 23:32:33 - INFO - __main__ -   Batch number = 44
01/05/2022 23:32:33 - INFO - __main__ -   Batch number = 45
01/05/2022 23:32:33 - INFO - __main__ -   Batch number = 46
01/05/2022 23:32:33 - INFO - __main__ -   Batch number = 47
01/05/2022 23:32:33 - INFO - __main__ -   Batch number = 48
01/05/2022 23:32:34 - INFO - __main__ -   Batch number = 49
01/05/2022 23:32:34 - INFO - __main__ -   Batch number = 50
01/05/2022 23:32:34 - INFO - __main__ -   Batch number = 51
01/05/2022 23:32:34 - INFO - __main__ -   Batch number = 52
01/05/2022 23:32:34 - INFO - __main__ -   Batch number = 53
01/05/2022 23:32:34 - INFO - __main__ -   Batch number = 54
01/05/2022 23:32:34 - INFO - __main__ -   Batch number = 55
01/05/2022 23:32:34 - INFO - __main__ -   Batch number = 56
01/05/2022 23:32:35 - INFO - __main__ -   Batch number = 57
01/05/2022 23:32:35 - INFO - __main__ -   Batch number = 58
01/05/2022 23:32:35 - INFO - __main__ -   Batch number = 59
01/05/2022 23:32:35 - INFO - __main__ -   Batch number = 60
01/05/2022 23:32:35 - INFO - __main__ -   Batch number = 61
01/05/2022 23:32:35 - INFO - __main__ -   Batch number = 62
01/05/2022 23:32:35 - INFO - __main__ -   Batch number = 63
01/05/2022 23:32:35 - INFO - __main__ -   Batch number = 64
01/05/2022 23:32:36 - INFO - __main__ -   Batch number = 65
01/05/2022 23:32:36 - INFO - __main__ -   Batch number = 66
01/05/2022 23:32:36 - INFO - __main__ -   Batch number = 67
01/05/2022 23:32:36 - INFO - __main__ -   Batch number = 68
01/05/2022 23:32:36 - INFO - __main__ -   Batch number = 69
01/05/2022 23:32:36 - INFO - __main__ -   Batch number = 70
01/05/2022 23:32:36 - INFO - __main__ -   Batch number = 71
01/05/2022 23:32:36 - INFO - __main__ -   Batch number = 72
01/05/2022 23:32:37 - INFO - __main__ -   Batch number = 73
01/05/2022 23:32:37 - INFO - __main__ -   Batch number = 74
01/05/2022 23:32:37 - INFO - __main__ -   Batch number = 75
01/05/2022 23:32:37 - INFO - __main__ -   Batch number = 76
01/05/2022 23:32:37 - INFO - __main__ -   Batch number = 77
01/05/2022 23:32:37 - INFO - __main__ -   Batch number = 78
01/05/2022 23:32:37 - INFO - __main__ -   Batch number = 79
01/05/2022 23:32:37 - INFO - __main__ -   Batch number = 80
01/05/2022 23:32:38 - INFO - __main__ -   Batch number = 81
01/05/2022 23:32:38 - INFO - __main__ -   Batch number = 82
01/05/2022 23:32:38 - INFO - __main__ -   Batch number = 83
01/05/2022 23:32:38 - INFO - __main__ -   Batch number = 84
01/05/2022 23:32:38 - INFO - __main__ -   Batch number = 85
01/05/2022 23:32:38 - INFO - __main__ -   Batch number = 86
01/05/2022 23:32:38 - INFO - __main__ -   Batch number = 87
01/05/2022 23:32:38 - INFO - __main__ -   Batch number = 88
01/05/2022 23:32:39 - INFO - __main__ -   Batch number = 89
01/05/2022 23:32:39 - INFO - __main__ -   Batch number = 90
01/05/2022 23:32:39 - INFO - __main__ -   Batch number = 91
01/05/2022 23:32:39 - INFO - __main__ -   Batch number = 92
01/05/2022 23:32:39 - INFO - __main__ -   Batch number = 93
01/05/2022 23:32:39 - INFO - __main__ -   Batch number = 94
01/05/2022 23:32:39 - INFO - __main__ -   Batch number = 95
01/05/2022 23:32:40 - INFO - __main__ -   Batch number = 96
01/05/2022 23:32:40 - INFO - __main__ -   Batch number = 97
01/05/2022 23:32:40 - INFO - __main__ -   Batch number = 98
01/05/2022 23:32:40 - INFO - __main__ -   Batch number = 99
01/05/2022 23:32:40 - INFO - __main__ -   Batch number = 100
01/05/2022 23:32:40 - INFO - __main__ -   Batch number = 101
01/05/2022 23:32:40 - INFO - __main__ -   Batch number = 102
01/05/2022 23:32:40 - INFO - __main__ -   Batch number = 103
01/05/2022 23:32:41 - INFO - __main__ -   Batch number = 104
01/05/2022 23:32:41 - INFO - __main__ -   Batch number = 105
01/05/2022 23:32:41 - INFO - __main__ -   Batch number = 106
01/05/2022 23:32:41 - INFO - __main__ -   Batch number = 107
01/05/2022 23:32:41 - INFO - __main__ -   Batch number = 108
01/05/2022 23:32:41 - INFO - __main__ -   Batch number = 109
01/05/2022 23:32:41 - INFO - __main__ -   Batch number = 110
01/05/2022 23:32:41 - INFO - __main__ -   Batch number = 111
01/05/2022 23:32:42 - INFO - __main__ -   Batch number = 112
01/05/2022 23:32:42 - INFO - __main__ -   Batch number = 113
01/05/2022 23:32:42 - INFO - __main__ -   Batch number = 114
01/05/2022 23:32:42 - INFO - __main__ -   Batch number = 115
01/05/2022 23:32:42 - INFO - __main__ -   Batch number = 116
01/05/2022 23:32:42 - INFO - __main__ -   Batch number = 117
01/05/2022 23:32:42 - INFO - __main__ -   Batch number = 118
01/05/2022 23:32:42 - INFO - __main__ -   Batch number = 119
01/05/2022 23:32:43 - INFO - __main__ -   Batch number = 120
01/05/2022 23:32:43 - INFO - __main__ -   Batch number = 121
01/05/2022 23:32:43 - INFO - __main__ -   Batch number = 122
01/05/2022 23:32:43 - INFO - __main__ -   Batch number = 123
01/05/2022 23:32:43 - INFO - __main__ -   Batch number = 124
01/05/2022 23:32:43 - INFO - __main__ -   Batch number = 125
01/05/2022 23:32:44 - INFO - __main__ -   ***** Evaluation result 17000 in en *****
01/05/2022 23:32:44 - INFO - __main__ -     f1 = 0.9453480806766429
01/05/2022 23:32:44 - INFO - __main__ -     loss = 0.3160722286403179
01/05/2022 23:32:44 - INFO - __main__ -     precision = 0.9449112658942721
01/05/2022 23:32:44 - INFO - __main__ -     recall = 0.9457852995083849
01/05/2022 23:32:44 - INFO - __main__ -   Hit patience=11
01/05/2022 23:38:42 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:38:42 - INFO - __main__ -   ***** Running evaluation 18000 in en *****
01/05/2022 23:38:42 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:38:42 - INFO - __main__ -     Batch size = 32
01/05/2022 23:38:42 - INFO - __main__ -   Batch number = 1
01/05/2022 23:38:42 - INFO - __main__ -   Batch number = 2
01/05/2022 23:38:42 - INFO - __main__ -   Batch number = 3
01/05/2022 23:38:42 - INFO - __main__ -   Batch number = 4
01/05/2022 23:38:42 - INFO - __main__ -   Batch number = 5
01/05/2022 23:38:42 - INFO - __main__ -   Batch number = 6
01/05/2022 23:38:43 - INFO - __main__ -   Batch number = 7
01/05/2022 23:38:43 - INFO - __main__ -   Batch number = 8
01/05/2022 23:38:43 - INFO - __main__ -   Batch number = 9
01/05/2022 23:38:43 - INFO - __main__ -   Batch number = 10
01/05/2022 23:38:43 - INFO - __main__ -   Batch number = 11
01/05/2022 23:38:43 - INFO - __main__ -   Batch number = 12
01/05/2022 23:38:43 - INFO - __main__ -   Batch number = 13
01/05/2022 23:38:43 - INFO - __main__ -   Batch number = 14
01/05/2022 23:38:44 - INFO - __main__ -   Batch number = 15
01/05/2022 23:38:44 - INFO - __main__ -   Batch number = 16
01/05/2022 23:38:44 - INFO - __main__ -   Batch number = 17
01/05/2022 23:38:44 - INFO - __main__ -   Batch number = 18
01/05/2022 23:38:44 - INFO - __main__ -   Batch number = 19
01/05/2022 23:38:44 - INFO - __main__ -   Batch number = 20
01/05/2022 23:38:44 - INFO - __main__ -   Batch number = 21
01/05/2022 23:38:44 - INFO - __main__ -   Batch number = 22
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 23
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 24
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 25
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 26
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 27
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 28
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 29
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 30
01/05/2022 23:38:45 - INFO - __main__ -   Batch number = 31
01/05/2022 23:38:46 - INFO - __main__ -   Batch number = 32
01/05/2022 23:38:46 - INFO - __main__ -   Batch number = 33
01/05/2022 23:38:46 - INFO - __main__ -   Batch number = 34
01/05/2022 23:38:46 - INFO - __main__ -   Batch number = 35
01/05/2022 23:38:46 - INFO - __main__ -   Batch number = 36
01/05/2022 23:38:46 - INFO - __main__ -   Batch number = 37
01/05/2022 23:38:46 - INFO - __main__ -   Batch number = 38
01/05/2022 23:38:46 - INFO - __main__ -   Batch number = 39
01/05/2022 23:38:47 - INFO - __main__ -   Batch number = 40
01/05/2022 23:38:47 - INFO - __main__ -   Batch number = 41
01/05/2022 23:38:47 - INFO - __main__ -   Batch number = 42
01/05/2022 23:38:47 - INFO - __main__ -   Batch number = 43
01/05/2022 23:38:47 - INFO - __main__ -   Batch number = 44
01/05/2022 23:38:47 - INFO - __main__ -   Batch number = 45
01/05/2022 23:38:47 - INFO - __main__ -   Batch number = 46
01/05/2022 23:38:47 - INFO - __main__ -   Batch number = 47
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 48
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 49
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 50
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 51
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 52
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 53
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 54
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 55
01/05/2022 23:38:48 - INFO - __main__ -   Batch number = 56
01/05/2022 23:38:49 - INFO - __main__ -   Batch number = 57
01/05/2022 23:38:49 - INFO - __main__ -   Batch number = 58
01/05/2022 23:38:49 - INFO - __main__ -   Batch number = 59
01/05/2022 23:38:49 - INFO - __main__ -   Batch number = 60
01/05/2022 23:38:49 - INFO - __main__ -   Batch number = 61
01/05/2022 23:38:49 - INFO - __main__ -   Batch number = 62
01/05/2022 23:38:49 - INFO - __main__ -   Batch number = 63
01/05/2022 23:38:49 - INFO - __main__ -   Batch number = 64
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 65
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 66
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 67
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 68
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 69
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 70
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 71
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 72
01/05/2022 23:38:50 - INFO - __main__ -   Batch number = 73
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 74
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 75
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 76
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 77
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 78
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 79
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 80
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 81
01/05/2022 23:38:51 - INFO - __main__ -   Batch number = 82
01/05/2022 23:38:52 - INFO - __main__ -   Batch number = 83
01/05/2022 23:38:52 - INFO - __main__ -   Batch number = 84
01/05/2022 23:38:52 - INFO - __main__ -   Batch number = 85
01/05/2022 23:38:52 - INFO - __main__ -   Batch number = 86
01/05/2022 23:38:52 - INFO - __main__ -   Batch number = 87
01/05/2022 23:38:52 - INFO - __main__ -   Batch number = 88
01/05/2022 23:38:52 - INFO - __main__ -   Batch number = 89
01/05/2022 23:38:52 - INFO - __main__ -   Batch number = 90
01/05/2022 23:38:53 - INFO - __main__ -   Batch number = 91
01/05/2022 23:38:53 - INFO - __main__ -   Batch number = 92
01/05/2022 23:38:53 - INFO - __main__ -   Batch number = 93
01/05/2022 23:38:53 - INFO - __main__ -   Batch number = 94
01/05/2022 23:38:53 - INFO - __main__ -   Batch number = 95
01/05/2022 23:38:53 - INFO - __main__ -   Batch number = 96
01/05/2022 23:38:53 - INFO - __main__ -   Batch number = 97
01/05/2022 23:38:53 - INFO - __main__ -   Batch number = 98
01/05/2022 23:38:54 - INFO - __main__ -   Batch number = 99
01/05/2022 23:38:54 - INFO - __main__ -   Batch number = 100
01/05/2022 23:38:54 - INFO - __main__ -   Batch number = 101
01/05/2022 23:38:54 - INFO - __main__ -   Batch number = 102
01/05/2022 23:38:54 - INFO - __main__ -   Batch number = 103
01/05/2022 23:38:54 - INFO - __main__ -   Batch number = 104
01/05/2022 23:38:54 - INFO - __main__ -   Batch number = 105
01/05/2022 23:38:54 - INFO - __main__ -   Batch number = 106
01/05/2022 23:38:55 - INFO - __main__ -   Batch number = 107
01/05/2022 23:38:55 - INFO - __main__ -   Batch number = 108
01/05/2022 23:38:55 - INFO - __main__ -   Batch number = 109
01/05/2022 23:38:55 - INFO - __main__ -   Batch number = 110
01/05/2022 23:38:55 - INFO - __main__ -   Batch number = 111
01/05/2022 23:38:55 - INFO - __main__ -   Batch number = 112
01/05/2022 23:38:55 - INFO - __main__ -   Batch number = 113
01/05/2022 23:38:55 - INFO - __main__ -   Batch number = 114
01/05/2022 23:38:56 - INFO - __main__ -   Batch number = 115
01/05/2022 23:38:56 - INFO - __main__ -   Batch number = 116
01/05/2022 23:38:56 - INFO - __main__ -   Batch number = 117
01/05/2022 23:38:56 - INFO - __main__ -   Batch number = 118
01/05/2022 23:38:56 - INFO - __main__ -   Batch number = 119
01/05/2022 23:38:56 - INFO - __main__ -   Batch number = 120
01/05/2022 23:38:56 - INFO - __main__ -   Batch number = 121
01/05/2022 23:38:56 - INFO - __main__ -   Batch number = 122
01/05/2022 23:38:57 - INFO - __main__ -   Batch number = 123
01/05/2022 23:38:57 - INFO - __main__ -   Batch number = 124
01/05/2022 23:38:57 - INFO - __main__ -   Batch number = 125
01/05/2022 23:38:58 - INFO - __main__ -   ***** Evaluation result 18000 in en *****
01/05/2022 23:38:58 - INFO - __main__ -     f1 = 0.9444068667323087
01/05/2022 23:38:58 - INFO - __main__ -     loss = 0.3404046455770731
01/05/2022 23:38:58 - INFO - __main__ -     precision = 0.9441077786907697
01/05/2022 23:38:58 - INFO - __main__ -     recall = 0.9447061443327224
01/05/2022 23:38:58 - INFO - __main__ -   Hit patience=12
01/05/2022 23:44:58 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:44:58 - INFO - __main__ -   ***** Running evaluation 19000 in en *****
01/05/2022 23:44:58 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:44:58 - INFO - __main__ -     Batch size = 32
01/05/2022 23:44:58 - INFO - __main__ -   Batch number = 1
01/05/2022 23:44:58 - INFO - __main__ -   Batch number = 2
01/05/2022 23:44:58 - INFO - __main__ -   Batch number = 3
01/05/2022 23:44:58 - INFO - __main__ -   Batch number = 4
01/05/2022 23:44:58 - INFO - __main__ -   Batch number = 5
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 6
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 7
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 8
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 9
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 10
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 11
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 12
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 13
01/05/2022 23:44:59 - INFO - __main__ -   Batch number = 14
01/05/2022 23:45:00 - INFO - __main__ -   Batch number = 15
01/05/2022 23:45:00 - INFO - __main__ -   Batch number = 16
01/05/2022 23:45:00 - INFO - __main__ -   Batch number = 17
01/05/2022 23:45:00 - INFO - __main__ -   Batch number = 18
01/05/2022 23:45:00 - INFO - __main__ -   Batch number = 19
01/05/2022 23:45:00 - INFO - __main__ -   Batch number = 20
01/05/2022 23:45:00 - INFO - __main__ -   Batch number = 21
01/05/2022 23:45:00 - INFO - __main__ -   Batch number = 22
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 23
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 24
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 25
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 26
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 27
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 28
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 29
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 30
01/05/2022 23:45:01 - INFO - __main__ -   Batch number = 31
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 32
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 33
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 34
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 35
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 36
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 37
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 38
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 39
01/05/2022 23:45:02 - INFO - __main__ -   Batch number = 40
01/05/2022 23:45:03 - INFO - __main__ -   Batch number = 41
01/05/2022 23:45:03 - INFO - __main__ -   Batch number = 42
01/05/2022 23:45:03 - INFO - __main__ -   Batch number = 43
01/05/2022 23:45:03 - INFO - __main__ -   Batch number = 44
01/05/2022 23:45:03 - INFO - __main__ -   Batch number = 45
01/05/2022 23:45:03 - INFO - __main__ -   Batch number = 46
01/05/2022 23:45:03 - INFO - __main__ -   Batch number = 47
01/05/2022 23:45:03 - INFO - __main__ -   Batch number = 48
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 49
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 50
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 51
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 52
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 53
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 54
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 55
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 56
01/05/2022 23:45:04 - INFO - __main__ -   Batch number = 57
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 58
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 59
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 60
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 61
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 62
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 63
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 64
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 65
01/05/2022 23:45:05 - INFO - __main__ -   Batch number = 66
01/05/2022 23:45:06 - INFO - __main__ -   Batch number = 67
01/05/2022 23:45:06 - INFO - __main__ -   Batch number = 68
01/05/2022 23:45:06 - INFO - __main__ -   Batch number = 69
01/05/2022 23:45:06 - INFO - __main__ -   Batch number = 70
01/05/2022 23:45:06 - INFO - __main__ -   Batch number = 71
01/05/2022 23:45:06 - INFO - __main__ -   Batch number = 72
01/05/2022 23:45:06 - INFO - __main__ -   Batch number = 73
01/05/2022 23:45:06 - INFO - __main__ -   Batch number = 74
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 75
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 76
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 77
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 78
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 79
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 80
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 81
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 82
01/05/2022 23:45:07 - INFO - __main__ -   Batch number = 83
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 84
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 85
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 86
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 87
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 88
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 89
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 90
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 91
01/05/2022 23:45:08 - INFO - __main__ -   Batch number = 92
01/05/2022 23:45:09 - INFO - __main__ -   Batch number = 93
01/05/2022 23:45:09 - INFO - __main__ -   Batch number = 94
01/05/2022 23:45:09 - INFO - __main__ -   Batch number = 95
01/05/2022 23:45:09 - INFO - __main__ -   Batch number = 96
01/05/2022 23:45:09 - INFO - __main__ -   Batch number = 97
01/05/2022 23:45:09 - INFO - __main__ -   Batch number = 98
01/05/2022 23:45:09 - INFO - __main__ -   Batch number = 99
01/05/2022 23:45:09 - INFO - __main__ -   Batch number = 100
01/05/2022 23:45:10 - INFO - __main__ -   Batch number = 101
01/05/2022 23:45:10 - INFO - __main__ -   Batch number = 102
01/05/2022 23:45:10 - INFO - __main__ -   Batch number = 103
01/05/2022 23:45:10 - INFO - __main__ -   Batch number = 104
01/05/2022 23:45:10 - INFO - __main__ -   Batch number = 105
01/05/2022 23:45:10 - INFO - __main__ -   Batch number = 106
01/05/2022 23:45:10 - INFO - __main__ -   Batch number = 107
01/05/2022 23:45:10 - INFO - __main__ -   Batch number = 108
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 109
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 110
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 111
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 112
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 113
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 114
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 115
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 116
01/05/2022 23:45:11 - INFO - __main__ -   Batch number = 117
01/05/2022 23:45:12 - INFO - __main__ -   Batch number = 118
01/05/2022 23:45:12 - INFO - __main__ -   Batch number = 119
01/05/2022 23:45:12 - INFO - __main__ -   Batch number = 120
01/05/2022 23:45:12 - INFO - __main__ -   Batch number = 121
01/05/2022 23:45:12 - INFO - __main__ -   Batch number = 122
01/05/2022 23:45:12 - INFO - __main__ -   Batch number = 123
01/05/2022 23:45:12 - INFO - __main__ -   Batch number = 124
01/05/2022 23:45:12 - INFO - __main__ -   Batch number = 125
01/05/2022 23:45:14 - INFO - __main__ -   ***** Evaluation result 19000 in en *****
01/05/2022 23:45:14 - INFO - __main__ -     f1 = 0.9448569397699731
01/05/2022 23:45:14 - INFO - __main__ -     loss = 0.3571478381156921
01/05/2022 23:45:14 - INFO - __main__ -     precision = 0.9447679397157047
01/05/2022 23:45:14 - INFO - __main__ -     recall = 0.9449459565939807
01/05/2022 23:45:14 - INFO - __main__ -   Hit patience=13
01/05/2022 23:51:21 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:51:21 - INFO - __main__ -   ***** Running evaluation 20000 in en *****
01/05/2022 23:51:21 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:51:21 - INFO - __main__ -     Batch size = 32
01/05/2022 23:51:21 - INFO - __main__ -   Batch number = 1
01/05/2022 23:51:21 - INFO - __main__ -   Batch number = 2
01/05/2022 23:51:21 - INFO - __main__ -   Batch number = 3
01/05/2022 23:51:21 - INFO - __main__ -   Batch number = 4
01/05/2022 23:51:21 - INFO - __main__ -   Batch number = 5
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 6
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 7
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 8
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 9
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 10
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 11
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 12
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 13
01/05/2022 23:51:22 - INFO - __main__ -   Batch number = 14
01/05/2022 23:51:23 - INFO - __main__ -   Batch number = 15
01/05/2022 23:51:23 - INFO - __main__ -   Batch number = 16
01/05/2022 23:51:23 - INFO - __main__ -   Batch number = 17
01/05/2022 23:51:23 - INFO - __main__ -   Batch number = 18
01/05/2022 23:51:23 - INFO - __main__ -   Batch number = 19
01/05/2022 23:51:23 - INFO - __main__ -   Batch number = 20
01/05/2022 23:51:23 - INFO - __main__ -   Batch number = 21
01/05/2022 23:51:23 - INFO - __main__ -   Batch number = 22
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 23
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 24
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 25
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 26
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 27
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 28
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 29
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 30
01/05/2022 23:51:24 - INFO - __main__ -   Batch number = 31
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 32
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 33
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 34
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 35
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 36
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 37
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 38
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 39
01/05/2022 23:51:25 - INFO - __main__ -   Batch number = 40
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 41
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 42
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 43
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 44
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 45
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 46
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 47
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 48
01/05/2022 23:51:26 - INFO - __main__ -   Batch number = 49
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 50
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 51
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 52
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 53
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 54
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 55
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 56
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 57
01/05/2022 23:51:27 - INFO - __main__ -   Batch number = 58
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 59
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 60
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 61
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 62
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 63
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 64
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 65
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 66
01/05/2022 23:51:28 - INFO - __main__ -   Batch number = 67
01/05/2022 23:51:29 - INFO - __main__ -   Batch number = 68
01/05/2022 23:51:29 - INFO - __main__ -   Batch number = 69
01/05/2022 23:51:29 - INFO - __main__ -   Batch number = 70
01/05/2022 23:51:29 - INFO - __main__ -   Batch number = 71
01/05/2022 23:51:29 - INFO - __main__ -   Batch number = 72
01/05/2022 23:51:29 - INFO - __main__ -   Batch number = 73
01/05/2022 23:51:29 - INFO - __main__ -   Batch number = 74
01/05/2022 23:51:29 - INFO - __main__ -   Batch number = 75
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 76
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 77
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 78
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 79
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 80
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 81
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 82
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 83
01/05/2022 23:51:30 - INFO - __main__ -   Batch number = 84
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 85
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 86
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 87
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 88
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 89
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 90
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 91
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 92
01/05/2022 23:51:31 - INFO - __main__ -   Batch number = 93
01/05/2022 23:51:32 - INFO - __main__ -   Batch number = 94
01/05/2022 23:51:32 - INFO - __main__ -   Batch number = 95
01/05/2022 23:51:32 - INFO - __main__ -   Batch number = 96
01/05/2022 23:51:32 - INFO - __main__ -   Batch number = 97
01/05/2022 23:51:32 - INFO - __main__ -   Batch number = 98
01/05/2022 23:51:32 - INFO - __main__ -   Batch number = 99
01/05/2022 23:51:32 - INFO - __main__ -   Batch number = 100
01/05/2022 23:51:32 - INFO - __main__ -   Batch number = 101
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 102
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 103
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 104
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 105
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 106
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 107
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 108
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 109
01/05/2022 23:51:33 - INFO - __main__ -   Batch number = 110
01/05/2022 23:51:34 - INFO - __main__ -   Batch number = 111
01/05/2022 23:51:34 - INFO - __main__ -   Batch number = 112
01/05/2022 23:51:34 - INFO - __main__ -   Batch number = 113
01/05/2022 23:51:34 - INFO - __main__ -   Batch number = 114
01/05/2022 23:51:34 - INFO - __main__ -   Batch number = 115
01/05/2022 23:51:34 - INFO - __main__ -   Batch number = 116
01/05/2022 23:51:34 - INFO - __main__ -   Batch number = 117
01/05/2022 23:51:34 - INFO - __main__ -   Batch number = 118
01/05/2022 23:51:35 - INFO - __main__ -   Batch number = 119
01/05/2022 23:51:35 - INFO - __main__ -   Batch number = 120
01/05/2022 23:51:35 - INFO - __main__ -   Batch number = 121
01/05/2022 23:51:35 - INFO - __main__ -   Batch number = 122
01/05/2022 23:51:35 - INFO - __main__ -   Batch number = 123
01/05/2022 23:51:35 - INFO - __main__ -   Batch number = 124
01/05/2022 23:51:35 - INFO - __main__ -   Batch number = 125
01/05/2022 23:51:37 - INFO - __main__ -   ***** Evaluation result 20000 in en *****
01/05/2022 23:51:37 - INFO - __main__ -     f1 = 0.9454152960526316
01/05/2022 23:51:37 - INFO - __main__ -     loss = 0.37186585080623624
01/05/2022 23:51:37 - INFO - __main__ -     precision = 0.9455935020648766
01/05/2022 23:51:37 - INFO - __main__ -     recall = 0.9452371571969372
01/05/2022 23:51:37 - INFO - __main__ -   Hit patience=14
01/05/2022 23:57:37 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/05/2022 23:57:37 - INFO - __main__ -   ***** Running evaluation 21000 in en *****
01/05/2022 23:57:37 - INFO - __main__ -     Num examples = 3974
01/05/2022 23:57:37 - INFO - __main__ -     Batch size = 32
01/05/2022 23:57:37 - INFO - __main__ -   Batch number = 1
01/05/2022 23:57:37 - INFO - __main__ -   Batch number = 2
01/05/2022 23:57:37 - INFO - __main__ -   Batch number = 3
01/05/2022 23:57:37 - INFO - __main__ -   Batch number = 4
01/05/2022 23:57:38 - INFO - __main__ -   Batch number = 5
01/05/2022 23:57:38 - INFO - __main__ -   Batch number = 6
01/05/2022 23:57:38 - INFO - __main__ -   Batch number = 7
01/05/2022 23:57:38 - INFO - __main__ -   Batch number = 8
01/05/2022 23:57:38 - INFO - __main__ -   Batch number = 9
01/05/2022 23:57:38 - INFO - __main__ -   Batch number = 10
01/05/2022 23:57:38 - INFO - __main__ -   Batch number = 11
01/05/2022 23:57:38 - INFO - __main__ -   Batch number = 12
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 13
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 14
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 15
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 16
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 17
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 18
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 19
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 20
01/05/2022 23:57:39 - INFO - __main__ -   Batch number = 21
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 22
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 23
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 24
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 25
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 26
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 27
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 28
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 29
01/05/2022 23:57:40 - INFO - __main__ -   Batch number = 30
01/05/2022 23:57:41 - INFO - __main__ -   Batch number = 31
01/05/2022 23:57:41 - INFO - __main__ -   Batch number = 32
01/05/2022 23:57:41 - INFO - __main__ -   Batch number = 33
01/05/2022 23:57:41 - INFO - __main__ -   Batch number = 34
01/05/2022 23:57:41 - INFO - __main__ -   Batch number = 35
01/05/2022 23:57:41 - INFO - __main__ -   Batch number = 36
01/05/2022 23:57:41 - INFO - __main__ -   Batch number = 37
01/05/2022 23:57:41 - INFO - __main__ -   Batch number = 38
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 39
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 40
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 41
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 42
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 43
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 44
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 45
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 46
01/05/2022 23:57:42 - INFO - __main__ -   Batch number = 47
01/05/2022 23:57:43 - INFO - __main__ -   Batch number = 48
01/05/2022 23:57:43 - INFO - __main__ -   Batch number = 49
01/05/2022 23:57:43 - INFO - __main__ -   Batch number = 50
01/05/2022 23:57:43 - INFO - __main__ -   Batch number = 51
01/05/2022 23:57:43 - INFO - __main__ -   Batch number = 52
01/05/2022 23:57:43 - INFO - __main__ -   Batch number = 53
01/05/2022 23:57:43 - INFO - __main__ -   Batch number = 54
01/05/2022 23:57:43 - INFO - __main__ -   Batch number = 55
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 56
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 57
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 58
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 59
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 60
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 61
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 62
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 63
01/05/2022 23:57:44 - INFO - __main__ -   Batch number = 64
01/05/2022 23:57:45 - INFO - __main__ -   Batch number = 65
01/05/2022 23:57:45 - INFO - __main__ -   Batch number = 66
01/05/2022 23:57:45 - INFO - __main__ -   Batch number = 67
01/05/2022 23:57:45 - INFO - __main__ -   Batch number = 68
01/05/2022 23:57:45 - INFO - __main__ -   Batch number = 69
01/05/2022 23:57:45 - INFO - __main__ -   Batch number = 70
01/05/2022 23:57:45 - INFO - __main__ -   Batch number = 71
01/05/2022 23:57:45 - INFO - __main__ -   Batch number = 72
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 73
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 74
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 75
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 76
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 77
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 78
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 79
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 80
01/05/2022 23:57:46 - INFO - __main__ -   Batch number = 81
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 82
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 83
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 84
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 85
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 86
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 87
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 88
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 89
01/05/2022 23:57:47 - INFO - __main__ -   Batch number = 90
01/05/2022 23:57:48 - INFO - __main__ -   Batch number = 91
01/05/2022 23:57:48 - INFO - __main__ -   Batch number = 92
01/05/2022 23:57:48 - INFO - __main__ -   Batch number = 93
01/05/2022 23:57:48 - INFO - __main__ -   Batch number = 94
01/05/2022 23:57:48 - INFO - __main__ -   Batch number = 95
01/05/2022 23:57:48 - INFO - __main__ -   Batch number = 96
01/05/2022 23:57:48 - INFO - __main__ -   Batch number = 97
01/05/2022 23:57:48 - INFO - __main__ -   Batch number = 98
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 99
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 100
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 101
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 102
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 103
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 104
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 105
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 106
01/05/2022 23:57:49 - INFO - __main__ -   Batch number = 107
01/05/2022 23:57:50 - INFO - __main__ -   Batch number = 108
01/05/2022 23:57:50 - INFO - __main__ -   Batch number = 109
01/05/2022 23:57:50 - INFO - __main__ -   Batch number = 110
01/05/2022 23:57:50 - INFO - __main__ -   Batch number = 111
01/05/2022 23:57:50 - INFO - __main__ -   Batch number = 112
01/05/2022 23:57:50 - INFO - __main__ -   Batch number = 113
01/05/2022 23:57:50 - INFO - __main__ -   Batch number = 114
01/05/2022 23:57:50 - INFO - __main__ -   Batch number = 115
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 116
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 117
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 118
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 119
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 120
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 121
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 122
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 123
01/05/2022 23:57:51 - INFO - __main__ -   Batch number = 124
01/05/2022 23:57:52 - INFO - __main__ -   Batch number = 125
01/05/2022 23:57:53 - INFO - __main__ -   ***** Evaluation result 21000 in en *****
01/05/2022 23:57:53 - INFO - __main__ -     f1 = 0.9440913995991846
01/05/2022 23:57:53 - INFO - __main__ -     loss = 0.3878318148255348
01/05/2022 23:57:53 - INFO - __main__ -     precision = 0.9440590582875152
01/05/2022 23:57:53 - INFO - __main__ -     recall = 0.9441237431268092
01/05/2022 23:57:53 - INFO - __main__ -   Hit patience=15
01/06/2022 00:03:57 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:03:58 - INFO - __main__ -   ***** Running evaluation 22000 in en *****
01/06/2022 00:03:58 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:03:58 - INFO - __main__ -     Batch size = 32
01/06/2022 00:03:58 - INFO - __main__ -   Batch number = 1
01/06/2022 00:03:58 - INFO - __main__ -   Batch number = 2
01/06/2022 00:03:58 - INFO - __main__ -   Batch number = 3
01/06/2022 00:03:58 - INFO - __main__ -   Batch number = 4
01/06/2022 00:03:58 - INFO - __main__ -   Batch number = 5
01/06/2022 00:03:58 - INFO - __main__ -   Batch number = 6
01/06/2022 00:03:58 - INFO - __main__ -   Batch number = 7
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 8
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 9
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 10
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 11
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 12
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 13
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 14
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 15
01/06/2022 00:03:59 - INFO - __main__ -   Batch number = 16
01/06/2022 00:04:00 - INFO - __main__ -   Batch number = 17
01/06/2022 00:04:00 - INFO - __main__ -   Batch number = 18
01/06/2022 00:04:00 - INFO - __main__ -   Batch number = 19
01/06/2022 00:04:00 - INFO - __main__ -   Batch number = 20
01/06/2022 00:04:00 - INFO - __main__ -   Batch number = 21
01/06/2022 00:04:00 - INFO - __main__ -   Batch number = 22
01/06/2022 00:04:00 - INFO - __main__ -   Batch number = 23
01/06/2022 00:04:00 - INFO - __main__ -   Batch number = 24
01/06/2022 00:04:01 - INFO - __main__ -   Batch number = 25
01/06/2022 00:04:01 - INFO - __main__ -   Batch number = 26
01/06/2022 00:04:01 - INFO - __main__ -   Batch number = 27
01/06/2022 00:04:01 - INFO - __main__ -   Batch number = 28
01/06/2022 00:04:01 - INFO - __main__ -   Batch number = 29
01/06/2022 00:04:01 - INFO - __main__ -   Batch number = 30
01/06/2022 00:04:01 - INFO - __main__ -   Batch number = 31
01/06/2022 00:04:01 - INFO - __main__ -   Batch number = 32
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 33
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 34
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 35
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 36
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 37
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 38
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 39
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 40
01/06/2022 00:04:02 - INFO - __main__ -   Batch number = 41
01/06/2022 00:04:03 - INFO - __main__ -   Batch number = 42
01/06/2022 00:04:03 - INFO - __main__ -   Batch number = 43
01/06/2022 00:04:03 - INFO - __main__ -   Batch number = 44
01/06/2022 00:04:03 - INFO - __main__ -   Batch number = 45
01/06/2022 00:04:03 - INFO - __main__ -   Batch number = 46
01/06/2022 00:04:03 - INFO - __main__ -   Batch number = 47
01/06/2022 00:04:03 - INFO - __main__ -   Batch number = 48
01/06/2022 00:04:03 - INFO - __main__ -   Batch number = 49
01/06/2022 00:04:04 - INFO - __main__ -   Batch number = 50
01/06/2022 00:04:04 - INFO - __main__ -   Batch number = 51
01/06/2022 00:04:04 - INFO - __main__ -   Batch number = 52
01/06/2022 00:04:04 - INFO - __main__ -   Batch number = 53
01/06/2022 00:04:04 - INFO - __main__ -   Batch number = 54
01/06/2022 00:04:04 - INFO - __main__ -   Batch number = 55
01/06/2022 00:04:04 - INFO - __main__ -   Batch number = 56
01/06/2022 00:04:04 - INFO - __main__ -   Batch number = 57
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 58
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 59
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 60
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 61
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 62
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 63
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 64
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 65
01/06/2022 00:04:05 - INFO - __main__ -   Batch number = 66
01/06/2022 00:04:06 - INFO - __main__ -   Batch number = 67
01/06/2022 00:04:06 - INFO - __main__ -   Batch number = 68
01/06/2022 00:04:06 - INFO - __main__ -   Batch number = 69
01/06/2022 00:04:06 - INFO - __main__ -   Batch number = 70
01/06/2022 00:04:06 - INFO - __main__ -   Batch number = 71
01/06/2022 00:04:06 - INFO - __main__ -   Batch number = 72
01/06/2022 00:04:06 - INFO - __main__ -   Batch number = 73
01/06/2022 00:04:06 - INFO - __main__ -   Batch number = 74
01/06/2022 00:04:07 - INFO - __main__ -   Batch number = 75
01/06/2022 00:04:07 - INFO - __main__ -   Batch number = 76
01/06/2022 00:04:07 - INFO - __main__ -   Batch number = 77
01/06/2022 00:04:07 - INFO - __main__ -   Batch number = 78
01/06/2022 00:04:07 - INFO - __main__ -   Batch number = 79
01/06/2022 00:04:07 - INFO - __main__ -   Batch number = 80
01/06/2022 00:04:07 - INFO - __main__ -   Batch number = 81
01/06/2022 00:04:07 - INFO - __main__ -   Batch number = 82
01/06/2022 00:04:08 - INFO - __main__ -   Batch number = 83
01/06/2022 00:04:08 - INFO - __main__ -   Batch number = 84
01/06/2022 00:04:08 - INFO - __main__ -   Batch number = 85
01/06/2022 00:04:08 - INFO - __main__ -   Batch number = 86
01/06/2022 00:04:08 - INFO - __main__ -   Batch number = 87
01/06/2022 00:04:08 - INFO - __main__ -   Batch number = 88
01/06/2022 00:04:08 - INFO - __main__ -   Batch number = 89
01/06/2022 00:04:08 - INFO - __main__ -   Batch number = 90
01/06/2022 00:04:09 - INFO - __main__ -   Batch number = 91
01/06/2022 00:04:09 - INFO - __main__ -   Batch number = 92
01/06/2022 00:04:09 - INFO - __main__ -   Batch number = 93
01/06/2022 00:04:09 - INFO - __main__ -   Batch number = 94
01/06/2022 00:04:09 - INFO - __main__ -   Batch number = 95
01/06/2022 00:04:09 - INFO - __main__ -   Batch number = 96
01/06/2022 00:04:09 - INFO - __main__ -   Batch number = 97
01/06/2022 00:04:09 - INFO - __main__ -   Batch number = 98
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 99
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 100
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 101
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 102
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 103
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 104
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 105
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 106
01/06/2022 00:04:10 - INFO - __main__ -   Batch number = 107
01/06/2022 00:04:11 - INFO - __main__ -   Batch number = 108
01/06/2022 00:04:11 - INFO - __main__ -   Batch number = 109
01/06/2022 00:04:11 - INFO - __main__ -   Batch number = 110
01/06/2022 00:04:11 - INFO - __main__ -   Batch number = 111
01/06/2022 00:04:11 - INFO - __main__ -   Batch number = 112
01/06/2022 00:04:11 - INFO - __main__ -   Batch number = 113
01/06/2022 00:04:11 - INFO - __main__ -   Batch number = 114
01/06/2022 00:04:11 - INFO - __main__ -   Batch number = 115
01/06/2022 00:04:12 - INFO - __main__ -   Batch number = 116
01/06/2022 00:04:12 - INFO - __main__ -   Batch number = 117
01/06/2022 00:04:12 - INFO - __main__ -   Batch number = 118
01/06/2022 00:04:12 - INFO - __main__ -   Batch number = 119
01/06/2022 00:04:12 - INFO - __main__ -   Batch number = 120
01/06/2022 00:04:12 - INFO - __main__ -   Batch number = 121
01/06/2022 00:04:12 - INFO - __main__ -   Batch number = 122
01/06/2022 00:04:12 - INFO - __main__ -   Batch number = 123
01/06/2022 00:04:13 - INFO - __main__ -   Batch number = 124
01/06/2022 00:04:13 - INFO - __main__ -   Batch number = 125
01/06/2022 00:04:14 - INFO - __main__ -   ***** Evaluation result 22000 in en *****
01/06/2022 00:04:14 - INFO - __main__ -     f1 = 0.9461393596986818
01/06/2022 00:04:14 - INFO - __main__ -     loss = 0.3942399064153433
01/06/2022 00:04:14 - INFO - __main__ -     precision = 0.9456374805359251
01/06/2022 00:04:14 - INFO - __main__ -     recall = 0.9466417718700217
01/06/2022 00:04:14 - INFO - __main__ -   Hit patience=16
01/06/2022 00:10:11 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:10:11 - INFO - __main__ -   ***** Running evaluation 23000 in en *****
01/06/2022 00:10:11 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:10:11 - INFO - __main__ -     Batch size = 32
01/06/2022 00:10:11 - INFO - __main__ -   Batch number = 1
01/06/2022 00:10:11 - INFO - __main__ -   Batch number = 2
01/06/2022 00:10:11 - INFO - __main__ -   Batch number = 3
01/06/2022 00:10:11 - INFO - __main__ -   Batch number = 4
01/06/2022 00:10:11 - INFO - __main__ -   Batch number = 5
01/06/2022 00:10:12 - INFO - __main__ -   Batch number = 6
01/06/2022 00:10:12 - INFO - __main__ -   Batch number = 7
01/06/2022 00:10:12 - INFO - __main__ -   Batch number = 8
01/06/2022 00:10:12 - INFO - __main__ -   Batch number = 9
01/06/2022 00:10:12 - INFO - __main__ -   Batch number = 10
01/06/2022 00:10:12 - INFO - __main__ -   Batch number = 11
01/06/2022 00:10:12 - INFO - __main__ -   Batch number = 12
01/06/2022 00:10:12 - INFO - __main__ -   Batch number = 13
01/06/2022 00:10:13 - INFO - __main__ -   Batch number = 14
01/06/2022 00:10:13 - INFO - __main__ -   Batch number = 15
01/06/2022 00:10:13 - INFO - __main__ -   Batch number = 16
01/06/2022 00:10:13 - INFO - __main__ -   Batch number = 17
01/06/2022 00:10:13 - INFO - __main__ -   Batch number = 18
01/06/2022 00:10:13 - INFO - __main__ -   Batch number = 19
01/06/2022 00:10:13 - INFO - __main__ -   Batch number = 20
01/06/2022 00:10:13 - INFO - __main__ -   Batch number = 21
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 22
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 23
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 24
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 25
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 26
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 27
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 28
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 29
01/06/2022 00:10:14 - INFO - __main__ -   Batch number = 30
01/06/2022 00:10:15 - INFO - __main__ -   Batch number = 31
01/06/2022 00:10:15 - INFO - __main__ -   Batch number = 32
01/06/2022 00:10:15 - INFO - __main__ -   Batch number = 33
01/06/2022 00:10:15 - INFO - __main__ -   Batch number = 34
01/06/2022 00:10:15 - INFO - __main__ -   Batch number = 35
01/06/2022 00:10:15 - INFO - __main__ -   Batch number = 36
01/06/2022 00:10:15 - INFO - __main__ -   Batch number = 37
01/06/2022 00:10:15 - INFO - __main__ -   Batch number = 38
01/06/2022 00:10:16 - INFO - __main__ -   Batch number = 39
01/06/2022 00:10:16 - INFO - __main__ -   Batch number = 40
01/06/2022 00:10:16 - INFO - __main__ -   Batch number = 41
01/06/2022 00:10:16 - INFO - __main__ -   Batch number = 42
01/06/2022 00:10:16 - INFO - __main__ -   Batch number = 43
01/06/2022 00:10:16 - INFO - __main__ -   Batch number = 44
01/06/2022 00:10:16 - INFO - __main__ -   Batch number = 45
01/06/2022 00:10:16 - INFO - __main__ -   Batch number = 46
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 47
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 48
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 49
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 50
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 51
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 52
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 53
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 54
01/06/2022 00:10:17 - INFO - __main__ -   Batch number = 55
01/06/2022 00:10:18 - INFO - __main__ -   Batch number = 56
01/06/2022 00:10:18 - INFO - __main__ -   Batch number = 57
01/06/2022 00:10:18 - INFO - __main__ -   Batch number = 58
01/06/2022 00:10:18 - INFO - __main__ -   Batch number = 59
01/06/2022 00:10:18 - INFO - __main__ -   Batch number = 60
01/06/2022 00:10:18 - INFO - __main__ -   Batch number = 61
01/06/2022 00:10:18 - INFO - __main__ -   Batch number = 62
01/06/2022 00:10:18 - INFO - __main__ -   Batch number = 63
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 64
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 65
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 66
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 67
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 68
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 69
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 70
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 71
01/06/2022 00:10:19 - INFO - __main__ -   Batch number = 72
01/06/2022 00:10:20 - INFO - __main__ -   Batch number = 73
01/06/2022 00:10:20 - INFO - __main__ -   Batch number = 74
01/06/2022 00:10:20 - INFO - __main__ -   Batch number = 75
01/06/2022 00:10:20 - INFO - __main__ -   Batch number = 76
01/06/2022 00:10:20 - INFO - __main__ -   Batch number = 77
01/06/2022 00:10:20 - INFO - __main__ -   Batch number = 78
01/06/2022 00:10:20 - INFO - __main__ -   Batch number = 79
01/06/2022 00:10:20 - INFO - __main__ -   Batch number = 80
01/06/2022 00:10:21 - INFO - __main__ -   Batch number = 81
01/06/2022 00:10:21 - INFO - __main__ -   Batch number = 82
01/06/2022 00:10:21 - INFO - __main__ -   Batch number = 83
01/06/2022 00:10:21 - INFO - __main__ -   Batch number = 84
01/06/2022 00:10:21 - INFO - __main__ -   Batch number = 85
01/06/2022 00:10:21 - INFO - __main__ -   Batch number = 86
01/06/2022 00:10:21 - INFO - __main__ -   Batch number = 87
01/06/2022 00:10:21 - INFO - __main__ -   Batch number = 88
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 89
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 90
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 91
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 92
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 93
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 94
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 95
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 96
01/06/2022 00:10:22 - INFO - __main__ -   Batch number = 97
01/06/2022 00:10:23 - INFO - __main__ -   Batch number = 98
01/06/2022 00:10:23 - INFO - __main__ -   Batch number = 99
01/06/2022 00:10:23 - INFO - __main__ -   Batch number = 100
01/06/2022 00:10:23 - INFO - __main__ -   Batch number = 101
01/06/2022 00:10:23 - INFO - __main__ -   Batch number = 102
01/06/2022 00:10:23 - INFO - __main__ -   Batch number = 103
01/06/2022 00:10:23 - INFO - __main__ -   Batch number = 104
01/06/2022 00:10:23 - INFO - __main__ -   Batch number = 105
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 106
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 107
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 108
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 109
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 110
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 111
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 112
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 113
01/06/2022 00:10:24 - INFO - __main__ -   Batch number = 114
01/06/2022 00:10:25 - INFO - __main__ -   Batch number = 115
01/06/2022 00:10:25 - INFO - __main__ -   Batch number = 116
01/06/2022 00:10:25 - INFO - __main__ -   Batch number = 117
01/06/2022 00:10:25 - INFO - __main__ -   Batch number = 118
01/06/2022 00:10:25 - INFO - __main__ -   Batch number = 119
01/06/2022 00:10:25 - INFO - __main__ -   Batch number = 120
01/06/2022 00:10:25 - INFO - __main__ -   Batch number = 121
01/06/2022 00:10:26 - INFO - __main__ -   Batch number = 122
01/06/2022 00:10:26 - INFO - __main__ -   Batch number = 123
01/06/2022 00:10:26 - INFO - __main__ -   Batch number = 124
01/06/2022 00:10:26 - INFO - __main__ -   Batch number = 125
01/06/2022 00:10:27 - INFO - __main__ -   ***** Evaluation result 23000 in en *****
01/06/2022 00:10:27 - INFO - __main__ -     f1 = 0.945120279624426
01/06/2022 00:10:27 - INFO - __main__ -     loss = 0.40151004046201705
01/06/2022 00:10:27 - INFO - __main__ -     precision = 0.9453632452998337
01/06/2022 00:10:27 - INFO - __main__ -     recall = 0.9448774388050497
01/06/2022 00:10:27 - INFO - __main__ -   Hit patience=17
01/06/2022 00:16:23 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:16:23 - INFO - __main__ -   ***** Running evaluation 24000 in en *****
01/06/2022 00:16:23 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:16:23 - INFO - __main__ -     Batch size = 32
01/06/2022 00:16:23 - INFO - __main__ -   Batch number = 1
01/06/2022 00:16:23 - INFO - __main__ -   Batch number = 2
01/06/2022 00:16:23 - INFO - __main__ -   Batch number = 3
01/06/2022 00:16:23 - INFO - __main__ -   Batch number = 4
01/06/2022 00:16:23 - INFO - __main__ -   Batch number = 5
01/06/2022 00:16:23 - INFO - __main__ -   Batch number = 6
01/06/2022 00:16:24 - INFO - __main__ -   Batch number = 7
01/06/2022 00:16:24 - INFO - __main__ -   Batch number = 8
01/06/2022 00:16:24 - INFO - __main__ -   Batch number = 9
01/06/2022 00:16:24 - INFO - __main__ -   Batch number = 10
01/06/2022 00:16:24 - INFO - __main__ -   Batch number = 11
01/06/2022 00:16:24 - INFO - __main__ -   Batch number = 12
01/06/2022 00:16:24 - INFO - __main__ -   Batch number = 13
01/06/2022 00:16:24 - INFO - __main__ -   Batch number = 14
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 15
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 16
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 17
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 18
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 19
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 20
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 21
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 22
01/06/2022 00:16:25 - INFO - __main__ -   Batch number = 23
01/06/2022 00:16:26 - INFO - __main__ -   Batch number = 24
01/06/2022 00:16:26 - INFO - __main__ -   Batch number = 25
01/06/2022 00:16:26 - INFO - __main__ -   Batch number = 26
01/06/2022 00:16:26 - INFO - __main__ -   Batch number = 27
01/06/2022 00:16:26 - INFO - __main__ -   Batch number = 28
01/06/2022 00:16:26 - INFO - __main__ -   Batch number = 29
01/06/2022 00:16:26 - INFO - __main__ -   Batch number = 30
01/06/2022 00:16:26 - INFO - __main__ -   Batch number = 31
01/06/2022 00:16:27 - INFO - __main__ -   Batch number = 32
01/06/2022 00:16:27 - INFO - __main__ -   Batch number = 33
01/06/2022 00:16:27 - INFO - __main__ -   Batch number = 34
01/06/2022 00:16:27 - INFO - __main__ -   Batch number = 35
01/06/2022 00:16:27 - INFO - __main__ -   Batch number = 36
01/06/2022 00:16:27 - INFO - __main__ -   Batch number = 37
01/06/2022 00:16:27 - INFO - __main__ -   Batch number = 38
01/06/2022 00:16:27 - INFO - __main__ -   Batch number = 39
01/06/2022 00:16:28 - INFO - __main__ -   Batch number = 40
01/06/2022 00:16:28 - INFO - __main__ -   Batch number = 41
01/06/2022 00:16:28 - INFO - __main__ -   Batch number = 42
01/06/2022 00:16:28 - INFO - __main__ -   Batch number = 43
01/06/2022 00:16:28 - INFO - __main__ -   Batch number = 44
01/06/2022 00:16:28 - INFO - __main__ -   Batch number = 45
01/06/2022 00:16:28 - INFO - __main__ -   Batch number = 46
01/06/2022 00:16:28 - INFO - __main__ -   Batch number = 47
01/06/2022 00:16:29 - INFO - __main__ -   Batch number = 48
01/06/2022 00:16:29 - INFO - __main__ -   Batch number = 49
01/06/2022 00:16:29 - INFO - __main__ -   Batch number = 50
01/06/2022 00:16:29 - INFO - __main__ -   Batch number = 51
01/06/2022 00:16:29 - INFO - __main__ -   Batch number = 52
01/06/2022 00:16:29 - INFO - __main__ -   Batch number = 53
01/06/2022 00:16:29 - INFO - __main__ -   Batch number = 54
01/06/2022 00:16:29 - INFO - __main__ -   Batch number = 55
01/06/2022 00:16:30 - INFO - __main__ -   Batch number = 56
01/06/2022 00:16:30 - INFO - __main__ -   Batch number = 57
01/06/2022 00:16:30 - INFO - __main__ -   Batch number = 58
01/06/2022 00:16:30 - INFO - __main__ -   Batch number = 59
01/06/2022 00:16:30 - INFO - __main__ -   Batch number = 60
01/06/2022 00:16:30 - INFO - __main__ -   Batch number = 61
01/06/2022 00:16:30 - INFO - __main__ -   Batch number = 62
01/06/2022 00:16:30 - INFO - __main__ -   Batch number = 63
01/06/2022 00:16:31 - INFO - __main__ -   Batch number = 64
01/06/2022 00:16:31 - INFO - __main__ -   Batch number = 65
01/06/2022 00:16:31 - INFO - __main__ -   Batch number = 66
01/06/2022 00:16:31 - INFO - __main__ -   Batch number = 67
01/06/2022 00:16:31 - INFO - __main__ -   Batch number = 68
01/06/2022 00:16:31 - INFO - __main__ -   Batch number = 69
01/06/2022 00:16:31 - INFO - __main__ -   Batch number = 70
01/06/2022 00:16:31 - INFO - __main__ -   Batch number = 71
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 72
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 73
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 74
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 75
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 76
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 77
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 78
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 79
01/06/2022 00:16:32 - INFO - __main__ -   Batch number = 80
01/06/2022 00:16:33 - INFO - __main__ -   Batch number = 81
01/06/2022 00:16:33 - INFO - __main__ -   Batch number = 82
01/06/2022 00:16:33 - INFO - __main__ -   Batch number = 83
01/06/2022 00:16:33 - INFO - __main__ -   Batch number = 84
01/06/2022 00:16:33 - INFO - __main__ -   Batch number = 85
01/06/2022 00:16:33 - INFO - __main__ -   Batch number = 86
01/06/2022 00:16:33 - INFO - __main__ -   Batch number = 87
01/06/2022 00:16:33 - INFO - __main__ -   Batch number = 88
01/06/2022 00:16:34 - INFO - __main__ -   Batch number = 89
01/06/2022 00:16:34 - INFO - __main__ -   Batch number = 90
01/06/2022 00:16:34 - INFO - __main__ -   Batch number = 91
01/06/2022 00:16:34 - INFO - __main__ -   Batch number = 92
01/06/2022 00:16:34 - INFO - __main__ -   Batch number = 93
01/06/2022 00:16:34 - INFO - __main__ -   Batch number = 94
01/06/2022 00:16:34 - INFO - __main__ -   Batch number = 95
01/06/2022 00:16:34 - INFO - __main__ -   Batch number = 96
01/06/2022 00:16:35 - INFO - __main__ -   Batch number = 97
01/06/2022 00:16:35 - INFO - __main__ -   Batch number = 98
01/06/2022 00:16:35 - INFO - __main__ -   Batch number = 99
01/06/2022 00:16:35 - INFO - __main__ -   Batch number = 100
01/06/2022 00:16:35 - INFO - __main__ -   Batch number = 101
01/06/2022 00:16:35 - INFO - __main__ -   Batch number = 102
01/06/2022 00:16:35 - INFO - __main__ -   Batch number = 103
01/06/2022 00:16:35 - INFO - __main__ -   Batch number = 104
01/06/2022 00:16:36 - INFO - __main__ -   Batch number = 105
01/06/2022 00:16:36 - INFO - __main__ -   Batch number = 106
01/06/2022 00:16:36 - INFO - __main__ -   Batch number = 107
01/06/2022 00:16:36 - INFO - __main__ -   Batch number = 108
01/06/2022 00:16:36 - INFO - __main__ -   Batch number = 109
01/06/2022 00:16:36 - INFO - __main__ -   Batch number = 110
01/06/2022 00:16:36 - INFO - __main__ -   Batch number = 111
01/06/2022 00:16:36 - INFO - __main__ -   Batch number = 112
01/06/2022 00:16:37 - INFO - __main__ -   Batch number = 113
01/06/2022 00:16:37 - INFO - __main__ -   Batch number = 114
01/06/2022 00:16:37 - INFO - __main__ -   Batch number = 115
01/06/2022 00:16:37 - INFO - __main__ -   Batch number = 116
01/06/2022 00:16:37 - INFO - __main__ -   Batch number = 117
01/06/2022 00:16:37 - INFO - __main__ -   Batch number = 118
01/06/2022 00:16:37 - INFO - __main__ -   Batch number = 119
01/06/2022 00:16:37 - INFO - __main__ -   Batch number = 120
01/06/2022 00:16:38 - INFO - __main__ -   Batch number = 121
01/06/2022 00:16:38 - INFO - __main__ -   Batch number = 122
01/06/2022 00:16:38 - INFO - __main__ -   Batch number = 123
01/06/2022 00:16:38 - INFO - __main__ -   Batch number = 124
01/06/2022 00:16:38 - INFO - __main__ -   Batch number = 125
01/06/2022 00:16:39 - INFO - __main__ -   ***** Evaluation result 24000 in en *****
01/06/2022 00:16:39 - INFO - __main__ -     f1 = 0.9458126391505394
01/06/2022 00:16:39 - INFO - __main__ -     loss = 0.40910896062850954
01/06/2022 00:16:39 - INFO - __main__ -     precision = 0.9456344925600589
01/06/2022 00:16:39 - INFO - __main__ -     recall = 0.9459908528751777
01/06/2022 00:16:39 - INFO - __main__ -   Hit patience=18
01/06/2022 00:22:33 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:22:33 - INFO - __main__ -   ***** Running evaluation 25000 in en *****
01/06/2022 00:22:33 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:22:33 - INFO - __main__ -     Batch size = 32
01/06/2022 00:22:33 - INFO - __main__ -   Batch number = 1
01/06/2022 00:22:33 - INFO - __main__ -   Batch number = 2
01/06/2022 00:22:33 - INFO - __main__ -   Batch number = 3
01/06/2022 00:22:33 - INFO - __main__ -   Batch number = 4
01/06/2022 00:22:33 - INFO - __main__ -   Batch number = 5
01/06/2022 00:22:33 - INFO - __main__ -   Batch number = 6
01/06/2022 00:22:33 - INFO - __main__ -   Batch number = 7
01/06/2022 00:22:34 - INFO - __main__ -   Batch number = 8
01/06/2022 00:22:34 - INFO - __main__ -   Batch number = 9
01/06/2022 00:22:34 - INFO - __main__ -   Batch number = 10
01/06/2022 00:22:34 - INFO - __main__ -   Batch number = 11
01/06/2022 00:22:34 - INFO - __main__ -   Batch number = 12
01/06/2022 00:22:34 - INFO - __main__ -   Batch number = 13
01/06/2022 00:22:34 - INFO - __main__ -   Batch number = 14
01/06/2022 00:22:34 - INFO - __main__ -   Batch number = 15
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 16
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 17
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 18
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 19
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 20
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 21
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 22
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 23
01/06/2022 00:22:35 - INFO - __main__ -   Batch number = 24
01/06/2022 00:22:36 - INFO - __main__ -   Batch number = 25
01/06/2022 00:22:36 - INFO - __main__ -   Batch number = 26
01/06/2022 00:22:36 - INFO - __main__ -   Batch number = 27
01/06/2022 00:22:36 - INFO - __main__ -   Batch number = 28
01/06/2022 00:22:36 - INFO - __main__ -   Batch number = 29
01/06/2022 00:22:36 - INFO - __main__ -   Batch number = 30
01/06/2022 00:22:36 - INFO - __main__ -   Batch number = 31
01/06/2022 00:22:36 - INFO - __main__ -   Batch number = 32
01/06/2022 00:22:37 - INFO - __main__ -   Batch number = 33
01/06/2022 00:22:37 - INFO - __main__ -   Batch number = 34
01/06/2022 00:22:37 - INFO - __main__ -   Batch number = 35
01/06/2022 00:22:37 - INFO - __main__ -   Batch number = 36
01/06/2022 00:22:37 - INFO - __main__ -   Batch number = 37
01/06/2022 00:22:37 - INFO - __main__ -   Batch number = 38
01/06/2022 00:22:37 - INFO - __main__ -   Batch number = 39
01/06/2022 00:22:37 - INFO - __main__ -   Batch number = 40
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 41
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 42
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 43
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 44
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 45
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 46
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 47
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 48
01/06/2022 00:22:38 - INFO - __main__ -   Batch number = 49
01/06/2022 00:22:39 - INFO - __main__ -   Batch number = 50
01/06/2022 00:22:39 - INFO - __main__ -   Batch number = 51
01/06/2022 00:22:39 - INFO - __main__ -   Batch number = 52
01/06/2022 00:22:39 - INFO - __main__ -   Batch number = 53
01/06/2022 00:22:39 - INFO - __main__ -   Batch number = 54
01/06/2022 00:22:39 - INFO - __main__ -   Batch number = 55
01/06/2022 00:22:39 - INFO - __main__ -   Batch number = 56
01/06/2022 00:22:39 - INFO - __main__ -   Batch number = 57
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 58
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 59
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 60
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 61
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 62
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 63
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 64
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 65
01/06/2022 00:22:40 - INFO - __main__ -   Batch number = 66
01/06/2022 00:22:41 - INFO - __main__ -   Batch number = 67
01/06/2022 00:22:41 - INFO - __main__ -   Batch number = 68
01/06/2022 00:22:41 - INFO - __main__ -   Batch number = 69
01/06/2022 00:22:41 - INFO - __main__ -   Batch number = 70
01/06/2022 00:22:41 - INFO - __main__ -   Batch number = 71
01/06/2022 00:22:41 - INFO - __main__ -   Batch number = 72
01/06/2022 00:22:41 - INFO - __main__ -   Batch number = 73
01/06/2022 00:22:41 - INFO - __main__ -   Batch number = 74
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 75
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 76
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 77
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 78
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 79
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 80
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 81
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 82
01/06/2022 00:22:42 - INFO - __main__ -   Batch number = 83
01/06/2022 00:22:43 - INFO - __main__ -   Batch number = 84
01/06/2022 00:22:43 - INFO - __main__ -   Batch number = 85
01/06/2022 00:22:43 - INFO - __main__ -   Batch number = 86
01/06/2022 00:22:43 - INFO - __main__ -   Batch number = 87
01/06/2022 00:22:43 - INFO - __main__ -   Batch number = 88
01/06/2022 00:22:43 - INFO - __main__ -   Batch number = 89
01/06/2022 00:22:43 - INFO - __main__ -   Batch number = 90
01/06/2022 00:22:43 - INFO - __main__ -   Batch number = 91
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 92
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 93
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 94
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 95
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 96
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 97
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 98
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 99
01/06/2022 00:22:44 - INFO - __main__ -   Batch number = 100
01/06/2022 00:22:45 - INFO - __main__ -   Batch number = 101
01/06/2022 00:22:45 - INFO - __main__ -   Batch number = 102
01/06/2022 00:22:45 - INFO - __main__ -   Batch number = 103
01/06/2022 00:22:45 - INFO - __main__ -   Batch number = 104
01/06/2022 00:22:45 - INFO - __main__ -   Batch number = 105
01/06/2022 00:22:45 - INFO - __main__ -   Batch number = 106
01/06/2022 00:22:45 - INFO - __main__ -   Batch number = 107
01/06/2022 00:22:45 - INFO - __main__ -   Batch number = 108
01/06/2022 00:22:46 - INFO - __main__ -   Batch number = 109
01/06/2022 00:22:46 - INFO - __main__ -   Batch number = 110
01/06/2022 00:22:46 - INFO - __main__ -   Batch number = 111
01/06/2022 00:22:46 - INFO - __main__ -   Batch number = 112
01/06/2022 00:22:46 - INFO - __main__ -   Batch number = 113
01/06/2022 00:22:46 - INFO - __main__ -   Batch number = 114
01/06/2022 00:22:46 - INFO - __main__ -   Batch number = 115
01/06/2022 00:22:46 - INFO - __main__ -   Batch number = 116
01/06/2022 00:22:47 - INFO - __main__ -   Batch number = 117
01/06/2022 00:22:47 - INFO - __main__ -   Batch number = 118
01/06/2022 00:22:47 - INFO - __main__ -   Batch number = 119
01/06/2022 00:22:47 - INFO - __main__ -   Batch number = 120
01/06/2022 00:22:47 - INFO - __main__ -   Batch number = 121
01/06/2022 00:22:47 - INFO - __main__ -   Batch number = 122
01/06/2022 00:22:47 - INFO - __main__ -   Batch number = 123
01/06/2022 00:22:47 - INFO - __main__ -   Batch number = 124
01/06/2022 00:22:48 - INFO - __main__ -   Batch number = 125
01/06/2022 00:22:49 - INFO - __main__ -   ***** Evaluation result 25000 in en *****
01/06/2022 00:22:49 - INFO - __main__ -     f1 = 0.9457189097541552
01/06/2022 00:22:49 - INFO - __main__ -     loss = 0.4212758188545704
01/06/2022 00:22:49 - INFO - __main__ -     precision = 0.9455326872367384
01/06/2022 00:22:49 - INFO - __main__ -     recall = 0.945905205639014
01/06/2022 00:22:49 - INFO - __main__ -   Hit patience=19
01/06/2022 00:28:46 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:28:47 - INFO - __main__ -   ***** Running evaluation 26000 in en *****
01/06/2022 00:28:47 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:28:47 - INFO - __main__ -     Batch size = 32
01/06/2022 00:28:47 - INFO - __main__ -   Batch number = 1
01/06/2022 00:28:47 - INFO - __main__ -   Batch number = 2
01/06/2022 00:28:47 - INFO - __main__ -   Batch number = 3
01/06/2022 00:28:47 - INFO - __main__ -   Batch number = 4
01/06/2022 00:28:47 - INFO - __main__ -   Batch number = 5
01/06/2022 00:28:47 - INFO - __main__ -   Batch number = 6
01/06/2022 00:28:47 - INFO - __main__ -   Batch number = 7
01/06/2022 00:28:47 - INFO - __main__ -   Batch number = 8
01/06/2022 00:28:48 - INFO - __main__ -   Batch number = 9
01/06/2022 00:28:48 - INFO - __main__ -   Batch number = 10
01/06/2022 00:28:48 - INFO - __main__ -   Batch number = 11
01/06/2022 00:28:48 - INFO - __main__ -   Batch number = 12
01/06/2022 00:28:48 - INFO - __main__ -   Batch number = 13
01/06/2022 00:28:48 - INFO - __main__ -   Batch number = 14
01/06/2022 00:28:48 - INFO - __main__ -   Batch number = 15
01/06/2022 00:28:48 - INFO - __main__ -   Batch number = 16
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 17
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 18
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 19
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 20
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 21
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 22
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 23
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 24
01/06/2022 00:28:49 - INFO - __main__ -   Batch number = 25
01/06/2022 00:28:50 - INFO - __main__ -   Batch number = 26
01/06/2022 00:28:50 - INFO - __main__ -   Batch number = 27
01/06/2022 00:28:50 - INFO - __main__ -   Batch number = 28
01/06/2022 00:28:50 - INFO - __main__ -   Batch number = 29
01/06/2022 00:28:50 - INFO - __main__ -   Batch number = 30
01/06/2022 00:28:50 - INFO - __main__ -   Batch number = 31
01/06/2022 00:28:50 - INFO - __main__ -   Batch number = 32
01/06/2022 00:28:50 - INFO - __main__ -   Batch number = 33
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 34
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 35
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 36
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 37
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 38
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 39
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 40
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 41
01/06/2022 00:28:51 - INFO - __main__ -   Batch number = 42
01/06/2022 00:28:52 - INFO - __main__ -   Batch number = 43
01/06/2022 00:28:52 - INFO - __main__ -   Batch number = 44
01/06/2022 00:28:52 - INFO - __main__ -   Batch number = 45
01/06/2022 00:28:52 - INFO - __main__ -   Batch number = 46
01/06/2022 00:28:52 - INFO - __main__ -   Batch number = 47
01/06/2022 00:28:52 - INFO - __main__ -   Batch number = 48
01/06/2022 00:28:52 - INFO - __main__ -   Batch number = 49
01/06/2022 00:28:52 - INFO - __main__ -   Batch number = 50
01/06/2022 00:28:53 - INFO - __main__ -   Batch number = 51
01/06/2022 00:28:53 - INFO - __main__ -   Batch number = 52
01/06/2022 00:28:53 - INFO - __main__ -   Batch number = 53
01/06/2022 00:28:53 - INFO - __main__ -   Batch number = 54
01/06/2022 00:28:53 - INFO - __main__ -   Batch number = 55
01/06/2022 00:28:53 - INFO - __main__ -   Batch number = 56
01/06/2022 00:28:53 - INFO - __main__ -   Batch number = 57
01/06/2022 00:28:53 - INFO - __main__ -   Batch number = 58
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 59
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 60
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 61
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 62
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 63
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 64
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 65
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 66
01/06/2022 00:28:54 - INFO - __main__ -   Batch number = 67
01/06/2022 00:28:55 - INFO - __main__ -   Batch number = 68
01/06/2022 00:28:55 - INFO - __main__ -   Batch number = 69
01/06/2022 00:28:55 - INFO - __main__ -   Batch number = 70
01/06/2022 00:28:55 - INFO - __main__ -   Batch number = 71
01/06/2022 00:28:55 - INFO - __main__ -   Batch number = 72
01/06/2022 00:28:55 - INFO - __main__ -   Batch number = 73
01/06/2022 00:28:55 - INFO - __main__ -   Batch number = 74
01/06/2022 00:28:55 - INFO - __main__ -   Batch number = 75
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 76
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 77
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 78
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 79
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 80
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 81
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 82
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 83
01/06/2022 00:28:56 - INFO - __main__ -   Batch number = 84
01/06/2022 00:28:57 - INFO - __main__ -   Batch number = 85
01/06/2022 00:28:57 - INFO - __main__ -   Batch number = 86
01/06/2022 00:28:57 - INFO - __main__ -   Batch number = 87
01/06/2022 00:28:57 - INFO - __main__ -   Batch number = 88
01/06/2022 00:28:57 - INFO - __main__ -   Batch number = 89
01/06/2022 00:28:57 - INFO - __main__ -   Batch number = 90
01/06/2022 00:28:57 - INFO - __main__ -   Batch number = 91
01/06/2022 00:28:57 - INFO - __main__ -   Batch number = 92
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 93
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 94
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 95
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 96
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 97
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 98
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 99
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 100
01/06/2022 00:28:58 - INFO - __main__ -   Batch number = 101
01/06/2022 00:28:59 - INFO - __main__ -   Batch number = 102
01/06/2022 00:28:59 - INFO - __main__ -   Batch number = 103
01/06/2022 00:28:59 - INFO - __main__ -   Batch number = 104
01/06/2022 00:28:59 - INFO - __main__ -   Batch number = 105
01/06/2022 00:28:59 - INFO - __main__ -   Batch number = 106
01/06/2022 00:28:59 - INFO - __main__ -   Batch number = 107
01/06/2022 00:28:59 - INFO - __main__ -   Batch number = 108
01/06/2022 00:28:59 - INFO - __main__ -   Batch number = 109
01/06/2022 00:29:00 - INFO - __main__ -   Batch number = 110
01/06/2022 00:29:00 - INFO - __main__ -   Batch number = 111
01/06/2022 00:29:00 - INFO - __main__ -   Batch number = 112
01/06/2022 00:29:00 - INFO - __main__ -   Batch number = 113
01/06/2022 00:29:00 - INFO - __main__ -   Batch number = 114
01/06/2022 00:29:00 - INFO - __main__ -   Batch number = 115
01/06/2022 00:29:00 - INFO - __main__ -   Batch number = 116
01/06/2022 00:29:00 - INFO - __main__ -   Batch number = 117
01/06/2022 00:29:01 - INFO - __main__ -   Batch number = 118
01/06/2022 00:29:01 - INFO - __main__ -   Batch number = 119
01/06/2022 00:29:01 - INFO - __main__ -   Batch number = 120
01/06/2022 00:29:01 - INFO - __main__ -   Batch number = 121
01/06/2022 00:29:01 - INFO - __main__ -   Batch number = 122
01/06/2022 00:29:01 - INFO - __main__ -   Batch number = 123
01/06/2022 00:29:01 - INFO - __main__ -   Batch number = 124
01/06/2022 00:29:01 - INFO - __main__ -   Batch number = 125
01/06/2022 00:29:03 - INFO - __main__ -   ***** Evaluation result 26000 in en *****
01/06/2022 00:29:03 - INFO - __main__ -     f1 = 0.9457815845824411
01/06/2022 00:29:03 - INFO - __main__ -     loss = 0.4275334497094154
01/06/2022 00:29:03 - INFO - __main__ -     precision = 0.9458463963269432
01/06/2022 00:29:03 - INFO - __main__ -     recall = 0.945716781719454
01/06/2022 00:29:03 - INFO - __main__ -   Hit patience=20
01/06/2022 00:35:11 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:35:11 - INFO - __main__ -   ***** Running evaluation 27000 in en *****
01/06/2022 00:35:11 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:35:11 - INFO - __main__ -     Batch size = 32
01/06/2022 00:35:11 - INFO - __main__ -   Batch number = 1
01/06/2022 00:35:11 - INFO - __main__ -   Batch number = 2
01/06/2022 00:35:11 - INFO - __main__ -   Batch number = 3
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 4
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 5
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 6
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 7
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 8
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 9
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 10
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 11
01/06/2022 00:35:12 - INFO - __main__ -   Batch number = 12
01/06/2022 00:35:13 - INFO - __main__ -   Batch number = 13
01/06/2022 00:35:13 - INFO - __main__ -   Batch number = 14
01/06/2022 00:35:13 - INFO - __main__ -   Batch number = 15
01/06/2022 00:35:13 - INFO - __main__ -   Batch number = 16
01/06/2022 00:35:13 - INFO - __main__ -   Batch number = 17
01/06/2022 00:35:13 - INFO - __main__ -   Batch number = 18
01/06/2022 00:35:13 - INFO - __main__ -   Batch number = 19
01/06/2022 00:35:13 - INFO - __main__ -   Batch number = 20
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 21
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 22
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 23
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 24
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 25
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 26
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 27
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 28
01/06/2022 00:35:14 - INFO - __main__ -   Batch number = 29
01/06/2022 00:35:15 - INFO - __main__ -   Batch number = 30
01/06/2022 00:35:15 - INFO - __main__ -   Batch number = 31
01/06/2022 00:35:15 - INFO - __main__ -   Batch number = 32
01/06/2022 00:35:15 - INFO - __main__ -   Batch number = 33
01/06/2022 00:35:15 - INFO - __main__ -   Batch number = 34
01/06/2022 00:35:15 - INFO - __main__ -   Batch number = 35
01/06/2022 00:35:15 - INFO - __main__ -   Batch number = 36
01/06/2022 00:35:15 - INFO - __main__ -   Batch number = 37
01/06/2022 00:35:16 - INFO - __main__ -   Batch number = 38
01/06/2022 00:35:16 - INFO - __main__ -   Batch number = 39
01/06/2022 00:35:16 - INFO - __main__ -   Batch number = 40
01/06/2022 00:35:16 - INFO - __main__ -   Batch number = 41
01/06/2022 00:35:16 - INFO - __main__ -   Batch number = 42
01/06/2022 00:35:16 - INFO - __main__ -   Batch number = 43
01/06/2022 00:35:16 - INFO - __main__ -   Batch number = 44
01/06/2022 00:35:16 - INFO - __main__ -   Batch number = 45
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 46
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 47
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 48
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 49
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 50
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 51
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 52
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 53
01/06/2022 00:35:17 - INFO - __main__ -   Batch number = 54
01/06/2022 00:35:18 - INFO - __main__ -   Batch number = 55
01/06/2022 00:35:18 - INFO - __main__ -   Batch number = 56
01/06/2022 00:35:18 - INFO - __main__ -   Batch number = 57
01/06/2022 00:35:18 - INFO - __main__ -   Batch number = 58
01/06/2022 00:35:18 - INFO - __main__ -   Batch number = 59
01/06/2022 00:35:18 - INFO - __main__ -   Batch number = 60
01/06/2022 00:35:18 - INFO - __main__ -   Batch number = 61
01/06/2022 00:35:18 - INFO - __main__ -   Batch number = 62
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 63
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 64
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 65
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 66
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 67
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 68
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 69
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 70
01/06/2022 00:35:19 - INFO - __main__ -   Batch number = 71
01/06/2022 00:35:20 - INFO - __main__ -   Batch number = 72
01/06/2022 00:35:20 - INFO - __main__ -   Batch number = 73
01/06/2022 00:35:20 - INFO - __main__ -   Batch number = 74
01/06/2022 00:35:20 - INFO - __main__ -   Batch number = 75
01/06/2022 00:35:20 - INFO - __main__ -   Batch number = 76
01/06/2022 00:35:20 - INFO - __main__ -   Batch number = 77
01/06/2022 00:35:20 - INFO - __main__ -   Batch number = 78
01/06/2022 00:35:20 - INFO - __main__ -   Batch number = 79
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 80
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 81
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 82
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 83
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 84
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 85
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 86
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 87
01/06/2022 00:35:21 - INFO - __main__ -   Batch number = 88
01/06/2022 00:35:22 - INFO - __main__ -   Batch number = 89
01/06/2022 00:35:22 - INFO - __main__ -   Batch number = 90
01/06/2022 00:35:22 - INFO - __main__ -   Batch number = 91
01/06/2022 00:35:22 - INFO - __main__ -   Batch number = 92
01/06/2022 00:35:22 - INFO - __main__ -   Batch number = 93
01/06/2022 00:35:22 - INFO - __main__ -   Batch number = 94
01/06/2022 00:35:22 - INFO - __main__ -   Batch number = 95
01/06/2022 00:35:22 - INFO - __main__ -   Batch number = 96
01/06/2022 00:35:23 - INFO - __main__ -   Batch number = 97
01/06/2022 00:35:23 - INFO - __main__ -   Batch number = 98
01/06/2022 00:35:23 - INFO - __main__ -   Batch number = 99
01/06/2022 00:35:23 - INFO - __main__ -   Batch number = 100
01/06/2022 00:35:23 - INFO - __main__ -   Batch number = 101
01/06/2022 00:35:23 - INFO - __main__ -   Batch number = 102
01/06/2022 00:35:23 - INFO - __main__ -   Batch number = 103
01/06/2022 00:35:23 - INFO - __main__ -   Batch number = 104
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 105
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 106
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 107
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 108
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 109
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 110
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 111
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 112
01/06/2022 00:35:24 - INFO - __main__ -   Batch number = 113
01/06/2022 00:35:25 - INFO - __main__ -   Batch number = 114
01/06/2022 00:35:25 - INFO - __main__ -   Batch number = 115
01/06/2022 00:35:25 - INFO - __main__ -   Batch number = 116
01/06/2022 00:35:25 - INFO - __main__ -   Batch number = 117
01/06/2022 00:35:25 - INFO - __main__ -   Batch number = 118
01/06/2022 00:35:25 - INFO - __main__ -   Batch number = 119
01/06/2022 00:35:25 - INFO - __main__ -   Batch number = 120
01/06/2022 00:35:25 - INFO - __main__ -   Batch number = 121
01/06/2022 00:35:26 - INFO - __main__ -   Batch number = 122
01/06/2022 00:35:26 - INFO - __main__ -   Batch number = 123
01/06/2022 00:35:26 - INFO - __main__ -   Batch number = 124
01/06/2022 00:35:26 - INFO - __main__ -   Batch number = 125
01/06/2022 00:35:27 - INFO - __main__ -   ***** Evaluation result 27000 in en *****
01/06/2022 00:35:27 - INFO - __main__ -     f1 = 0.9453691884621646
01/06/2022 00:35:27 - INFO - __main__ -     loss = 0.4326276608407497
01/06/2022 00:35:27 - INFO - __main__ -     precision = 0.9456041131105398
01/06/2022 00:35:27 - INFO - __main__ -     recall = 0.9451343805135408
01/06/2022 00:35:27 - INFO - __main__ -   Hit patience=21
01/06/2022 00:41:24 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:41:24 - INFO - __main__ -   ***** Running evaluation 28000 in en *****
01/06/2022 00:41:24 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:41:24 - INFO - __main__ -     Batch size = 32
01/06/2022 00:41:24 - INFO - __main__ -   Batch number = 1
01/06/2022 00:41:24 - INFO - __main__ -   Batch number = 2
01/06/2022 00:41:24 - INFO - __main__ -   Batch number = 3
01/06/2022 00:41:24 - INFO - __main__ -   Batch number = 4
01/06/2022 00:41:24 - INFO - __main__ -   Batch number = 5
01/06/2022 00:41:24 - INFO - __main__ -   Batch number = 6
01/06/2022 00:41:25 - INFO - __main__ -   Batch number = 7
01/06/2022 00:41:25 - INFO - __main__ -   Batch number = 8
01/06/2022 00:41:25 - INFO - __main__ -   Batch number = 9
01/06/2022 00:41:25 - INFO - __main__ -   Batch number = 10
01/06/2022 00:41:25 - INFO - __main__ -   Batch number = 11
01/06/2022 00:41:25 - INFO - __main__ -   Batch number = 12
01/06/2022 00:41:25 - INFO - __main__ -   Batch number = 13
01/06/2022 00:41:25 - INFO - __main__ -   Batch number = 14
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 15
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 16
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 17
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 18
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 19
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 20
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 21
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 22
01/06/2022 00:41:26 - INFO - __main__ -   Batch number = 23
01/06/2022 00:41:27 - INFO - __main__ -   Batch number = 24
01/06/2022 00:41:27 - INFO - __main__ -   Batch number = 25
01/06/2022 00:41:27 - INFO - __main__ -   Batch number = 26
01/06/2022 00:41:27 - INFO - __main__ -   Batch number = 27
01/06/2022 00:41:27 - INFO - __main__ -   Batch number = 28
01/06/2022 00:41:27 - INFO - __main__ -   Batch number = 29
01/06/2022 00:41:27 - INFO - __main__ -   Batch number = 30
01/06/2022 00:41:27 - INFO - __main__ -   Batch number = 31
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 32
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 33
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 34
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 35
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 36
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 37
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 38
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 39
01/06/2022 00:41:28 - INFO - __main__ -   Batch number = 40
01/06/2022 00:41:29 - INFO - __main__ -   Batch number = 41
01/06/2022 00:41:29 - INFO - __main__ -   Batch number = 42
01/06/2022 00:41:29 - INFO - __main__ -   Batch number = 43
01/06/2022 00:41:29 - INFO - __main__ -   Batch number = 44
01/06/2022 00:41:29 - INFO - __main__ -   Batch number = 45
01/06/2022 00:41:29 - INFO - __main__ -   Batch number = 46
01/06/2022 00:41:29 - INFO - __main__ -   Batch number = 47
01/06/2022 00:41:29 - INFO - __main__ -   Batch number = 48
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 49
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 50
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 51
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 52
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 53
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 54
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 55
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 56
01/06/2022 00:41:30 - INFO - __main__ -   Batch number = 57
01/06/2022 00:41:31 - INFO - __main__ -   Batch number = 58
01/06/2022 00:41:31 - INFO - __main__ -   Batch number = 59
01/06/2022 00:41:31 - INFO - __main__ -   Batch number = 60
01/06/2022 00:41:31 - INFO - __main__ -   Batch number = 61
01/06/2022 00:41:31 - INFO - __main__ -   Batch number = 62
01/06/2022 00:41:31 - INFO - __main__ -   Batch number = 63
01/06/2022 00:41:31 - INFO - __main__ -   Batch number = 64
01/06/2022 00:41:31 - INFO - __main__ -   Batch number = 65
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 66
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 67
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 68
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 69
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 70
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 71
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 72
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 73
01/06/2022 00:41:32 - INFO - __main__ -   Batch number = 74
01/06/2022 00:41:33 - INFO - __main__ -   Batch number = 75
01/06/2022 00:41:33 - INFO - __main__ -   Batch number = 76
01/06/2022 00:41:33 - INFO - __main__ -   Batch number = 77
01/06/2022 00:41:33 - INFO - __main__ -   Batch number = 78
01/06/2022 00:41:33 - INFO - __main__ -   Batch number = 79
01/06/2022 00:41:33 - INFO - __main__ -   Batch number = 80
01/06/2022 00:41:33 - INFO - __main__ -   Batch number = 81
01/06/2022 00:41:33 - INFO - __main__ -   Batch number = 82
01/06/2022 00:41:34 - INFO - __main__ -   Batch number = 83
01/06/2022 00:41:34 - INFO - __main__ -   Batch number = 84
01/06/2022 00:41:34 - INFO - __main__ -   Batch number = 85
01/06/2022 00:41:34 - INFO - __main__ -   Batch number = 86
01/06/2022 00:41:34 - INFO - __main__ -   Batch number = 87
01/06/2022 00:41:34 - INFO - __main__ -   Batch number = 88
01/06/2022 00:41:34 - INFO - __main__ -   Batch number = 89
01/06/2022 00:41:34 - INFO - __main__ -   Batch number = 90
01/06/2022 00:41:35 - INFO - __main__ -   Batch number = 91
01/06/2022 00:41:35 - INFO - __main__ -   Batch number = 92
01/06/2022 00:41:35 - INFO - __main__ -   Batch number = 93
01/06/2022 00:41:35 - INFO - __main__ -   Batch number = 94
01/06/2022 00:41:35 - INFO - __main__ -   Batch number = 95
01/06/2022 00:41:35 - INFO - __main__ -   Batch number = 96
01/06/2022 00:41:35 - INFO - __main__ -   Batch number = 97
01/06/2022 00:41:35 - INFO - __main__ -   Batch number = 98
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 99
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 100
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 101
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 102
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 103
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 104
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 105
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 106
01/06/2022 00:41:36 - INFO - __main__ -   Batch number = 107
01/06/2022 00:41:37 - INFO - __main__ -   Batch number = 108
01/06/2022 00:41:37 - INFO - __main__ -   Batch number = 109
01/06/2022 00:41:37 - INFO - __main__ -   Batch number = 110
01/06/2022 00:41:37 - INFO - __main__ -   Batch number = 111
01/06/2022 00:41:37 - INFO - __main__ -   Batch number = 112
01/06/2022 00:41:37 - INFO - __main__ -   Batch number = 113
01/06/2022 00:41:37 - INFO - __main__ -   Batch number = 114
01/06/2022 00:41:37 - INFO - __main__ -   Batch number = 115
01/06/2022 00:41:38 - INFO - __main__ -   Batch number = 116
01/06/2022 00:41:38 - INFO - __main__ -   Batch number = 117
01/06/2022 00:41:38 - INFO - __main__ -   Batch number = 118
01/06/2022 00:41:38 - INFO - __main__ -   Batch number = 119
01/06/2022 00:41:38 - INFO - __main__ -   Batch number = 120
01/06/2022 00:41:38 - INFO - __main__ -   Batch number = 121
01/06/2022 00:41:38 - INFO - __main__ -   Batch number = 122
01/06/2022 00:41:38 - INFO - __main__ -   Batch number = 123
01/06/2022 00:41:39 - INFO - __main__ -   Batch number = 124
01/06/2022 00:41:39 - INFO - __main__ -   Batch number = 125
01/06/2022 00:41:40 - INFO - __main__ -   ***** Evaluation result 28000 in en *****
01/06/2022 00:41:40 - INFO - __main__ -     f1 = 0.945696475665308
01/06/2022 00:41:40 - INFO - __main__ -     loss = 0.4340004130601883
01/06/2022 00:41:40 - INFO - __main__ -     precision = 0.9454536116009519
01/06/2022 00:41:40 - INFO - __main__ -     recall = 0.9459394645334795
01/06/2022 00:41:40 - INFO - __main__ -   Hit patience=22
01/06/2022 00:47:36 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:47:36 - INFO - __main__ -   ***** Running evaluation 29000 in en *****
01/06/2022 00:47:36 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:47:36 - INFO - __main__ -     Batch size = 32
01/06/2022 00:47:36 - INFO - __main__ -   Batch number = 1
01/06/2022 00:47:36 - INFO - __main__ -   Batch number = 2
01/06/2022 00:47:36 - INFO - __main__ -   Batch number = 3
01/06/2022 00:47:37 - INFO - __main__ -   Batch number = 4
01/06/2022 00:47:37 - INFO - __main__ -   Batch number = 5
01/06/2022 00:47:37 - INFO - __main__ -   Batch number = 6
01/06/2022 00:47:37 - INFO - __main__ -   Batch number = 7
01/06/2022 00:47:37 - INFO - __main__ -   Batch number = 8
01/06/2022 00:47:37 - INFO - __main__ -   Batch number = 9
01/06/2022 00:47:37 - INFO - __main__ -   Batch number = 10
01/06/2022 00:47:37 - INFO - __main__ -   Batch number = 11
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 12
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 13
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 14
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 15
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 16
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 17
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 18
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 19
01/06/2022 00:47:38 - INFO - __main__ -   Batch number = 20
01/06/2022 00:47:39 - INFO - __main__ -   Batch number = 21
01/06/2022 00:47:39 - INFO - __main__ -   Batch number = 22
01/06/2022 00:47:39 - INFO - __main__ -   Batch number = 23
01/06/2022 00:47:39 - INFO - __main__ -   Batch number = 24
01/06/2022 00:47:39 - INFO - __main__ -   Batch number = 25
01/06/2022 00:47:39 - INFO - __main__ -   Batch number = 26
01/06/2022 00:47:39 - INFO - __main__ -   Batch number = 27
01/06/2022 00:47:39 - INFO - __main__ -   Batch number = 28
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 29
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 30
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 31
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 32
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 33
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 34
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 35
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 36
01/06/2022 00:47:40 - INFO - __main__ -   Batch number = 37
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 38
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 39
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 40
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 41
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 42
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 43
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 44
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 45
01/06/2022 00:47:41 - INFO - __main__ -   Batch number = 46
01/06/2022 00:47:42 - INFO - __main__ -   Batch number = 47
01/06/2022 00:47:42 - INFO - __main__ -   Batch number = 48
01/06/2022 00:47:42 - INFO - __main__ -   Batch number = 49
01/06/2022 00:47:42 - INFO - __main__ -   Batch number = 50
01/06/2022 00:47:42 - INFO - __main__ -   Batch number = 51
01/06/2022 00:47:42 - INFO - __main__ -   Batch number = 52
01/06/2022 00:47:42 - INFO - __main__ -   Batch number = 53
01/06/2022 00:47:42 - INFO - __main__ -   Batch number = 54
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 55
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 56
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 57
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 58
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 59
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 60
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 61
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 62
01/06/2022 00:47:43 - INFO - __main__ -   Batch number = 63
01/06/2022 00:47:44 - INFO - __main__ -   Batch number = 64
01/06/2022 00:47:44 - INFO - __main__ -   Batch number = 65
01/06/2022 00:47:44 - INFO - __main__ -   Batch number = 66
01/06/2022 00:47:44 - INFO - __main__ -   Batch number = 67
01/06/2022 00:47:44 - INFO - __main__ -   Batch number = 68
01/06/2022 00:47:44 - INFO - __main__ -   Batch number = 69
01/06/2022 00:47:44 - INFO - __main__ -   Batch number = 70
01/06/2022 00:47:44 - INFO - __main__ -   Batch number = 71
01/06/2022 00:47:45 - INFO - __main__ -   Batch number = 72
01/06/2022 00:47:45 - INFO - __main__ -   Batch number = 73
01/06/2022 00:47:45 - INFO - __main__ -   Batch number = 74
01/06/2022 00:47:45 - INFO - __main__ -   Batch number = 75
01/06/2022 00:47:45 - INFO - __main__ -   Batch number = 76
01/06/2022 00:47:45 - INFO - __main__ -   Batch number = 77
01/06/2022 00:47:45 - INFO - __main__ -   Batch number = 78
01/06/2022 00:47:45 - INFO - __main__ -   Batch number = 79
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 80
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 81
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 82
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 83
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 84
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 85
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 86
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 87
01/06/2022 00:47:46 - INFO - __main__ -   Batch number = 88
01/06/2022 00:47:47 - INFO - __main__ -   Batch number = 89
01/06/2022 00:47:47 - INFO - __main__ -   Batch number = 90
01/06/2022 00:47:47 - INFO - __main__ -   Batch number = 91
01/06/2022 00:47:47 - INFO - __main__ -   Batch number = 92
01/06/2022 00:47:47 - INFO - __main__ -   Batch number = 93
01/06/2022 00:47:47 - INFO - __main__ -   Batch number = 94
01/06/2022 00:47:47 - INFO - __main__ -   Batch number = 95
01/06/2022 00:47:47 - INFO - __main__ -   Batch number = 96
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 97
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 98
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 99
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 100
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 101
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 102
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 103
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 104
01/06/2022 00:47:48 - INFO - __main__ -   Batch number = 105
01/06/2022 00:47:49 - INFO - __main__ -   Batch number = 106
01/06/2022 00:47:49 - INFO - __main__ -   Batch number = 107
01/06/2022 00:47:49 - INFO - __main__ -   Batch number = 108
01/06/2022 00:47:49 - INFO - __main__ -   Batch number = 109
01/06/2022 00:47:49 - INFO - __main__ -   Batch number = 110
01/06/2022 00:47:49 - INFO - __main__ -   Batch number = 111
01/06/2022 00:47:49 - INFO - __main__ -   Batch number = 112
01/06/2022 00:47:49 - INFO - __main__ -   Batch number = 113
01/06/2022 00:47:50 - INFO - __main__ -   Batch number = 114
01/06/2022 00:47:50 - INFO - __main__ -   Batch number = 115
01/06/2022 00:47:50 - INFO - __main__ -   Batch number = 116
01/06/2022 00:47:50 - INFO - __main__ -   Batch number = 117
01/06/2022 00:47:50 - INFO - __main__ -   Batch number = 118
01/06/2022 00:47:50 - INFO - __main__ -   Batch number = 119
01/06/2022 00:47:50 - INFO - __main__ -   Batch number = 120
01/06/2022 00:47:50 - INFO - __main__ -   Batch number = 121
01/06/2022 00:47:51 - INFO - __main__ -   Batch number = 122
01/06/2022 00:47:51 - INFO - __main__ -   Batch number = 123
01/06/2022 00:47:51 - INFO - __main__ -   Batch number = 124
01/06/2022 00:47:51 - INFO - __main__ -   Batch number = 125
01/06/2022 00:47:52 - INFO - __main__ -   ***** Evaluation result 29000 in en *****
01/06/2022 00:47:52 - INFO - __main__ -     f1 = 0.945201959642331
01/06/2022 00:47:52 - INFO - __main__ -     loss = 0.4437008743584156
01/06/2022 00:47:52 - INFO - __main__ -     precision = 0.9452181509841204
01/06/2022 00:47:52 - INFO - __main__ -     recall = 0.9451857688552391
01/06/2022 00:47:52 - INFO - __main__ -   Hit patience=23
01/06/2022 00:53:48 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 00:53:48 - INFO - __main__ -   ***** Running evaluation 30000 in en *****
01/06/2022 00:53:48 - INFO - __main__ -     Num examples = 3974
01/06/2022 00:53:48 - INFO - __main__ -     Batch size = 32
01/06/2022 00:53:48 - INFO - __main__ -   Batch number = 1
01/06/2022 00:53:48 - INFO - __main__ -   Batch number = 2
01/06/2022 00:53:48 - INFO - __main__ -   Batch number = 3
01/06/2022 00:53:48 - INFO - __main__ -   Batch number = 4
01/06/2022 00:53:48 - INFO - __main__ -   Batch number = 5
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 6
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 7
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 8
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 9
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 10
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 11
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 12
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 13
01/06/2022 00:53:49 - INFO - __main__ -   Batch number = 14
01/06/2022 00:53:50 - INFO - __main__ -   Batch number = 15
01/06/2022 00:53:50 - INFO - __main__ -   Batch number = 16
01/06/2022 00:53:50 - INFO - __main__ -   Batch number = 17
01/06/2022 00:53:50 - INFO - __main__ -   Batch number = 18
01/06/2022 00:53:50 - INFO - __main__ -   Batch number = 19
01/06/2022 00:53:50 - INFO - __main__ -   Batch number = 20
01/06/2022 00:53:50 - INFO - __main__ -   Batch number = 21
01/06/2022 00:53:50 - INFO - __main__ -   Batch number = 22
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 23
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 24
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 25
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 26
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 27
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 28
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 29
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 30
01/06/2022 00:53:51 - INFO - __main__ -   Batch number = 31
01/06/2022 00:53:52 - INFO - __main__ -   Batch number = 32
01/06/2022 00:53:52 - INFO - __main__ -   Batch number = 33
01/06/2022 00:53:52 - INFO - __main__ -   Batch number = 34
01/06/2022 00:53:52 - INFO - __main__ -   Batch number = 35
01/06/2022 00:53:52 - INFO - __main__ -   Batch number = 36
01/06/2022 00:53:52 - INFO - __main__ -   Batch number = 37
01/06/2022 00:53:52 - INFO - __main__ -   Batch number = 38
01/06/2022 00:53:52 - INFO - __main__ -   Batch number = 39
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 40
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 41
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 42
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 43
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 44
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 45
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 46
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 47
01/06/2022 00:53:53 - INFO - __main__ -   Batch number = 48
01/06/2022 00:53:54 - INFO - __main__ -   Batch number = 49
01/06/2022 00:53:54 - INFO - __main__ -   Batch number = 50
01/06/2022 00:53:54 - INFO - __main__ -   Batch number = 51
01/06/2022 00:53:54 - INFO - __main__ -   Batch number = 52
01/06/2022 00:53:54 - INFO - __main__ -   Batch number = 53
01/06/2022 00:53:54 - INFO - __main__ -   Batch number = 54
01/06/2022 00:53:54 - INFO - __main__ -   Batch number = 55
01/06/2022 00:53:54 - INFO - __main__ -   Batch number = 56
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 57
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 58
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 59
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 60
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 61
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 62
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 63
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 64
01/06/2022 00:53:55 - INFO - __main__ -   Batch number = 65
01/06/2022 00:53:56 - INFO - __main__ -   Batch number = 66
01/06/2022 00:53:56 - INFO - __main__ -   Batch number = 67
01/06/2022 00:53:56 - INFO - __main__ -   Batch number = 68
01/06/2022 00:53:56 - INFO - __main__ -   Batch number = 69
01/06/2022 00:53:56 - INFO - __main__ -   Batch number = 70
01/06/2022 00:53:56 - INFO - __main__ -   Batch number = 71
01/06/2022 00:53:56 - INFO - __main__ -   Batch number = 72
01/06/2022 00:53:56 - INFO - __main__ -   Batch number = 73
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 74
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 75
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 76
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 77
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 78
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 79
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 80
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 81
01/06/2022 00:53:57 - INFO - __main__ -   Batch number = 82
01/06/2022 00:53:58 - INFO - __main__ -   Batch number = 83
01/06/2022 00:53:58 - INFO - __main__ -   Batch number = 84
01/06/2022 00:53:58 - INFO - __main__ -   Batch number = 85
01/06/2022 00:53:58 - INFO - __main__ -   Batch number = 86
01/06/2022 00:53:58 - INFO - __main__ -   Batch number = 87
01/06/2022 00:53:58 - INFO - __main__ -   Batch number = 88
01/06/2022 00:53:58 - INFO - __main__ -   Batch number = 89
01/06/2022 00:53:58 - INFO - __main__ -   Batch number = 90
01/06/2022 00:53:59 - INFO - __main__ -   Batch number = 91
01/06/2022 00:53:59 - INFO - __main__ -   Batch number = 92
01/06/2022 00:53:59 - INFO - __main__ -   Batch number = 93
01/06/2022 00:53:59 - INFO - __main__ -   Batch number = 94
01/06/2022 00:53:59 - INFO - __main__ -   Batch number = 95
01/06/2022 00:53:59 - INFO - __main__ -   Batch number = 96
01/06/2022 00:53:59 - INFO - __main__ -   Batch number = 97
01/06/2022 00:53:59 - INFO - __main__ -   Batch number = 98
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 99
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 100
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 101
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 102
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 103
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 104
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 105
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 106
01/06/2022 00:54:00 - INFO - __main__ -   Batch number = 107
01/06/2022 00:54:01 - INFO - __main__ -   Batch number = 108
01/06/2022 00:54:01 - INFO - __main__ -   Batch number = 109
01/06/2022 00:54:01 - INFO - __main__ -   Batch number = 110
01/06/2022 00:54:01 - INFO - __main__ -   Batch number = 111
01/06/2022 00:54:01 - INFO - __main__ -   Batch number = 112
01/06/2022 00:54:01 - INFO - __main__ -   Batch number = 113
01/06/2022 00:54:01 - INFO - __main__ -   Batch number = 114
01/06/2022 00:54:01 - INFO - __main__ -   Batch number = 115
01/06/2022 00:54:02 - INFO - __main__ -   Batch number = 116
01/06/2022 00:54:02 - INFO - __main__ -   Batch number = 117
01/06/2022 00:54:02 - INFO - __main__ -   Batch number = 118
01/06/2022 00:54:02 - INFO - __main__ -   Batch number = 119
01/06/2022 00:54:02 - INFO - __main__ -   Batch number = 120
01/06/2022 00:54:02 - INFO - __main__ -   Batch number = 121
01/06/2022 00:54:02 - INFO - __main__ -   Batch number = 122
01/06/2022 00:54:02 - INFO - __main__ -   Batch number = 123
01/06/2022 00:54:03 - INFO - __main__ -   Batch number = 124
01/06/2022 00:54:03 - INFO - __main__ -   Batch number = 125
01/06/2022 00:54:04 - INFO - __main__ -   ***** Evaluation result 30000 in en *****
01/06/2022 00:54:04 - INFO - __main__ -     f1 = 0.9449911358906504
01/06/2022 00:54:04 - INFO - __main__ -     loss = 0.4448958461284637
01/06/2022 00:54:04 - INFO - __main__ -     precision = 0.9449506714168265
01/06/2022 00:54:04 - INFO - __main__ -     recall = 0.9450316038301444
01/06/2022 00:54:04 - INFO - __main__ -   Hit patience=24
01/06/2022 01:00:02 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 01:00:02 - INFO - __main__ -   ***** Running evaluation 31000 in en *****
01/06/2022 01:00:02 - INFO - __main__ -     Num examples = 3974
01/06/2022 01:00:02 - INFO - __main__ -     Batch size = 32
01/06/2022 01:00:02 - INFO - __main__ -   Batch number = 1
01/06/2022 01:00:02 - INFO - __main__ -   Batch number = 2
01/06/2022 01:00:02 - INFO - __main__ -   Batch number = 3
01/06/2022 01:00:02 - INFO - __main__ -   Batch number = 4
01/06/2022 01:00:02 - INFO - __main__ -   Batch number = 5
01/06/2022 01:00:02 - INFO - __main__ -   Batch number = 6
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 7
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 8
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 9
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 10
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 11
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 12
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 13
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 14
01/06/2022 01:00:03 - INFO - __main__ -   Batch number = 15
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 16
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 17
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 18
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 19
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 20
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 21
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 22
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 23
01/06/2022 01:00:04 - INFO - __main__ -   Batch number = 24
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 25
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 26
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 27
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 28
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 29
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 30
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 31
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 32
01/06/2022 01:00:05 - INFO - __main__ -   Batch number = 33
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 34
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 35
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 36
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 37
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 38
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 39
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 40
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 41
01/06/2022 01:00:06 - INFO - __main__ -   Batch number = 42
01/06/2022 01:00:07 - INFO - __main__ -   Batch number = 43
01/06/2022 01:00:07 - INFO - __main__ -   Batch number = 44
01/06/2022 01:00:07 - INFO - __main__ -   Batch number = 45
01/06/2022 01:00:07 - INFO - __main__ -   Batch number = 46
01/06/2022 01:00:07 - INFO - __main__ -   Batch number = 47
01/06/2022 01:00:07 - INFO - __main__ -   Batch number = 48
01/06/2022 01:00:07 - INFO - __main__ -   Batch number = 49
01/06/2022 01:00:07 - INFO - __main__ -   Batch number = 50
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 51
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 52
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 53
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 54
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 55
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 56
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 57
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 58
01/06/2022 01:00:08 - INFO - __main__ -   Batch number = 59
01/06/2022 01:00:09 - INFO - __main__ -   Batch number = 60
01/06/2022 01:00:09 - INFO - __main__ -   Batch number = 61
01/06/2022 01:00:09 - INFO - __main__ -   Batch number = 62
01/06/2022 01:00:09 - INFO - __main__ -   Batch number = 63
01/06/2022 01:00:09 - INFO - __main__ -   Batch number = 64
01/06/2022 01:00:09 - INFO - __main__ -   Batch number = 65
01/06/2022 01:00:09 - INFO - __main__ -   Batch number = 66
01/06/2022 01:00:09 - INFO - __main__ -   Batch number = 67
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 68
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 69
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 70
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 71
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 72
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 73
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 74
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 75
01/06/2022 01:00:10 - INFO - __main__ -   Batch number = 76
01/06/2022 01:00:11 - INFO - __main__ -   Batch number = 77
01/06/2022 01:00:11 - INFO - __main__ -   Batch number = 78
01/06/2022 01:00:11 - INFO - __main__ -   Batch number = 79
01/06/2022 01:00:11 - INFO - __main__ -   Batch number = 80
01/06/2022 01:00:11 - INFO - __main__ -   Batch number = 81
01/06/2022 01:00:11 - INFO - __main__ -   Batch number = 82
01/06/2022 01:00:11 - INFO - __main__ -   Batch number = 83
01/06/2022 01:00:11 - INFO - __main__ -   Batch number = 84
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 85
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 86
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 87
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 88
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 89
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 90
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 91
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 92
01/06/2022 01:00:12 - INFO - __main__ -   Batch number = 93
01/06/2022 01:00:13 - INFO - __main__ -   Batch number = 94
01/06/2022 01:00:13 - INFO - __main__ -   Batch number = 95
01/06/2022 01:00:13 - INFO - __main__ -   Batch number = 96
01/06/2022 01:00:13 - INFO - __main__ -   Batch number = 97
01/06/2022 01:00:13 - INFO - __main__ -   Batch number = 98
01/06/2022 01:00:13 - INFO - __main__ -   Batch number = 99
01/06/2022 01:00:13 - INFO - __main__ -   Batch number = 100
01/06/2022 01:00:13 - INFO - __main__ -   Batch number = 101
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 102
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 103
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 104
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 105
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 106
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 107
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 108
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 109
01/06/2022 01:00:14 - INFO - __main__ -   Batch number = 110
01/06/2022 01:00:15 - INFO - __main__ -   Batch number = 111
01/06/2022 01:00:15 - INFO - __main__ -   Batch number = 112
01/06/2022 01:00:15 - INFO - __main__ -   Batch number = 113
01/06/2022 01:00:15 - INFO - __main__ -   Batch number = 114
01/06/2022 01:00:15 - INFO - __main__ -   Batch number = 115
01/06/2022 01:00:15 - INFO - __main__ -   Batch number = 116
01/06/2022 01:00:15 - INFO - __main__ -   Batch number = 117
01/06/2022 01:00:15 - INFO - __main__ -   Batch number = 118
01/06/2022 01:00:16 - INFO - __main__ -   Batch number = 119
01/06/2022 01:00:16 - INFO - __main__ -   Batch number = 120
01/06/2022 01:00:16 - INFO - __main__ -   Batch number = 121
01/06/2022 01:00:16 - INFO - __main__ -   Batch number = 122
01/06/2022 01:00:16 - INFO - __main__ -   Batch number = 123
01/06/2022 01:00:16 - INFO - __main__ -   Batch number = 124
01/06/2022 01:00:16 - INFO - __main__ -   Batch number = 125
01/06/2022 01:00:18 - INFO - __main__ -   ***** Evaluation result 31000 in en *****
01/06/2022 01:00:18 - INFO - __main__ -     f1 = 0.9458515283842794
01/06/2022 01:00:18 - INFO - __main__ -     loss = 0.44842592322826386
01/06/2022 01:00:18 - INFO - __main__ -     precision = 0.9455924397801784
01/06/2022 01:00:18 - INFO - __main__ -     recall = 0.9461107590058069
01/06/2022 01:00:18 - INFO - __main__ -   Hit patience=25
01/06/2022 01:06:20 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 01:06:20 - INFO - __main__ -   ***** Running evaluation 32000 in en *****
01/06/2022 01:06:20 - INFO - __main__ -     Num examples = 3974
01/06/2022 01:06:20 - INFO - __main__ -     Batch size = 32
01/06/2022 01:06:20 - INFO - __main__ -   Batch number = 1
01/06/2022 01:06:20 - INFO - __main__ -   Batch number = 2
01/06/2022 01:06:20 - INFO - __main__ -   Batch number = 3
01/06/2022 01:06:21 - INFO - __main__ -   Batch number = 4
01/06/2022 01:06:21 - INFO - __main__ -   Batch number = 5
01/06/2022 01:06:21 - INFO - __main__ -   Batch number = 6
01/06/2022 01:06:21 - INFO - __main__ -   Batch number = 7
01/06/2022 01:06:21 - INFO - __main__ -   Batch number = 8
01/06/2022 01:06:21 - INFO - __main__ -   Batch number = 9
01/06/2022 01:06:21 - INFO - __main__ -   Batch number = 10
01/06/2022 01:06:21 - INFO - __main__ -   Batch number = 11
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 12
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 13
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 14
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 15
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 16
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 17
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 18
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 19
01/06/2022 01:06:22 - INFO - __main__ -   Batch number = 20
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 21
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 22
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 23
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 24
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 25
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 26
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 27
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 28
01/06/2022 01:06:23 - INFO - __main__ -   Batch number = 29
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 30
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 31
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 32
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 33
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 34
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 35
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 36
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 37
01/06/2022 01:06:24 - INFO - __main__ -   Batch number = 38
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 39
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 40
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 41
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 42
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 43
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 44
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 45
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 46
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 47
01/06/2022 01:06:25 - INFO - __main__ -   Batch number = 48
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 49
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 50
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 51
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 52
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 53
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 54
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 55
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 56
01/06/2022 01:06:26 - INFO - __main__ -   Batch number = 57
01/06/2022 01:06:27 - INFO - __main__ -   Batch number = 58
01/06/2022 01:06:27 - INFO - __main__ -   Batch number = 59
01/06/2022 01:06:27 - INFO - __main__ -   Batch number = 60
01/06/2022 01:06:27 - INFO - __main__ -   Batch number = 61
01/06/2022 01:06:27 - INFO - __main__ -   Batch number = 62
01/06/2022 01:06:27 - INFO - __main__ -   Batch number = 63
01/06/2022 01:06:27 - INFO - __main__ -   Batch number = 64
01/06/2022 01:06:27 - INFO - __main__ -   Batch number = 65
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 66
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 67
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 68
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 69
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 70
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 71
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 72
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 73
01/06/2022 01:06:28 - INFO - __main__ -   Batch number = 74
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 75
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 76
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 77
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 78
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 79
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 80
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 81
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 82
01/06/2022 01:06:29 - INFO - __main__ -   Batch number = 83
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 84
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 85
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 86
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 87
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 88
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 89
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 90
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 91
01/06/2022 01:06:30 - INFO - __main__ -   Batch number = 92
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 93
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 94
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 95
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 96
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 97
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 98
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 99
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 100
01/06/2022 01:06:31 - INFO - __main__ -   Batch number = 101
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 102
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 103
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 104
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 105
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 106
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 107
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 108
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 109
01/06/2022 01:06:32 - INFO - __main__ -   Batch number = 110
01/06/2022 01:06:33 - INFO - __main__ -   Batch number = 111
01/06/2022 01:06:33 - INFO - __main__ -   Batch number = 112
01/06/2022 01:06:33 - INFO - __main__ -   Batch number = 113
01/06/2022 01:06:33 - INFO - __main__ -   Batch number = 114
01/06/2022 01:06:33 - INFO - __main__ -   Batch number = 115
01/06/2022 01:06:33 - INFO - __main__ -   Batch number = 116
01/06/2022 01:06:33 - INFO - __main__ -   Batch number = 117
01/06/2022 01:06:33 - INFO - __main__ -   Batch number = 118
01/06/2022 01:06:34 - INFO - __main__ -   Batch number = 119
01/06/2022 01:06:34 - INFO - __main__ -   Batch number = 120
01/06/2022 01:06:34 - INFO - __main__ -   Batch number = 121
01/06/2022 01:06:34 - INFO - __main__ -   Batch number = 122
01/06/2022 01:06:34 - INFO - __main__ -   Batch number = 123
01/06/2022 01:06:34 - INFO - __main__ -   Batch number = 124
01/06/2022 01:06:34 - INFO - __main__ -   Batch number = 125
01/06/2022 01:06:36 - INFO - __main__ -   ***** Evaluation result 32000 in en *****
01/06/2022 01:06:36 - INFO - __main__ -     f1 = 0.9453754527783249
01/06/2022 01:06:36 - INFO - __main__ -     loss = 0.45200752359628676
01/06/2022 01:06:36 - INFO - __main__ -     precision = 0.9452054794520548
01/06/2022 01:06:36 - INFO - __main__ -     recall = 0.9455454872471265
01/06/2022 01:06:36 - INFO - __main__ -   Hit patience=26
01/06/2022 01:12:00 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 01:12:00 - INFO - __main__ -   ***** Running evaluation 33000 in en *****
01/06/2022 01:12:00 - INFO - __main__ -     Num examples = 3974
01/06/2022 01:12:00 - INFO - __main__ -     Batch size = 32
01/06/2022 01:12:00 - INFO - __main__ -   Batch number = 1
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 2
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 3
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 4
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 5
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 6
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 7
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 8
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 9
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 10
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 11
01/06/2022 01:12:01 - INFO - __main__ -   Batch number = 12
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 13
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 14
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 15
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 16
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 17
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 18
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 19
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 20
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 21
01/06/2022 01:12:02 - INFO - __main__ -   Batch number = 22
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 23
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 24
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 25
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 26
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 27
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 28
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 29
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 30
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 31
01/06/2022 01:12:03 - INFO - __main__ -   Batch number = 32
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 33
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 34
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 35
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 36
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 37
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 38
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 39
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 40
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 41
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 42
01/06/2022 01:12:04 - INFO - __main__ -   Batch number = 43
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 44
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 45
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 46
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 47
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 48
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 49
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 50
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 51
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 52
01/06/2022 01:12:05 - INFO - __main__ -   Batch number = 53
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 54
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 55
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 56
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 57
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 58
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 59
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 60
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 61
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 62
01/06/2022 01:12:06 - INFO - __main__ -   Batch number = 63
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 64
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 65
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 66
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 67
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 68
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 69
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 70
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 71
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 72
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 73
01/06/2022 01:12:07 - INFO - __main__ -   Batch number = 74
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 75
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 76
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 77
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 78
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 79
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 80
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 81
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 82
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 83
01/06/2022 01:12:08 - INFO - __main__ -   Batch number = 84
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 85
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 86
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 87
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 88
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 89
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 90
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 91
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 92
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 93
01/06/2022 01:12:09 - INFO - __main__ -   Batch number = 94
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 95
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 96
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 97
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 98
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 99
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 100
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 101
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 102
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 103
01/06/2022 01:12:10 - INFO - __main__ -   Batch number = 104
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 105
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 106
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 107
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 108
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 109
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 110
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 111
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 112
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 113
01/06/2022 01:12:11 - INFO - __main__ -   Batch number = 114
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 115
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 116
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 117
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 118
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 119
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 120
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 121
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 122
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 123
01/06/2022 01:12:12 - INFO - __main__ -   Batch number = 124
01/06/2022 01:12:13 - INFO - __main__ -   Batch number = 125
01/06/2022 01:12:14 - INFO - __main__ -   ***** Evaluation result 33000 in en *****
01/06/2022 01:12:14 - INFO - __main__ -     f1 = 0.945744799294297
01/06/2022 01:12:14 - INFO - __main__ -     loss = 0.45178947484493254
01/06/2022 01:12:14 - INFO - __main__ -     precision = 0.9457043025486435
01/06/2022 01:12:14 - INFO - __main__ -     recall = 0.9457852995083849
01/06/2022 01:12:14 - INFO - __main__ -   Hit patience=27
01/06/2022 01:17:02 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 01:17:02 - INFO - __main__ -   ***** Running evaluation 34000 in en *****
01/06/2022 01:17:02 - INFO - __main__ -     Num examples = 3974
01/06/2022 01:17:02 - INFO - __main__ -     Batch size = 32
01/06/2022 01:17:02 - INFO - __main__ -   Batch number = 1
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 2
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 3
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 4
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 5
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 6
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 7
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 8
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 9
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 10
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 11
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 12
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 13
01/06/2022 01:17:03 - INFO - __main__ -   Batch number = 14
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 15
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 16
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 17
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 18
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 19
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 20
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 21
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 22
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 23
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 24
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 25
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 26
01/06/2022 01:17:04 - INFO - __main__ -   Batch number = 27
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 28
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 29
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 30
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 31
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 32
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 33
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 34
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 35
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 36
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 37
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 38
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 39
01/06/2022 01:17:05 - INFO - __main__ -   Batch number = 40
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 41
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 42
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 43
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 44
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 45
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 46
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 47
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 48
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 49
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 50
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 51
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 52
01/06/2022 01:17:06 - INFO - __main__ -   Batch number = 53
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 54
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 55
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 56
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 57
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 58
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 59
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 60
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 61
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 62
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 63
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 64
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 65
01/06/2022 01:17:07 - INFO - __main__ -   Batch number = 66
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 67
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 68
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 69
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 70
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 71
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 72
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 73
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 74
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 75
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 76
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 77
01/06/2022 01:17:08 - INFO - __main__ -   Batch number = 78
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 79
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 80
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 81
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 82
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 83
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 84
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 85
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 86
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 87
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 88
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 89
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 90
01/06/2022 01:17:09 - INFO - __main__ -   Batch number = 91
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 92
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 93
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 94
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 95
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 96
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 97
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 98
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 99
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 100
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 101
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 102
01/06/2022 01:17:10 - INFO - __main__ -   Batch number = 103
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 104
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 105
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 106
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 107
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 108
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 109
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 110
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 111
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 112
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 113
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 114
01/06/2022 01:17:11 - INFO - __main__ -   Batch number = 115
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 116
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 117
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 118
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 119
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 120
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 121
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 122
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 123
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 124
01/06/2022 01:17:12 - INFO - __main__ -   Batch number = 125
01/06/2022 01:17:13 - INFO - __main__ -   ***** Evaluation result 34000 in en *****
01/06/2022 01:17:13 - INFO - __main__ -     f1 = 0.9457818427836154
01/06/2022 01:17:13 - INFO - __main__ -     loss = 0.4513774753510952
01/06/2022 01:17:13 - INFO - __main__ -     precision = 0.9456927556088371
01/06/2022 01:17:13 - INFO - __main__ -     recall = 0.9458709467445485
01/06/2022 01:17:13 - INFO - __main__ -   Hit patience=28
01/06/2022 01:17:25 - INFO - __main__ -    global_step = 34050, average loss = 0.03361088512743413
01/06/2022 01:17:25 - INFO - __main__ -   Saving model checkpoint to /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/
01/06/2022 01:17:25 - INFO - root -   Save adapter
01/06/2022 01:17:25 - INFO - __main__ -   Loading pretrained model and tokenizer
01/06/2022 01:17:28 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/06/2022 01:17:33 - INFO - __main__ -   Using lang2id = None
01/06/2022 01:17:33 - INFO - __main__ -   Evaluating the model on dev set of training language(en)
01/06/2022 01:17:33 - INFO - __main__ -   Task Adapter will be loaded from this path /root/Desktop/cloud-emea-copy/output//udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_task_s2/checkpoint-best/udpos
01/06/2022 01:17:33 - INFO - root -   Trying to decide if add adapter
01/06/2022 01:17:33 - INFO - root -   loading task adapter
01/06/2022 01:17:34 - INFO - __main__ -   Loading features from cached file /root/Desktop/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_en_bert-base-multilingual-cased_128
01/06/2022 01:17:34 - INFO - __main__ -   ***** Running evaluation debugging in en *****
01/06/2022 01:17:34 - INFO - __main__ -     Num examples = 3974
01/06/2022 01:17:34 - INFO - __main__ -     Batch size = 32
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 1
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 2
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 3
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 4
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 5
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 6
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 7
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 8
01/06/2022 01:17:34 - INFO - __main__ -   Batch number = 9
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 10
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 11
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 12
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 13
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 14
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 15
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 16
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 17
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 18
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 19
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 20
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 21
01/06/2022 01:17:35 - INFO - __main__ -   Batch number = 22
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 23
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 24
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 25
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 26
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 27
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 28
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 29
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 30
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 31
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 32
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 33
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 34
01/06/2022 01:17:36 - INFO - __main__ -   Batch number = 35
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 36
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 37
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 38
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 39
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 40
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 41
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 42
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 43
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 44
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 45
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 46
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 47
01/06/2022 01:17:37 - INFO - __main__ -   Batch number = 48
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 49
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 50
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 51
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 52
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 53
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 54
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 55
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 56
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 57
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 58
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 59
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 60
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 61
01/06/2022 01:17:38 - INFO - __main__ -   Batch number = 62
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 63
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 64
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 65
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 66
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 67
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 68
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 69
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 70
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 71
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 72
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 73
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 74
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 75
01/06/2022 01:17:39 - INFO - __main__ -   Batch number = 76
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 77
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 78
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 79
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 80
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 81
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 82
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 83
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 84
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 85
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 86
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 87
01/06/2022 01:17:40 - INFO - __main__ -   Batch number = 88
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 89
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 90
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 91
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 92
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 93
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 94
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 95
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 96
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 97
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 98
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 99
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 100
01/06/2022 01:17:41 - INFO - __main__ -   Batch number = 101
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 102
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 103
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 104
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 105
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 106
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 107
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 108
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 109
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 110
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 111
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 112
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 113
01/06/2022 01:17:42 - INFO - __main__ -   Batch number = 114
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 115
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 116
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 117
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 118
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 119
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 120
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 121
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 122
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 123
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 124
01/06/2022 01:17:43 - INFO - __main__ -   Batch number = 125
01/06/2022 01:17:45 - INFO - __main__ -   ***** Evaluation result debugging in en *****
01/06/2022 01:17:45 - INFO - __main__ -     f1 = 0.9493291293246741
01/06/2022 01:17:45 - INFO - __main__ -     loss = 0.14065848419070243
01/06/2022 01:17:45 - INFO - __main__ -     precision = 0.949687151795663
01/06/2022 01:17:45 - INFO - __main__ -     recall = 0.948971376693674
