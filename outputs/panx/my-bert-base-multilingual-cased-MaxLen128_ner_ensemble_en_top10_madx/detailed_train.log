PyTorch version 1.10.1+cu102 available.
01/14/2022 16:04:00 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ja', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:04:00 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:04:00 - INFO - __main__ -   Seed = 1
01/14/2022 16:04:00 - INFO - root -   save model
01/14/2022 16:04:00 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ja', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:04:00 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:04:03 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:04:08 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:04:08 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:04:08 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:04:08 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:04:08 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:04:08 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,ja/wiki@ukp
01/14/2022 16:04:08 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'ja'], Length : 10
01/14/2022 16:04:08 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'ja/wiki@ukp'], Length : 10
01/14/2022 16:04:08 - INFO - __main__ -   Language = en
01/14/2022 16:04:08 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:04:09 - INFO - __main__ -   Language = pt
01/14/2022 16:04:09 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:04:11 - INFO - __main__ -   Language = id
01/14/2022 16:04:11 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:04:13 - INFO - __main__ -   Language = cs
01/14/2022 16:04:13 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:04:16 - INFO - __main__ -   Language = tr
01/14/2022 16:04:16 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:04:18 - INFO - __main__ -   Language = eu
01/14/2022 16:04:18 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:04:20 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:04:20 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:04:22 - INFO - __main__ -   Language = vi
01/14/2022 16:04:22 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:04:25 - INFO - __main__ -   Language = fr
01/14/2022 16:04:25 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:04:27 - INFO - __main__ -   Language = ja
01/14/2022 16:04:27 - INFO - __main__ -   Adapter Name = ja/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ja/bert-base-multilingual-cased/pfeiffer/ja_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted/adapter_config.json
Adding adapter 'ja' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted'
01/14/2022 16:04:32 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:04:32 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'ja']
01/14/2022 16:04:32 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:04:32 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:04:32 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:04:32 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ja_bert-base-multilingual-cased_128
01/14/2022 16:04:33 - INFO - __main__ -   ***** Running evaluation  in ja *****
01/14/2022 16:04:33 - INFO - __main__ -     Num examples = 10612
01/14/2022 16:04:33 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/332 [00:00<?, ?it/s]01/14/2022 16:04:33 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/332 [00:00<01:36,  3.43it/s]01/14/2022 16:04:33 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/332 [00:00<01:33,  3.52it/s]01/14/2022 16:04:33 - INFO - __main__ -   Batch number = 3
Evaluating:   1%|          | 3/332 [00:00<01:32,  3.55it/s]01/14/2022 16:04:34 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/332 [00:01<01:31,  3.57it/s]01/14/2022 16:04:34 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/332 [00:01<01:31,  3.58it/s]01/14/2022 16:04:34 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/332 [00:01<01:30,  3.59it/s]01/14/2022 16:04:35 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/332 [00:02<01:38,  3.30it/s]01/14/2022 16:04:35 - INFO - __main__ -   Batch number = 8
Evaluating:   2%|▏         | 8/332 [00:02<01:35,  3.38it/s]01/14/2022 16:04:35 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/332 [00:02<01:33,  3.44it/s]01/14/2022 16:04:35 - INFO - __main__ -   Batch number = 10
Evaluating:   3%|▎         | 10/332 [00:02<01:32,  3.49it/s]01/14/2022 16:04:36 - INFO - __main__ -   Batch number = 11
Evaluating:   3%|▎         | 11/332 [00:03<01:31,  3.52it/s]01/14/2022 16:04:36 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▎         | 12/332 [00:03<01:30,  3.53it/s]01/14/2022 16:04:36 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/332 [00:03<01:30,  3.54it/s]01/14/2022 16:04:37 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/332 [00:03<01:29,  3.55it/s]01/14/2022 16:04:37 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/332 [00:04<01:29,  3.55it/s]01/14/2022 16:04:37 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▍         | 16/332 [00:04<01:28,  3.56it/s]01/14/2022 16:04:37 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/332 [00:04<01:28,  3.56it/s]01/14/2022 16:04:38 - INFO - __main__ -   Batch number = 18
Evaluating:   5%|▌         | 18/332 [00:05<01:28,  3.56it/s]01/14/2022 16:04:38 - INFO - __main__ -   Batch number = 19
Evaluating:   6%|▌         | 19/332 [00:05<01:27,  3.57it/s]01/14/2022 16:04:38 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▌         | 20/332 [00:05<01:27,  3.57it/s]01/14/2022 16:04:38 - INFO - __main__ -   Batch number = 21
Evaluating:   6%|▋         | 21/332 [00:05<01:27,  3.57it/s]01/14/2022 16:04:39 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/332 [00:06<01:26,  3.56it/s]01/14/2022 16:04:39 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/332 [00:06<01:26,  3.56it/s]01/14/2022 16:04:39 - INFO - __main__ -   Batch number = 24
Evaluating:   7%|▋         | 24/332 [00:06<01:26,  3.56it/s]01/14/2022 16:04:40 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/332 [00:07<01:26,  3.55it/s]01/14/2022 16:04:40 - INFO - __main__ -   Batch number = 26
Evaluating:   8%|▊         | 26/332 [00:07<01:25,  3.56it/s]01/14/2022 16:04:40 - INFO - __main__ -   Batch number = 27
Evaluating:   8%|▊         | 27/332 [00:07<01:25,  3.56it/s]01/14/2022 16:04:40 - INFO - __main__ -   Batch number = 28
Evaluating:   8%|▊         | 28/332 [00:07<01:25,  3.55it/s]01/14/2022 16:04:41 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▊         | 29/332 [00:08<01:25,  3.55it/s]01/14/2022 16:04:41 - INFO - __main__ -   Batch number = 30
Evaluating:   9%|▉         | 30/332 [00:08<01:25,  3.55it/s]01/14/2022 16:04:41 - INFO - __main__ -   Batch number = 31
Evaluating:   9%|▉         | 31/332 [00:08<01:24,  3.56it/s]01/14/2022 16:04:42 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|▉         | 32/332 [00:09<01:24,  3.56it/s]01/14/2022 16:04:42 - INFO - __main__ -   Batch number = 33
Evaluating:  10%|▉         | 33/332 [00:09<01:23,  3.56it/s]01/14/2022 16:04:42 - INFO - __main__ -   Batch number = 34
Evaluating:  10%|█         | 34/332 [00:09<01:23,  3.55it/s]01/14/2022 16:04:42 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/332 [00:09<01:23,  3.55it/s]01/14/2022 16:04:43 - INFO - __main__ -   Batch number = 36
Evaluating:  11%|█         | 36/332 [00:10<01:23,  3.54it/s]01/14/2022 16:04:43 - INFO - __main__ -   Batch number = 37
Evaluating:  11%|█         | 37/332 [00:10<01:23,  3.52it/s]01/14/2022 16:04:43 - INFO - __main__ -   Batch number = 38
Evaluating:  11%|█▏        | 38/332 [00:10<01:23,  3.53it/s]01/14/2022 16:04:44 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/332 [00:11<01:23,  3.53it/s]01/14/2022 16:04:44 - INFO - __main__ -   Batch number = 40
Evaluating:  12%|█▏        | 40/332 [00:11<01:22,  3.52it/s]01/14/2022 16:04:44 - INFO - __main__ -   Batch number = 41
Evaluating:  12%|█▏        | 41/332 [00:11<01:22,  3.52it/s]01/14/2022 16:04:44 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/332 [00:11<01:22,  3.53it/s]01/14/2022 16:04:45 - INFO - __main__ -   Batch number = 43
Evaluating:  13%|█▎        | 43/332 [00:12<01:21,  3.54it/s]01/14/2022 16:04:45 - INFO - __main__ -   Batch number = 44
Evaluating:  13%|█▎        | 44/332 [00:12<01:21,  3.52it/s]01/14/2022 16:04:45 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▎        | 45/332 [00:12<01:21,  3.52it/s]01/14/2022 16:04:46 - INFO - __main__ -   Batch number = 46
Evaluating:  14%|█▍        | 46/332 [00:13<01:21,  3.53it/s]01/14/2022 16:04:46 - INFO - __main__ -   Batch number = 47
Evaluating:  14%|█▍        | 47/332 [00:13<01:20,  3.53it/s]01/14/2022 16:04:46 - INFO - __main__ -   Batch number = 48
Evaluating:  14%|█▍        | 48/332 [00:13<01:20,  3.53it/s]01/14/2022 16:04:46 - INFO - __main__ -   Batch number = 49
Evaluating:  15%|█▍        | 49/332 [00:13<01:20,  3.53it/s]01/14/2022 16:04:47 - INFO - __main__ -   Batch number = 50
Evaluating:  15%|█▌        | 50/332 [00:14<01:20,  3.52it/s]01/14/2022 16:04:47 - INFO - __main__ -   Batch number = 51
Evaluating:  15%|█▌        | 51/332 [00:14<01:20,  3.51it/s]01/14/2022 16:04:47 - INFO - __main__ -   Batch number = 52
Evaluating:  16%|█▌        | 52/332 [00:14<01:19,  3.52it/s]01/14/2022 16:04:48 - INFO - __main__ -   Batch number = 53
Evaluating:  16%|█▌        | 53/332 [00:15<01:19,  3.52it/s]01/14/2022 16:04:48 - INFO - __main__ -   Batch number = 54
Evaluating:  16%|█▋        | 54/332 [00:15<01:18,  3.53it/s]01/14/2022 16:04:48 - INFO - __main__ -   Batch number = 55
Evaluating:  17%|█▋        | 55/332 [00:15<01:18,  3.53it/s]01/14/2022 16:04:48 - INFO - __main__ -   Batch number = 56
Evaluating:  17%|█▋        | 56/332 [00:15<01:18,  3.53it/s]01/14/2022 16:04:49 - INFO - __main__ -   Batch number = 57
Evaluating:  17%|█▋        | 57/332 [00:16<01:17,  3.53it/s]01/14/2022 16:04:49 - INFO - __main__ -   Batch number = 58
Evaluating:  17%|█▋        | 58/332 [00:16<01:17,  3.53it/s]01/14/2022 16:04:49 - INFO - __main__ -   Batch number = 59
Evaluating:  18%|█▊        | 59/332 [00:16<01:17,  3.53it/s]01/14/2022 16:04:50 - INFO - __main__ -   Batch number = 60
Evaluating:  18%|█▊        | 60/332 [00:17<01:22,  3.32it/s]01/14/2022 16:04:50 - INFO - __main__ -   Batch number = 61
Evaluating:  18%|█▊        | 61/332 [00:17<01:20,  3.36it/s]01/14/2022 16:04:50 - INFO - __main__ -   Batch number = 62
Evaluating:  19%|█▊        | 62/332 [00:17<01:19,  3.41it/s]01/14/2022 16:04:50 - INFO - __main__ -   Batch number = 63
Evaluating:  19%|█▉        | 63/332 [00:17<01:18,  3.44it/s]01/14/2022 16:04:51 - INFO - __main__ -   Batch number = 64
Evaluating:  19%|█▉        | 64/332 [00:18<01:17,  3.47it/s]01/14/2022 16:04:51 - INFO - __main__ -   Batch number = 65
Evaluating:  20%|█▉        | 65/332 [00:18<01:16,  3.49it/s]01/14/2022 16:04:51 - INFO - __main__ -   Batch number = 66
Evaluating:  20%|█▉        | 66/332 [00:18<01:16,  3.49it/s]01/14/2022 16:04:52 - INFO - __main__ -   Batch number = 67
Evaluating:  20%|██        | 67/332 [00:19<01:15,  3.50it/s]01/14/2022 16:04:52 - INFO - __main__ -   Batch number = 68
Evaluating:  20%|██        | 68/332 [00:19<01:15,  3.50it/s]01/14/2022 16:04:52 - INFO - __main__ -   Batch number = 69
Evaluating:  21%|██        | 69/332 [00:19<01:15,  3.51it/s]01/14/2022 16:04:52 - INFO - __main__ -   Batch number = 70
Evaluating:  21%|██        | 70/332 [00:19<01:14,  3.50it/s]01/14/2022 16:04:53 - INFO - __main__ -   Batch number = 71
Evaluating:  21%|██▏       | 71/332 [00:20<01:14,  3.50it/s]01/14/2022 16:04:53 - INFO - __main__ -   Batch number = 72
Evaluating:  22%|██▏       | 72/332 [00:20<01:14,  3.51it/s]01/14/2022 16:04:53 - INFO - __main__ -   Batch number = 73
Evaluating:  22%|██▏       | 73/332 [00:20<01:13,  3.50it/s]01/14/2022 16:04:54 - INFO - __main__ -   Batch number = 74
Evaluating:  22%|██▏       | 74/332 [00:21<01:13,  3.50it/s]01/14/2022 16:04:54 - INFO - __main__ -   Batch number = 75
Evaluating:  23%|██▎       | 75/332 [00:21<01:13,  3.51it/s]01/14/2022 16:04:54 - INFO - __main__ -   Batch number = 76
Evaluating:  23%|██▎       | 76/332 [00:21<01:12,  3.52it/s]01/14/2022 16:04:54 - INFO - __main__ -   Batch number = 77
Evaluating:  23%|██▎       | 77/332 [00:21<01:12,  3.52it/s]01/14/2022 16:04:55 - INFO - __main__ -   Batch number = 78
Evaluating:  23%|██▎       | 78/332 [00:22<01:12,  3.52it/s]01/14/2022 16:04:55 - INFO - __main__ -   Batch number = 79
Evaluating:  24%|██▍       | 79/332 [00:22<01:11,  3.52it/s]01/14/2022 16:04:55 - INFO - __main__ -   Batch number = 80
Evaluating:  24%|██▍       | 80/332 [00:22<01:11,  3.51it/s]01/14/2022 16:04:56 - INFO - __main__ -   Batch number = 81
Evaluating:  24%|██▍       | 81/332 [00:23<01:11,  3.51it/s]01/14/2022 16:04:56 - INFO - __main__ -   Batch number = 82
Evaluating:  25%|██▍       | 82/332 [00:23<01:11,  3.49it/s]01/14/2022 16:04:56 - INFO - __main__ -   Batch number = 83
Evaluating:  25%|██▌       | 83/332 [00:23<01:11,  3.48it/s]01/14/2022 16:04:56 - INFO - __main__ -   Batch number = 84
Evaluating:  25%|██▌       | 84/332 [00:23<01:11,  3.49it/s]01/14/2022 16:04:57 - INFO - __main__ -   Batch number = 85
Evaluating:  26%|██▌       | 85/332 [00:24<01:10,  3.49it/s]01/14/2022 16:04:57 - INFO - __main__ -   Batch number = 86
Evaluating:  26%|██▌       | 86/332 [00:24<01:10,  3.49it/s]01/14/2022 16:04:57 - INFO - __main__ -   Batch number = 87
Evaluating:  26%|██▌       | 87/332 [00:24<01:10,  3.50it/s]01/14/2022 16:04:58 - INFO - __main__ -   Batch number = 88
Evaluating:  27%|██▋       | 88/332 [00:25<01:09,  3.50it/s]01/14/2022 16:04:58 - INFO - __main__ -   Batch number = 89
Evaluating:  27%|██▋       | 89/332 [00:25<01:09,  3.50it/s]01/14/2022 16:04:58 - INFO - __main__ -   Batch number = 90
Evaluating:  27%|██▋       | 90/332 [00:25<01:09,  3.50it/s]01/14/2022 16:04:58 - INFO - __main__ -   Batch number = 91
Evaluating:  27%|██▋       | 91/332 [00:25<01:08,  3.50it/s]01/14/2022 16:04:59 - INFO - __main__ -   Batch number = 92
Evaluating:  28%|██▊       | 92/332 [00:26<01:08,  3.50it/s]01/14/2022 16:04:59 - INFO - __main__ -   Batch number = 93
Evaluating:  28%|██▊       | 93/332 [00:26<01:08,  3.50it/s]01/14/2022 16:04:59 - INFO - __main__ -   Batch number = 94
Evaluating:  28%|██▊       | 94/332 [00:26<01:08,  3.50it/s]01/14/2022 16:05:00 - INFO - __main__ -   Batch number = 95
Evaluating:  29%|██▊       | 95/332 [00:27<01:09,  3.42it/s]01/14/2022 16:05:00 - INFO - __main__ -   Batch number = 96
Evaluating:  29%|██▉       | 96/332 [00:27<01:08,  3.45it/s]01/14/2022 16:05:00 - INFO - __main__ -   Batch number = 97
Evaluating:  29%|██▉       | 97/332 [00:27<01:07,  3.46it/s]01/14/2022 16:05:00 - INFO - __main__ -   Batch number = 98
Evaluating:  30%|██▉       | 98/332 [00:27<01:07,  3.47it/s]01/14/2022 16:05:01 - INFO - __main__ -   Batch number = 99
Evaluating:  30%|██▉       | 99/332 [00:28<01:06,  3.48it/s]01/14/2022 16:05:01 - INFO - __main__ -   Batch number = 100
Evaluating:  30%|███       | 100/332 [00:28<01:06,  3.47it/s]01/14/2022 16:05:01 - INFO - __main__ -   Batch number = 101
Evaluating:  30%|███       | 101/332 [00:28<01:06,  3.48it/s]01/14/2022 16:05:02 - INFO - __main__ -   Batch number = 102
Evaluating:  31%|███       | 102/332 [00:29<01:06,  3.48it/s]01/14/2022 16:05:02 - INFO - __main__ -   Batch number = 103
Evaluating:  31%|███       | 103/332 [00:29<01:06,  3.46it/s]01/14/2022 16:05:02 - INFO - __main__ -   Batch number = 104
Evaluating:  31%|███▏      | 104/332 [00:29<01:06,  3.45it/s]01/14/2022 16:05:02 - INFO - __main__ -   Batch number = 105
Evaluating:  32%|███▏      | 105/332 [00:29<01:05,  3.45it/s]01/14/2022 16:05:03 - INFO - __main__ -   Batch number = 106
Evaluating:  32%|███▏      | 106/332 [00:30<01:05,  3.46it/s]01/14/2022 16:05:03 - INFO - __main__ -   Batch number = 107
Evaluating:  32%|███▏      | 107/332 [00:30<01:04,  3.47it/s]01/14/2022 16:05:03 - INFO - __main__ -   Batch number = 108
Evaluating:  33%|███▎      | 108/332 [00:30<01:04,  3.48it/s]01/14/2022 16:05:04 - INFO - __main__ -   Batch number = 109
Evaluating:  33%|███▎      | 109/332 [00:31<01:04,  3.48it/s]01/14/2022 16:05:04 - INFO - __main__ -   Batch number = 110
Evaluating:  33%|███▎      | 110/332 [00:31<01:03,  3.48it/s]01/14/2022 16:05:04 - INFO - __main__ -   Batch number = 111
Evaluating:  33%|███▎      | 111/332 [00:31<01:03,  3.49it/s]01/14/2022 16:05:04 - INFO - __main__ -   Batch number = 112
Evaluating:  34%|███▎      | 112/332 [00:31<01:02,  3.49it/s]01/14/2022 16:05:05 - INFO - __main__ -   Batch number = 113
Evaluating:  34%|███▍      | 113/332 [00:32<01:02,  3.49it/s]01/14/2022 16:05:05 - INFO - __main__ -   Batch number = 114
Evaluating:  34%|███▍      | 114/332 [00:32<01:02,  3.49it/s]01/14/2022 16:05:05 - INFO - __main__ -   Batch number = 115
Evaluating:  35%|███▍      | 115/332 [00:32<01:02,  3.49it/s]01/14/2022 16:05:06 - INFO - __main__ -   Batch number = 116
Evaluating:  35%|███▍      | 116/332 [00:33<01:01,  3.49it/s]01/14/2022 16:05:06 - INFO - __main__ -   Batch number = 117
Evaluating:  35%|███▌      | 117/332 [00:33<01:01,  3.48it/s]01/14/2022 16:05:06 - INFO - __main__ -   Batch number = 118
Evaluating:  36%|███▌      | 118/332 [00:33<01:01,  3.48it/s]01/14/2022 16:05:06 - INFO - __main__ -   Batch number = 119
Evaluating:  36%|███▌      | 119/332 [00:33<01:01,  3.48it/s]01/14/2022 16:05:07 - INFO - __main__ -   Batch number = 120
Evaluating:  36%|███▌      | 120/332 [00:34<01:00,  3.48it/s]01/14/2022 16:05:07 - INFO - __main__ -   Batch number = 121
Evaluating:  36%|███▋      | 121/332 [00:34<01:00,  3.48it/s]01/14/2022 16:05:07 - INFO - __main__ -   Batch number = 122
Evaluating:  37%|███▋      | 122/332 [00:34<01:00,  3.48it/s]01/14/2022 16:05:08 - INFO - __main__ -   Batch number = 123
Evaluating:  37%|███▋      | 123/332 [00:35<01:00,  3.48it/s]01/14/2022 16:05:08 - INFO - __main__ -   Batch number = 124
Evaluating:  37%|███▋      | 124/332 [00:35<00:59,  3.48it/s]01/14/2022 16:05:08 - INFO - __main__ -   Batch number = 125
Evaluating:  38%|███▊      | 125/332 [00:35<00:59,  3.47it/s]01/14/2022 16:05:08 - INFO - __main__ -   Batch number = 126
Evaluating:  38%|███▊      | 126/332 [00:35<00:59,  3.47it/s]01/14/2022 16:05:09 - INFO - __main__ -   Batch number = 127
Evaluating:  38%|███▊      | 127/332 [00:36<00:59,  3.47it/s]01/14/2022 16:05:09 - INFO - __main__ -   Batch number = 128
Evaluating:  39%|███▊      | 128/332 [00:36<00:59,  3.45it/s]01/14/2022 16:05:09 - INFO - __main__ -   Batch number = 129
Evaluating:  39%|███▉      | 129/332 [00:36<00:58,  3.45it/s]01/14/2022 16:05:10 - INFO - __main__ -   Batch number = 130
Evaluating:  39%|███▉      | 130/332 [00:37<00:58,  3.45it/s]01/14/2022 16:05:10 - INFO - __main__ -   Batch number = 131
Evaluating:  39%|███▉      | 131/332 [00:37<00:58,  3.45it/s]01/14/2022 16:05:10 - INFO - __main__ -   Batch number = 132
Evaluating:  40%|███▉      | 132/332 [00:37<00:58,  3.44it/s]01/14/2022 16:05:10 - INFO - __main__ -   Batch number = 133
Evaluating:  40%|████      | 133/332 [00:38<00:57,  3.43it/s]01/14/2022 16:05:11 - INFO - __main__ -   Batch number = 134
Evaluating:  40%|████      | 134/332 [00:38<00:57,  3.44it/s]01/14/2022 16:05:11 - INFO - __main__ -   Batch number = 135
Evaluating:  41%|████      | 135/332 [00:38<00:57,  3.41it/s]01/14/2022 16:05:11 - INFO - __main__ -   Batch number = 136
Evaluating:  41%|████      | 136/332 [00:38<00:57,  3.41it/s]01/14/2022 16:05:12 - INFO - __main__ -   Batch number = 137
Evaluating:  41%|████▏     | 137/332 [00:39<00:56,  3.43it/s]01/14/2022 16:05:12 - INFO - __main__ -   Batch number = 138
Evaluating:  42%|████▏     | 138/332 [00:39<00:56,  3.44it/s]01/14/2022 16:05:12 - INFO - __main__ -   Batch number = 139
Evaluating:  42%|████▏     | 139/332 [00:39<00:56,  3.43it/s]01/14/2022 16:05:13 - INFO - __main__ -   Batch number = 140
Evaluating:  42%|████▏     | 140/332 [00:40<00:56,  3.41it/s]01/14/2022 16:05:13 - INFO - __main__ -   Batch number = 141
Evaluating:  42%|████▏     | 141/332 [00:40<00:56,  3.41it/s]01/14/2022 16:05:13 - INFO - __main__ -   Batch number = 142
Evaluating:  43%|████▎     | 142/332 [00:40<00:55,  3.40it/s]01/14/2022 16:05:13 - INFO - __main__ -   Batch number = 143
Evaluating:  43%|████▎     | 143/332 [00:40<00:55,  3.41it/s]01/14/2022 16:05:14 - INFO - __main__ -   Batch number = 144
Evaluating:  43%|████▎     | 144/332 [00:41<00:54,  3.42it/s]01/14/2022 16:05:14 - INFO - __main__ -   Batch number = 145
Evaluating:  44%|████▎     | 145/332 [00:41<00:54,  3.43it/s]01/14/2022 16:05:14 - INFO - __main__ -   Batch number = 146
Evaluating:  44%|████▍     | 146/332 [00:41<00:54,  3.43it/s]01/14/2022 16:05:15 - INFO - __main__ -   Batch number = 147
Evaluating:  44%|████▍     | 147/332 [00:42<00:57,  3.22it/s]01/14/2022 16:05:15 - INFO - __main__ -   Batch number = 148
Evaluating:  45%|████▍     | 148/332 [00:42<00:56,  3.28it/s]01/14/2022 16:05:15 - INFO - __main__ -   Batch number = 149
Evaluating:  45%|████▍     | 149/332 [00:42<00:55,  3.32it/s]01/14/2022 16:05:16 - INFO - __main__ -   Batch number = 150
Evaluating:  45%|████▌     | 150/332 [00:43<00:54,  3.35it/s]01/14/2022 16:05:16 - INFO - __main__ -   Batch number = 151
Evaluating:  45%|████▌     | 151/332 [00:43<00:53,  3.36it/s]01/14/2022 16:05:16 - INFO - __main__ -   Batch number = 152
Evaluating:  46%|████▌     | 152/332 [00:43<00:53,  3.37it/s]01/14/2022 16:05:16 - INFO - __main__ -   Batch number = 153
Evaluating:  46%|████▌     | 153/332 [00:43<00:53,  3.37it/s]01/14/2022 16:05:17 - INFO - __main__ -   Batch number = 154
Evaluating:  46%|████▋     | 154/332 [00:44<00:52,  3.38it/s]01/14/2022 16:05:17 - INFO - __main__ -   Batch number = 155
Evaluating:  47%|████▋     | 155/332 [00:44<00:52,  3.38it/s]01/14/2022 16:05:17 - INFO - __main__ -   Batch number = 156
Evaluating:  47%|████▋     | 156/332 [00:44<00:51,  3.40it/s]01/14/2022 16:05:18 - INFO - __main__ -   Batch number = 157
Evaluating:  47%|████▋     | 157/332 [00:45<00:51,  3.41it/s]01/14/2022 16:05:18 - INFO - __main__ -   Batch number = 158
Evaluating:  48%|████▊     | 158/332 [00:45<00:51,  3.41it/s]01/14/2022 16:05:18 - INFO - __main__ -   Batch number = 159
Evaluating:  48%|████▊     | 159/332 [00:45<00:50,  3.39it/s]01/14/2022 16:05:18 - INFO - __main__ -   Batch number = 160
Evaluating:  48%|████▊     | 160/332 [00:45<00:51,  3.37it/s]01/14/2022 16:05:19 - INFO - __main__ -   Batch number = 161
Evaluating:  48%|████▊     | 161/332 [00:46<00:50,  3.36it/s]01/14/2022 16:05:19 - INFO - __main__ -   Batch number = 162
Evaluating:  49%|████▉     | 162/332 [00:46<00:50,  3.34it/s]01/14/2022 16:05:19 - INFO - __main__ -   Batch number = 163
Evaluating:  49%|████▉     | 163/332 [00:46<00:50,  3.34it/s]01/14/2022 16:05:20 - INFO - __main__ -   Batch number = 164
Evaluating:  49%|████▉     | 164/332 [00:47<00:49,  3.36it/s]01/14/2022 16:05:20 - INFO - __main__ -   Batch number = 165
Evaluating:  50%|████▉     | 165/332 [00:47<00:52,  3.17it/s]01/14/2022 16:05:20 - INFO - __main__ -   Batch number = 166
Evaluating:  50%|█████     | 166/332 [00:47<00:52,  3.18it/s]01/14/2022 16:05:21 - INFO - __main__ -   Batch number = 167
Evaluating:  50%|█████     | 167/332 [00:48<00:51,  3.18it/s]01/14/2022 16:05:21 - INFO - __main__ -   Batch number = 168
Evaluating:  51%|█████     | 168/332 [00:48<00:51,  3.18it/s]01/14/2022 16:05:21 - INFO - __main__ -   Batch number = 169
Evaluating:  51%|█████     | 169/332 [00:48<00:51,  3.18it/s]01/14/2022 16:05:22 - INFO - __main__ -   Batch number = 170
Evaluating:  51%|█████     | 170/332 [00:49<00:50,  3.18it/s]01/14/2022 16:05:22 - INFO - __main__ -   Batch number = 171
Evaluating:  52%|█████▏    | 171/332 [00:49<00:50,  3.17it/s]01/14/2022 16:05:22 - INFO - __main__ -   Batch number = 172
Evaluating:  52%|█████▏    | 172/332 [00:49<00:50,  3.17it/s]01/14/2022 16:05:23 - INFO - __main__ -   Batch number = 173
Evaluating:  52%|█████▏    | 173/332 [00:50<00:50,  3.18it/s]01/14/2022 16:05:23 - INFO - __main__ -   Batch number = 174
Evaluating:  52%|█████▏    | 174/332 [00:50<00:49,  3.19it/s]01/14/2022 16:05:23 - INFO - __main__ -   Batch number = 175
Evaluating:  53%|█████▎    | 175/332 [00:50<00:49,  3.20it/s]01/14/2022 16:05:23 - INFO - __main__ -   Batch number = 176
Evaluating:  53%|█████▎    | 176/332 [00:50<00:48,  3.21it/s]01/14/2022 16:05:24 - INFO - __main__ -   Batch number = 177
Evaluating:  53%|█████▎    | 177/332 [00:51<00:48,  3.22it/s]01/14/2022 16:05:24 - INFO - __main__ -   Batch number = 178
Evaluating:  54%|█████▎    | 178/332 [00:51<00:47,  3.25it/s]01/14/2022 16:05:24 - INFO - __main__ -   Batch number = 179
Evaluating:  54%|█████▍    | 179/332 [00:51<00:46,  3.27it/s]01/14/2022 16:05:25 - INFO - __main__ -   Batch number = 180
Evaluating:  54%|█████▍    | 180/332 [00:52<00:46,  3.29it/s]01/14/2022 16:05:25 - INFO - __main__ -   Batch number = 181
Evaluating:  55%|█████▍    | 181/332 [00:52<00:48,  3.14it/s]01/14/2022 16:05:25 - INFO - __main__ -   Batch number = 182
Evaluating:  55%|█████▍    | 182/332 [00:52<00:46,  3.21it/s]01/14/2022 16:05:26 - INFO - __main__ -   Batch number = 183
Evaluating:  55%|█████▌    | 183/332 [00:53<00:45,  3.27it/s]01/14/2022 16:05:26 - INFO - __main__ -   Batch number = 184
Evaluating:  55%|█████▌    | 184/332 [00:53<00:44,  3.31it/s]01/14/2022 16:05:26 - INFO - __main__ -   Batch number = 185
Evaluating:  56%|█████▌    | 185/332 [00:53<00:44,  3.33it/s]01/14/2022 16:05:27 - INFO - __main__ -   Batch number = 186
Evaluating:  56%|█████▌    | 186/332 [00:54<00:43,  3.36it/s]01/14/2022 16:05:27 - INFO - __main__ -   Batch number = 187
Evaluating:  56%|█████▋    | 187/332 [00:54<00:42,  3.37it/s]01/14/2022 16:05:27 - INFO - __main__ -   Batch number = 188
Evaluating:  57%|█████▋    | 188/332 [00:54<00:42,  3.38it/s]01/14/2022 16:05:27 - INFO - __main__ -   Batch number = 189
Evaluating:  57%|█████▋    | 189/332 [00:54<00:42,  3.36it/s]01/14/2022 16:05:28 - INFO - __main__ -   Batch number = 190
Evaluating:  57%|█████▋    | 190/332 [00:55<00:42,  3.32it/s]01/14/2022 16:05:28 - INFO - __main__ -   Batch number = 191
Evaluating:  58%|█████▊    | 191/332 [00:55<00:42,  3.29it/s]01/14/2022 16:05:28 - INFO - __main__ -   Batch number = 192
Evaluating:  58%|█████▊    | 192/332 [00:55<00:42,  3.30it/s]01/14/2022 16:05:29 - INFO - __main__ -   Batch number = 193
Evaluating:  58%|█████▊    | 193/332 [00:56<00:42,  3.31it/s]01/14/2022 16:05:29 - INFO - __main__ -   Batch number = 194
Evaluating:  58%|█████▊    | 194/332 [00:56<00:41,  3.33it/s]01/14/2022 16:05:29 - INFO - __main__ -   Batch number = 195
Evaluating:  59%|█████▊    | 195/332 [00:56<00:40,  3.36it/s]01/14/2022 16:05:30 - INFO - __main__ -   Batch number = 196
Evaluating:  59%|█████▉    | 196/332 [00:57<00:40,  3.38it/s]01/14/2022 16:05:30 - INFO - __main__ -   Batch number = 197
Evaluating:  59%|█████▉    | 197/332 [00:57<00:39,  3.40it/s]01/14/2022 16:05:30 - INFO - __main__ -   Batch number = 198
Evaluating:  60%|█████▉    | 198/332 [00:57<00:45,  2.97it/s]01/14/2022 16:05:31 - INFO - __main__ -   Batch number = 199
Evaluating:  60%|█████▉    | 199/332 [00:58<00:42,  3.10it/s]01/14/2022 16:05:31 - INFO - __main__ -   Batch number = 200
Evaluating:  60%|██████    | 200/332 [00:58<00:41,  3.19it/s]01/14/2022 16:05:31 - INFO - __main__ -   Batch number = 201
Evaluating:  61%|██████    | 201/332 [00:58<00:40,  3.23it/s]01/14/2022 16:05:31 - INFO - __main__ -   Batch number = 202
Evaluating:  61%|██████    | 202/332 [00:58<00:40,  3.25it/s]01/14/2022 16:05:32 - INFO - __main__ -   Batch number = 203
Evaluating:  61%|██████    | 203/332 [00:59<00:39,  3.24it/s]01/14/2022 16:05:32 - INFO - __main__ -   Batch number = 204
Evaluating:  61%|██████▏   | 204/332 [00:59<00:39,  3.22it/s]01/14/2022 16:05:32 - INFO - __main__ -   Batch number = 205
Evaluating:  62%|██████▏   | 205/332 [00:59<00:39,  3.22it/s]01/14/2022 16:05:33 - INFO - __main__ -   Batch number = 206
Evaluating:  62%|██████▏   | 206/332 [01:00<00:39,  3.22it/s]01/14/2022 16:05:33 - INFO - __main__ -   Batch number = 207
Evaluating:  62%|██████▏   | 207/332 [01:00<00:39,  3.17it/s]01/14/2022 16:05:33 - INFO - __main__ -   Batch number = 208
Evaluating:  63%|██████▎   | 208/332 [01:00<00:39,  3.17it/s]01/14/2022 16:05:34 - INFO - __main__ -   Batch number = 209
Evaluating:  63%|██████▎   | 209/332 [01:01<00:38,  3.16it/s]01/14/2022 16:05:34 - INFO - __main__ -   Batch number = 210
Evaluating:  63%|██████▎   | 210/332 [01:01<00:38,  3.19it/s]01/14/2022 16:05:34 - INFO - __main__ -   Batch number = 211
Evaluating:  64%|██████▎   | 211/332 [01:01<00:37,  3.23it/s]01/14/2022 16:05:35 - INFO - __main__ -   Batch number = 212
Evaluating:  64%|██████▍   | 212/332 [01:02<00:36,  3.27it/s]01/14/2022 16:05:35 - INFO - __main__ -   Batch number = 213
Evaluating:  64%|██████▍   | 213/332 [01:02<00:36,  3.30it/s]01/14/2022 16:05:35 - INFO - __main__ -   Batch number = 214
Evaluating:  64%|██████▍   | 214/332 [01:02<00:38,  3.10it/s]01/14/2022 16:05:35 - INFO - __main__ -   Batch number = 215
Evaluating:  65%|██████▍   | 215/332 [01:03<00:37,  3.11it/s]01/14/2022 16:05:36 - INFO - __main__ -   Batch number = 216
Evaluating:  65%|██████▌   | 216/332 [01:03<00:37,  3.13it/s]01/14/2022 16:05:36 - INFO - __main__ -   Batch number = 217
Evaluating:  65%|██████▌   | 217/332 [01:03<00:36,  3.14it/s]01/14/2022 16:05:36 - INFO - __main__ -   Batch number = 218
Evaluating:  66%|██████▌   | 218/332 [01:03<00:36,  3.16it/s]01/14/2022 16:05:37 - INFO - __main__ -   Batch number = 219
Evaluating:  66%|██████▌   | 219/332 [01:04<00:35,  3.19it/s]01/14/2022 16:05:37 - INFO - __main__ -   Batch number = 220
Evaluating:  66%|██████▋   | 220/332 [01:04<00:35,  3.19it/s]01/14/2022 16:05:37 - INFO - __main__ -   Batch number = 221
Evaluating:  67%|██████▋   | 221/332 [01:04<00:34,  3.22it/s]01/14/2022 16:05:38 - INFO - __main__ -   Batch number = 222
Evaluating:  67%|██████▋   | 222/332 [01:05<00:33,  3.25it/s]01/14/2022 16:05:38 - INFO - __main__ -   Batch number = 223
Evaluating:  67%|██████▋   | 223/332 [01:05<00:33,  3.28it/s]01/14/2022 16:05:38 - INFO - __main__ -   Batch number = 224
Evaluating:  67%|██████▋   | 224/332 [01:05<00:32,  3.28it/s]01/14/2022 16:05:39 - INFO - __main__ -   Batch number = 225
Evaluating:  68%|██████▊   | 225/332 [01:06<00:32,  3.25it/s]01/14/2022 16:05:39 - INFO - __main__ -   Batch number = 226
Evaluating:  68%|██████▊   | 226/332 [01:06<00:33,  3.21it/s]01/14/2022 16:05:39 - INFO - __main__ -   Batch number = 227
Evaluating:  68%|██████▊   | 227/332 [01:06<00:32,  3.21it/s]01/14/2022 16:05:40 - INFO - __main__ -   Batch number = 228
Evaluating:  69%|██████▊   | 228/332 [01:07<00:32,  3.22it/s]01/14/2022 16:05:40 - INFO - __main__ -   Batch number = 229
Evaluating:  69%|██████▉   | 229/332 [01:07<00:31,  3.23it/s]01/14/2022 16:05:40 - INFO - __main__ -   Batch number = 230
Evaluating:  69%|██████▉   | 230/332 [01:07<00:32,  3.11it/s]01/14/2022 16:05:40 - INFO - __main__ -   Batch number = 231
Evaluating:  70%|██████▉   | 231/332 [01:07<00:31,  3.17it/s]01/14/2022 16:05:41 - INFO - __main__ -   Batch number = 232
Evaluating:  70%|██████▉   | 232/332 [01:08<00:31,  3.22it/s]01/14/2022 16:05:41 - INFO - __main__ -   Batch number = 233
Evaluating:  70%|███████   | 233/332 [01:08<00:30,  3.26it/s]01/14/2022 16:05:41 - INFO - __main__ -   Batch number = 234
Evaluating:  70%|███████   | 234/332 [01:08<00:29,  3.29it/s]01/14/2022 16:05:42 - INFO - __main__ -   Batch number = 235
Evaluating:  71%|███████   | 235/332 [01:09<00:29,  3.33it/s]01/14/2022 16:05:42 - INFO - __main__ -   Batch number = 236
Evaluating:  71%|███████   | 236/332 [01:09<00:28,  3.36it/s]01/14/2022 16:05:42 - INFO - __main__ -   Batch number = 237
Evaluating:  71%|███████▏  | 237/332 [01:09<00:28,  3.37it/s]01/14/2022 16:05:43 - INFO - __main__ -   Batch number = 238
Evaluating:  72%|███████▏  | 238/332 [01:10<00:27,  3.37it/s]01/14/2022 16:05:43 - INFO - __main__ -   Batch number = 239
Evaluating:  72%|███████▏  | 239/332 [01:10<00:27,  3.35it/s]01/14/2022 16:05:43 - INFO - __main__ -   Batch number = 240
Evaluating:  72%|███████▏  | 240/332 [01:10<00:27,  3.30it/s]01/14/2022 16:05:43 - INFO - __main__ -   Batch number = 241
Evaluating:  73%|███████▎  | 241/332 [01:10<00:27,  3.26it/s]01/14/2022 16:05:44 - INFO - __main__ -   Batch number = 242
Evaluating:  73%|███████▎  | 242/332 [01:11<00:27,  3.22it/s]01/14/2022 16:05:44 - INFO - __main__ -   Batch number = 243
Evaluating:  73%|███████▎  | 243/332 [01:11<00:27,  3.24it/s]01/14/2022 16:05:44 - INFO - __main__ -   Batch number = 244
Evaluating:  73%|███████▎  | 244/332 [01:11<00:27,  3.24it/s]01/14/2022 16:05:45 - INFO - __main__ -   Batch number = 245
Evaluating:  74%|███████▍  | 245/332 [01:12<00:27,  3.22it/s]01/14/2022 16:05:45 - INFO - __main__ -   Batch number = 246
Evaluating:  74%|███████▍  | 246/332 [01:12<00:26,  3.22it/s]01/14/2022 16:05:45 - INFO - __main__ -   Batch number = 247
Evaluating:  74%|███████▍  | 247/332 [01:12<00:28,  3.02it/s]01/14/2022 16:05:46 - INFO - __main__ -   Batch number = 248
Evaluating:  75%|███████▍  | 248/332 [01:13<00:27,  3.07it/s]01/14/2022 16:05:46 - INFO - __main__ -   Batch number = 249
Evaluating:  75%|███████▌  | 249/332 [01:13<00:26,  3.11it/s]01/14/2022 16:05:46 - INFO - __main__ -   Batch number = 250
Evaluating:  75%|███████▌  | 250/332 [01:13<00:25,  3.15it/s]01/14/2022 16:05:47 - INFO - __main__ -   Batch number = 251
Evaluating:  76%|███████▌  | 251/332 [01:14<00:25,  3.20it/s]01/14/2022 16:05:47 - INFO - __main__ -   Batch number = 252
Evaluating:  76%|███████▌  | 252/332 [01:14<00:24,  3.23it/s]01/14/2022 16:05:47 - INFO - __main__ -   Batch number = 253
Evaluating:  76%|███████▌  | 253/332 [01:14<00:24,  3.25it/s]01/14/2022 16:05:48 - INFO - __main__ -   Batch number = 254
Evaluating:  77%|███████▋  | 254/332 [01:15<00:23,  3.29it/s]01/14/2022 16:05:48 - INFO - __main__ -   Batch number = 255
Evaluating:  77%|███████▋  | 255/332 [01:15<00:23,  3.32it/s]01/14/2022 16:05:48 - INFO - __main__ -   Batch number = 256
Evaluating:  77%|███████▋  | 256/332 [01:15<00:22,  3.34it/s]01/14/2022 16:05:48 - INFO - __main__ -   Batch number = 257
Evaluating:  77%|███████▋  | 257/332 [01:15<00:22,  3.37it/s]01/14/2022 16:05:49 - INFO - __main__ -   Batch number = 258
Evaluating:  78%|███████▊  | 258/332 [01:16<00:21,  3.38it/s]01/14/2022 16:05:49 - INFO - __main__ -   Batch number = 259
Evaluating:  78%|███████▊  | 259/332 [01:16<00:21,  3.39it/s]01/14/2022 16:05:49 - INFO - __main__ -   Batch number = 260
Evaluating:  78%|███████▊  | 260/332 [01:16<00:21,  3.39it/s]01/14/2022 16:05:50 - INFO - __main__ -   Batch number = 261
Evaluating:  79%|███████▊  | 261/332 [01:17<00:21,  3.37it/s]01/14/2022 16:05:50 - INFO - __main__ -   Batch number = 262
Evaluating:  79%|███████▉  | 262/332 [01:17<00:21,  3.33it/s]01/14/2022 16:05:50 - INFO - __main__ -   Batch number = 263
Evaluating:  79%|███████▉  | 263/332 [01:17<00:21,  3.24it/s]01/14/2022 16:05:51 - INFO - __main__ -   Batch number = 264
Evaluating:  80%|███████▉  | 264/332 [01:18<00:21,  3.21it/s]01/14/2022 16:05:51 - INFO - __main__ -   Batch number = 265
Evaluating:  80%|███████▉  | 265/332 [01:18<00:20,  3.20it/s]01/14/2022 16:05:51 - INFO - __main__ -   Batch number = 266
Evaluating:  80%|████████  | 266/332 [01:18<00:20,  3.21it/s]01/14/2022 16:05:52 - INFO - __main__ -   Batch number = 267
Evaluating:  80%|████████  | 267/332 [01:19<00:20,  3.24it/s]01/14/2022 16:05:52 - INFO - __main__ -   Batch number = 268
Evaluating:  81%|████████  | 268/332 [01:19<00:19,  3.28it/s]01/14/2022 16:05:52 - INFO - __main__ -   Batch number = 269
Evaluating:  81%|████████  | 269/332 [01:19<00:19,  3.30it/s]01/14/2022 16:05:52 - INFO - __main__ -   Batch number = 270
Evaluating:  81%|████████▏ | 270/332 [01:19<00:18,  3.30it/s]01/14/2022 16:05:53 - INFO - __main__ -   Batch number = 271
Evaluating:  82%|████████▏ | 271/332 [01:20<00:18,  3.28it/s]01/14/2022 16:05:53 - INFO - __main__ -   Batch number = 272
Evaluating:  82%|████████▏ | 272/332 [01:20<00:18,  3.24it/s]01/14/2022 16:05:53 - INFO - __main__ -   Batch number = 273
Evaluating:  82%|████████▏ | 273/332 [01:20<00:18,  3.22it/s]01/14/2022 16:05:54 - INFO - __main__ -   Batch number = 274
Evaluating:  83%|████████▎ | 274/332 [01:21<00:18,  3.19it/s]01/14/2022 16:05:54 - INFO - __main__ -   Batch number = 275
Evaluating:  83%|████████▎ | 275/332 [01:21<00:17,  3.21it/s]01/14/2022 16:05:54 - INFO - __main__ -   Batch number = 276
Evaluating:  83%|████████▎ | 276/332 [01:21<00:17,  3.25it/s]01/14/2022 16:05:55 - INFO - __main__ -   Batch number = 277
Evaluating:  83%|████████▎ | 277/332 [01:22<00:16,  3.28it/s]01/14/2022 16:05:55 - INFO - __main__ -   Batch number = 278
Evaluating:  84%|████████▎ | 278/332 [01:22<00:16,  3.31it/s]01/14/2022 16:05:55 - INFO - __main__ -   Batch number = 279
Evaluating:  84%|████████▍ | 279/332 [01:22<00:15,  3.34it/s]01/14/2022 16:05:55 - INFO - __main__ -   Batch number = 280
Evaluating:  84%|████████▍ | 280/332 [01:22<00:15,  3.27it/s]01/14/2022 16:05:56 - INFO - __main__ -   Batch number = 281
Evaluating:  85%|████████▍ | 281/332 [01:23<00:15,  3.25it/s]01/14/2022 16:05:56 - INFO - __main__ -   Batch number = 282
Evaluating:  85%|████████▍ | 282/332 [01:23<00:15,  3.22it/s]01/14/2022 16:05:56 - INFO - __main__ -   Batch number = 283
Evaluating:  85%|████████▌ | 283/332 [01:23<00:15,  3.21it/s]01/14/2022 16:05:57 - INFO - __main__ -   Batch number = 284
Evaluating:  86%|████████▌ | 284/332 [01:24<00:14,  3.20it/s]01/14/2022 16:05:57 - INFO - __main__ -   Batch number = 285
Evaluating:  86%|████████▌ | 285/332 [01:24<00:14,  3.21it/s]01/14/2022 16:05:57 - INFO - __main__ -   Batch number = 286
Evaluating:  86%|████████▌ | 286/332 [01:24<00:14,  3.23it/s]01/14/2022 16:05:58 - INFO - __main__ -   Batch number = 287
Evaluating:  86%|████████▋ | 287/332 [01:25<00:13,  3.24it/s]01/14/2022 16:05:58 - INFO - __main__ -   Batch number = 288
Evaluating:  87%|████████▋ | 288/332 [01:25<00:13,  3.27it/s]01/14/2022 16:05:58 - INFO - __main__ -   Batch number = 289
Evaluating:  87%|████████▋ | 289/332 [01:25<00:13,  3.29it/s]01/14/2022 16:05:59 - INFO - __main__ -   Batch number = 290
Evaluating:  87%|████████▋ | 290/332 [01:26<00:12,  3.32it/s]01/14/2022 16:05:59 - INFO - __main__ -   Batch number = 291
Evaluating:  88%|████████▊ | 291/332 [01:26<00:12,  3.33it/s]01/14/2022 16:05:59 - INFO - __main__ -   Batch number = 292
Evaluating:  88%|████████▊ | 292/332 [01:26<00:12,  3.31it/s]01/14/2022 16:05:59 - INFO - __main__ -   Batch number = 293
Evaluating:  88%|████████▊ | 293/332 [01:26<00:11,  3.26it/s]01/14/2022 16:06:00 - INFO - __main__ -   Batch number = 294
Evaluating:  89%|████████▊ | 294/332 [01:27<00:11,  3.23it/s]01/14/2022 16:06:00 - INFO - __main__ -   Batch number = 295
Evaluating:  89%|████████▉ | 295/332 [01:27<00:11,  3.22it/s]01/14/2022 16:06:00 - INFO - __main__ -   Batch number = 296
Evaluating:  89%|████████▉ | 296/332 [01:27<00:11,  3.24it/s]01/14/2022 16:06:01 - INFO - __main__ -   Batch number = 297
Evaluating:  89%|████████▉ | 297/332 [01:28<00:10,  3.26it/s]01/14/2022 16:06:01 - INFO - __main__ -   Batch number = 298
Evaluating:  90%|████████▉ | 298/332 [01:28<00:10,  3.27it/s]01/14/2022 16:06:01 - INFO - __main__ -   Batch number = 299
Evaluating:  90%|█████████ | 299/332 [01:28<00:10,  3.29it/s]01/14/2022 16:06:02 - INFO - __main__ -   Batch number = 300
Evaluating:  90%|█████████ | 300/332 [01:29<00:09,  3.32it/s]01/14/2022 16:06:02 - INFO - __main__ -   Batch number = 301
Evaluating:  91%|█████████ | 301/332 [01:29<00:09,  3.32it/s]01/14/2022 16:06:02 - INFO - __main__ -   Batch number = 302
Evaluating:  91%|█████████ | 302/332 [01:29<00:09,  3.33it/s]01/14/2022 16:06:03 - INFO - __main__ -   Batch number = 303
Evaluating:  91%|█████████▏| 303/332 [01:30<00:08,  3.33it/s]01/14/2022 16:06:03 - INFO - __main__ -   Batch number = 304
Evaluating:  92%|█████████▏| 304/332 [01:30<00:08,  3.33it/s]01/14/2022 16:06:03 - INFO - __main__ -   Batch number = 305
Evaluating:  92%|█████████▏| 305/332 [01:30<00:08,  3.34it/s]01/14/2022 16:06:03 - INFO - __main__ -   Batch number = 306
Evaluating:  92%|█████████▏| 306/332 [01:30<00:07,  3.36it/s]01/14/2022 16:06:04 - INFO - __main__ -   Batch number = 307
Evaluating:  92%|█████████▏| 307/332 [01:31<00:07,  3.35it/s]01/14/2022 16:06:04 - INFO - __main__ -   Batch number = 308
Evaluating:  93%|█████████▎| 308/332 [01:31<00:07,  3.37it/s]01/14/2022 16:06:04 - INFO - __main__ -   Batch number = 309
Evaluating:  93%|█████████▎| 309/332 [01:31<00:06,  3.38it/s]01/14/2022 16:06:05 - INFO - __main__ -   Batch number = 310
Evaluating:  93%|█████████▎| 310/332 [01:32<00:06,  3.39it/s]01/14/2022 16:06:05 - INFO - __main__ -   Batch number = 311
Evaluating:  94%|█████████▎| 311/332 [01:32<00:06,  3.37it/s]01/14/2022 16:06:05 - INFO - __main__ -   Batch number = 312
Evaluating:  94%|█████████▍| 312/332 [01:32<00:06,  3.33it/s]01/14/2022 16:06:05 - INFO - __main__ -   Batch number = 313
Evaluating:  94%|█████████▍| 313/332 [01:33<00:05,  3.28it/s]01/14/2022 16:06:06 - INFO - __main__ -   Batch number = 314
Evaluating:  95%|█████████▍| 314/332 [01:33<00:05,  3.22it/s]01/14/2022 16:06:06 - INFO - __main__ -   Batch number = 315
Evaluating:  95%|█████████▍| 315/332 [01:33<00:05,  3.22it/s]01/14/2022 16:06:06 - INFO - __main__ -   Batch number = 316
Evaluating:  95%|█████████▌| 316/332 [01:33<00:04,  3.23it/s]01/14/2022 16:06:07 - INFO - __main__ -   Batch number = 317
Evaluating:  95%|█████████▌| 317/332 [01:34<00:04,  3.20it/s]01/14/2022 16:06:07 - INFO - __main__ -   Batch number = 318
Evaluating:  96%|█████████▌| 318/332 [01:34<00:04,  3.20it/s]01/14/2022 16:06:07 - INFO - __main__ -   Batch number = 319
Evaluating:  96%|█████████▌| 319/332 [01:34<00:04,  3.21it/s]01/14/2022 16:06:08 - INFO - __main__ -   Batch number = 320
Evaluating:  96%|█████████▋| 320/332 [01:35<00:03,  3.23it/s]01/14/2022 16:06:08 - INFO - __main__ -   Batch number = 321
Evaluating:  97%|█████████▋| 321/332 [01:35<00:03,  3.27it/s]01/14/2022 16:06:08 - INFO - __main__ -   Batch number = 322
Evaluating:  97%|█████████▋| 322/332 [01:35<00:03,  3.31it/s]01/14/2022 16:06:09 - INFO - __main__ -   Batch number = 323
Evaluating:  97%|█████████▋| 323/332 [01:36<00:02,  3.29it/s]01/14/2022 16:06:09 - INFO - __main__ -   Batch number = 324
Evaluating:  98%|█████████▊| 324/332 [01:36<00:02,  3.30it/s]01/14/2022 16:06:09 - INFO - __main__ -   Batch number = 325
Evaluating:  98%|█████████▊| 325/332 [01:36<00:02,  3.29it/s]01/14/2022 16:06:09 - INFO - __main__ -   Batch number = 326
Evaluating:  98%|█████████▊| 326/332 [01:37<00:01,  3.23it/s]01/14/2022 16:06:10 - INFO - __main__ -   Batch number = 327
Evaluating:  98%|█████████▊| 327/332 [01:37<00:01,  3.22it/s]01/14/2022 16:06:10 - INFO - __main__ -   Batch number = 328
Evaluating:  99%|█████████▉| 328/332 [01:37<00:01,  3.26it/s]01/14/2022 16:06:11 - INFO - __main__ -   Batch number = 329
Evaluating:  99%|█████████▉| 329/332 [01:38<00:01,  2.62it/s]01/14/2022 16:06:11 - INFO - __main__ -   Batch number = 330
Evaluating:  99%|█████████▉| 330/332 [01:38<00:00,  2.79it/s]01/14/2022 16:06:11 - INFO - __main__ -   Batch number = 331
Evaluating: 100%|█████████▉| 331/332 [01:38<00:00,  2.93it/s]01/14/2022 16:06:12 - INFO - __main__ -   Batch number = 332
Evaluating: 100%|██████████| 332/332 [01:39<00:00,  3.30it/s]Evaluating: 100%|██████████| 332/332 [01:39<00:00,  3.35it/s]
01/14/2022 16:06:15 - INFO - __main__ -   ***** Evaluation result  in ja *****
01/14/2022 16:06:15 - INFO - __main__ -     f1 = 0.20212637136421982
01/14/2022 16:06:15 - INFO - __main__ -     loss = 3.8501403769814826
01/14/2022 16:06:15 - INFO - __main__ -     precision = 0.15298042378473495
01/14/2022 16:06:15 - INFO - __main__ -     recall = 0.2977949047313209
109.45user 39.49system 2:17.92elapsed 107%CPU (0avgtext+0avgdata 4231072maxresident)k
8inputs+2328outputs (0major+2387629minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:06:18 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ja', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:06:18 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:06:18 - INFO - __main__ -   Seed = 2
01/14/2022 16:06:18 - INFO - root -   save model
01/14/2022 16:06:18 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ja', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:06:18 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:06:21 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:06:26 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:06:26 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:06:26 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:06:26 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:06:26 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:06:26 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,ja/wiki@ukp
01/14/2022 16:06:26 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'ja'], Length : 10
01/14/2022 16:06:26 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'ja/wiki@ukp'], Length : 10
01/14/2022 16:06:26 - INFO - __main__ -   Language = en
01/14/2022 16:06:26 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:06:28 - INFO - __main__ -   Language = pt
01/14/2022 16:06:28 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:06:30 - INFO - __main__ -   Language = id
01/14/2022 16:06:30 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:06:32 - INFO - __main__ -   Language = tr
01/14/2022 16:06:32 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:06:34 - INFO - __main__ -   Language = cs
01/14/2022 16:06:34 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:06:36 - INFO - __main__ -   Language = vi
01/14/2022 16:06:36 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:06:37 - INFO - __main__ -   Language = eu
01/14/2022 16:06:37 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:06:39 - INFO - __main__ -   Language = fa
01/14/2022 16:06:39 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:06:41 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:06:41 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:06:43 - INFO - __main__ -   Language = ja
01/14/2022 16:06:43 - INFO - __main__ -   Adapter Name = ja/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ja/bert-base-multilingual-cased/pfeiffer/ja_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted/adapter_config.json
Adding adapter 'ja' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted'
01/14/2022 16:06:47 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:06:47 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'ja']
01/14/2022 16:06:47 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:06:47 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:06:47 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:06:47 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ja_bert-base-multilingual-cased_128
01/14/2022 16:06:48 - INFO - __main__ -   ***** Running evaluation  in ja *****
01/14/2022 16:06:48 - INFO - __main__ -     Num examples = 10612
01/14/2022 16:06:48 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/332 [00:00<?, ?it/s]01/14/2022 16:06:49 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/332 [00:00<01:43,  3.21it/s]01/14/2022 16:06:49 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/332 [00:00<01:37,  3.38it/s]01/14/2022 16:06:49 - INFO - __main__ -   Batch number = 3
Evaluating:   1%|          | 3/332 [00:00<01:35,  3.45it/s]01/14/2022 16:06:49 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/332 [00:01<01:34,  3.48it/s]01/14/2022 16:06:50 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/332 [00:01<01:33,  3.51it/s]01/14/2022 16:06:50 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/332 [00:01<01:32,  3.52it/s]01/14/2022 16:06:50 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/332 [00:02<01:32,  3.53it/s]01/14/2022 16:06:51 - INFO - __main__ -   Batch number = 8
Evaluating:   2%|▏         | 8/332 [00:02<01:47,  3.00it/s]01/14/2022 16:06:51 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/332 [00:02<01:42,  3.15it/s]01/14/2022 16:06:51 - INFO - __main__ -   Batch number = 10
Evaluating:   3%|▎         | 10/332 [00:03<01:38,  3.26it/s]01/14/2022 16:06:52 - INFO - __main__ -   Batch number = 11
Evaluating:   3%|▎         | 11/332 [00:03<01:36,  3.34it/s]01/14/2022 16:06:52 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▎         | 12/332 [00:03<01:34,  3.39it/s]01/14/2022 16:06:52 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/332 [00:03<01:32,  3.43it/s]01/14/2022 16:06:52 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/332 [00:04<01:31,  3.47it/s]01/14/2022 16:06:53 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/332 [00:04<01:30,  3.49it/s]01/14/2022 16:06:53 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▍         | 16/332 [00:04<01:30,  3.50it/s]01/14/2022 16:06:53 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/332 [00:04<01:29,  3.51it/s]01/14/2022 16:06:53 - INFO - __main__ -   Batch number = 18
Evaluating:   5%|▌         | 18/332 [00:05<01:29,  3.52it/s]01/14/2022 16:06:54 - INFO - __main__ -   Batch number = 19
Evaluating:   6%|▌         | 19/332 [00:05<01:28,  3.52it/s]01/14/2022 16:06:54 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▌         | 20/332 [00:05<01:28,  3.53it/s]01/14/2022 16:06:54 - INFO - __main__ -   Batch number = 21
Evaluating:   6%|▋         | 21/332 [00:06<01:28,  3.52it/s]01/14/2022 16:06:55 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/332 [00:06<01:28,  3.52it/s]01/14/2022 16:06:55 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/332 [00:06<01:27,  3.51it/s]01/14/2022 16:06:55 - INFO - __main__ -   Batch number = 24
Evaluating:   7%|▋         | 24/332 [00:06<01:27,  3.51it/s]01/14/2022 16:06:56 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/332 [00:07<01:33,  3.29it/s]01/14/2022 16:06:56 - INFO - __main__ -   Batch number = 26
Evaluating:   8%|▊         | 26/332 [00:07<01:31,  3.36it/s]01/14/2022 16:06:56 - INFO - __main__ -   Batch number = 27
Evaluating:   8%|▊         | 27/332 [00:07<01:29,  3.41it/s]01/14/2022 16:06:56 - INFO - __main__ -   Batch number = 28
Evaluating:   8%|▊         | 28/332 [00:08<01:28,  3.44it/s]01/14/2022 16:06:57 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▊         | 29/332 [00:08<01:27,  3.46it/s]01/14/2022 16:06:57 - INFO - __main__ -   Batch number = 30
Evaluating:   9%|▉         | 30/332 [00:08<01:26,  3.48it/s]01/14/2022 16:06:57 - INFO - __main__ -   Batch number = 31
Evaluating:   9%|▉         | 31/332 [00:09<01:26,  3.48it/s]01/14/2022 16:06:58 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|▉         | 32/332 [00:09<01:25,  3.49it/s]01/14/2022 16:06:58 - INFO - __main__ -   Batch number = 33
Evaluating:  10%|▉         | 33/332 [00:09<01:25,  3.50it/s]01/14/2022 16:06:58 - INFO - __main__ -   Batch number = 34
Evaluating:  10%|█         | 34/332 [00:09<01:25,  3.50it/s]01/14/2022 16:06:58 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/332 [00:10<01:24,  3.50it/s]01/14/2022 16:06:59 - INFO - __main__ -   Batch number = 36
Evaluating:  11%|█         | 36/332 [00:10<01:24,  3.50it/s]01/14/2022 16:06:59 - INFO - __main__ -   Batch number = 37
Evaluating:  11%|█         | 37/332 [00:10<01:24,  3.50it/s]01/14/2022 16:06:59 - INFO - __main__ -   Batch number = 38
Evaluating:  11%|█▏        | 38/332 [00:11<01:23,  3.50it/s]01/14/2022 16:07:00 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/332 [00:11<01:23,  3.51it/s]01/14/2022 16:07:00 - INFO - __main__ -   Batch number = 40
Evaluating:  12%|█▏        | 40/332 [00:11<01:23,  3.51it/s]01/14/2022 16:07:00 - INFO - __main__ -   Batch number = 41
Evaluating:  12%|█▏        | 41/332 [00:11<01:22,  3.51it/s]01/14/2022 16:07:00 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/332 [00:12<01:22,  3.51it/s]01/14/2022 16:07:01 - INFO - __main__ -   Batch number = 43
Evaluating:  13%|█▎        | 43/332 [00:12<01:22,  3.50it/s]01/14/2022 16:07:01 - INFO - __main__ -   Batch number = 44
Evaluating:  13%|█▎        | 44/332 [00:12<01:22,  3.51it/s]01/14/2022 16:07:01 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▎        | 45/332 [00:13<01:22,  3.50it/s]01/14/2022 16:07:02 - INFO - __main__ -   Batch number = 46
Evaluating:  14%|█▍        | 46/332 [00:13<01:21,  3.50it/s]01/14/2022 16:07:02 - INFO - __main__ -   Batch number = 47
Evaluating:  14%|█▍        | 47/332 [00:13<01:21,  3.50it/s]01/14/2022 16:07:02 - INFO - __main__ -   Batch number = 48
Evaluating:  14%|█▍        | 48/332 [00:13<01:21,  3.50it/s]01/14/2022 16:07:02 - INFO - __main__ -   Batch number = 49
Evaluating:  15%|█▍        | 49/332 [00:14<01:20,  3.50it/s]01/14/2022 16:07:03 - INFO - __main__ -   Batch number = 50
Evaluating:  15%|█▌        | 50/332 [00:14<01:20,  3.50it/s]01/14/2022 16:07:03 - INFO - __main__ -   Batch number = 51
Evaluating:  15%|█▌        | 51/332 [00:14<01:20,  3.50it/s]01/14/2022 16:07:03 - INFO - __main__ -   Batch number = 52
Evaluating:  16%|█▌        | 52/332 [00:15<01:20,  3.50it/s]01/14/2022 16:07:04 - INFO - __main__ -   Batch number = 53
Evaluating:  16%|█▌        | 53/332 [00:15<01:19,  3.50it/s]01/14/2022 16:07:04 - INFO - __main__ -   Batch number = 54
Evaluating:  16%|█▋        | 54/332 [00:15<01:19,  3.49it/s]01/14/2022 16:07:04 - INFO - __main__ -   Batch number = 55
Evaluating:  17%|█▋        | 55/332 [00:15<01:19,  3.49it/s]01/14/2022 16:07:04 - INFO - __main__ -   Batch number = 56
Evaluating:  17%|█▋        | 56/332 [00:16<01:19,  3.48it/s]01/14/2022 16:07:05 - INFO - __main__ -   Batch number = 57
Evaluating:  17%|█▋        | 57/332 [00:16<01:18,  3.48it/s]01/14/2022 16:07:05 - INFO - __main__ -   Batch number = 58
Evaluating:  17%|█▋        | 58/332 [00:16<01:18,  3.48it/s]01/14/2022 16:07:05 - INFO - __main__ -   Batch number = 59
Evaluating:  18%|█▊        | 59/332 [00:17<01:18,  3.48it/s]01/14/2022 16:07:06 - INFO - __main__ -   Batch number = 60
Evaluating:  18%|█▊        | 60/332 [00:17<01:20,  3.39it/s]01/14/2022 16:07:06 - INFO - __main__ -   Batch number = 61
Evaluating:  18%|█▊        | 61/332 [00:17<01:19,  3.40it/s]01/14/2022 16:07:06 - INFO - __main__ -   Batch number = 62
Evaluating:  19%|█▊        | 62/332 [00:17<01:19,  3.41it/s]01/14/2022 16:07:06 - INFO - __main__ -   Batch number = 63
Evaluating:  19%|█▉        | 63/332 [00:18<01:18,  3.41it/s]01/14/2022 16:07:07 - INFO - __main__ -   Batch number = 64
Evaluating:  19%|█▉        | 64/332 [00:18<01:18,  3.39it/s]01/14/2022 16:07:07 - INFO - __main__ -   Batch number = 65
Evaluating:  20%|█▉        | 65/332 [00:18<01:19,  3.38it/s]01/14/2022 16:07:07 - INFO - __main__ -   Batch number = 66
Evaluating:  20%|█▉        | 66/332 [00:19<01:18,  3.39it/s]01/14/2022 16:07:08 - INFO - __main__ -   Batch number = 67
Evaluating:  20%|██        | 67/332 [00:19<01:18,  3.39it/s]01/14/2022 16:07:08 - INFO - __main__ -   Batch number = 68
Evaluating:  20%|██        | 68/332 [00:19<01:17,  3.41it/s]01/14/2022 16:07:08 - INFO - __main__ -   Batch number = 69
Evaluating:  21%|██        | 69/332 [00:19<01:16,  3.42it/s]01/14/2022 16:07:08 - INFO - __main__ -   Batch number = 70
Evaluating:  21%|██        | 70/332 [00:20<01:16,  3.43it/s]01/14/2022 16:07:09 - INFO - __main__ -   Batch number = 71
Evaluating:  21%|██▏       | 71/332 [00:20<01:16,  3.43it/s]01/14/2022 16:07:09 - INFO - __main__ -   Batch number = 72
Evaluating:  22%|██▏       | 72/332 [00:20<01:15,  3.44it/s]01/14/2022 16:07:09 - INFO - __main__ -   Batch number = 73
Evaluating:  22%|██▏       | 73/332 [00:21<01:15,  3.44it/s]01/14/2022 16:07:10 - INFO - __main__ -   Batch number = 74
Evaluating:  22%|██▏       | 74/332 [00:21<01:14,  3.45it/s]01/14/2022 16:07:10 - INFO - __main__ -   Batch number = 75
Evaluating:  23%|██▎       | 75/332 [00:21<01:14,  3.46it/s]01/14/2022 16:07:10 - INFO - __main__ -   Batch number = 76
Evaluating:  23%|██▎       | 76/332 [00:22<01:14,  3.45it/s]01/14/2022 16:07:11 - INFO - __main__ -   Batch number = 77
Evaluating:  23%|██▎       | 77/332 [00:22<01:14,  3.42it/s]01/14/2022 16:07:11 - INFO - __main__ -   Batch number = 78
Evaluating:  23%|██▎       | 78/332 [00:22<01:14,  3.43it/s]01/14/2022 16:07:11 - INFO - __main__ -   Batch number = 79
Evaluating:  24%|██▍       | 79/332 [00:22<01:14,  3.42it/s]01/14/2022 16:07:11 - INFO - __main__ -   Batch number = 80
Evaluating:  24%|██▍       | 80/332 [00:23<01:13,  3.41it/s]01/14/2022 16:07:12 - INFO - __main__ -   Batch number = 81
Evaluating:  24%|██▍       | 81/332 [00:23<01:13,  3.40it/s]01/14/2022 16:07:12 - INFO - __main__ -   Batch number = 82
Evaluating:  25%|██▍       | 82/332 [00:23<01:13,  3.41it/s]01/14/2022 16:07:12 - INFO - __main__ -   Batch number = 83
Evaluating:  25%|██▌       | 83/332 [00:24<01:13,  3.41it/s]01/14/2022 16:07:13 - INFO - __main__ -   Batch number = 84
Evaluating:  25%|██▌       | 84/332 [00:24<01:12,  3.40it/s]01/14/2022 16:07:13 - INFO - __main__ -   Batch number = 85
Evaluating:  26%|██▌       | 85/332 [00:24<01:12,  3.39it/s]01/14/2022 16:07:13 - INFO - __main__ -   Batch number = 86
Evaluating:  26%|██▌       | 86/332 [00:24<01:12,  3.37it/s]01/14/2022 16:07:13 - INFO - __main__ -   Batch number = 87
Evaluating:  26%|██▌       | 87/332 [00:25<01:12,  3.36it/s]01/14/2022 16:07:14 - INFO - __main__ -   Batch number = 88
Evaluating:  27%|██▋       | 88/332 [00:25<01:12,  3.34it/s]01/14/2022 16:07:14 - INFO - __main__ -   Batch number = 89
Evaluating:  27%|██▋       | 89/332 [00:25<01:12,  3.33it/s]01/14/2022 16:07:14 - INFO - __main__ -   Batch number = 90
Evaluating:  27%|██▋       | 90/332 [00:26<01:12,  3.34it/s]01/14/2022 16:07:15 - INFO - __main__ -   Batch number = 91
Evaluating:  27%|██▋       | 91/332 [00:26<01:12,  3.34it/s]01/14/2022 16:07:15 - INFO - __main__ -   Batch number = 92
Evaluating:  28%|██▊       | 92/332 [00:26<01:11,  3.34it/s]01/14/2022 16:07:15 - INFO - __main__ -   Batch number = 93
Evaluating:  28%|██▊       | 93/332 [00:27<01:11,  3.33it/s]01/14/2022 16:07:16 - INFO - __main__ -   Batch number = 94
Evaluating:  28%|██▊       | 94/332 [00:27<01:11,  3.33it/s]01/14/2022 16:07:16 - INFO - __main__ -   Batch number = 95
Evaluating:  29%|██▊       | 95/332 [00:27<01:11,  3.32it/s]01/14/2022 16:07:16 - INFO - __main__ -   Batch number = 96
Evaluating:  29%|██▉       | 96/332 [00:27<01:11,  3.30it/s]01/14/2022 16:07:16 - INFO - __main__ -   Batch number = 97
Evaluating:  29%|██▉       | 97/332 [00:28<01:11,  3.28it/s]01/14/2022 16:07:17 - INFO - __main__ -   Batch number = 98
Evaluating:  30%|██▉       | 98/332 [00:28<01:11,  3.27it/s]01/14/2022 16:07:17 - INFO - __main__ -   Batch number = 99
Evaluating:  30%|██▉       | 99/332 [00:28<01:11,  3.28it/s]01/14/2022 16:07:17 - INFO - __main__ -   Batch number = 100
Evaluating:  30%|███       | 100/332 [00:29<01:11,  3.26it/s]01/14/2022 16:07:18 - INFO - __main__ -   Batch number = 101
Evaluating:  30%|███       | 101/332 [00:29<01:10,  3.27it/s]01/14/2022 16:07:18 - INFO - __main__ -   Batch number = 102
Evaluating:  31%|███       | 102/332 [00:29<01:09,  3.30it/s]01/14/2022 16:07:18 - INFO - __main__ -   Batch number = 103
Evaluating:  31%|███       | 103/332 [00:30<01:08,  3.33it/s]01/14/2022 16:07:19 - INFO - __main__ -   Batch number = 104
Evaluating:  31%|███▏      | 104/332 [00:30<01:08,  3.35it/s]01/14/2022 16:07:19 - INFO - __main__ -   Batch number = 105
Evaluating:  32%|███▏      | 105/332 [00:30<01:07,  3.35it/s]01/14/2022 16:07:19 - INFO - __main__ -   Batch number = 106
Evaluating:  32%|███▏      | 106/332 [00:31<01:07,  3.33it/s]01/14/2022 16:07:20 - INFO - __main__ -   Batch number = 107
Evaluating:  32%|███▏      | 107/332 [00:31<01:08,  3.28it/s]01/14/2022 16:07:20 - INFO - __main__ -   Batch number = 108
Evaluating:  33%|███▎      | 108/332 [00:31<01:08,  3.25it/s]01/14/2022 16:07:20 - INFO - __main__ -   Batch number = 109
Evaluating:  33%|███▎      | 109/332 [00:31<01:09,  3.22it/s]01/14/2022 16:07:21 - INFO - __main__ -   Batch number = 110
Evaluating:  33%|███▎      | 110/332 [00:32<01:14,  2.99it/s]01/14/2022 16:07:21 - INFO - __main__ -   Batch number = 111
Evaluating:  33%|███▎      | 111/332 [00:32<01:11,  3.10it/s]01/14/2022 16:07:21 - INFO - __main__ -   Batch number = 112
Evaluating:  34%|███▎      | 112/332 [00:32<01:09,  3.17it/s]01/14/2022 16:07:21 - INFO - __main__ -   Batch number = 113
Evaluating:  34%|███▍      | 113/332 [00:33<01:07,  3.23it/s]01/14/2022 16:07:22 - INFO - __main__ -   Batch number = 114
Evaluating:  34%|███▍      | 114/332 [00:33<01:06,  3.26it/s]01/14/2022 16:07:22 - INFO - __main__ -   Batch number = 115
Evaluating:  35%|███▍      | 115/332 [00:33<01:06,  3.28it/s]01/14/2022 16:07:22 - INFO - __main__ -   Batch number = 116
Evaluating:  35%|███▍      | 116/332 [00:34<01:05,  3.29it/s]01/14/2022 16:07:23 - INFO - __main__ -   Batch number = 117
Evaluating:  35%|███▌      | 117/332 [00:34<01:05,  3.30it/s]01/14/2022 16:07:23 - INFO - __main__ -   Batch number = 118
Evaluating:  36%|███▌      | 118/332 [00:34<01:04,  3.31it/s]01/14/2022 16:07:23 - INFO - __main__ -   Batch number = 119
Evaluating:  36%|███▌      | 119/332 [00:35<01:04,  3.32it/s]01/14/2022 16:07:24 - INFO - __main__ -   Batch number = 120
Evaluating:  36%|███▌      | 120/332 [00:35<01:03,  3.34it/s]01/14/2022 16:07:24 - INFO - __main__ -   Batch number = 121
Evaluating:  36%|███▋      | 121/332 [00:35<01:02,  3.35it/s]01/14/2022 16:07:24 - INFO - __main__ -   Batch number = 122
Evaluating:  37%|███▋      | 122/332 [00:35<01:02,  3.36it/s]01/14/2022 16:07:24 - INFO - __main__ -   Batch number = 123
Evaluating:  37%|███▋      | 123/332 [00:36<01:02,  3.36it/s]01/14/2022 16:07:25 - INFO - __main__ -   Batch number = 124
Evaluating:  37%|███▋      | 124/332 [00:36<01:01,  3.36it/s]01/14/2022 16:07:25 - INFO - __main__ -   Batch number = 125
Evaluating:  38%|███▊      | 125/332 [00:36<01:01,  3.37it/s]01/14/2022 16:07:25 - INFO - __main__ -   Batch number = 126
Evaluating:  38%|███▊      | 126/332 [00:37<01:00,  3.38it/s]01/14/2022 16:07:26 - INFO - __main__ -   Batch number = 127
Evaluating:  38%|███▊      | 127/332 [00:37<01:02,  3.26it/s]01/14/2022 16:07:26 - INFO - __main__ -   Batch number = 128
Evaluating:  39%|███▊      | 128/332 [00:37<01:01,  3.31it/s]01/14/2022 16:07:26 - INFO - __main__ -   Batch number = 129
Evaluating:  39%|███▉      | 129/332 [00:38<01:00,  3.34it/s]01/14/2022 16:07:27 - INFO - __main__ -   Batch number = 130
Evaluating:  39%|███▉      | 130/332 [00:38<01:00,  3.36it/s]01/14/2022 16:07:27 - INFO - __main__ -   Batch number = 131
Evaluating:  39%|███▉      | 131/332 [00:38<00:59,  3.37it/s]01/14/2022 16:07:27 - INFO - __main__ -   Batch number = 132
Evaluating:  40%|███▉      | 132/332 [00:38<00:59,  3.37it/s]01/14/2022 16:07:27 - INFO - __main__ -   Batch number = 133
Evaluating:  40%|████      | 133/332 [00:39<00:59,  3.35it/s]01/14/2022 16:07:28 - INFO - __main__ -   Batch number = 134
Evaluating:  40%|████      | 134/332 [00:39<00:59,  3.31it/s]01/14/2022 16:07:28 - INFO - __main__ -   Batch number = 135
Evaluating:  41%|████      | 135/332 [00:39<01:00,  3.27it/s]01/14/2022 16:07:28 - INFO - __main__ -   Batch number = 136
Evaluating:  41%|████      | 136/332 [00:40<01:00,  3.25it/s]01/14/2022 16:07:29 - INFO - __main__ -   Batch number = 137
Evaluating:  41%|████▏     | 137/332 [00:40<01:00,  3.24it/s]01/14/2022 16:07:29 - INFO - __main__ -   Batch number = 138
Evaluating:  42%|████▏     | 138/332 [00:40<01:00,  3.22it/s]01/14/2022 16:07:29 - INFO - __main__ -   Batch number = 139
Evaluating:  42%|████▏     | 139/332 [00:41<01:00,  3.19it/s]01/14/2022 16:07:30 - INFO - __main__ -   Batch number = 140
Evaluating:  42%|████▏     | 140/332 [00:41<01:00,  3.18it/s]01/14/2022 16:07:30 - INFO - __main__ -   Batch number = 141
Evaluating:  42%|████▏     | 141/332 [00:41<01:00,  3.18it/s]01/14/2022 16:07:30 - INFO - __main__ -   Batch number = 142
Evaluating:  43%|████▎     | 142/332 [00:42<01:00,  3.17it/s]01/14/2022 16:07:31 - INFO - __main__ -   Batch number = 143
Evaluating:  43%|████▎     | 143/332 [00:42<01:01,  3.08it/s]01/14/2022 16:07:31 - INFO - __main__ -   Batch number = 144
Evaluating:  43%|████▎     | 144/332 [00:42<01:00,  3.13it/s]01/14/2022 16:07:31 - INFO - __main__ -   Batch number = 145
Evaluating:  44%|████▎     | 145/332 [00:43<00:59,  3.14it/s]01/14/2022 16:07:32 - INFO - __main__ -   Batch number = 146
Evaluating:  44%|████▍     | 146/332 [00:43<00:59,  3.14it/s]01/14/2022 16:07:32 - INFO - __main__ -   Batch number = 147
Evaluating:  44%|████▍     | 147/332 [00:43<00:58,  3.15it/s]01/14/2022 16:07:32 - INFO - __main__ -   Batch number = 148
Evaluating:  45%|████▍     | 148/332 [00:43<00:58,  3.17it/s]01/14/2022 16:07:32 - INFO - __main__ -   Batch number = 149
Evaluating:  45%|████▍     | 149/332 [00:44<00:57,  3.19it/s]01/14/2022 16:07:33 - INFO - __main__ -   Batch number = 150
Evaluating:  45%|████▌     | 150/332 [00:44<00:56,  3.21it/s]01/14/2022 16:07:33 - INFO - __main__ -   Batch number = 151
Evaluating:  45%|████▌     | 151/332 [00:44<00:55,  3.24it/s]01/14/2022 16:07:33 - INFO - __main__ -   Batch number = 152
Evaluating:  46%|████▌     | 152/332 [00:45<00:55,  3.26it/s]01/14/2022 16:07:34 - INFO - __main__ -   Batch number = 153
Evaluating:  46%|████▌     | 153/332 [00:45<00:54,  3.28it/s]01/14/2022 16:07:34 - INFO - __main__ -   Batch number = 154
Evaluating:  46%|████▋     | 154/332 [00:45<00:54,  3.29it/s]01/14/2022 16:07:34 - INFO - __main__ -   Batch number = 155
Evaluating:  47%|████▋     | 155/332 [00:46<00:53,  3.29it/s]01/14/2022 16:07:35 - INFO - __main__ -   Batch number = 156
Evaluating:  47%|████▋     | 156/332 [00:46<00:53,  3.27it/s]01/14/2022 16:07:35 - INFO - __main__ -   Batch number = 157
Evaluating:  47%|████▋     | 157/332 [00:46<00:54,  3.23it/s]01/14/2022 16:07:35 - INFO - __main__ -   Batch number = 158
Evaluating:  48%|████▊     | 158/332 [00:47<00:54,  3.19it/s]01/14/2022 16:07:36 - INFO - __main__ -   Batch number = 159
Evaluating:  48%|████▊     | 159/332 [00:47<01:00,  2.86it/s]01/14/2022 16:07:36 - INFO - __main__ -   Batch number = 160
Evaluating:  48%|████▊     | 160/332 [00:47<00:58,  2.95it/s]01/14/2022 16:07:36 - INFO - __main__ -   Batch number = 161
Evaluating:  48%|████▊     | 161/332 [00:48<00:56,  3.02it/s]01/14/2022 16:07:37 - INFO - __main__ -   Batch number = 162
Evaluating:  49%|████▉     | 162/332 [00:48<00:55,  3.07it/s]01/14/2022 16:07:37 - INFO - __main__ -   Batch number = 163
Evaluating:  49%|████▉     | 163/332 [00:48<00:54,  3.11it/s]01/14/2022 16:07:37 - INFO - __main__ -   Batch number = 164
Evaluating:  49%|████▉     | 164/332 [00:49<00:53,  3.14it/s]01/14/2022 16:07:38 - INFO - __main__ -   Batch number = 165
Evaluating:  50%|████▉     | 165/332 [00:49<00:52,  3.17it/s]01/14/2022 16:07:38 - INFO - __main__ -   Batch number = 166
Evaluating:  50%|█████     | 166/332 [00:49<00:52,  3.19it/s]01/14/2022 16:07:38 - INFO - __main__ -   Batch number = 167
Evaluating:  50%|█████     | 167/332 [00:49<00:51,  3.19it/s]01/14/2022 16:07:38 - INFO - __main__ -   Batch number = 168
Evaluating:  51%|█████     | 168/332 [00:50<00:51,  3.17it/s]01/14/2022 16:07:39 - INFO - __main__ -   Batch number = 169
Evaluating:  51%|█████     | 169/332 [00:50<00:51,  3.17it/s]01/14/2022 16:07:39 - INFO - __main__ -   Batch number = 170
Evaluating:  51%|█████     | 170/332 [00:50<00:51,  3.17it/s]01/14/2022 16:07:39 - INFO - __main__ -   Batch number = 171
Evaluating:  52%|█████▏    | 171/332 [00:51<00:50,  3.17it/s]01/14/2022 16:07:40 - INFO - __main__ -   Batch number = 172
Evaluating:  52%|█████▏    | 172/332 [00:51<00:50,  3.15it/s]01/14/2022 16:07:40 - INFO - __main__ -   Batch number = 173
Evaluating:  52%|█████▏    | 173/332 [00:51<00:49,  3.18it/s]01/14/2022 16:07:40 - INFO - __main__ -   Batch number = 174
Evaluating:  52%|█████▏    | 174/332 [00:52<00:48,  3.23it/s]01/14/2022 16:07:41 - INFO - __main__ -   Batch number = 175
Evaluating:  53%|█████▎    | 175/332 [00:52<00:47,  3.28it/s]01/14/2022 16:07:41 - INFO - __main__ -   Batch number = 176
Evaluating:  53%|█████▎    | 176/332 [00:52<00:47,  3.30it/s]01/14/2022 16:07:41 - INFO - __main__ -   Batch number = 177
Evaluating:  53%|█████▎    | 177/332 [00:53<00:46,  3.31it/s]01/14/2022 16:07:42 - INFO - __main__ -   Batch number = 178
Evaluating:  54%|█████▎    | 178/332 [00:53<00:46,  3.30it/s]01/14/2022 16:07:42 - INFO - __main__ -   Batch number = 179
Evaluating:  54%|█████▍    | 179/332 [00:53<00:47,  3.24it/s]01/14/2022 16:07:42 - INFO - __main__ -   Batch number = 180
Evaluating:  54%|█████▍    | 180/332 [00:54<00:47,  3.21it/s]01/14/2022 16:07:43 - INFO - __main__ -   Batch number = 181
Evaluating:  55%|█████▍    | 181/332 [00:54<00:47,  3.21it/s]01/14/2022 16:07:43 - INFO - __main__ -   Batch number = 182
Evaluating:  55%|█████▍    | 182/332 [00:54<00:46,  3.20it/s]01/14/2022 16:07:43 - INFO - __main__ -   Batch number = 183
Evaluating:  55%|█████▌    | 183/332 [00:54<00:46,  3.21it/s]01/14/2022 16:07:43 - INFO - __main__ -   Batch number = 184
Evaluating:  55%|█████▌    | 184/332 [00:55<00:45,  3.25it/s]01/14/2022 16:07:44 - INFO - __main__ -   Batch number = 185
Evaluating:  56%|█████▌    | 185/332 [00:55<00:44,  3.30it/s]01/14/2022 16:07:44 - INFO - __main__ -   Batch number = 186
Evaluating:  56%|█████▌    | 186/332 [00:55<00:43,  3.32it/s]01/14/2022 16:07:44 - INFO - __main__ -   Batch number = 187
Evaluating:  56%|█████▋    | 187/332 [00:56<00:43,  3.35it/s]01/14/2022 16:07:45 - INFO - __main__ -   Batch number = 188
Evaluating:  57%|█████▋    | 188/332 [00:56<00:42,  3.35it/s]01/14/2022 16:07:45 - INFO - __main__ -   Batch number = 189
Evaluating:  57%|█████▋    | 189/332 [00:56<00:42,  3.34it/s]01/14/2022 16:07:45 - INFO - __main__ -   Batch number = 190
Evaluating:  57%|█████▋    | 190/332 [00:57<00:42,  3.34it/s]01/14/2022 16:07:46 - INFO - __main__ -   Batch number = 191
Evaluating:  58%|█████▊    | 191/332 [00:57<00:47,  2.95it/s]01/14/2022 16:07:46 - INFO - __main__ -   Batch number = 192
Evaluating:  58%|█████▊    | 192/332 [00:57<00:46,  3.01it/s]01/14/2022 16:07:46 - INFO - __main__ -   Batch number = 193
Evaluating:  58%|█████▊    | 193/332 [00:58<00:45,  3.05it/s]01/14/2022 16:07:47 - INFO - __main__ -   Batch number = 194
Evaluating:  58%|█████▊    | 194/332 [00:58<00:44,  3.10it/s]01/14/2022 16:07:47 - INFO - __main__ -   Batch number = 195
Evaluating:  59%|█████▊    | 195/332 [00:58<00:43,  3.16it/s]01/14/2022 16:07:47 - INFO - __main__ -   Batch number = 196
Evaluating:  59%|█████▉    | 196/332 [00:58<00:42,  3.21it/s]01/14/2022 16:07:47 - INFO - __main__ -   Batch number = 197
Evaluating:  59%|█████▉    | 197/332 [00:59<00:41,  3.23it/s]01/14/2022 16:07:48 - INFO - __main__ -   Batch number = 198
Evaluating:  60%|█████▉    | 198/332 [00:59<00:41,  3.25it/s]01/14/2022 16:07:48 - INFO - __main__ -   Batch number = 199
Evaluating:  60%|█████▉    | 199/332 [00:59<00:40,  3.25it/s]01/14/2022 16:07:48 - INFO - __main__ -   Batch number = 200
Evaluating:  60%|██████    | 200/332 [01:00<00:40,  3.23it/s]01/14/2022 16:07:49 - INFO - __main__ -   Batch number = 201
Evaluating:  61%|██████    | 201/332 [01:00<00:40,  3.22it/s]01/14/2022 16:07:49 - INFO - __main__ -   Batch number = 202
Evaluating:  61%|██████    | 202/332 [01:00<00:40,  3.20it/s]01/14/2022 16:07:49 - INFO - __main__ -   Batch number = 203
Evaluating:  61%|██████    | 203/332 [01:01<00:40,  3.19it/s]01/14/2022 16:07:50 - INFO - __main__ -   Batch number = 204
Evaluating:  61%|██████▏   | 204/332 [01:01<00:39,  3.21it/s]01/14/2022 16:07:50 - INFO - __main__ -   Batch number = 205
Evaluating:  62%|██████▏   | 205/332 [01:01<00:39,  3.25it/s]01/14/2022 16:07:50 - INFO - __main__ -   Batch number = 206
Evaluating:  62%|██████▏   | 206/332 [01:02<00:38,  3.29it/s]01/14/2022 16:07:51 - INFO - __main__ -   Batch number = 207
Evaluating:  62%|██████▏   | 207/332 [01:02<00:37,  3.31it/s]01/14/2022 16:07:51 - INFO - __main__ -   Batch number = 208
Evaluating:  63%|██████▎   | 208/332 [01:02<00:37,  3.34it/s]01/14/2022 16:07:51 - INFO - __main__ -   Batch number = 209
Evaluating:  63%|██████▎   | 209/332 [01:02<00:36,  3.37it/s]01/14/2022 16:07:51 - INFO - __main__ -   Batch number = 210
Evaluating:  63%|██████▎   | 210/332 [01:03<00:36,  3.36it/s]01/14/2022 16:07:52 - INFO - __main__ -   Batch number = 211
Evaluating:  64%|██████▎   | 211/332 [01:03<00:36,  3.33it/s]01/14/2022 16:07:52 - INFO - __main__ -   Batch number = 212
Evaluating:  64%|██████▍   | 212/332 [01:03<00:35,  3.35it/s]01/14/2022 16:07:52 - INFO - __main__ -   Batch number = 213
Evaluating:  64%|██████▍   | 213/332 [01:04<00:35,  3.35it/s]01/14/2022 16:07:53 - INFO - __main__ -   Batch number = 214
Evaluating:  64%|██████▍   | 214/332 [01:04<00:35,  3.36it/s]01/14/2022 16:07:53 - INFO - __main__ -   Batch number = 215
Evaluating:  65%|██████▍   | 215/332 [01:04<00:34,  3.35it/s]01/14/2022 16:07:53 - INFO - __main__ -   Batch number = 216
Evaluating:  65%|██████▌   | 216/332 [01:05<00:34,  3.36it/s]01/14/2022 16:07:54 - INFO - __main__ -   Batch number = 217
Evaluating:  65%|██████▌   | 217/332 [01:05<00:34,  3.36it/s]01/14/2022 16:07:54 - INFO - __main__ -   Batch number = 218
Evaluating:  66%|██████▌   | 218/332 [01:05<00:34,  3.34it/s]01/14/2022 16:07:54 - INFO - __main__ -   Batch number = 219
Evaluating:  66%|██████▌   | 219/332 [01:05<00:33,  3.33it/s]01/14/2022 16:07:54 - INFO - __main__ -   Batch number = 220
Evaluating:  66%|██████▋   | 220/332 [01:06<00:33,  3.34it/s]01/14/2022 16:07:55 - INFO - __main__ -   Batch number = 221
Evaluating:  67%|██████▋   | 221/332 [01:06<00:33,  3.34it/s]01/14/2022 16:07:55 - INFO - __main__ -   Batch number = 222
Evaluating:  67%|██████▋   | 222/332 [01:06<00:32,  3.34it/s]01/14/2022 16:07:55 - INFO - __main__ -   Batch number = 223
Evaluating:  67%|██████▋   | 223/332 [01:07<00:32,  3.33it/s]01/14/2022 16:07:56 - INFO - __main__ -   Batch number = 224
Evaluating:  67%|██████▋   | 224/332 [01:07<00:32,  3.34it/s]01/14/2022 16:07:56 - INFO - __main__ -   Batch number = 225
Evaluating:  68%|██████▊   | 225/332 [01:07<00:32,  3.34it/s]01/14/2022 16:07:56 - INFO - __main__ -   Batch number = 226
Evaluating:  68%|██████▊   | 226/332 [01:08<00:31,  3.33it/s]01/14/2022 16:07:57 - INFO - __main__ -   Batch number = 227
Evaluating:  68%|██████▊   | 227/332 [01:08<00:31,  3.33it/s]01/14/2022 16:07:57 - INFO - __main__ -   Batch number = 228
Evaluating:  69%|██████▊   | 228/332 [01:08<00:31,  3.33it/s]01/14/2022 16:07:57 - INFO - __main__ -   Batch number = 229
Evaluating:  69%|██████▉   | 229/332 [01:08<00:30,  3.35it/s]01/14/2022 16:07:57 - INFO - __main__ -   Batch number = 230
Evaluating:  69%|██████▉   | 230/332 [01:09<00:30,  3.37it/s]01/14/2022 16:07:58 - INFO - __main__ -   Batch number = 231
Evaluating:  70%|██████▉   | 231/332 [01:09<00:29,  3.37it/s]01/14/2022 16:07:58 - INFO - __main__ -   Batch number = 232
Evaluating:  70%|██████▉   | 232/332 [01:09<00:29,  3.36it/s]01/14/2022 16:07:58 - INFO - __main__ -   Batch number = 233
Evaluating:  70%|███████   | 233/332 [01:10<00:29,  3.36it/s]01/14/2022 16:07:59 - INFO - __main__ -   Batch number = 234
Evaluating:  70%|███████   | 234/332 [01:10<00:29,  3.36it/s]01/14/2022 16:07:59 - INFO - __main__ -   Batch number = 235
Evaluating:  71%|███████   | 235/332 [01:10<00:28,  3.36it/s]01/14/2022 16:07:59 - INFO - __main__ -   Batch number = 236
Evaluating:  71%|███████   | 236/332 [01:11<00:28,  3.36it/s]01/14/2022 16:08:00 - INFO - __main__ -   Batch number = 237
Evaluating:  71%|███████▏  | 237/332 [01:11<00:28,  3.37it/s]01/14/2022 16:08:00 - INFO - __main__ -   Batch number = 238
Evaluating:  72%|███████▏  | 238/332 [01:11<00:27,  3.38it/s]01/14/2022 16:08:00 - INFO - __main__ -   Batch number = 239
Evaluating:  72%|███████▏  | 239/332 [01:11<00:27,  3.36it/s]01/14/2022 16:08:00 - INFO - __main__ -   Batch number = 240
Evaluating:  72%|███████▏  | 240/332 [01:12<00:27,  3.36it/s]01/14/2022 16:08:01 - INFO - __main__ -   Batch number = 241
Evaluating:  73%|███████▎  | 241/332 [01:12<00:27,  3.35it/s]01/14/2022 16:08:01 - INFO - __main__ -   Batch number = 242
Evaluating:  73%|███████▎  | 242/332 [01:12<00:27,  3.32it/s]01/14/2022 16:08:01 - INFO - __main__ -   Batch number = 243
Evaluating:  73%|███████▎  | 243/332 [01:13<00:27,  3.29it/s]01/14/2022 16:08:02 - INFO - __main__ -   Batch number = 244
Evaluating:  73%|███████▎  | 244/332 [01:13<00:27,  3.25it/s]01/14/2022 16:08:02 - INFO - __main__ -   Batch number = 245
Evaluating:  74%|███████▍  | 245/332 [01:13<00:27,  3.16it/s]01/14/2022 16:08:02 - INFO - __main__ -   Batch number = 246
Evaluating:  74%|███████▍  | 246/332 [01:14<00:27,  3.18it/s]01/14/2022 16:08:03 - INFO - __main__ -   Batch number = 247
Evaluating:  74%|███████▍  | 247/332 [01:14<00:26,  3.20it/s]01/14/2022 16:08:03 - INFO - __main__ -   Batch number = 248
Evaluating:  75%|███████▍  | 248/332 [01:14<00:25,  3.23it/s]01/14/2022 16:08:03 - INFO - __main__ -   Batch number = 249
Evaluating:  75%|███████▌  | 249/332 [01:14<00:25,  3.27it/s]01/14/2022 16:08:03 - INFO - __main__ -   Batch number = 250
Evaluating:  75%|███████▌  | 250/332 [01:15<00:24,  3.29it/s]01/14/2022 16:08:04 - INFO - __main__ -   Batch number = 251
Evaluating:  76%|███████▌  | 251/332 [01:15<00:24,  3.31it/s]01/14/2022 16:08:04 - INFO - __main__ -   Batch number = 252
Evaluating:  76%|███████▌  | 252/332 [01:15<00:24,  3.31it/s]01/14/2022 16:08:04 - INFO - __main__ -   Batch number = 253
Evaluating:  76%|███████▌  | 253/332 [01:16<00:23,  3.31it/s]01/14/2022 16:08:05 - INFO - __main__ -   Batch number = 254
Evaluating:  77%|███████▋  | 254/332 [01:16<00:23,  3.28it/s]01/14/2022 16:08:05 - INFO - __main__ -   Batch number = 255
Evaluating:  77%|███████▋  | 255/332 [01:16<00:23,  3.23it/s]01/14/2022 16:08:05 - INFO - __main__ -   Batch number = 256
Evaluating:  77%|███████▋  | 256/332 [01:17<00:23,  3.22it/s]01/14/2022 16:08:06 - INFO - __main__ -   Batch number = 257
Evaluating:  77%|███████▋  | 257/332 [01:17<00:23,  3.20it/s]01/14/2022 16:08:06 - INFO - __main__ -   Batch number = 258
Evaluating:  78%|███████▊  | 258/332 [01:17<00:22,  3.24it/s]01/14/2022 16:08:06 - INFO - __main__ -   Batch number = 259
Evaluating:  78%|███████▊  | 259/332 [01:18<00:22,  3.24it/s]01/14/2022 16:08:07 - INFO - __main__ -   Batch number = 260
Evaluating:  78%|███████▊  | 260/332 [01:18<00:21,  3.28it/s]01/14/2022 16:08:07 - INFO - __main__ -   Batch number = 261
Evaluating:  79%|███████▊  | 261/332 [01:18<00:21,  3.31it/s]01/14/2022 16:08:07 - INFO - __main__ -   Batch number = 262
Evaluating:  79%|███████▉  | 262/332 [01:18<00:21,  3.30it/s]01/14/2022 16:08:07 - INFO - __main__ -   Batch number = 263
Evaluating:  79%|███████▉  | 263/332 [01:19<00:20,  3.29it/s]01/14/2022 16:08:08 - INFO - __main__ -   Batch number = 264
Evaluating:  80%|███████▉  | 264/332 [01:19<00:20,  3.27it/s]01/14/2022 16:08:08 - INFO - __main__ -   Batch number = 265
Evaluating:  80%|███████▉  | 265/332 [01:19<00:20,  3.23it/s]01/14/2022 16:08:08 - INFO - __main__ -   Batch number = 266
Evaluating:  80%|████████  | 266/332 [01:20<00:20,  3.25it/s]01/14/2022 16:08:09 - INFO - __main__ -   Batch number = 267
Evaluating:  80%|████████  | 267/332 [01:20<00:19,  3.26it/s]01/14/2022 16:08:09 - INFO - __main__ -   Batch number = 268
Evaluating:  81%|████████  | 268/332 [01:20<00:19,  3.23it/s]01/14/2022 16:08:09 - INFO - __main__ -   Batch number = 269
Evaluating:  81%|████████  | 269/332 [01:21<00:19,  3.21it/s]01/14/2022 16:08:10 - INFO - __main__ -   Batch number = 270
Evaluating:  81%|████████▏ | 270/332 [01:21<00:19,  3.19it/s]01/14/2022 16:08:10 - INFO - __main__ -   Batch number = 271
Evaluating:  82%|████████▏ | 271/332 [01:21<00:19,  3.18it/s]01/14/2022 16:08:10 - INFO - __main__ -   Batch number = 272
Evaluating:  82%|████████▏ | 272/332 [01:22<00:18,  3.21it/s]01/14/2022 16:08:11 - INFO - __main__ -   Batch number = 273
Evaluating:  82%|████████▏ | 273/332 [01:22<00:18,  3.22it/s]01/14/2022 16:08:11 - INFO - __main__ -   Batch number = 274
Evaluating:  83%|████████▎ | 274/332 [01:22<00:17,  3.23it/s]01/14/2022 16:08:11 - INFO - __main__ -   Batch number = 275
Evaluating:  83%|████████▎ | 275/332 [01:22<00:17,  3.26it/s]01/14/2022 16:08:11 - INFO - __main__ -   Batch number = 276
Evaluating:  83%|████████▎ | 276/332 [01:23<00:17,  3.28it/s]01/14/2022 16:08:12 - INFO - __main__ -   Batch number = 277
Evaluating:  83%|████████▎ | 277/332 [01:23<00:16,  3.26it/s]01/14/2022 16:08:12 - INFO - __main__ -   Batch number = 278
Evaluating:  84%|████████▎ | 278/332 [01:23<00:16,  3.29it/s]01/14/2022 16:08:12 - INFO - __main__ -   Batch number = 279
Evaluating:  84%|████████▍ | 279/332 [01:24<00:15,  3.32it/s]01/14/2022 16:08:13 - INFO - __main__ -   Batch number = 280
Evaluating:  84%|████████▍ | 280/332 [01:24<00:15,  3.35it/s]01/14/2022 16:08:13 - INFO - __main__ -   Batch number = 281
Evaluating:  85%|████████▍ | 281/332 [01:24<00:15,  3.36it/s]01/14/2022 16:08:13 - INFO - __main__ -   Batch number = 282
Evaluating:  85%|████████▍ | 282/332 [01:25<00:14,  3.38it/s]01/14/2022 16:08:14 - INFO - __main__ -   Batch number = 283
Evaluating:  85%|████████▌ | 283/332 [01:25<00:14,  3.38it/s]01/14/2022 16:08:14 - INFO - __main__ -   Batch number = 284
Evaluating:  86%|████████▌ | 284/332 [01:25<00:14,  3.38it/s]01/14/2022 16:08:14 - INFO - __main__ -   Batch number = 285
Evaluating:  86%|████████▌ | 285/332 [01:25<00:13,  3.39it/s]01/14/2022 16:08:14 - INFO - __main__ -   Batch number = 286
Evaluating:  86%|████████▌ | 286/332 [01:26<00:13,  3.39it/s]01/14/2022 16:08:15 - INFO - __main__ -   Batch number = 287
Evaluating:  86%|████████▋ | 287/332 [01:26<00:13,  3.40it/s]01/14/2022 16:08:15 - INFO - __main__ -   Batch number = 288
Evaluating:  87%|████████▋ | 288/332 [01:26<00:12,  3.40it/s]01/14/2022 16:08:15 - INFO - __main__ -   Batch number = 289
Evaluating:  87%|████████▋ | 289/332 [01:27<00:12,  3.38it/s]01/14/2022 16:08:16 - INFO - __main__ -   Batch number = 290
Evaluating:  87%|████████▋ | 290/332 [01:27<00:12,  3.34it/s]01/14/2022 16:08:16 - INFO - __main__ -   Batch number = 291
Evaluating:  88%|████████▊ | 291/332 [01:27<00:12,  3.33it/s]01/14/2022 16:08:16 - INFO - __main__ -   Batch number = 292
Evaluating:  88%|████████▊ | 292/332 [01:28<00:12,  3.32it/s]01/14/2022 16:08:17 - INFO - __main__ -   Batch number = 293
Evaluating:  88%|████████▊ | 293/332 [01:28<00:11,  3.32it/s]01/14/2022 16:08:17 - INFO - __main__ -   Batch number = 294
Evaluating:  89%|████████▊ | 294/332 [01:28<00:11,  3.32it/s]01/14/2022 16:08:17 - INFO - __main__ -   Batch number = 295
Evaluating:  89%|████████▉ | 295/332 [01:28<00:11,  3.33it/s]01/14/2022 16:08:17 - INFO - __main__ -   Batch number = 296
Evaluating:  89%|████████▉ | 296/332 [01:29<00:10,  3.33it/s]01/14/2022 16:08:18 - INFO - __main__ -   Batch number = 297
Evaluating:  89%|████████▉ | 297/332 [01:29<00:10,  3.34it/s]01/14/2022 16:08:18 - INFO - __main__ -   Batch number = 298
Evaluating:  90%|████████▉ | 298/332 [01:29<00:10,  3.33it/s]01/14/2022 16:08:18 - INFO - __main__ -   Batch number = 299
Evaluating:  90%|█████████ | 299/332 [01:30<00:09,  3.35it/s]01/14/2022 16:08:19 - INFO - __main__ -   Batch number = 300
Evaluating:  90%|█████████ | 300/332 [01:30<00:09,  3.35it/s]01/14/2022 16:08:19 - INFO - __main__ -   Batch number = 301
Evaluating:  91%|█████████ | 301/332 [01:30<00:09,  3.36it/s]01/14/2022 16:08:19 - INFO - __main__ -   Batch number = 302
Evaluating:  91%|█████████ | 302/332 [01:31<00:08,  3.35it/s]01/14/2022 16:08:20 - INFO - __main__ -   Batch number = 303
Evaluating:  91%|█████████▏| 303/332 [01:31<00:08,  3.35it/s]01/14/2022 16:08:20 - INFO - __main__ -   Batch number = 304
Evaluating:  92%|█████████▏| 304/332 [01:31<00:08,  3.32it/s]01/14/2022 16:08:20 - INFO - __main__ -   Batch number = 305
Evaluating:  92%|█████████▏| 305/332 [01:31<00:08,  3.25it/s]01/14/2022 16:08:21 - INFO - __main__ -   Batch number = 306
Evaluating:  92%|█████████▏| 306/332 [01:32<00:08,  2.92it/s]01/14/2022 16:08:21 - INFO - __main__ -   Batch number = 307
Evaluating:  92%|█████████▏| 307/332 [01:32<00:08,  2.97it/s]01/14/2022 16:08:21 - INFO - __main__ -   Batch number = 308
Evaluating:  93%|█████████▎| 308/332 [01:33<00:07,  3.03it/s]01/14/2022 16:08:22 - INFO - __main__ -   Batch number = 309
Evaluating:  93%|█████████▎| 309/332 [01:33<00:07,  3.08it/s]01/14/2022 16:08:22 - INFO - __main__ -   Batch number = 310
Evaluating:  93%|█████████▎| 310/332 [01:33<00:07,  3.10it/s]01/14/2022 16:08:22 - INFO - __main__ -   Batch number = 311
Evaluating:  94%|█████████▎| 311/332 [01:33<00:06,  3.15it/s]01/14/2022 16:08:22 - INFO - __main__ -   Batch number = 312
Evaluating:  94%|█████████▍| 312/332 [01:34<00:06,  3.18it/s]01/14/2022 16:08:23 - INFO - __main__ -   Batch number = 313
Evaluating:  94%|█████████▍| 313/332 [01:34<00:05,  3.23it/s]01/14/2022 16:08:23 - INFO - __main__ -   Batch number = 314
Evaluating:  95%|█████████▍| 314/332 [01:34<00:05,  3.27it/s]01/14/2022 16:08:23 - INFO - __main__ -   Batch number = 315
Evaluating:  95%|█████████▍| 315/332 [01:35<00:05,  3.28it/s]01/14/2022 16:08:24 - INFO - __main__ -   Batch number = 316
Evaluating:  95%|█████████▌| 316/332 [01:35<00:04,  3.29it/s]01/14/2022 16:08:24 - INFO - __main__ -   Batch number = 317
Evaluating:  95%|█████████▌| 317/332 [01:35<00:04,  3.28it/s]01/14/2022 16:08:24 - INFO - __main__ -   Batch number = 318
Evaluating:  96%|█████████▌| 318/332 [01:36<00:04,  3.30it/s]01/14/2022 16:08:25 - INFO - __main__ -   Batch number = 319
Evaluating:  96%|█████████▌| 319/332 [01:36<00:03,  3.32it/s]01/14/2022 16:08:25 - INFO - __main__ -   Batch number = 320
Evaluating:  96%|█████████▋| 320/332 [01:36<00:03,  3.32it/s]01/14/2022 16:08:25 - INFO - __main__ -   Batch number = 321
Evaluating:  97%|█████████▋| 321/332 [01:36<00:03,  3.31it/s]01/14/2022 16:08:26 - INFO - __main__ -   Batch number = 322
Evaluating:  97%|█████████▋| 322/332 [01:37<00:03,  2.82it/s]01/14/2022 16:08:26 - INFO - __main__ -   Batch number = 323
Evaluating:  97%|█████████▋| 323/332 [01:37<00:03,  2.94it/s]01/14/2022 16:08:26 - INFO - __main__ -   Batch number = 324
Evaluating:  98%|█████████▊| 324/332 [01:38<00:02,  3.06it/s]01/14/2022 16:08:27 - INFO - __main__ -   Batch number = 325
Evaluating:  98%|█████████▊| 325/332 [01:38<00:02,  3.07it/s]01/14/2022 16:08:27 - INFO - __main__ -   Batch number = 326
Evaluating:  98%|█████████▊| 326/332 [01:38<00:01,  3.14it/s]01/14/2022 16:08:27 - INFO - __main__ -   Batch number = 327
Evaluating:  98%|█████████▊| 327/332 [01:38<00:01,  3.18it/s]01/14/2022 16:08:27 - INFO - __main__ -   Batch number = 328
Evaluating:  99%|█████████▉| 328/332 [01:39<00:01,  3.24it/s]01/14/2022 16:08:28 - INFO - __main__ -   Batch number = 329
Evaluating:  99%|█████████▉| 329/332 [01:39<00:00,  3.28it/s]01/14/2022 16:08:28 - INFO - __main__ -   Batch number = 330
Evaluating:  99%|█████████▉| 330/332 [01:39<00:00,  3.29it/s]01/14/2022 16:08:28 - INFO - __main__ -   Batch number = 331
Evaluating: 100%|█████████▉| 331/332 [01:40<00:00,  3.32it/s]01/14/2022 16:08:29 - INFO - __main__ -   Batch number = 332
Evaluating: 100%|██████████| 332/332 [01:40<00:00,  3.65it/s]Evaluating: 100%|██████████| 332/332 [01:40<00:00,  3.31it/s]
01/14/2022 16:08:32 - INFO - __main__ -   ***** Evaluation result  in ja *****
01/14/2022 16:08:32 - INFO - __main__ -     f1 = 0.19917680744452398
01/14/2022 16:08:32 - INFO - __main__ -     loss = 4.604087640003986
01/14/2022 16:08:32 - INFO - __main__ -     precision = 0.14505881202958523
01/14/2022 16:08:32 - INFO - __main__ -     recall = 0.3177049882252194
106.41user 42.44system 2:16.85elapsed 108%CPU (0avgtext+0avgdata 4225300maxresident)k
0inputs+2592outputs (0major+2647929minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:08:35 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ja', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:08:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:08:35 - INFO - __main__ -   Seed = 3
01/14/2022 16:08:35 - INFO - root -   save model
01/14/2022 16:08:35 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ja', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:08:35 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:08:37 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:08:43 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:08:43 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:08:43 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:08:43 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:08:43 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:08:43 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,ja/wiki@ukp
01/14/2022 16:08:43 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'ja'], Length : 10
01/14/2022 16:08:43 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'ja/wiki@ukp'], Length : 10
01/14/2022 16:08:43 - INFO - __main__ -   Language = en
01/14/2022 16:08:43 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:08:44 - INFO - __main__ -   Language = pt
01/14/2022 16:08:44 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:08:46 - INFO - __main__ -   Language = id
01/14/2022 16:08:46 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:08:48 - INFO - __main__ -   Language = tr
01/14/2022 16:08:48 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:08:51 - INFO - __main__ -   Language = vi
01/14/2022 16:08:51 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:08:53 - INFO - __main__ -   Language = fa
01/14/2022 16:08:53 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:08:55 - INFO - __main__ -   Language = eu
01/14/2022 16:08:55 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:08:57 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:08:57 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:08:59 - INFO - __main__ -   Language = cs
01/14/2022 16:08:59 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:09:01 - INFO - __main__ -   Language = ja
01/14/2022 16:09:01 - INFO - __main__ -   Adapter Name = ja/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ja/bert-base-multilingual-cased/pfeiffer/ja_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted/adapter_config.json
Adding adapter 'ja' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/33f7674e5dcc12c60ce1dc71157f57efc53ee8197319eb35aafdc432f1ec80e2-b68bc1b6391b647454339755813fc89a9be7a240365678187ee4f8e1dfd52fb2-extracted'
01/14/2022 16:09:05 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:09:06 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'ja']
01/14/2022 16:09:06 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:09:06 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:09:06 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:09:06 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ja_bert-base-multilingual-cased_128
01/14/2022 16:09:07 - INFO - __main__ -   ***** Running evaluation  in ja *****
01/14/2022 16:09:07 - INFO - __main__ -     Num examples = 10612
01/14/2022 16:09:07 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/332 [00:00<?, ?it/s]01/14/2022 16:09:07 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/332 [00:00<01:41,  3.26it/s]01/14/2022 16:09:07 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/332 [00:00<01:36,  3.43it/s]01/14/2022 16:09:07 - INFO - __main__ -   Batch number = 3
Evaluating:   1%|          | 3/332 [00:00<01:34,  3.49it/s]01/14/2022 16:09:08 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/332 [00:01<01:33,  3.52it/s]01/14/2022 16:09:08 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/332 [00:01<01:32,  3.53it/s]01/14/2022 16:09:08 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/332 [00:01<01:32,  3.54it/s]01/14/2022 16:09:08 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/332 [00:01<01:31,  3.55it/s]01/14/2022 16:09:09 - INFO - __main__ -   Batch number = 8
Evaluating:   2%|▏         | 8/332 [00:02<01:31,  3.55it/s]01/14/2022 16:09:09 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/332 [00:02<01:31,  3.55it/s]01/14/2022 16:09:09 - INFO - __main__ -   Batch number = 10
Evaluating:   3%|▎         | 10/332 [00:02<01:30,  3.55it/s]01/14/2022 16:09:10 - INFO - __main__ -   Batch number = 11
Evaluating:   3%|▎         | 11/332 [00:03<01:30,  3.55it/s]01/14/2022 16:09:10 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▎         | 12/332 [00:03<01:30,  3.55it/s]01/14/2022 16:09:10 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/332 [00:03<01:29,  3.55it/s]01/14/2022 16:09:10 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/332 [00:03<01:29,  3.55it/s]01/14/2022 16:09:11 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/332 [00:04<01:29,  3.54it/s]01/14/2022 16:09:11 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▍         | 16/332 [00:04<01:29,  3.55it/s]01/14/2022 16:09:11 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/332 [00:04<01:28,  3.55it/s]01/14/2022 16:09:12 - INFO - __main__ -   Batch number = 18
Evaluating:   5%|▌         | 18/332 [00:05<01:28,  3.54it/s]01/14/2022 16:09:12 - INFO - __main__ -   Batch number = 19
Evaluating:   6%|▌         | 19/332 [00:05<01:28,  3.55it/s]01/14/2022 16:09:12 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▌         | 20/332 [00:05<01:28,  3.54it/s]01/14/2022 16:09:12 - INFO - __main__ -   Batch number = 21
Evaluating:   6%|▋         | 21/332 [00:05<01:27,  3.54it/s]01/14/2022 16:09:13 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/332 [00:06<01:27,  3.54it/s]01/14/2022 16:09:13 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/332 [00:06<01:27,  3.52it/s]01/14/2022 16:09:13 - INFO - __main__ -   Batch number = 24
Evaluating:   7%|▋         | 24/332 [00:06<01:27,  3.53it/s]01/14/2022 16:09:14 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/332 [00:07<01:27,  3.53it/s]01/14/2022 16:09:14 - INFO - __main__ -   Batch number = 26
Evaluating:   8%|▊         | 26/332 [00:07<01:26,  3.53it/s]01/14/2022 16:09:14 - INFO - __main__ -   Batch number = 27
Evaluating:   8%|▊         | 27/332 [00:07<01:26,  3.53it/s]01/14/2022 16:09:14 - INFO - __main__ -   Batch number = 28
Evaluating:   8%|▊         | 28/332 [00:07<01:26,  3.53it/s]01/14/2022 16:09:15 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▊         | 29/332 [00:08<01:25,  3.53it/s]01/14/2022 16:09:15 - INFO - __main__ -   Batch number = 30
Evaluating:   9%|▉         | 30/332 [00:08<01:25,  3.53it/s]01/14/2022 16:09:15 - INFO - __main__ -   Batch number = 31
Evaluating:   9%|▉         | 31/332 [00:08<01:25,  3.53it/s]01/14/2022 16:09:16 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|▉         | 32/332 [00:09<01:27,  3.42it/s]01/14/2022 16:09:16 - INFO - __main__ -   Batch number = 33
Evaluating:  10%|▉         | 33/332 [00:09<01:26,  3.45it/s]01/14/2022 16:09:16 - INFO - __main__ -   Batch number = 34
Evaluating:  10%|█         | 34/332 [00:09<01:26,  3.46it/s]01/14/2022 16:09:16 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/332 [00:09<01:25,  3.48it/s]01/14/2022 16:09:17 - INFO - __main__ -   Batch number = 36
Evaluating:  11%|█         | 36/332 [00:10<01:24,  3.49it/s]01/14/2022 16:09:17 - INFO - __main__ -   Batch number = 37
Evaluating:  11%|█         | 37/332 [00:10<01:24,  3.50it/s]01/14/2022 16:09:17 - INFO - __main__ -   Batch number = 38
Evaluating:  11%|█▏        | 38/332 [00:10<01:24,  3.50it/s]01/14/2022 16:09:18 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/332 [00:11<01:23,  3.51it/s]01/14/2022 16:09:18 - INFO - __main__ -   Batch number = 40
Evaluating:  12%|█▏        | 40/332 [00:11<01:23,  3.51it/s]01/14/2022 16:09:18 - INFO - __main__ -   Batch number = 41
Evaluating:  12%|█▏        | 41/332 [00:11<01:22,  3.51it/s]01/14/2022 16:09:18 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/332 [00:11<01:22,  3.51it/s]01/14/2022 16:09:19 - INFO - __main__ -   Batch number = 43
Evaluating:  13%|█▎        | 43/332 [00:12<01:22,  3.51it/s]01/14/2022 16:09:19 - INFO - __main__ -   Batch number = 44
Evaluating:  13%|█▎        | 44/332 [00:12<01:21,  3.51it/s]01/14/2022 16:09:19 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▎        | 45/332 [00:12<01:21,  3.51it/s]01/14/2022 16:09:19 - INFO - __main__ -   Batch number = 46
Evaluating:  14%|█▍        | 46/332 [00:13<01:21,  3.52it/s]01/14/2022 16:09:20 - INFO - __main__ -   Batch number = 47
Evaluating:  14%|█▍        | 47/332 [00:13<01:21,  3.51it/s]01/14/2022 16:09:20 - INFO - __main__ -   Batch number = 48
Evaluating:  14%|█▍        | 48/332 [00:13<01:20,  3.51it/s]01/14/2022 16:09:20 - INFO - __main__ -   Batch number = 49
Evaluating:  15%|█▍        | 49/332 [00:13<01:20,  3.51it/s]01/14/2022 16:09:21 - INFO - __main__ -   Batch number = 50
Evaluating:  15%|█▌        | 50/332 [00:14<01:20,  3.51it/s]01/14/2022 16:09:21 - INFO - __main__ -   Batch number = 51
Evaluating:  15%|█▌        | 51/332 [00:14<01:20,  3.50it/s]01/14/2022 16:09:21 - INFO - __main__ -   Batch number = 52
Evaluating:  16%|█▌        | 52/332 [00:14<01:19,  3.50it/s]01/14/2022 16:09:21 - INFO - __main__ -   Batch number = 53
Evaluating:  16%|█▌        | 53/332 [00:15<01:19,  3.51it/s]01/14/2022 16:09:22 - INFO - __main__ -   Batch number = 54
Evaluating:  16%|█▋        | 54/332 [00:15<01:19,  3.50it/s]01/14/2022 16:09:22 - INFO - __main__ -   Batch number = 55
Evaluating:  17%|█▋        | 55/332 [00:15<01:18,  3.51it/s]01/14/2022 16:09:22 - INFO - __main__ -   Batch number = 56
Evaluating:  17%|█▋        | 56/332 [00:15<01:18,  3.51it/s]01/14/2022 16:09:23 - INFO - __main__ -   Batch number = 57
Evaluating:  17%|█▋        | 57/332 [00:16<01:18,  3.51it/s]01/14/2022 16:09:23 - INFO - __main__ -   Batch number = 58
Evaluating:  17%|█▋        | 58/332 [00:16<01:18,  3.51it/s]01/14/2022 16:09:23 - INFO - __main__ -   Batch number = 59
Evaluating:  18%|█▊        | 59/332 [00:16<01:17,  3.50it/s]01/14/2022 16:09:23 - INFO - __main__ -   Batch number = 60
Evaluating:  18%|█▊        | 60/332 [00:17<01:17,  3.49it/s]01/14/2022 16:09:24 - INFO - __main__ -   Batch number = 61
Evaluating:  18%|█▊        | 61/332 [00:17<01:17,  3.48it/s]01/14/2022 16:09:24 - INFO - __main__ -   Batch number = 62
Evaluating:  19%|█▊        | 62/332 [00:17<01:17,  3.48it/s]01/14/2022 16:09:24 - INFO - __main__ -   Batch number = 63
Evaluating:  19%|█▉        | 63/332 [00:17<01:17,  3.47it/s]01/14/2022 16:09:25 - INFO - __main__ -   Batch number = 64
Evaluating:  19%|█▉        | 64/332 [00:18<01:17,  3.46it/s]01/14/2022 16:09:25 - INFO - __main__ -   Batch number = 65
Evaluating:  20%|█▉        | 65/332 [00:18<01:17,  3.46it/s]01/14/2022 16:09:25 - INFO - __main__ -   Batch number = 66
Evaluating:  20%|█▉        | 66/332 [00:18<01:16,  3.47it/s]01/14/2022 16:09:26 - INFO - __main__ -   Batch number = 67
Evaluating:  20%|██        | 67/332 [00:19<01:23,  3.18it/s]01/14/2022 16:09:26 - INFO - __main__ -   Batch number = 68
Evaluating:  20%|██        | 68/332 [00:19<01:20,  3.27it/s]01/14/2022 16:09:26 - INFO - __main__ -   Batch number = 69
Evaluating:  21%|██        | 69/332 [00:19<01:19,  3.32it/s]01/14/2022 16:09:26 - INFO - __main__ -   Batch number = 70
Evaluating:  21%|██        | 70/332 [00:20<01:18,  3.35it/s]01/14/2022 16:09:27 - INFO - __main__ -   Batch number = 71
Evaluating:  21%|██▏       | 71/332 [00:20<01:17,  3.39it/s]01/14/2022 16:09:27 - INFO - __main__ -   Batch number = 72
Evaluating:  22%|██▏       | 72/332 [00:20<01:16,  3.41it/s]01/14/2022 16:09:27 - INFO - __main__ -   Batch number = 73
Evaluating:  22%|██▏       | 73/332 [00:20<01:15,  3.43it/s]01/14/2022 16:09:28 - INFO - __main__ -   Batch number = 74
Evaluating:  22%|██▏       | 74/332 [00:21<01:15,  3.44it/s]01/14/2022 16:09:28 - INFO - __main__ -   Batch number = 75
Evaluating:  23%|██▎       | 75/332 [00:21<01:14,  3.43it/s]01/14/2022 16:09:28 - INFO - __main__ -   Batch number = 76
Evaluating:  23%|██▎       | 76/332 [00:21<01:14,  3.42it/s]01/14/2022 16:09:28 - INFO - __main__ -   Batch number = 77
Evaluating:  23%|██▎       | 77/332 [00:22<01:14,  3.42it/s]01/14/2022 16:09:29 - INFO - __main__ -   Batch number = 78
Evaluating:  23%|██▎       | 78/332 [00:22<01:14,  3.41it/s]01/14/2022 16:09:29 - INFO - __main__ -   Batch number = 79
Evaluating:  24%|██▍       | 79/332 [00:22<01:14,  3.41it/s]01/14/2022 16:09:29 - INFO - __main__ -   Batch number = 80
Evaluating:  24%|██▍       | 80/332 [00:22<01:14,  3.40it/s]01/14/2022 16:09:30 - INFO - __main__ -   Batch number = 81
Evaluating:  24%|██▍       | 81/332 [00:23<01:13,  3.39it/s]01/14/2022 16:09:30 - INFO - __main__ -   Batch number = 82
Evaluating:  25%|██▍       | 82/332 [00:23<01:13,  3.39it/s]01/14/2022 16:09:30 - INFO - __main__ -   Batch number = 83
Evaluating:  25%|██▌       | 83/332 [00:23<01:13,  3.41it/s]01/14/2022 16:09:31 - INFO - __main__ -   Batch number = 84
Evaluating:  25%|██▌       | 84/332 [00:24<01:12,  3.42it/s]01/14/2022 16:09:31 - INFO - __main__ -   Batch number = 85
Evaluating:  26%|██▌       | 85/332 [00:24<01:11,  3.44it/s]01/14/2022 16:09:31 - INFO - __main__ -   Batch number = 86
Evaluating:  26%|██▌       | 86/332 [00:24<01:11,  3.44it/s]01/14/2022 16:09:31 - INFO - __main__ -   Batch number = 87
Evaluating:  26%|██▌       | 87/332 [00:25<01:11,  3.43it/s]01/14/2022 16:09:32 - INFO - __main__ -   Batch number = 88
Evaluating:  27%|██▋       | 88/332 [00:25<01:11,  3.42it/s]01/14/2022 16:09:32 - INFO - __main__ -   Batch number = 89
Evaluating:  27%|██▋       | 89/332 [00:25<01:10,  3.43it/s]01/14/2022 16:09:32 - INFO - __main__ -   Batch number = 90
Evaluating:  27%|██▋       | 90/332 [00:25<01:10,  3.44it/s]01/14/2022 16:09:33 - INFO - __main__ -   Batch number = 91
Evaluating:  27%|██▋       | 91/332 [00:26<01:09,  3.45it/s]01/14/2022 16:09:33 - INFO - __main__ -   Batch number = 92
Evaluating:  28%|██▊       | 92/332 [00:26<01:09,  3.44it/s]01/14/2022 16:09:33 - INFO - __main__ -   Batch number = 93
Evaluating:  28%|██▊       | 93/332 [00:26<01:09,  3.43it/s]01/14/2022 16:09:33 - INFO - __main__ -   Batch number = 94
Evaluating:  28%|██▊       | 94/332 [00:27<01:10,  3.39it/s]01/14/2022 16:09:34 - INFO - __main__ -   Batch number = 95
Evaluating:  29%|██▊       | 95/332 [00:27<01:10,  3.37it/s]01/14/2022 16:09:34 - INFO - __main__ -   Batch number = 96
Evaluating:  29%|██▉       | 96/332 [00:27<01:10,  3.35it/s]01/14/2022 16:09:34 - INFO - __main__ -   Batch number = 97
Evaluating:  29%|██▉       | 97/332 [00:27<01:10,  3.33it/s]01/14/2022 16:09:35 - INFO - __main__ -   Batch number = 98
Evaluating:  30%|██▉       | 98/332 [00:28<01:10,  3.30it/s]01/14/2022 16:09:35 - INFO - __main__ -   Batch number = 99
Evaluating:  30%|██▉       | 99/332 [00:28<01:11,  3.27it/s]01/14/2022 16:09:35 - INFO - __main__ -   Batch number = 100
Evaluating:  30%|███       | 100/332 [00:28<01:11,  3.24it/s]01/14/2022 16:09:36 - INFO - __main__ -   Batch number = 101
Evaluating:  30%|███       | 101/332 [00:29<01:11,  3.24it/s]01/14/2022 16:09:36 - INFO - __main__ -   Batch number = 102
Evaluating:  31%|███       | 102/332 [00:29<01:11,  3.23it/s]01/14/2022 16:09:36 - INFO - __main__ -   Batch number = 103
Evaluating:  31%|███       | 103/332 [00:29<01:11,  3.22it/s]01/14/2022 16:09:37 - INFO - __main__ -   Batch number = 104
Evaluating:  31%|███▏      | 104/332 [00:30<01:10,  3.22it/s]01/14/2022 16:09:37 - INFO - __main__ -   Batch number = 105
Evaluating:  32%|███▏      | 105/332 [00:30<01:10,  3.21it/s]01/14/2022 16:09:37 - INFO - __main__ -   Batch number = 106
Evaluating:  32%|███▏      | 106/332 [00:30<01:11,  3.18it/s]01/14/2022 16:09:37 - INFO - __main__ -   Batch number = 107
Evaluating:  32%|███▏      | 107/332 [00:31<01:10,  3.20it/s]01/14/2022 16:09:38 - INFO - __main__ -   Batch number = 108
Evaluating:  33%|███▎      | 108/332 [00:31<01:09,  3.22it/s]01/14/2022 16:09:38 - INFO - __main__ -   Batch number = 109
Evaluating:  33%|███▎      | 109/332 [00:31<01:08,  3.24it/s]01/14/2022 16:09:38 - INFO - __main__ -   Batch number = 110
Evaluating:  33%|███▎      | 110/332 [00:32<01:08,  3.24it/s]01/14/2022 16:09:39 - INFO - __main__ -   Batch number = 111
Evaluating:  33%|███▎      | 111/332 [00:32<01:08,  3.22it/s]01/14/2022 16:09:39 - INFO - __main__ -   Batch number = 112
Evaluating:  34%|███▎      | 112/332 [00:32<01:08,  3.20it/s]01/14/2022 16:09:39 - INFO - __main__ -   Batch number = 113
Evaluating:  34%|███▍      | 113/332 [00:32<01:08,  3.21it/s]01/14/2022 16:09:40 - INFO - __main__ -   Batch number = 114
Evaluating:  34%|███▍      | 114/332 [00:33<01:08,  3.20it/s]01/14/2022 16:09:40 - INFO - __main__ -   Batch number = 115
Evaluating:  35%|███▍      | 115/332 [00:33<01:07,  3.21it/s]01/14/2022 16:09:40 - INFO - __main__ -   Batch number = 116
Evaluating:  35%|███▍      | 116/332 [00:33<01:06,  3.24it/s]01/14/2022 16:09:41 - INFO - __main__ -   Batch number = 117
Evaluating:  35%|███▌      | 117/332 [00:34<01:14,  2.90it/s]01/14/2022 16:09:41 - INFO - __main__ -   Batch number = 118
Evaluating:  36%|███▌      | 118/332 [00:34<01:10,  3.03it/s]01/14/2022 16:09:41 - INFO - __main__ -   Batch number = 119
Evaluating:  36%|███▌      | 119/332 [00:34<01:07,  3.14it/s]01/14/2022 16:09:42 - INFO - __main__ -   Batch number = 120
Evaluating:  36%|███▌      | 120/332 [00:35<01:06,  3.21it/s]01/14/2022 16:09:42 - INFO - __main__ -   Batch number = 121
Evaluating:  36%|███▋      | 121/332 [00:35<01:04,  3.25it/s]01/14/2022 16:09:42 - INFO - __main__ -   Batch number = 122
Evaluating:  37%|███▋      | 122/332 [00:35<01:04,  3.27it/s]01/14/2022 16:09:42 - INFO - __main__ -   Batch number = 123
Evaluating:  37%|███▋      | 123/332 [00:36<01:03,  3.27it/s]01/14/2022 16:09:43 - INFO - __main__ -   Batch number = 124
Evaluating:  37%|███▋      | 124/332 [00:36<01:03,  3.26it/s]01/14/2022 16:09:43 - INFO - __main__ -   Batch number = 125
Evaluating:  38%|███▊      | 125/332 [00:36<01:03,  3.25it/s]01/14/2022 16:09:43 - INFO - __main__ -   Batch number = 126
Evaluating:  38%|███▊      | 126/332 [00:37<01:03,  3.24it/s]01/14/2022 16:09:44 - INFO - __main__ -   Batch number = 127
Evaluating:  38%|███▊      | 127/332 [00:37<01:03,  3.23it/s]01/14/2022 16:09:44 - INFO - __main__ -   Batch number = 128
Evaluating:  39%|███▊      | 128/332 [00:37<01:03,  3.22it/s]01/14/2022 16:09:44 - INFO - __main__ -   Batch number = 129
Evaluating:  39%|███▉      | 129/332 [00:37<01:03,  3.21it/s]01/14/2022 16:09:45 - INFO - __main__ -   Batch number = 130
Evaluating:  39%|███▉      | 130/332 [00:38<01:02,  3.21it/s]01/14/2022 16:09:45 - INFO - __main__ -   Batch number = 131
Evaluating:  39%|███▉      | 131/332 [00:38<01:02,  3.24it/s]01/14/2022 16:09:45 - INFO - __main__ -   Batch number = 132
Evaluating:  40%|███▉      | 132/332 [00:38<01:01,  3.24it/s]01/14/2022 16:09:46 - INFO - __main__ -   Batch number = 133
Evaluating:  40%|████      | 133/332 [00:39<01:01,  3.24it/s]01/14/2022 16:09:46 - INFO - __main__ -   Batch number = 134
Evaluating:  40%|████      | 134/332 [00:39<01:01,  3.23it/s]01/14/2022 16:09:46 - INFO - __main__ -   Batch number = 135
Evaluating:  41%|████      | 135/332 [00:39<01:01,  3.22it/s]01/14/2022 16:09:47 - INFO - __main__ -   Batch number = 136
Evaluating:  41%|████      | 136/332 [00:40<01:00,  3.21it/s]01/14/2022 16:09:47 - INFO - __main__ -   Batch number = 137
Evaluating:  41%|████▏     | 137/332 [00:40<01:00,  3.21it/s]01/14/2022 16:09:47 - INFO - __main__ -   Batch number = 138
Evaluating:  42%|████▏     | 138/332 [00:40<01:00,  3.21it/s]01/14/2022 16:09:47 - INFO - __main__ -   Batch number = 139
Evaluating:  42%|████▏     | 139/332 [00:41<01:00,  3.19it/s]01/14/2022 16:09:48 - INFO - __main__ -   Batch number = 140
Evaluating:  42%|████▏     | 140/332 [00:41<01:00,  3.18it/s]01/14/2022 16:09:48 - INFO - __main__ -   Batch number = 141
Evaluating:  42%|████▏     | 141/332 [00:41<00:59,  3.23it/s]01/14/2022 16:09:48 - INFO - __main__ -   Batch number = 142
Evaluating:  43%|████▎     | 142/332 [00:41<00:57,  3.28it/s]01/14/2022 16:09:49 - INFO - __main__ -   Batch number = 143
Evaluating:  43%|████▎     | 143/332 [00:42<00:56,  3.32it/s]01/14/2022 16:09:49 - INFO - __main__ -   Batch number = 144
Evaluating:  43%|████▎     | 144/332 [00:42<00:56,  3.35it/s]01/14/2022 16:09:49 - INFO - __main__ -   Batch number = 145
Evaluating:  44%|████▎     | 145/332 [00:42<00:55,  3.37it/s]01/14/2022 16:09:50 - INFO - __main__ -   Batch number = 146
Evaluating:  44%|████▍     | 146/332 [00:43<00:54,  3.39it/s]01/14/2022 16:09:50 - INFO - __main__ -   Batch number = 147
Evaluating:  44%|████▍     | 147/332 [00:43<00:54,  3.36it/s]01/14/2022 16:09:50 - INFO - __main__ -   Batch number = 148
Evaluating:  45%|████▍     | 148/332 [00:43<00:54,  3.36it/s]01/14/2022 16:09:50 - INFO - __main__ -   Batch number = 149
Evaluating:  45%|████▍     | 149/332 [00:44<00:54,  3.37it/s]01/14/2022 16:09:51 - INFO - __main__ -   Batch number = 150
Evaluating:  45%|████▌     | 150/332 [00:44<00:54,  3.37it/s]01/14/2022 16:09:51 - INFO - __main__ -   Batch number = 151
Evaluating:  45%|████▌     | 151/332 [00:44<00:53,  3.36it/s]01/14/2022 16:09:51 - INFO - __main__ -   Batch number = 152
Evaluating:  46%|████▌     | 152/332 [00:44<00:53,  3.35it/s]01/14/2022 16:09:52 - INFO - __main__ -   Batch number = 153
Evaluating:  46%|████▌     | 153/332 [00:45<00:53,  3.35it/s]01/14/2022 16:09:52 - INFO - __main__ -   Batch number = 154
Evaluating:  46%|████▋     | 154/332 [00:45<00:53,  3.34it/s]01/14/2022 16:09:52 - INFO - __main__ -   Batch number = 155
Evaluating:  47%|████▋     | 155/332 [00:45<00:53,  3.33it/s]01/14/2022 16:09:53 - INFO - __main__ -   Batch number = 156
Evaluating:  47%|████▋     | 156/332 [00:46<00:52,  3.32it/s]01/14/2022 16:09:53 - INFO - __main__ -   Batch number = 157
Evaluating:  47%|████▋     | 157/332 [00:46<00:52,  3.31it/s]01/14/2022 16:09:53 - INFO - __main__ -   Batch number = 158
Evaluating:  48%|████▊     | 158/332 [00:46<00:52,  3.32it/s]01/14/2022 16:09:53 - INFO - __main__ -   Batch number = 159
Evaluating:  48%|████▊     | 159/332 [00:47<00:51,  3.33it/s]01/14/2022 16:09:54 - INFO - __main__ -   Batch number = 160
Evaluating:  48%|████▊     | 160/332 [00:47<00:51,  3.32it/s]01/14/2022 16:09:54 - INFO - __main__ -   Batch number = 161
Evaluating:  48%|████▊     | 161/332 [00:47<00:51,  3.29it/s]01/14/2022 16:09:54 - INFO - __main__ -   Batch number = 162
Evaluating:  49%|████▉     | 162/332 [00:47<00:52,  3.26it/s]01/14/2022 16:09:55 - INFO - __main__ -   Batch number = 163
Evaluating:  49%|████▉     | 163/332 [00:48<00:52,  3.24it/s]01/14/2022 16:09:55 - INFO - __main__ -   Batch number = 164
Evaluating:  49%|████▉     | 164/332 [00:48<00:52,  3.22it/s]01/14/2022 16:09:55 - INFO - __main__ -   Batch number = 165
Evaluating:  50%|████▉     | 165/332 [00:48<00:51,  3.22it/s]01/14/2022 16:09:56 - INFO - __main__ -   Batch number = 166
Evaluating:  50%|█████     | 166/332 [00:49<00:51,  3.22it/s]01/14/2022 16:09:56 - INFO - __main__ -   Batch number = 167
Evaluating:  50%|█████     | 167/332 [00:49<00:51,  3.22it/s]01/14/2022 16:09:56 - INFO - __main__ -   Batch number = 168
Evaluating:  51%|█████     | 168/332 [00:49<00:50,  3.24it/s]01/14/2022 16:09:57 - INFO - __main__ -   Batch number = 169
Evaluating:  51%|█████     | 169/332 [00:50<00:50,  3.25it/s]01/14/2022 16:09:57 - INFO - __main__ -   Batch number = 170
Evaluating:  51%|█████     | 170/332 [00:50<00:49,  3.27it/s]01/14/2022 16:09:57 - INFO - __main__ -   Batch number = 171
Evaluating:  52%|█████▏    | 171/332 [00:50<00:49,  3.28it/s]01/14/2022 16:09:57 - INFO - __main__ -   Batch number = 172
Evaluating:  52%|█████▏    | 172/332 [00:51<00:48,  3.29it/s]01/14/2022 16:09:58 - INFO - __main__ -   Batch number = 173
Evaluating:  52%|█████▏    | 173/332 [00:51<00:48,  3.29it/s]01/14/2022 16:09:58 - INFO - __main__ -   Batch number = 174
Evaluating:  52%|█████▏    | 174/332 [00:51<00:48,  3.27it/s]01/14/2022 16:09:58 - INFO - __main__ -   Batch number = 175
Evaluating:  53%|█████▎    | 175/332 [00:51<00:48,  3.25it/s]01/14/2022 16:09:59 - INFO - __main__ -   Batch number = 176
Evaluating:  53%|█████▎    | 176/332 [00:52<00:47,  3.26it/s]01/14/2022 16:09:59 - INFO - __main__ -   Batch number = 177
Evaluating:  53%|█████▎    | 177/332 [00:52<00:47,  3.26it/s]01/14/2022 16:09:59 - INFO - __main__ -   Batch number = 178
Evaluating:  54%|█████▎    | 178/332 [00:52<00:47,  3.25it/s]01/14/2022 16:10:00 - INFO - __main__ -   Batch number = 179
Evaluating:  54%|█████▍    | 179/332 [00:53<00:47,  3.23it/s]01/14/2022 16:10:00 - INFO - __main__ -   Batch number = 180
Evaluating:  54%|█████▍    | 180/332 [00:53<00:47,  3.22it/s]01/14/2022 16:10:00 - INFO - __main__ -   Batch number = 181
Evaluating:  55%|█████▍    | 181/332 [00:53<00:51,  2.94it/s]01/14/2022 16:10:01 - INFO - __main__ -   Batch number = 182
Evaluating:  55%|█████▍    | 182/332 [00:54<00:48,  3.07it/s]01/14/2022 16:10:01 - INFO - __main__ -   Batch number = 183
Evaluating:  55%|█████▌    | 183/332 [00:54<00:46,  3.18it/s]01/14/2022 16:10:01 - INFO - __main__ -   Batch number = 184
Evaluating:  55%|█████▌    | 184/332 [00:54<00:45,  3.24it/s]01/14/2022 16:10:02 - INFO - __main__ -   Batch number = 185
Evaluating:  56%|█████▌    | 185/332 [00:55<00:44,  3.28it/s]01/14/2022 16:10:02 - INFO - __main__ -   Batch number = 186
Evaluating:  56%|█████▌    | 186/332 [00:55<00:44,  3.31it/s]01/14/2022 16:10:02 - INFO - __main__ -   Batch number = 187
Evaluating:  56%|█████▋    | 187/332 [00:55<00:43,  3.32it/s]01/14/2022 16:10:02 - INFO - __main__ -   Batch number = 188
Evaluating:  57%|█████▋    | 188/332 [00:55<00:43,  3.33it/s]01/14/2022 16:10:03 - INFO - __main__ -   Batch number = 189
Evaluating:  57%|█████▋    | 189/332 [00:56<00:42,  3.33it/s]01/14/2022 16:10:03 - INFO - __main__ -   Batch number = 190
Evaluating:  57%|█████▋    | 190/332 [00:56<00:42,  3.31it/s]01/14/2022 16:10:03 - INFO - __main__ -   Batch number = 191
Evaluating:  58%|█████▊    | 191/332 [00:56<00:42,  3.29it/s]01/14/2022 16:10:04 - INFO - __main__ -   Batch number = 192
Evaluating:  58%|█████▊    | 192/332 [00:57<00:42,  3.28it/s]01/14/2022 16:10:04 - INFO - __main__ -   Batch number = 193
Evaluating:  58%|█████▊    | 193/332 [00:57<00:42,  3.28it/s]01/14/2022 16:10:04 - INFO - __main__ -   Batch number = 194
Evaluating:  58%|█████▊    | 194/332 [00:57<00:41,  3.29it/s]01/14/2022 16:10:05 - INFO - __main__ -   Batch number = 195
Evaluating:  59%|█████▊    | 195/332 [00:58<00:41,  3.29it/s]01/14/2022 16:10:05 - INFO - __main__ -   Batch number = 196
Evaluating:  59%|█████▉    | 196/332 [00:58<00:41,  3.30it/s]01/14/2022 16:10:05 - INFO - __main__ -   Batch number = 197
Evaluating:  59%|█████▉    | 197/332 [00:58<00:40,  3.30it/s]01/14/2022 16:10:05 - INFO - __main__ -   Batch number = 198
Evaluating:  60%|█████▉    | 198/332 [00:59<00:41,  3.26it/s]01/14/2022 16:10:06 - INFO - __main__ -   Batch number = 199
Evaluating:  60%|█████▉    | 199/332 [00:59<00:40,  3.28it/s]01/14/2022 16:10:06 - INFO - __main__ -   Batch number = 200
Evaluating:  60%|██████    | 200/332 [00:59<00:40,  3.28it/s]01/14/2022 16:10:06 - INFO - __main__ -   Batch number = 201
Evaluating:  61%|██████    | 201/332 [00:59<00:40,  3.27it/s]01/14/2022 16:10:07 - INFO - __main__ -   Batch number = 202
Evaluating:  61%|██████    | 202/332 [01:00<00:39,  3.25it/s]01/14/2022 16:10:07 - INFO - __main__ -   Batch number = 203
Evaluating:  61%|██████    | 203/332 [01:00<00:39,  3.27it/s]01/14/2022 16:10:07 - INFO - __main__ -   Batch number = 204
Evaluating:  61%|██████▏   | 204/332 [01:00<00:39,  3.26it/s]01/14/2022 16:10:08 - INFO - __main__ -   Batch number = 205
Evaluating:  62%|██████▏   | 205/332 [01:01<00:38,  3.26it/s]01/14/2022 16:10:08 - INFO - __main__ -   Batch number = 206
Evaluating:  62%|██████▏   | 206/332 [01:01<00:38,  3.26it/s]01/14/2022 16:10:08 - INFO - __main__ -   Batch number = 207
Evaluating:  62%|██████▏   | 207/332 [01:01<00:38,  3.27it/s]01/14/2022 16:10:09 - INFO - __main__ -   Batch number = 208
Evaluating:  63%|██████▎   | 208/332 [01:02<00:37,  3.29it/s]01/14/2022 16:10:09 - INFO - __main__ -   Batch number = 209
Evaluating:  63%|██████▎   | 209/332 [01:02<00:37,  3.30it/s]01/14/2022 16:10:09 - INFO - __main__ -   Batch number = 210
Evaluating:  63%|██████▎   | 210/332 [01:02<00:37,  3.29it/s]01/14/2022 16:10:09 - INFO - __main__ -   Batch number = 211
Evaluating:  64%|██████▎   | 211/332 [01:03<00:36,  3.27it/s]01/14/2022 16:10:10 - INFO - __main__ -   Batch number = 212
Evaluating:  64%|██████▍   | 212/332 [01:03<00:37,  3.24it/s]01/14/2022 16:10:10 - INFO - __main__ -   Batch number = 213
Evaluating:  64%|██████▍   | 213/332 [01:03<00:36,  3.22it/s]01/14/2022 16:10:10 - INFO - __main__ -   Batch number = 214
Evaluating:  64%|██████▍   | 214/332 [01:03<00:36,  3.21it/s]01/14/2022 16:10:11 - INFO - __main__ -   Batch number = 215
Evaluating:  65%|██████▍   | 215/332 [01:04<00:36,  3.22it/s]01/14/2022 16:10:11 - INFO - __main__ -   Batch number = 216
Evaluating:  65%|██████▌   | 216/332 [01:04<00:35,  3.23it/s]01/14/2022 16:10:11 - INFO - __main__ -   Batch number = 217
Evaluating:  65%|██████▌   | 217/332 [01:04<00:35,  3.23it/s]01/14/2022 16:10:12 - INFO - __main__ -   Batch number = 218
Evaluating:  66%|██████▌   | 218/332 [01:05<00:35,  3.23it/s]01/14/2022 16:10:12 - INFO - __main__ -   Batch number = 219
Evaluating:  66%|██████▌   | 219/332 [01:05<00:35,  3.22it/s]01/14/2022 16:10:12 - INFO - __main__ -   Batch number = 220
Evaluating:  66%|██████▋   | 220/332 [01:05<00:34,  3.22it/s]01/14/2022 16:10:13 - INFO - __main__ -   Batch number = 221
Evaluating:  67%|██████▋   | 221/332 [01:06<00:34,  3.24it/s]01/14/2022 16:10:13 - INFO - __main__ -   Batch number = 222
Evaluating:  67%|██████▋   | 222/332 [01:06<00:33,  3.26it/s]01/14/2022 16:10:13 - INFO - __main__ -   Batch number = 223
Evaluating:  67%|██████▋   | 223/332 [01:06<00:33,  3.28it/s]01/14/2022 16:10:13 - INFO - __main__ -   Batch number = 224
Evaluating:  67%|██████▋   | 224/332 [01:07<00:32,  3.30it/s]01/14/2022 16:10:14 - INFO - __main__ -   Batch number = 225
Evaluating:  68%|██████▊   | 225/332 [01:07<00:32,  3.32it/s]01/14/2022 16:10:14 - INFO - __main__ -   Batch number = 226
Evaluating:  68%|██████▊   | 226/332 [01:07<00:31,  3.33it/s]01/14/2022 16:10:14 - INFO - __main__ -   Batch number = 227
Evaluating:  68%|██████▊   | 227/332 [01:07<00:31,  3.30it/s]01/14/2022 16:10:15 - INFO - __main__ -   Batch number = 228
Evaluating:  69%|██████▊   | 228/332 [01:08<00:31,  3.25it/s]01/14/2022 16:10:15 - INFO - __main__ -   Batch number = 229
Evaluating:  69%|██████▉   | 229/332 [01:08<00:31,  3.23it/s]01/14/2022 16:10:15 - INFO - __main__ -   Batch number = 230
Evaluating:  69%|██████▉   | 230/332 [01:08<00:31,  3.23it/s]01/14/2022 16:10:16 - INFO - __main__ -   Batch number = 231
Evaluating:  70%|██████▉   | 231/332 [01:09<00:31,  3.23it/s]01/14/2022 16:10:16 - INFO - __main__ -   Batch number = 232
Evaluating:  70%|██████▉   | 232/332 [01:09<00:30,  3.24it/s]01/14/2022 16:10:16 - INFO - __main__ -   Batch number = 233
Evaluating:  70%|███████   | 233/332 [01:09<00:30,  3.24it/s]01/14/2022 16:10:17 - INFO - __main__ -   Batch number = 234
Evaluating:  70%|███████   | 234/332 [01:10<00:30,  3.26it/s]01/14/2022 16:10:17 - INFO - __main__ -   Batch number = 235
Evaluating:  71%|███████   | 235/332 [01:10<00:29,  3.27it/s]01/14/2022 16:10:17 - INFO - __main__ -   Batch number = 236
Evaluating:  71%|███████   | 236/332 [01:10<00:29,  3.27it/s]01/14/2022 16:10:17 - INFO - __main__ -   Batch number = 237
Evaluating:  71%|███████▏  | 237/332 [01:11<00:28,  3.28it/s]01/14/2022 16:10:18 - INFO - __main__ -   Batch number = 238
Evaluating:  72%|███████▏  | 238/332 [01:11<00:28,  3.29it/s]01/14/2022 16:10:18 - INFO - __main__ -   Batch number = 239
Evaluating:  72%|███████▏  | 239/332 [01:11<00:28,  3.28it/s]01/14/2022 16:10:18 - INFO - __main__ -   Batch number = 240
Evaluating:  72%|███████▏  | 240/332 [01:11<00:28,  3.27it/s]01/14/2022 16:10:19 - INFO - __main__ -   Batch number = 241
Evaluating:  73%|███████▎  | 241/332 [01:12<00:28,  3.25it/s]01/14/2022 16:10:19 - INFO - __main__ -   Batch number = 242
Evaluating:  73%|███████▎  | 242/332 [01:12<00:27,  3.23it/s]01/14/2022 16:10:19 - INFO - __main__ -   Batch number = 243
Evaluating:  73%|███████▎  | 243/332 [01:12<00:27,  3.24it/s]01/14/2022 16:10:20 - INFO - __main__ -   Batch number = 244
Evaluating:  73%|███████▎  | 244/332 [01:13<00:26,  3.27it/s]01/14/2022 16:10:20 - INFO - __main__ -   Batch number = 245
Evaluating:  74%|███████▍  | 245/332 [01:13<00:26,  3.28it/s]01/14/2022 16:10:20 - INFO - __main__ -   Batch number = 246
Evaluating:  74%|███████▍  | 246/332 [01:13<00:26,  3.29it/s]01/14/2022 16:10:20 - INFO - __main__ -   Batch number = 247
Evaluating:  74%|███████▍  | 247/332 [01:14<00:25,  3.28it/s]01/14/2022 16:10:21 - INFO - __main__ -   Batch number = 248
Evaluating:  75%|███████▍  | 248/332 [01:14<00:25,  3.25it/s]01/14/2022 16:10:21 - INFO - __main__ -   Batch number = 249
Evaluating:  75%|███████▌  | 249/332 [01:14<00:25,  3.23it/s]01/14/2022 16:10:21 - INFO - __main__ -   Batch number = 250
Evaluating:  75%|███████▌  | 250/332 [01:15<00:25,  3.21it/s]01/14/2022 16:10:22 - INFO - __main__ -   Batch number = 251
Evaluating:  76%|███████▌  | 251/332 [01:15<00:25,  3.20it/s]01/14/2022 16:10:22 - INFO - __main__ -   Batch number = 252
Evaluating:  76%|███████▌  | 252/332 [01:15<00:25,  3.19it/s]01/14/2022 16:10:22 - INFO - __main__ -   Batch number = 253
Evaluating:  76%|███████▌  | 253/332 [01:15<00:24,  3.19it/s]01/14/2022 16:10:23 - INFO - __main__ -   Batch number = 254
Evaluating:  77%|███████▋  | 254/332 [01:16<00:26,  2.98it/s]01/14/2022 16:10:23 - INFO - __main__ -   Batch number = 255
Evaluating:  77%|███████▋  | 255/332 [01:16<00:25,  3.06it/s]01/14/2022 16:10:23 - INFO - __main__ -   Batch number = 256
Evaluating:  77%|███████▋  | 256/332 [01:16<00:24,  3.13it/s]01/14/2022 16:10:24 - INFO - __main__ -   Batch number = 257
Evaluating:  77%|███████▋  | 257/332 [01:17<00:23,  3.19it/s]01/14/2022 16:10:24 - INFO - __main__ -   Batch number = 258
Evaluating:  78%|███████▊  | 258/332 [01:17<00:22,  3.23it/s]01/14/2022 16:10:24 - INFO - __main__ -   Batch number = 259
Evaluating:  78%|███████▊  | 259/332 [01:17<00:22,  3.24it/s]01/14/2022 16:10:25 - INFO - __main__ -   Batch number = 260
Evaluating:  78%|███████▊  | 260/332 [01:18<00:22,  3.25it/s]01/14/2022 16:10:25 - INFO - __main__ -   Batch number = 261
Evaluating:  79%|███████▊  | 261/332 [01:18<00:22,  3.22it/s]01/14/2022 16:10:25 - INFO - __main__ -   Batch number = 262
Evaluating:  79%|███████▉  | 262/332 [01:18<00:21,  3.21it/s]01/14/2022 16:10:26 - INFO - __main__ -   Batch number = 263
Evaluating:  79%|███████▉  | 263/332 [01:19<00:21,  3.22it/s]01/14/2022 16:10:26 - INFO - __main__ -   Batch number = 264
Evaluating:  80%|███████▉  | 264/332 [01:19<00:21,  3.22it/s]01/14/2022 16:10:26 - INFO - __main__ -   Batch number = 265
Evaluating:  80%|███████▉  | 265/332 [01:19<00:20,  3.26it/s]01/14/2022 16:10:26 - INFO - __main__ -   Batch number = 266
Evaluating:  80%|████████  | 266/332 [01:20<00:20,  3.28it/s]01/14/2022 16:10:27 - INFO - __main__ -   Batch number = 267
Evaluating:  80%|████████  | 267/332 [01:20<00:19,  3.28it/s]01/14/2022 16:10:27 - INFO - __main__ -   Batch number = 268
Evaluating:  81%|████████  | 268/332 [01:20<00:19,  3.28it/s]01/14/2022 16:10:27 - INFO - __main__ -   Batch number = 269
Evaluating:  81%|████████  | 269/332 [01:20<00:19,  3.29it/s]01/14/2022 16:10:28 - INFO - __main__ -   Batch number = 270
Evaluating:  81%|████████▏ | 270/332 [01:21<00:19,  3.15it/s]01/14/2022 16:10:28 - INFO - __main__ -   Batch number = 271
Evaluating:  82%|████████▏ | 271/332 [01:21<00:19,  3.19it/s]01/14/2022 16:10:28 - INFO - __main__ -   Batch number = 272
Evaluating:  82%|████████▏ | 272/332 [01:21<00:18,  3.23it/s]01/14/2022 16:10:29 - INFO - __main__ -   Batch number = 273
Evaluating:  82%|████████▏ | 273/332 [01:22<00:18,  3.25it/s]01/14/2022 16:10:29 - INFO - __main__ -   Batch number = 274
Evaluating:  83%|████████▎ | 274/332 [01:22<00:17,  3.28it/s]01/14/2022 16:10:29 - INFO - __main__ -   Batch number = 275
Evaluating:  83%|████████▎ | 275/332 [01:22<00:17,  3.31it/s]01/14/2022 16:10:29 - INFO - __main__ -   Batch number = 276
Evaluating:  83%|████████▎ | 276/332 [01:23<00:16,  3.33it/s]01/14/2022 16:10:30 - INFO - __main__ -   Batch number = 277
Evaluating:  83%|████████▎ | 277/332 [01:23<00:16,  3.33it/s]01/14/2022 16:10:30 - INFO - __main__ -   Batch number = 278
Evaluating:  84%|████████▎ | 278/332 [01:23<00:16,  3.35it/s]01/14/2022 16:10:30 - INFO - __main__ -   Batch number = 279
Evaluating:  84%|████████▍ | 279/332 [01:23<00:15,  3.36it/s]01/14/2022 16:10:31 - INFO - __main__ -   Batch number = 280
Evaluating:  84%|████████▍ | 280/332 [01:24<00:15,  3.38it/s]01/14/2022 16:10:31 - INFO - __main__ -   Batch number = 281
Evaluating:  85%|████████▍ | 281/332 [01:24<00:15,  3.39it/s]01/14/2022 16:10:31 - INFO - __main__ -   Batch number = 282
Evaluating:  85%|████████▍ | 282/332 [01:24<00:14,  3.39it/s]01/14/2022 16:10:32 - INFO - __main__ -   Batch number = 283
Evaluating:  85%|████████▌ | 283/332 [01:25<00:14,  3.40it/s]01/14/2022 16:10:32 - INFO - __main__ -   Batch number = 284
Evaluating:  86%|████████▌ | 284/332 [01:25<00:14,  3.40it/s]01/14/2022 16:10:32 - INFO - __main__ -   Batch number = 285
Evaluating:  86%|████████▌ | 285/332 [01:25<00:13,  3.38it/s]01/14/2022 16:10:32 - INFO - __main__ -   Batch number = 286
Evaluating:  86%|████████▌ | 286/332 [01:26<00:13,  3.36it/s]01/14/2022 16:10:33 - INFO - __main__ -   Batch number = 287
Evaluating:  86%|████████▋ | 287/332 [01:26<00:13,  3.35it/s]01/14/2022 16:10:33 - INFO - __main__ -   Batch number = 288
Evaluating:  87%|████████▋ | 288/332 [01:26<00:13,  3.36it/s]01/14/2022 16:10:33 - INFO - __main__ -   Batch number = 289
Evaluating:  87%|████████▋ | 289/332 [01:26<00:12,  3.37it/s]01/14/2022 16:10:34 - INFO - __main__ -   Batch number = 290
Evaluating:  87%|████████▋ | 290/332 [01:27<00:12,  3.38it/s]01/14/2022 16:10:34 - INFO - __main__ -   Batch number = 291
Evaluating:  88%|████████▊ | 291/332 [01:27<00:12,  3.39it/s]01/14/2022 16:10:34 - INFO - __main__ -   Batch number = 292
Evaluating:  88%|████████▊ | 292/332 [01:27<00:11,  3.39it/s]01/14/2022 16:10:35 - INFO - __main__ -   Batch number = 293
Evaluating:  88%|████████▊ | 293/332 [01:28<00:11,  3.39it/s]01/14/2022 16:10:35 - INFO - __main__ -   Batch number = 294
Evaluating:  89%|████████▊ | 294/332 [01:28<00:11,  3.37it/s]01/14/2022 16:10:35 - INFO - __main__ -   Batch number = 295
Evaluating:  89%|████████▉ | 295/332 [01:28<00:11,  3.36it/s]01/14/2022 16:10:35 - INFO - __main__ -   Batch number = 296
Evaluating:  89%|████████▉ | 296/332 [01:29<00:10,  3.31it/s]01/14/2022 16:10:36 - INFO - __main__ -   Batch number = 297
Evaluating:  89%|████████▉ | 297/332 [01:29<00:10,  3.28it/s]01/14/2022 16:10:36 - INFO - __main__ -   Batch number = 298
Evaluating:  90%|████████▉ | 298/332 [01:29<00:10,  3.24it/s]01/14/2022 16:10:36 - INFO - __main__ -   Batch number = 299
Evaluating:  90%|█████████ | 299/332 [01:29<00:10,  3.19it/s]01/14/2022 16:10:37 - INFO - __main__ -   Batch number = 300
Evaluating:  90%|█████████ | 300/332 [01:30<00:09,  3.20it/s]01/14/2022 16:10:37 - INFO - __main__ -   Batch number = 301
Evaluating:  91%|█████████ | 301/332 [01:30<00:09,  3.23it/s]01/14/2022 16:10:37 - INFO - __main__ -   Batch number = 302
Evaluating:  91%|█████████ | 302/332 [01:30<00:09,  3.25it/s]01/14/2022 16:10:38 - INFO - __main__ -   Batch number = 303
Evaluating:  91%|█████████▏| 303/332 [01:31<00:08,  3.28it/s]01/14/2022 16:10:38 - INFO - __main__ -   Batch number = 304
Evaluating:  92%|█████████▏| 304/332 [01:31<00:08,  3.25it/s]01/14/2022 16:10:38 - INFO - __main__ -   Batch number = 305
Evaluating:  92%|█████████▏| 305/332 [01:31<00:08,  3.27it/s]01/14/2022 16:10:39 - INFO - __main__ -   Batch number = 306
Evaluating:  92%|█████████▏| 306/332 [01:32<00:07,  3.29it/s]01/14/2022 16:10:39 - INFO - __main__ -   Batch number = 307
Evaluating:  92%|█████████▏| 307/332 [01:32<00:07,  3.29it/s]01/14/2022 16:10:39 - INFO - __main__ -   Batch number = 308
Evaluating:  93%|█████████▎| 308/332 [01:32<00:07,  3.28it/s]01/14/2022 16:10:39 - INFO - __main__ -   Batch number = 309
Evaluating:  93%|█████████▎| 309/332 [01:33<00:07,  3.28it/s]01/14/2022 16:10:40 - INFO - __main__ -   Batch number = 310
Evaluating:  93%|█████████▎| 310/332 [01:33<00:06,  3.26it/s]01/14/2022 16:10:40 - INFO - __main__ -   Batch number = 311
Evaluating:  94%|█████████▎| 311/332 [01:33<00:06,  3.23it/s]01/14/2022 16:10:40 - INFO - __main__ -   Batch number = 312
Evaluating:  94%|█████████▍| 312/332 [01:33<00:06,  3.20it/s]01/14/2022 16:10:41 - INFO - __main__ -   Batch number = 313
Evaluating:  94%|█████████▍| 313/332 [01:34<00:05,  3.19it/s]01/14/2022 16:10:41 - INFO - __main__ -   Batch number = 314
Evaluating:  95%|█████████▍| 314/332 [01:34<00:06,  2.71it/s]01/14/2022 16:10:41 - INFO - __main__ -   Batch number = 315
Evaluating:  95%|█████████▍| 315/332 [01:35<00:06,  2.83it/s]01/14/2022 16:10:42 - INFO - __main__ -   Batch number = 316
Evaluating:  95%|█████████▌| 316/332 [01:35<00:05,  2.93it/s]01/14/2022 16:10:42 - INFO - __main__ -   Batch number = 317
Evaluating:  95%|█████████▌| 317/332 [01:35<00:04,  3.01it/s]01/14/2022 16:10:42 - INFO - __main__ -   Batch number = 318
Evaluating:  96%|█████████▌| 318/332 [01:36<00:04,  3.11it/s]01/14/2022 16:10:43 - INFO - __main__ -   Batch number = 319
Evaluating:  96%|█████████▌| 319/332 [01:36<00:04,  3.19it/s]01/14/2022 16:10:43 - INFO - __main__ -   Batch number = 320
Evaluating:  96%|█████████▋| 320/332 [01:36<00:03,  3.22it/s]01/14/2022 16:10:43 - INFO - __main__ -   Batch number = 321
Evaluating:  97%|█████████▋| 321/332 [01:36<00:03,  3.26it/s]01/14/2022 16:10:44 - INFO - __main__ -   Batch number = 322
Evaluating:  97%|█████████▋| 322/332 [01:37<00:03,  3.27it/s]01/14/2022 16:10:44 - INFO - __main__ -   Batch number = 323
Evaluating:  97%|█████████▋| 323/332 [01:37<00:02,  3.23it/s]01/14/2022 16:10:44 - INFO - __main__ -   Batch number = 324
Evaluating:  98%|█████████▊| 324/332 [01:37<00:02,  3.22it/s]01/14/2022 16:10:45 - INFO - __main__ -   Batch number = 325
Evaluating:  98%|█████████▊| 325/332 [01:38<00:02,  3.22it/s]01/14/2022 16:10:45 - INFO - __main__ -   Batch number = 326
Evaluating:  98%|█████████▊| 326/332 [01:38<00:01,  3.21it/s]01/14/2022 16:10:45 - INFO - __main__ -   Batch number = 327
Evaluating:  98%|█████████▊| 327/332 [01:38<00:01,  3.23it/s]01/14/2022 16:10:45 - INFO - __main__ -   Batch number = 328
Evaluating:  99%|█████████▉| 328/332 [01:39<00:01,  3.25it/s]01/14/2022 16:10:46 - INFO - __main__ -   Batch number = 329
Evaluating:  99%|█████████▉| 329/332 [01:39<00:00,  3.26it/s]01/14/2022 16:10:46 - INFO - __main__ -   Batch number = 330
Evaluating:  99%|█████████▉| 330/332 [01:39<00:00,  3.27it/s]01/14/2022 16:10:46 - INFO - __main__ -   Batch number = 331
Evaluating: 100%|█████████▉| 331/332 [01:40<00:00,  3.24it/s]01/14/2022 16:10:47 - INFO - __main__ -   Batch number = 332
Evaluating: 100%|██████████| 332/332 [01:40<00:00,  3.53it/s]Evaluating: 100%|██████████| 332/332 [01:40<00:00,  3.31it/s]
01/14/2022 16:10:51 - INFO - __main__ -   ***** Evaluation result  in ja *****
01/14/2022 16:10:51 - INFO - __main__ -     f1 = 0.21671729807005002
01/14/2022 16:10:51 - INFO - __main__ -     loss = 4.282998661678958
01/14/2022 16:10:51 - INFO - __main__ -     precision = 0.15773045033327915
01/14/2022 16:10:51 - INFO - __main__ -     recall = 0.34617854849068724
111.99user 41.90system 2:18.16elapsed 111%CPU (0avgtext+0avgdata 4225060maxresident)k
0inputs+2504outputs (0major+2675568minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:12:55 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='zh', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:12:55 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:12:55 - INFO - __main__ -   Seed = 1
01/14/2022 16:12:55 - INFO - root -   save model
01/14/2022 16:12:55 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='zh', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:12:55 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:12:57 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:13:03 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:13:03 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:13:03 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:13:03 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:13:03 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:13:03 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,zh/wiki@ukp
01/14/2022 16:13:03 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'zh'], Length : 10
01/14/2022 16:13:03 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'zh/wiki@ukp'], Length : 10
01/14/2022 16:13:03 - INFO - __main__ -   Language = en
01/14/2022 16:13:03 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:13:05 - INFO - __main__ -   Language = pt
01/14/2022 16:13:05 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:13:06 - INFO - __main__ -   Language = id
01/14/2022 16:13:06 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:13:08 - INFO - __main__ -   Language = cs
01/14/2022 16:13:08 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:13:10 - INFO - __main__ -   Language = tr
01/14/2022 16:13:10 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:13:13 - INFO - __main__ -   Language = eu
01/14/2022 16:13:13 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:13:15 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:13:15 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:13:17 - INFO - __main__ -   Language = vi
01/14/2022 16:13:17 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:13:19 - INFO - __main__ -   Language = fr
01/14/2022 16:13:19 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:13:20 - INFO - __main__ -   Language = zh
01/14/2022 16:13:20 - INFO - __main__ -   Adapter Name = zh/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh/bert-base-multilingual-cased/pfeiffer/zh_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted/adapter_config.json
Adding adapter 'zh' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted/pytorch_adapter.bin
Some module weights could not be found in loaded weights file: encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, invertible_lang_adapters.zh_yue.F.0.weight, invertible_lang_adapters.zh_yue.F.0.bias, invertible_lang_adapters.zh_yue.F.2.weight, invertible_lang_adapters.zh_yue.F.2.bias, invertible_lang_adapters.zh_yue.G.0.weight, invertible_lang_adapters.zh_yue.G.0.bias, invertible_lang_adapters.zh_yue.G.2.weight, invertible_lang_adapters.zh_yue.G.2.bias
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted'
01/14/2022 16:13:25 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:13:25 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'zh']
01/14/2022 16:13:25 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:13:25 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:13:25 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:13:25 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_zh_bert-base-multilingual-cased_128
01/14/2022 16:13:26 - INFO - __main__ -   ***** Running evaluation  in zh *****
01/14/2022 16:13:26 - INFO - __main__ -     Num examples = 10257
01/14/2022 16:13:26 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/321 [00:00<?, ?it/s]01/14/2022 16:13:26 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/321 [00:00<01:38,  3.25it/s]01/14/2022 16:13:26 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/321 [00:00<01:33,  3.42it/s]01/14/2022 16:13:27 - INFO - __main__ -   Batch number = 3
Evaluating:   1%|          | 3/321 [00:00<01:31,  3.49it/s]01/14/2022 16:13:27 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/321 [00:01<01:29,  3.53it/s]01/14/2022 16:13:27 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/321 [00:01<01:29,  3.54it/s]01/14/2022 16:13:27 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/321 [00:01<01:28,  3.56it/s]01/14/2022 16:13:28 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/321 [00:01<01:28,  3.56it/s]01/14/2022 16:13:28 - INFO - __main__ -   Batch number = 8
Evaluating:   2%|▏         | 8/321 [00:02<01:27,  3.57it/s]01/14/2022 16:13:28 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/321 [00:02<01:27,  3.57it/s]01/14/2022 16:13:29 - INFO - __main__ -   Batch number = 10
Evaluating:   3%|▎         | 10/321 [00:02<01:27,  3.57it/s]01/14/2022 16:13:29 - INFO - __main__ -   Batch number = 11
Evaluating:   3%|▎         | 11/321 [00:03<01:27,  3.56it/s]01/14/2022 16:13:29 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▎         | 12/321 [00:03<01:26,  3.56it/s]01/14/2022 16:13:29 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/321 [00:03<01:26,  3.55it/s]01/14/2022 16:13:30 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/321 [00:03<01:26,  3.56it/s]01/14/2022 16:13:30 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/321 [00:04<01:26,  3.55it/s]01/14/2022 16:13:30 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▍         | 16/321 [00:04<01:25,  3.56it/s]01/14/2022 16:13:31 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/321 [00:04<01:25,  3.55it/s]01/14/2022 16:13:31 - INFO - __main__ -   Batch number = 18
Evaluating:   6%|▌         | 18/321 [00:05<01:25,  3.55it/s]01/14/2022 16:13:31 - INFO - __main__ -   Batch number = 19
Evaluating:   6%|▌         | 19/321 [00:05<01:24,  3.56it/s]01/14/2022 16:13:31 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▌         | 20/321 [00:05<01:24,  3.56it/s]01/14/2022 16:13:32 - INFO - __main__ -   Batch number = 21
Evaluating:   7%|▋         | 21/321 [00:05<01:24,  3.56it/s]01/14/2022 16:13:32 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/321 [00:06<01:24,  3.56it/s]01/14/2022 16:13:32 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/321 [00:06<01:23,  3.55it/s]01/14/2022 16:13:32 - INFO - __main__ -   Batch number = 24
Evaluating:   7%|▋         | 24/321 [00:06<01:23,  3.55it/s]01/14/2022 16:13:33 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/321 [00:07<01:23,  3.55it/s]01/14/2022 16:13:33 - INFO - __main__ -   Batch number = 26
Evaluating:   8%|▊         | 26/321 [00:07<01:23,  3.55it/s]01/14/2022 16:13:33 - INFO - __main__ -   Batch number = 27
Evaluating:   8%|▊         | 27/321 [00:07<01:22,  3.55it/s]01/14/2022 16:13:34 - INFO - __main__ -   Batch number = 28
Evaluating:   9%|▊         | 28/321 [00:07<01:22,  3.55it/s]01/14/2022 16:13:34 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▉         | 29/321 [00:08<01:22,  3.55it/s]01/14/2022 16:13:34 - INFO - __main__ -   Batch number = 30
Evaluating:   9%|▉         | 30/321 [00:08<01:22,  3.54it/s]01/14/2022 16:13:34 - INFO - __main__ -   Batch number = 31
Evaluating:  10%|▉         | 31/321 [00:08<01:21,  3.55it/s]01/14/2022 16:13:35 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|▉         | 32/321 [00:09<01:21,  3.55it/s]01/14/2022 16:13:35 - INFO - __main__ -   Batch number = 33
Evaluating:  10%|█         | 33/321 [00:09<01:21,  3.55it/s]01/14/2022 16:13:35 - INFO - __main__ -   Batch number = 34
Evaluating:  11%|█         | 34/321 [00:09<01:20,  3.54it/s]01/14/2022 16:13:36 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/321 [00:09<01:20,  3.54it/s]01/14/2022 16:13:36 - INFO - __main__ -   Batch number = 36
Evaluating:  11%|█         | 36/321 [00:10<01:20,  3.53it/s]01/14/2022 16:13:36 - INFO - __main__ -   Batch number = 37
Evaluating:  12%|█▏        | 37/321 [00:10<01:20,  3.53it/s]01/14/2022 16:13:36 - INFO - __main__ -   Batch number = 38
Evaluating:  12%|█▏        | 38/321 [00:10<01:20,  3.53it/s]01/14/2022 16:13:37 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/321 [00:11<01:19,  3.53it/s]01/14/2022 16:13:37 - INFO - __main__ -   Batch number = 40
Evaluating:  12%|█▏        | 40/321 [00:11<01:19,  3.53it/s]01/14/2022 16:13:37 - INFO - __main__ -   Batch number = 41
Evaluating:  13%|█▎        | 41/321 [00:11<01:19,  3.53it/s]01/14/2022 16:13:38 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/321 [00:11<01:18,  3.53it/s]01/14/2022 16:13:38 - INFO - __main__ -   Batch number = 43
Evaluating:  13%|█▎        | 43/321 [00:12<01:18,  3.53it/s]01/14/2022 16:13:38 - INFO - __main__ -   Batch number = 44
Evaluating:  14%|█▎        | 44/321 [00:12<01:18,  3.53it/s]01/14/2022 16:13:38 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▍        | 45/321 [00:12<01:18,  3.53it/s]01/14/2022 16:13:39 - INFO - __main__ -   Batch number = 46
Evaluating:  14%|█▍        | 46/321 [00:13<01:26,  3.17it/s]01/14/2022 16:13:39 - INFO - __main__ -   Batch number = 47
Evaluating:  15%|█▍        | 47/321 [00:13<01:23,  3.27it/s]01/14/2022 16:13:39 - INFO - __main__ -   Batch number = 48
Evaluating:  15%|█▍        | 48/321 [00:13<01:21,  3.34it/s]01/14/2022 16:13:40 - INFO - __main__ -   Batch number = 49
Evaluating:  15%|█▌        | 49/321 [00:13<01:20,  3.39it/s]01/14/2022 16:13:40 - INFO - __main__ -   Batch number = 50
Evaluating:  16%|█▌        | 50/321 [00:14<01:18,  3.43it/s]01/14/2022 16:13:40 - INFO - __main__ -   Batch number = 51
Evaluating:  16%|█▌        | 51/321 [00:14<01:18,  3.46it/s]01/14/2022 16:13:41 - INFO - __main__ -   Batch number = 52
Evaluating:  16%|█▌        | 52/321 [00:14<01:17,  3.48it/s]01/14/2022 16:13:41 - INFO - __main__ -   Batch number = 53
Evaluating:  17%|█▋        | 53/321 [00:15<01:16,  3.50it/s]01/14/2022 16:13:41 - INFO - __main__ -   Batch number = 54
Evaluating:  17%|█▋        | 54/321 [00:15<01:16,  3.51it/s]01/14/2022 16:13:41 - INFO - __main__ -   Batch number = 55
Evaluating:  17%|█▋        | 55/321 [00:15<01:15,  3.52it/s]01/14/2022 16:13:42 - INFO - __main__ -   Batch number = 56
Evaluating:  17%|█▋        | 56/321 [00:15<01:15,  3.52it/s]01/14/2022 16:13:42 - INFO - __main__ -   Batch number = 57
Evaluating:  18%|█▊        | 57/321 [00:16<01:14,  3.53it/s]01/14/2022 16:13:42 - INFO - __main__ -   Batch number = 58
Evaluating:  18%|█▊        | 58/321 [00:16<01:14,  3.53it/s]01/14/2022 16:13:42 - INFO - __main__ -   Batch number = 59
Evaluating:  18%|█▊        | 59/321 [00:16<01:14,  3.53it/s]01/14/2022 16:13:43 - INFO - __main__ -   Batch number = 60
Evaluating:  19%|█▊        | 60/321 [00:17<01:14,  3.52it/s]01/14/2022 16:13:43 - INFO - __main__ -   Batch number = 61
Evaluating:  19%|█▉        | 61/321 [00:17<01:13,  3.52it/s]01/14/2022 16:13:43 - INFO - __main__ -   Batch number = 62
Evaluating:  19%|█▉        | 62/321 [00:17<01:13,  3.52it/s]01/14/2022 16:13:44 - INFO - __main__ -   Batch number = 63
Evaluating:  20%|█▉        | 63/321 [00:17<01:13,  3.51it/s]01/14/2022 16:13:44 - INFO - __main__ -   Batch number = 64
Evaluating:  20%|█▉        | 64/321 [00:18<01:13,  3.51it/s]01/14/2022 16:13:44 - INFO - __main__ -   Batch number = 65
Evaluating:  20%|██        | 65/321 [00:18<01:12,  3.51it/s]01/14/2022 16:13:44 - INFO - __main__ -   Batch number = 66
Evaluating:  21%|██        | 66/321 [00:18<01:12,  3.51it/s]01/14/2022 16:13:45 - INFO - __main__ -   Batch number = 67
Evaluating:  21%|██        | 67/321 [00:19<01:12,  3.51it/s]01/14/2022 16:13:45 - INFO - __main__ -   Batch number = 68
Evaluating:  21%|██        | 68/321 [00:19<01:12,  3.51it/s]01/14/2022 16:13:45 - INFO - __main__ -   Batch number = 69
Evaluating:  21%|██▏       | 69/321 [00:19<01:11,  3.51it/s]01/14/2022 16:13:46 - INFO - __main__ -   Batch number = 70
Evaluating:  22%|██▏       | 70/321 [00:19<01:11,  3.51it/s]01/14/2022 16:13:46 - INFO - __main__ -   Batch number = 71
Evaluating:  22%|██▏       | 71/321 [00:20<01:11,  3.51it/s]01/14/2022 16:13:46 - INFO - __main__ -   Batch number = 72
Evaluating:  22%|██▏       | 72/321 [00:20<01:11,  3.49it/s]01/14/2022 16:13:46 - INFO - __main__ -   Batch number = 73
Evaluating:  23%|██▎       | 73/321 [00:20<01:11,  3.49it/s]01/14/2022 16:13:47 - INFO - __main__ -   Batch number = 74
Evaluating:  23%|██▎       | 74/321 [00:21<01:10,  3.49it/s]01/14/2022 16:13:47 - INFO - __main__ -   Batch number = 75
Evaluating:  23%|██▎       | 75/321 [00:21<01:10,  3.50it/s]01/14/2022 16:13:47 - INFO - __main__ -   Batch number = 76
Evaluating:  24%|██▎       | 76/321 [00:21<01:09,  3.50it/s]01/14/2022 16:13:48 - INFO - __main__ -   Batch number = 77
Evaluating:  24%|██▍       | 77/321 [00:21<01:09,  3.50it/s]01/14/2022 16:13:48 - INFO - __main__ -   Batch number = 78
Evaluating:  24%|██▍       | 78/321 [00:22<01:09,  3.50it/s]01/14/2022 16:13:48 - INFO - __main__ -   Batch number = 79
Evaluating:  25%|██▍       | 79/321 [00:22<01:09,  3.50it/s]01/14/2022 16:13:48 - INFO - __main__ -   Batch number = 80
Evaluating:  25%|██▍       | 80/321 [00:22<01:08,  3.50it/s]01/14/2022 16:13:49 - INFO - __main__ -   Batch number = 81
Evaluating:  25%|██▌       | 81/321 [00:23<01:08,  3.49it/s]01/14/2022 16:13:49 - INFO - __main__ -   Batch number = 82
Evaluating:  26%|██▌       | 82/321 [00:23<01:08,  3.48it/s]01/14/2022 16:13:49 - INFO - __main__ -   Batch number = 83
Evaluating:  26%|██▌       | 83/321 [00:23<01:08,  3.48it/s]01/14/2022 16:13:50 - INFO - __main__ -   Batch number = 84
Evaluating:  26%|██▌       | 84/321 [00:23<01:08,  3.48it/s]01/14/2022 16:13:50 - INFO - __main__ -   Batch number = 85
Evaluating:  26%|██▋       | 85/321 [00:24<01:08,  3.47it/s]01/14/2022 16:13:50 - INFO - __main__ -   Batch number = 86
Evaluating:  27%|██▋       | 86/321 [00:24<01:07,  3.47it/s]01/14/2022 16:13:51 - INFO - __main__ -   Batch number = 87
Evaluating:  27%|██▋       | 87/321 [00:24<01:07,  3.47it/s]01/14/2022 16:13:51 - INFO - __main__ -   Batch number = 88
Evaluating:  27%|██▋       | 88/321 [00:25<01:07,  3.47it/s]01/14/2022 16:13:51 - INFO - __main__ -   Batch number = 89
Evaluating:  28%|██▊       | 89/321 [00:25<01:06,  3.47it/s]01/14/2022 16:13:51 - INFO - __main__ -   Batch number = 90
Evaluating:  28%|██▊       | 90/321 [00:25<01:06,  3.47it/s]01/14/2022 16:13:52 - INFO - __main__ -   Batch number = 91
Evaluating:  28%|██▊       | 91/321 [00:25<01:06,  3.48it/s]01/14/2022 16:13:52 - INFO - __main__ -   Batch number = 92
Evaluating:  29%|██▊       | 92/321 [00:26<01:05,  3.48it/s]01/14/2022 16:13:52 - INFO - __main__ -   Batch number = 93
Evaluating:  29%|██▉       | 93/321 [00:26<01:05,  3.49it/s]01/14/2022 16:13:53 - INFO - __main__ -   Batch number = 94
Evaluating:  29%|██▉       | 94/321 [00:26<01:05,  3.49it/s]01/14/2022 16:13:53 - INFO - __main__ -   Batch number = 95
Evaluating:  30%|██▉       | 95/321 [00:27<01:04,  3.49it/s]01/14/2022 16:13:53 - INFO - __main__ -   Batch number = 96
Evaluating:  30%|██▉       | 96/321 [00:27<01:04,  3.49it/s]01/14/2022 16:13:53 - INFO - __main__ -   Batch number = 97
Evaluating:  30%|███       | 97/321 [00:27<01:04,  3.48it/s]01/14/2022 16:13:54 - INFO - __main__ -   Batch number = 98
Evaluating:  31%|███       | 98/321 [00:27<01:03,  3.49it/s]01/14/2022 16:13:54 - INFO - __main__ -   Batch number = 99
Evaluating:  31%|███       | 99/321 [00:28<01:03,  3.48it/s]01/14/2022 16:13:54 - INFO - __main__ -   Batch number = 100
Evaluating:  31%|███       | 100/321 [00:28<01:03,  3.49it/s]01/14/2022 16:13:55 - INFO - __main__ -   Batch number = 101
Evaluating:  31%|███▏      | 101/321 [00:28<01:03,  3.48it/s]01/14/2022 16:13:55 - INFO - __main__ -   Batch number = 102
Evaluating:  32%|███▏      | 102/321 [00:29<01:02,  3.49it/s]01/14/2022 16:13:55 - INFO - __main__ -   Batch number = 103
Evaluating:  32%|███▏      | 103/321 [00:29<01:02,  3.48it/s]01/14/2022 16:13:55 - INFO - __main__ -   Batch number = 104
Evaluating:  32%|███▏      | 104/321 [00:29<01:02,  3.48it/s]01/14/2022 16:13:56 - INFO - __main__ -   Batch number = 105
Evaluating:  33%|███▎      | 105/321 [00:29<01:02,  3.48it/s]01/14/2022 16:13:56 - INFO - __main__ -   Batch number = 106
Evaluating:  33%|███▎      | 106/321 [00:30<01:01,  3.48it/s]01/14/2022 16:13:56 - INFO - __main__ -   Batch number = 107
Evaluating:  33%|███▎      | 107/321 [00:30<01:01,  3.48it/s]01/14/2022 16:13:57 - INFO - __main__ -   Batch number = 108
Evaluating:  34%|███▎      | 108/321 [00:30<01:01,  3.48it/s]01/14/2022 16:13:57 - INFO - __main__ -   Batch number = 109
Evaluating:  34%|███▍      | 109/321 [00:31<01:01,  3.47it/s]01/14/2022 16:13:57 - INFO - __main__ -   Batch number = 110
Evaluating:  34%|███▍      | 110/321 [00:31<01:00,  3.47it/s]01/14/2022 16:13:57 - INFO - __main__ -   Batch number = 111
Evaluating:  35%|███▍      | 111/321 [00:31<01:00,  3.47it/s]01/14/2022 16:13:58 - INFO - __main__ -   Batch number = 112
Evaluating:  35%|███▍      | 112/321 [00:31<01:00,  3.47it/s]01/14/2022 16:13:58 - INFO - __main__ -   Batch number = 113
Evaluating:  35%|███▌      | 113/321 [00:32<00:59,  3.47it/s]01/14/2022 16:13:58 - INFO - __main__ -   Batch number = 114
Evaluating:  36%|███▌      | 114/321 [00:32<00:59,  3.46it/s]01/14/2022 16:13:59 - INFO - __main__ -   Batch number = 115
Evaluating:  36%|███▌      | 115/321 [00:32<00:59,  3.45it/s]01/14/2022 16:13:59 - INFO - __main__ -   Batch number = 116
Evaluating:  36%|███▌      | 116/321 [00:33<00:59,  3.45it/s]01/14/2022 16:13:59 - INFO - __main__ -   Batch number = 117
Evaluating:  36%|███▋      | 117/321 [00:33<00:59,  3.46it/s]01/14/2022 16:13:59 - INFO - __main__ -   Batch number = 118
Evaluating:  37%|███▋      | 118/321 [00:33<00:58,  3.46it/s]01/14/2022 16:14:00 - INFO - __main__ -   Batch number = 119
Evaluating:  37%|███▋      | 119/321 [00:33<00:58,  3.47it/s]01/14/2022 16:14:00 - INFO - __main__ -   Batch number = 120
Evaluating:  37%|███▋      | 120/321 [00:34<00:58,  3.46it/s]01/14/2022 16:14:00 - INFO - __main__ -   Batch number = 121
Evaluating:  38%|███▊      | 121/321 [00:34<00:57,  3.46it/s]01/14/2022 16:14:01 - INFO - __main__ -   Batch number = 122
Evaluating:  38%|███▊      | 122/321 [00:34<00:57,  3.46it/s]01/14/2022 16:14:01 - INFO - __main__ -   Batch number = 123
Evaluating:  38%|███▊      | 123/321 [00:35<00:57,  3.46it/s]01/14/2022 16:14:01 - INFO - __main__ -   Batch number = 124
Evaluating:  39%|███▊      | 124/321 [00:35<00:56,  3.46it/s]01/14/2022 16:14:01 - INFO - __main__ -   Batch number = 125
Evaluating:  39%|███▉      | 125/321 [00:35<00:56,  3.46it/s]01/14/2022 16:14:02 - INFO - __main__ -   Batch number = 126
Evaluating:  39%|███▉      | 126/321 [00:36<00:56,  3.46it/s]01/14/2022 16:14:02 - INFO - __main__ -   Batch number = 127
Evaluating:  40%|███▉      | 127/321 [00:36<00:56,  3.46it/s]01/14/2022 16:14:02 - INFO - __main__ -   Batch number = 128
Evaluating:  40%|███▉      | 128/321 [00:36<00:55,  3.46it/s]01/14/2022 16:14:03 - INFO - __main__ -   Batch number = 129
Evaluating:  40%|████      | 129/321 [00:36<00:55,  3.46it/s]01/14/2022 16:14:03 - INFO - __main__ -   Batch number = 130
Evaluating:  40%|████      | 130/321 [00:37<00:55,  3.45it/s]01/14/2022 16:14:03 - INFO - __main__ -   Batch number = 131
Evaluating:  41%|████      | 131/321 [00:37<00:55,  3.43it/s]01/14/2022 16:14:03 - INFO - __main__ -   Batch number = 132
Evaluating:  41%|████      | 132/321 [00:37<00:55,  3.42it/s]01/14/2022 16:14:04 - INFO - __main__ -   Batch number = 133
Evaluating:  41%|████▏     | 133/321 [00:38<00:57,  3.26it/s]01/14/2022 16:14:04 - INFO - __main__ -   Batch number = 134
Evaluating:  42%|████▏     | 134/321 [00:38<00:56,  3.32it/s]01/14/2022 16:14:04 - INFO - __main__ -   Batch number = 135
Evaluating:  42%|████▏     | 135/321 [00:38<00:55,  3.35it/s]01/14/2022 16:14:05 - INFO - __main__ -   Batch number = 136
Evaluating:  42%|████▏     | 136/321 [00:38<00:54,  3.37it/s]01/14/2022 16:14:05 - INFO - __main__ -   Batch number = 137
Evaluating:  43%|████▎     | 137/321 [00:39<00:54,  3.38it/s]01/14/2022 16:14:05 - INFO - __main__ -   Batch number = 138
Evaluating:  43%|████▎     | 138/321 [00:39<00:53,  3.39it/s]01/14/2022 16:14:06 - INFO - __main__ -   Batch number = 139
Evaluating:  43%|████▎     | 139/321 [00:39<00:53,  3.40it/s]01/14/2022 16:14:06 - INFO - __main__ -   Batch number = 140
Evaluating:  44%|████▎     | 140/321 [00:40<00:53,  3.40it/s]01/14/2022 16:14:06 - INFO - __main__ -   Batch number = 141
Evaluating:  44%|████▍     | 141/321 [00:40<00:52,  3.40it/s]01/14/2022 16:14:06 - INFO - __main__ -   Batch number = 142
Evaluating:  44%|████▍     | 142/321 [00:40<00:52,  3.39it/s]01/14/2022 16:14:07 - INFO - __main__ -   Batch number = 143
Evaluating:  45%|████▍     | 143/321 [00:41<00:52,  3.39it/s]01/14/2022 16:14:07 - INFO - __main__ -   Batch number = 144
Evaluating:  45%|████▍     | 144/321 [00:41<00:52,  3.40it/s]01/14/2022 16:14:07 - INFO - __main__ -   Batch number = 145
Evaluating:  45%|████▌     | 145/321 [00:41<00:51,  3.40it/s]01/14/2022 16:14:08 - INFO - __main__ -   Batch number = 146
Evaluating:  45%|████▌     | 146/321 [00:41<00:51,  3.41it/s]01/14/2022 16:14:08 - INFO - __main__ -   Batch number = 147
Evaluating:  46%|████▌     | 147/321 [00:42<00:51,  3.41it/s]01/14/2022 16:14:08 - INFO - __main__ -   Batch number = 148
Evaluating:  46%|████▌     | 148/321 [00:42<00:51,  3.36it/s]01/14/2022 16:14:09 - INFO - __main__ -   Batch number = 149
Evaluating:  46%|████▋     | 149/321 [00:42<00:51,  3.32it/s]01/14/2022 16:14:09 - INFO - __main__ -   Batch number = 150
Evaluating:  47%|████▋     | 150/321 [00:43<00:56,  3.03it/s]01/14/2022 16:14:09 - INFO - __main__ -   Batch number = 151
Evaluating:  47%|████▋     | 151/321 [00:43<00:55,  3.07it/s]01/14/2022 16:14:10 - INFO - __main__ -   Batch number = 152
Evaluating:  47%|████▋     | 152/321 [00:43<00:54,  3.10it/s]01/14/2022 16:14:10 - INFO - __main__ -   Batch number = 153
Evaluating:  48%|████▊     | 153/321 [00:44<00:53,  3.12it/s]01/14/2022 16:14:10 - INFO - __main__ -   Batch number = 154
Evaluating:  48%|████▊     | 154/321 [00:44<00:53,  3.14it/s]01/14/2022 16:14:10 - INFO - __main__ -   Batch number = 155
Evaluating:  48%|████▊     | 155/321 [00:44<00:52,  3.16it/s]01/14/2022 16:14:11 - INFO - __main__ -   Batch number = 156
Evaluating:  49%|████▊     | 156/321 [00:45<00:51,  3.18it/s]01/14/2022 16:14:11 - INFO - __main__ -   Batch number = 157
Evaluating:  49%|████▉     | 157/321 [00:45<00:51,  3.19it/s]01/14/2022 16:14:11 - INFO - __main__ -   Batch number = 158
Evaluating:  49%|████▉     | 158/321 [00:45<00:50,  3.22it/s]01/14/2022 16:14:12 - INFO - __main__ -   Batch number = 159
Evaluating:  50%|████▉     | 159/321 [00:46<00:50,  3.24it/s]01/14/2022 16:14:12 - INFO - __main__ -   Batch number = 160
Evaluating:  50%|████▉     | 160/321 [00:46<00:49,  3.27it/s]01/14/2022 16:14:12 - INFO - __main__ -   Batch number = 161
Evaluating:  50%|█████     | 161/321 [00:46<00:48,  3.29it/s]01/14/2022 16:14:13 - INFO - __main__ -   Batch number = 162
Evaluating:  50%|█████     | 162/321 [00:46<00:47,  3.32it/s]01/14/2022 16:14:13 - INFO - __main__ -   Batch number = 163
Evaluating:  51%|█████     | 163/321 [00:47<00:47,  3.34it/s]01/14/2022 16:14:13 - INFO - __main__ -   Batch number = 164
Evaluating:  51%|█████     | 164/321 [00:47<00:46,  3.36it/s]01/14/2022 16:14:14 - INFO - __main__ -   Batch number = 165
Evaluating:  51%|█████▏    | 165/321 [00:47<00:46,  3.37it/s]01/14/2022 16:14:14 - INFO - __main__ -   Batch number = 166
Evaluating:  52%|█████▏    | 166/321 [00:48<00:49,  3.13it/s]01/14/2022 16:14:14 - INFO - __main__ -   Batch number = 167
Evaluating:  52%|█████▏    | 167/321 [00:48<00:47,  3.22it/s]01/14/2022 16:14:14 - INFO - __main__ -   Batch number = 168
Evaluating:  52%|█████▏    | 168/321 [00:48<00:46,  3.28it/s]01/14/2022 16:14:15 - INFO - __main__ -   Batch number = 169
Evaluating:  53%|█████▎    | 169/321 [00:49<00:45,  3.31it/s]01/14/2022 16:14:15 - INFO - __main__ -   Batch number = 170
Evaluating:  53%|█████▎    | 170/321 [00:49<00:45,  3.29it/s]01/14/2022 16:14:15 - INFO - __main__ -   Batch number = 171
Evaluating:  53%|█████▎    | 171/321 [00:49<00:45,  3.31it/s]01/14/2022 16:14:16 - INFO - __main__ -   Batch number = 172
Evaluating:  54%|█████▎    | 172/321 [00:49<00:44,  3.34it/s]01/14/2022 16:14:16 - INFO - __main__ -   Batch number = 173
Evaluating:  54%|█████▍    | 173/321 [00:50<00:43,  3.37it/s]01/14/2022 16:14:16 - INFO - __main__ -   Batch number = 174
Evaluating:  54%|█████▍    | 174/321 [00:50<00:43,  3.39it/s]01/14/2022 16:14:17 - INFO - __main__ -   Batch number = 175
Evaluating:  55%|█████▍    | 175/321 [00:50<00:42,  3.40it/s]01/14/2022 16:14:17 - INFO - __main__ -   Batch number = 176
Evaluating:  55%|█████▍    | 176/321 [00:51<00:42,  3.41it/s]01/14/2022 16:14:17 - INFO - __main__ -   Batch number = 177
Evaluating:  55%|█████▌    | 177/321 [00:51<00:42,  3.41it/s]01/14/2022 16:14:17 - INFO - __main__ -   Batch number = 178
Evaluating:  55%|█████▌    | 178/321 [00:51<00:41,  3.41it/s]01/14/2022 16:14:18 - INFO - __main__ -   Batch number = 179
Evaluating:  56%|█████▌    | 179/321 [00:52<00:41,  3.40it/s]01/14/2022 16:14:18 - INFO - __main__ -   Batch number = 180
Evaluating:  56%|█████▌    | 180/321 [00:52<00:41,  3.40it/s]01/14/2022 16:14:18 - INFO - __main__ -   Batch number = 181
Evaluating:  56%|█████▋    | 181/321 [00:52<00:41,  3.41it/s]01/14/2022 16:14:19 - INFO - __main__ -   Batch number = 182
Evaluating:  57%|█████▋    | 182/321 [00:52<00:40,  3.41it/s]01/14/2022 16:14:19 - INFO - __main__ -   Batch number = 183
Evaluating:  57%|█████▋    | 183/321 [00:53<00:49,  2.78it/s]01/14/2022 16:14:19 - INFO - __main__ -   Batch number = 184
Evaluating:  57%|█████▋    | 184/321 [00:53<00:47,  2.88it/s]01/14/2022 16:14:20 - INFO - __main__ -   Batch number = 185
Evaluating:  58%|█████▊    | 185/321 [00:54<00:45,  2.97it/s]01/14/2022 16:14:20 - INFO - __main__ -   Batch number = 186
Evaluating:  58%|█████▊    | 186/321 [00:54<00:44,  3.04it/s]01/14/2022 16:14:20 - INFO - __main__ -   Batch number = 187
Evaluating:  58%|█████▊    | 187/321 [00:54<00:43,  3.10it/s]01/14/2022 16:14:21 - INFO - __main__ -   Batch number = 188
Evaluating:  59%|█████▊    | 188/321 [00:54<00:42,  3.10it/s]01/14/2022 16:14:21 - INFO - __main__ -   Batch number = 189
Evaluating:  59%|█████▉    | 189/321 [00:55<00:42,  3.13it/s]01/14/2022 16:14:21 - INFO - __main__ -   Batch number = 190
Evaluating:  59%|█████▉    | 190/321 [00:55<00:41,  3.19it/s]01/14/2022 16:14:22 - INFO - __main__ -   Batch number = 191
Evaluating:  60%|█████▉    | 191/321 [00:55<00:40,  3.25it/s]01/14/2022 16:14:22 - INFO - __main__ -   Batch number = 192
Evaluating:  60%|█████▉    | 192/321 [00:56<00:39,  3.29it/s]01/14/2022 16:14:22 - INFO - __main__ -   Batch number = 193
Evaluating:  60%|██████    | 193/321 [00:56<00:38,  3.33it/s]01/14/2022 16:14:22 - INFO - __main__ -   Batch number = 194
Evaluating:  60%|██████    | 194/321 [00:56<00:37,  3.36it/s]01/14/2022 16:14:23 - INFO - __main__ -   Batch number = 195
Evaluating:  61%|██████    | 195/321 [00:57<00:37,  3.37it/s]01/14/2022 16:14:23 - INFO - __main__ -   Batch number = 196
Evaluating:  61%|██████    | 196/321 [00:57<00:37,  3.36it/s]01/14/2022 16:14:23 - INFO - __main__ -   Batch number = 197
Evaluating:  61%|██████▏   | 197/321 [00:57<00:37,  3.33it/s]01/14/2022 16:14:24 - INFO - __main__ -   Batch number = 198
Evaluating:  62%|██████▏   | 198/321 [00:57<00:36,  3.34it/s]01/14/2022 16:14:24 - INFO - __main__ -   Batch number = 199
Evaluating:  62%|██████▏   | 199/321 [00:58<00:38,  3.14it/s]01/14/2022 16:14:24 - INFO - __main__ -   Batch number = 200
Evaluating:  62%|██████▏   | 200/321 [00:58<00:38,  3.16it/s]01/14/2022 16:14:25 - INFO - __main__ -   Batch number = 201
Evaluating:  63%|██████▎   | 201/321 [00:58<00:37,  3.18it/s]01/14/2022 16:14:25 - INFO - __main__ -   Batch number = 202
Evaluating:  63%|██████▎   | 202/321 [00:59<00:37,  3.21it/s]01/14/2022 16:14:25 - INFO - __main__ -   Batch number = 203
Evaluating:  63%|██████▎   | 203/321 [00:59<00:36,  3.21it/s]01/14/2022 16:14:26 - INFO - __main__ -   Batch number = 204
Evaluating:  64%|██████▎   | 204/321 [00:59<00:36,  3.21it/s]01/14/2022 16:14:26 - INFO - __main__ -   Batch number = 205
Evaluating:  64%|██████▍   | 205/321 [01:00<00:35,  3.24it/s]01/14/2022 16:14:26 - INFO - __main__ -   Batch number = 206
Evaluating:  64%|██████▍   | 206/321 [01:00<00:35,  3.25it/s]01/14/2022 16:14:26 - INFO - __main__ -   Batch number = 207
Evaluating:  64%|██████▍   | 207/321 [01:00<00:34,  3.27it/s]01/14/2022 16:14:27 - INFO - __main__ -   Batch number = 208
Evaluating:  65%|██████▍   | 208/321 [01:01<00:34,  3.29it/s]01/14/2022 16:14:27 - INFO - __main__ -   Batch number = 209
Evaluating:  65%|██████▌   | 209/321 [01:01<00:33,  3.31it/s]01/14/2022 16:14:27 - INFO - __main__ -   Batch number = 210
Evaluating:  65%|██████▌   | 210/321 [01:01<00:33,  3.33it/s]01/14/2022 16:14:28 - INFO - __main__ -   Batch number = 211
Evaluating:  66%|██████▌   | 211/321 [01:01<00:33,  3.32it/s]01/14/2022 16:14:28 - INFO - __main__ -   Batch number = 212
Evaluating:  66%|██████▌   | 212/321 [01:02<00:33,  3.29it/s]01/14/2022 16:14:28 - INFO - __main__ -   Batch number = 213
Evaluating:  66%|██████▋   | 213/321 [01:02<00:33,  3.25it/s]01/14/2022 16:14:29 - INFO - __main__ -   Batch number = 214
Evaluating:  67%|██████▋   | 214/321 [01:02<00:33,  3.22it/s]01/14/2022 16:14:29 - INFO - __main__ -   Batch number = 215
Evaluating:  67%|██████▋   | 215/321 [01:03<00:32,  3.21it/s]01/14/2022 16:14:29 - INFO - __main__ -   Batch number = 216
Evaluating:  67%|██████▋   | 216/321 [01:03<00:34,  3.05it/s]01/14/2022 16:14:30 - INFO - __main__ -   Batch number = 217
Evaluating:  68%|██████▊   | 217/321 [01:03<00:33,  3.08it/s]01/14/2022 16:14:30 - INFO - __main__ -   Batch number = 218
Evaluating:  68%|██████▊   | 218/321 [01:04<00:33,  3.10it/s]01/14/2022 16:14:30 - INFO - __main__ -   Batch number = 219
Evaluating:  68%|██████▊   | 219/321 [01:04<00:33,  3.09it/s]01/14/2022 16:14:31 - INFO - __main__ -   Batch number = 220
Evaluating:  69%|██████▊   | 220/321 [01:04<00:32,  3.11it/s]01/14/2022 16:14:31 - INFO - __main__ -   Batch number = 221
Evaluating:  69%|██████▉   | 221/321 [01:05<00:31,  3.16it/s]01/14/2022 16:14:31 - INFO - __main__ -   Batch number = 222
Evaluating:  69%|██████▉   | 222/321 [01:05<00:31,  3.18it/s]01/14/2022 16:14:31 - INFO - __main__ -   Batch number = 223
Evaluating:  69%|██████▉   | 223/321 [01:05<00:30,  3.23it/s]01/14/2022 16:14:32 - INFO - __main__ -   Batch number = 224
Evaluating:  70%|██████▉   | 224/321 [01:06<00:29,  3.27it/s]01/14/2022 16:14:32 - INFO - __main__ -   Batch number = 225
Evaluating:  70%|███████   | 225/321 [01:06<00:28,  3.31it/s]01/14/2022 16:14:32 - INFO - __main__ -   Batch number = 226
Evaluating:  70%|███████   | 226/321 [01:06<00:28,  3.32it/s]01/14/2022 16:14:33 - INFO - __main__ -   Batch number = 227
Evaluating:  71%|███████   | 227/321 [01:06<00:28,  3.33it/s]01/14/2022 16:14:33 - INFO - __main__ -   Batch number = 228
Evaluating:  71%|███████   | 228/321 [01:07<00:27,  3.33it/s]01/14/2022 16:14:33 - INFO - __main__ -   Batch number = 229
Evaluating:  71%|███████▏  | 229/321 [01:07<00:27,  3.34it/s]01/14/2022 16:14:34 - INFO - __main__ -   Batch number = 230
Evaluating:  72%|███████▏  | 230/321 [01:07<00:27,  3.34it/s]01/14/2022 16:14:34 - INFO - __main__ -   Batch number = 231
Evaluating:  72%|███████▏  | 231/321 [01:08<00:27,  3.33it/s]01/14/2022 16:14:34 - INFO - __main__ -   Batch number = 232
Evaluating:  72%|███████▏  | 232/321 [01:08<00:26,  3.33it/s]01/14/2022 16:14:34 - INFO - __main__ -   Batch number = 233
Evaluating:  73%|███████▎  | 233/321 [01:08<00:26,  3.33it/s]01/14/2022 16:14:35 - INFO - __main__ -   Batch number = 234
Evaluating:  73%|███████▎  | 234/321 [01:09<00:26,  3.34it/s]01/14/2022 16:14:35 - INFO - __main__ -   Batch number = 235
Evaluating:  73%|███████▎  | 235/321 [01:09<00:25,  3.35it/s]01/14/2022 16:14:35 - INFO - __main__ -   Batch number = 236
Evaluating:  74%|███████▎  | 236/321 [01:09<00:25,  3.37it/s]01/14/2022 16:14:36 - INFO - __main__ -   Batch number = 237
Evaluating:  74%|███████▍  | 237/321 [01:09<00:24,  3.37it/s]01/14/2022 16:14:36 - INFO - __main__ -   Batch number = 238
Evaluating:  74%|███████▍  | 238/321 [01:10<00:24,  3.35it/s]01/14/2022 16:14:36 - INFO - __main__ -   Batch number = 239
Evaluating:  74%|███████▍  | 239/321 [01:10<00:24,  3.31it/s]01/14/2022 16:14:37 - INFO - __main__ -   Batch number = 240
Evaluating:  75%|███████▍  | 240/321 [01:10<00:24,  3.28it/s]01/14/2022 16:14:37 - INFO - __main__ -   Batch number = 241
Evaluating:  75%|███████▌  | 241/321 [01:11<00:24,  3.26it/s]01/14/2022 16:14:37 - INFO - __main__ -   Batch number = 242
Evaluating:  75%|███████▌  | 242/321 [01:11<00:24,  3.23it/s]01/14/2022 16:14:38 - INFO - __main__ -   Batch number = 243
Evaluating:  76%|███████▌  | 243/321 [01:11<00:24,  3.20it/s]01/14/2022 16:14:38 - INFO - __main__ -   Batch number = 244
Evaluating:  76%|███████▌  | 244/321 [01:12<00:24,  3.19it/s]01/14/2022 16:14:38 - INFO - __main__ -   Batch number = 245
Evaluating:  76%|███████▋  | 245/321 [01:12<00:23,  3.21it/s]01/14/2022 16:14:38 - INFO - __main__ -   Batch number = 246
Evaluating:  77%|███████▋  | 246/321 [01:12<00:23,  3.24it/s]01/14/2022 16:14:39 - INFO - __main__ -   Batch number = 247
Evaluating:  77%|███████▋  | 247/321 [01:13<00:22,  3.27it/s]01/14/2022 16:14:39 - INFO - __main__ -   Batch number = 248
Evaluating:  77%|███████▋  | 248/321 [01:13<00:22,  3.30it/s]01/14/2022 16:14:39 - INFO - __main__ -   Batch number = 249
Evaluating:  78%|███████▊  | 249/321 [01:13<00:21,  3.30it/s]01/14/2022 16:14:40 - INFO - __main__ -   Batch number = 250
Evaluating:  78%|███████▊  | 250/321 [01:13<00:21,  3.28it/s]01/14/2022 16:14:40 - INFO - __main__ -   Batch number = 251
Evaluating:  78%|███████▊  | 251/321 [01:14<00:21,  3.25it/s]01/14/2022 16:14:40 - INFO - __main__ -   Batch number = 252
Evaluating:  79%|███████▊  | 252/321 [01:14<00:21,  3.22it/s]01/14/2022 16:14:41 - INFO - __main__ -   Batch number = 253
Evaluating:  79%|███████▉  | 253/321 [01:14<00:21,  3.22it/s]01/14/2022 16:14:41 - INFO - __main__ -   Batch number = 254
Evaluating:  79%|███████▉  | 254/321 [01:15<00:20,  3.23it/s]01/14/2022 16:14:41 - INFO - __main__ -   Batch number = 255
Evaluating:  79%|███████▉  | 255/321 [01:15<00:20,  3.25it/s]01/14/2022 16:14:42 - INFO - __main__ -   Batch number = 256
Evaluating:  80%|███████▉  | 256/321 [01:15<00:19,  3.28it/s]01/14/2022 16:14:42 - INFO - __main__ -   Batch number = 257
Evaluating:  80%|████████  | 257/321 [01:16<00:19,  3.29it/s]01/14/2022 16:14:42 - INFO - __main__ -   Batch number = 258
Evaluating:  80%|████████  | 258/321 [01:16<00:19,  3.29it/s]01/14/2022 16:14:42 - INFO - __main__ -   Batch number = 259
Evaluating:  81%|████████  | 259/321 [01:16<00:18,  3.28it/s]01/14/2022 16:14:43 - INFO - __main__ -   Batch number = 260
Evaluating:  81%|████████  | 260/321 [01:17<00:18,  3.26it/s]01/14/2022 16:14:43 - INFO - __main__ -   Batch number = 261
Evaluating:  81%|████████▏ | 261/321 [01:17<00:18,  3.23it/s]01/14/2022 16:14:43 - INFO - __main__ -   Batch number = 262
Evaluating:  82%|████████▏ | 262/321 [01:17<00:18,  3.22it/s]01/14/2022 16:14:44 - INFO - __main__ -   Batch number = 263
Evaluating:  82%|████████▏ | 263/321 [01:17<00:18,  3.20it/s]01/14/2022 16:14:44 - INFO - __main__ -   Batch number = 264
Evaluating:  82%|████████▏ | 264/321 [01:18<00:17,  3.20it/s]01/14/2022 16:14:44 - INFO - __main__ -   Batch number = 265
Evaluating:  83%|████████▎ | 265/321 [01:18<00:17,  3.18it/s]01/14/2022 16:14:45 - INFO - __main__ -   Batch number = 266
Evaluating:  83%|████████▎ | 266/321 [01:18<00:17,  3.21it/s]01/14/2022 16:14:45 - INFO - __main__ -   Batch number = 267
Evaluating:  83%|████████▎ | 267/321 [01:19<00:16,  3.24it/s]01/14/2022 16:14:45 - INFO - __main__ -   Batch number = 268
Evaluating:  83%|████████▎ | 268/321 [01:19<00:16,  3.28it/s]01/14/2022 16:14:46 - INFO - __main__ -   Batch number = 269
Evaluating:  84%|████████▍ | 269/321 [01:19<00:15,  3.27it/s]01/14/2022 16:14:46 - INFO - __main__ -   Batch number = 270
Evaluating:  84%|████████▍ | 270/321 [01:20<00:15,  3.31it/s]01/14/2022 16:14:46 - INFO - __main__ -   Batch number = 271
Evaluating:  84%|████████▍ | 271/321 [01:20<00:15,  3.33it/s]01/14/2022 16:14:46 - INFO - __main__ -   Batch number = 272
Evaluating:  85%|████████▍ | 272/321 [01:20<00:14,  3.34it/s]01/14/2022 16:14:47 - INFO - __main__ -   Batch number = 273
Evaluating:  85%|████████▌ | 273/321 [01:21<00:14,  3.34it/s]01/14/2022 16:14:47 - INFO - __main__ -   Batch number = 274
Evaluating:  85%|████████▌ | 274/321 [01:21<00:14,  3.31it/s]01/14/2022 16:14:47 - INFO - __main__ -   Batch number = 275
Evaluating:  86%|████████▌ | 275/321 [01:21<00:13,  3.32it/s]01/14/2022 16:14:48 - INFO - __main__ -   Batch number = 276
Evaluating:  86%|████████▌ | 276/321 [01:21<00:13,  3.33it/s]01/14/2022 16:14:48 - INFO - __main__ -   Batch number = 277
Evaluating:  86%|████████▋ | 277/321 [01:22<00:13,  3.33it/s]01/14/2022 16:14:48 - INFO - __main__ -   Batch number = 278
Evaluating:  87%|████████▋ | 278/321 [01:22<00:12,  3.34it/s]01/14/2022 16:14:49 - INFO - __main__ -   Batch number = 279
Evaluating:  87%|████████▋ | 279/321 [01:22<00:12,  3.36it/s]01/14/2022 16:14:49 - INFO - __main__ -   Batch number = 280
Evaluating:  87%|████████▋ | 280/321 [01:23<00:12,  3.37it/s]01/14/2022 16:14:49 - INFO - __main__ -   Batch number = 281
Evaluating:  88%|████████▊ | 281/321 [01:23<00:11,  3.38it/s]01/14/2022 16:14:49 - INFO - __main__ -   Batch number = 282
Evaluating:  88%|████████▊ | 282/321 [01:23<00:12,  3.24it/s]01/14/2022 16:14:50 - INFO - __main__ -   Batch number = 283
Evaluating:  88%|████████▊ | 283/321 [01:24<00:11,  3.27it/s]01/14/2022 16:14:50 - INFO - __main__ -   Batch number = 284
Evaluating:  88%|████████▊ | 284/321 [01:24<00:11,  3.30it/s]01/14/2022 16:14:50 - INFO - __main__ -   Batch number = 285
Evaluating:  89%|████████▉ | 285/321 [01:24<00:10,  3.33it/s]01/14/2022 16:14:51 - INFO - __main__ -   Batch number = 286
Evaluating:  89%|████████▉ | 286/321 [01:24<00:10,  3.33it/s]01/14/2022 16:14:51 - INFO - __main__ -   Batch number = 287
Evaluating:  89%|████████▉ | 287/321 [01:25<00:10,  3.32it/s]01/14/2022 16:14:51 - INFO - __main__ -   Batch number = 288
Evaluating:  90%|████████▉ | 288/321 [01:25<00:10,  3.29it/s]01/14/2022 16:14:52 - INFO - __main__ -   Batch number = 289
Evaluating:  90%|█████████ | 289/321 [01:25<00:09,  3.25it/s]01/14/2022 16:14:52 - INFO - __main__ -   Batch number = 290
Evaluating:  90%|█████████ | 290/321 [01:26<00:09,  3.22it/s]01/14/2022 16:14:52 - INFO - __main__ -   Batch number = 291
Evaluating:  91%|█████████ | 291/321 [01:26<00:09,  3.20it/s]01/14/2022 16:14:52 - INFO - __main__ -   Batch number = 292
Evaluating:  91%|█████████ | 292/321 [01:26<00:09,  3.20it/s]01/14/2022 16:14:53 - INFO - __main__ -   Batch number = 293
Evaluating:  91%|█████████▏| 293/321 [01:27<00:08,  3.21it/s]01/14/2022 16:14:53 - INFO - __main__ -   Batch number = 294
Evaluating:  92%|█████████▏| 294/321 [01:27<00:08,  3.24it/s]01/14/2022 16:14:53 - INFO - __main__ -   Batch number = 295
Evaluating:  92%|█████████▏| 295/321 [01:27<00:07,  3.25it/s]01/14/2022 16:14:54 - INFO - __main__ -   Batch number = 296
Evaluating:  92%|█████████▏| 296/321 [01:28<00:07,  3.27it/s]01/14/2022 16:14:54 - INFO - __main__ -   Batch number = 297
Evaluating:  93%|█████████▎| 297/321 [01:28<00:07,  3.29it/s]01/14/2022 16:14:54 - INFO - __main__ -   Batch number = 298
Evaluating:  93%|█████████▎| 298/321 [01:28<00:06,  3.32it/s]01/14/2022 16:14:55 - INFO - __main__ -   Batch number = 299
Evaluating:  93%|█████████▎| 299/321 [01:28<00:06,  3.34it/s]01/14/2022 16:14:55 - INFO - __main__ -   Batch number = 300
Evaluating:  93%|█████████▎| 300/321 [01:29<00:06,  3.33it/s]01/14/2022 16:14:55 - INFO - __main__ -   Batch number = 301
Evaluating:  94%|█████████▍| 301/321 [01:29<00:05,  3.34it/s]01/14/2022 16:14:56 - INFO - __main__ -   Batch number = 302
Evaluating:  94%|█████████▍| 302/321 [01:29<00:05,  3.33it/s]01/14/2022 16:14:56 - INFO - __main__ -   Batch number = 303
Evaluating:  94%|█████████▍| 303/321 [01:30<00:05,  3.31it/s]01/14/2022 16:14:56 - INFO - __main__ -   Batch number = 304
Evaluating:  95%|█████████▍| 304/321 [01:30<00:05,  3.29it/s]01/14/2022 16:14:56 - INFO - __main__ -   Batch number = 305
Evaluating:  95%|█████████▌| 305/321 [01:30<00:04,  3.28it/s]01/14/2022 16:14:57 - INFO - __main__ -   Batch number = 306
Evaluating:  95%|█████████▌| 306/321 [01:31<00:04,  3.31it/s]01/14/2022 16:14:57 - INFO - __main__ -   Batch number = 307
Evaluating:  96%|█████████▌| 307/321 [01:31<00:04,  3.32it/s]01/14/2022 16:14:57 - INFO - __main__ -   Batch number = 308
Evaluating:  96%|█████████▌| 308/321 [01:31<00:03,  3.31it/s]01/14/2022 16:14:58 - INFO - __main__ -   Batch number = 309
Evaluating:  96%|█████████▋| 309/321 [01:31<00:03,  3.34it/s]01/14/2022 16:14:58 - INFO - __main__ -   Batch number = 310
Evaluating:  97%|█████████▋| 310/321 [01:32<00:03,  3.36it/s]01/14/2022 16:14:58 - INFO - __main__ -   Batch number = 311
Evaluating:  97%|█████████▋| 311/321 [01:32<00:02,  3.37it/s]01/14/2022 16:14:59 - INFO - __main__ -   Batch number = 312
Evaluating:  97%|█████████▋| 312/321 [01:32<00:02,  3.38it/s]01/14/2022 16:14:59 - INFO - __main__ -   Batch number = 313
Evaluating:  98%|█████████▊| 313/321 [01:33<00:02,  3.36it/s]01/14/2022 16:14:59 - INFO - __main__ -   Batch number = 314
Evaluating:  98%|█████████▊| 314/321 [01:33<00:02,  3.34it/s]01/14/2022 16:14:59 - INFO - __main__ -   Batch number = 315
Evaluating:  98%|█████████▊| 315/321 [01:33<00:01,  3.27it/s]01/14/2022 16:15:00 - INFO - __main__ -   Batch number = 316
Evaluating:  98%|█████████▊| 316/321 [01:34<00:01,  3.23it/s]01/14/2022 16:15:00 - INFO - __main__ -   Batch number = 317
Evaluating:  99%|█████████▉| 317/321 [01:34<00:01,  3.24it/s]01/14/2022 16:15:00 - INFO - __main__ -   Batch number = 318
Evaluating:  99%|█████████▉| 318/321 [01:34<00:00,  3.25it/s]01/14/2022 16:15:01 - INFO - __main__ -   Batch number = 319
Evaluating:  99%|█████████▉| 319/321 [01:34<00:00,  3.29it/s]01/14/2022 16:15:01 - INFO - __main__ -   Batch number = 320
Evaluating: 100%|█████████▉| 320/321 [01:35<00:00,  3.32it/s]01/14/2022 16:15:01 - INFO - __main__ -   Batch number = 321
Evaluating: 100%|██████████| 321/321 [01:35<00:00,  3.80it/s]Evaluating: 100%|██████████| 321/321 [01:35<00:00,  3.36it/s]
01/14/2022 16:15:04 - INFO - __main__ -   ***** Evaluation result  in zh *****
01/14/2022 16:15:04 - INFO - __main__ -     f1 = 0.33014956704277093
01/14/2022 16:15:04 - INFO - __main__ -     loss = 3.2364519478004667
01/14/2022 16:15:04 - INFO - __main__ -     precision = 0.2460016423571736
01/14/2022 16:15:04 - INFO - __main__ -     recall = 0.501794687724336
102.39user 39.43system 2:11.92elapsed 107%CPU (0avgtext+0avgdata 4227812maxresident)k
52848inputs+1824outputs (0major+2457918minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:15:06 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='zh', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:15:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:15:06 - INFO - __main__ -   Seed = 2
01/14/2022 16:15:06 - INFO - root -   save model
01/14/2022 16:15:06 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='zh', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:15:06 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:15:09 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:15:15 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:15:15 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:15:15 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:15:15 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:15:15 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:15:15 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,zh/wiki@ukp
01/14/2022 16:15:15 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'zh'], Length : 10
01/14/2022 16:15:15 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'zh/wiki@ukp'], Length : 10
01/14/2022 16:15:15 - INFO - __main__ -   Language = en
01/14/2022 16:15:15 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:15:16 - INFO - __main__ -   Language = pt
01/14/2022 16:15:16 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:15:18 - INFO - __main__ -   Language = id
01/14/2022 16:15:18 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:15:20 - INFO - __main__ -   Language = tr
01/14/2022 16:15:20 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:15:22 - INFO - __main__ -   Language = cs
01/14/2022 16:15:22 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:15:24 - INFO - __main__ -   Language = vi
01/14/2022 16:15:24 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:15:26 - INFO - __main__ -   Language = eu
01/14/2022 16:15:26 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:15:29 - INFO - __main__ -   Language = fa
01/14/2022 16:15:29 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:15:31 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:15:31 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:15:33 - INFO - __main__ -   Language = zh
01/14/2022 16:15:33 - INFO - __main__ -   Adapter Name = zh/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh/bert-base-multilingual-cased/pfeiffer/zh_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted/adapter_config.json
Adding adapter 'zh' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted/pytorch_adapter.bin
Some module weights could not be found in loaded weights file: encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, invertible_lang_adapters.zh_yue.F.0.weight, invertible_lang_adapters.zh_yue.F.0.bias, invertible_lang_adapters.zh_yue.F.2.weight, invertible_lang_adapters.zh_yue.F.2.bias, invertible_lang_adapters.zh_yue.G.0.weight, invertible_lang_adapters.zh_yue.G.0.bias, invertible_lang_adapters.zh_yue.G.2.weight, invertible_lang_adapters.zh_yue.G.2.bias
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted'
01/14/2022 16:15:37 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:15:37 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'zh']
01/14/2022 16:15:37 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:15:37 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:15:37 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:15:37 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_zh_bert-base-multilingual-cased_128
01/14/2022 16:15:39 - INFO - __main__ -   ***** Running evaluation  in zh *****
01/14/2022 16:15:39 - INFO - __main__ -     Num examples = 10257
01/14/2022 16:15:39 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/321 [00:00<?, ?it/s]01/14/2022 16:15:39 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/321 [00:00<01:38,  3.25it/s]01/14/2022 16:15:39 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/321 [00:00<01:33,  3.41it/s]01/14/2022 16:15:39 - INFO - __main__ -   Batch number = 3
Evaluating:   1%|          | 3/321 [00:00<01:31,  3.48it/s]01/14/2022 16:15:40 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/321 [00:01<01:58,  2.68it/s]01/14/2022 16:15:40 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/321 [00:01<01:47,  2.95it/s]01/14/2022 16:15:40 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/321 [00:01<01:40,  3.13it/s]01/14/2022 16:15:40 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/321 [00:02<01:36,  3.26it/s]01/14/2022 16:15:41 - INFO - __main__ -   Batch number = 8
Evaluating:   2%|▏         | 8/321 [00:02<01:33,  3.36it/s]01/14/2022 16:15:41 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/321 [00:02<01:31,  3.43it/s]01/14/2022 16:15:41 - INFO - __main__ -   Batch number = 10
Evaluating:   3%|▎         | 10/321 [00:03<01:29,  3.47it/s]01/14/2022 16:15:42 - INFO - __main__ -   Batch number = 11
Evaluating:   3%|▎         | 11/321 [00:03<01:28,  3.50it/s]01/14/2022 16:15:42 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▎         | 12/321 [00:03<01:27,  3.51it/s]01/14/2022 16:15:42 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/321 [00:03<01:27,  3.53it/s]01/14/2022 16:15:42 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/321 [00:04<01:26,  3.54it/s]01/14/2022 16:15:43 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/321 [00:04<01:26,  3.54it/s]01/14/2022 16:15:43 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▍         | 16/321 [00:04<01:25,  3.55it/s]01/14/2022 16:15:43 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/321 [00:05<01:25,  3.56it/s]01/14/2022 16:15:44 - INFO - __main__ -   Batch number = 18
Evaluating:   6%|▌         | 18/321 [00:05<01:24,  3.56it/s]01/14/2022 16:15:44 - INFO - __main__ -   Batch number = 19
Evaluating:   6%|▌         | 19/321 [00:05<01:24,  3.56it/s]01/14/2022 16:15:44 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▌         | 20/321 [00:05<01:24,  3.56it/s]01/14/2022 16:15:45 - INFO - __main__ -   Batch number = 21
Evaluating:   7%|▋         | 21/321 [00:06<01:33,  3.22it/s]01/14/2022 16:15:45 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/321 [00:06<01:30,  3.32it/s]01/14/2022 16:15:45 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/321 [00:06<01:28,  3.38it/s]01/14/2022 16:15:45 - INFO - __main__ -   Batch number = 24
Evaluating:   7%|▋         | 24/321 [00:07<01:26,  3.44it/s]01/14/2022 16:15:46 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/321 [00:07<01:25,  3.47it/s]01/14/2022 16:15:46 - INFO - __main__ -   Batch number = 26
Evaluating:   8%|▊         | 26/321 [00:07<01:24,  3.49it/s]01/14/2022 16:15:46 - INFO - __main__ -   Batch number = 27
Evaluating:   8%|▊         | 27/321 [00:07<01:23,  3.51it/s]01/14/2022 16:15:46 - INFO - __main__ -   Batch number = 28
Evaluating:   9%|▊         | 28/321 [00:08<01:23,  3.52it/s]01/14/2022 16:15:47 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▉         | 29/321 [00:08<01:22,  3.52it/s]01/14/2022 16:15:47 - INFO - __main__ -   Batch number = 30
Evaluating:   9%|▉         | 30/321 [00:08<01:22,  3.53it/s]01/14/2022 16:15:47 - INFO - __main__ -   Batch number = 31
Evaluating:  10%|▉         | 31/321 [00:09<01:22,  3.53it/s]01/14/2022 16:15:48 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|▉         | 32/321 [00:09<01:21,  3.53it/s]01/14/2022 16:15:48 - INFO - __main__ -   Batch number = 33
Evaluating:  10%|█         | 33/321 [00:09<01:21,  3.54it/s]01/14/2022 16:15:48 - INFO - __main__ -   Batch number = 34
Evaluating:  11%|█         | 34/321 [00:09<01:20,  3.55it/s]01/14/2022 16:15:48 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/321 [00:10<01:20,  3.54it/s]01/14/2022 16:15:49 - INFO - __main__ -   Batch number = 36
Evaluating:  11%|█         | 36/321 [00:10<01:20,  3.55it/s]01/14/2022 16:15:49 - INFO - __main__ -   Batch number = 37
Evaluating:  12%|█▏        | 37/321 [00:10<01:20,  3.54it/s]01/14/2022 16:15:49 - INFO - __main__ -   Batch number = 38
Evaluating:  12%|█▏        | 38/321 [00:11<01:19,  3.54it/s]01/14/2022 16:15:50 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/321 [00:11<01:19,  3.53it/s]01/14/2022 16:15:50 - INFO - __main__ -   Batch number = 40
Evaluating:  12%|█▏        | 40/321 [00:11<01:19,  3.53it/s]01/14/2022 16:15:50 - INFO - __main__ -   Batch number = 41
Evaluating:  13%|█▎        | 41/321 [00:11<01:19,  3.53it/s]01/14/2022 16:15:50 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/321 [00:12<01:18,  3.53it/s]01/14/2022 16:15:51 - INFO - __main__ -   Batch number = 43
Evaluating:  13%|█▎        | 43/321 [00:12<01:18,  3.54it/s]01/14/2022 16:15:51 - INFO - __main__ -   Batch number = 44
Evaluating:  14%|█▎        | 44/321 [00:12<01:18,  3.54it/s]01/14/2022 16:15:51 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▍        | 45/321 [00:13<01:17,  3.54it/s]01/14/2022 16:15:52 - INFO - __main__ -   Batch number = 46
Evaluating:  14%|█▍        | 46/321 [00:13<01:17,  3.53it/s]01/14/2022 16:15:52 - INFO - __main__ -   Batch number = 47
Evaluating:  15%|█▍        | 47/321 [00:13<01:17,  3.53it/s]01/14/2022 16:15:52 - INFO - __main__ -   Batch number = 48
Evaluating:  15%|█▍        | 48/321 [00:13<01:17,  3.53it/s]01/14/2022 16:15:52 - INFO - __main__ -   Batch number = 49
Evaluating:  15%|█▌        | 49/321 [00:14<01:16,  3.53it/s]01/14/2022 16:15:53 - INFO - __main__ -   Batch number = 50
Evaluating:  16%|█▌        | 50/321 [00:14<01:16,  3.53it/s]01/14/2022 16:15:53 - INFO - __main__ -   Batch number = 51
Evaluating:  16%|█▌        | 51/321 [00:14<01:16,  3.53it/s]01/14/2022 16:15:53 - INFO - __main__ -   Batch number = 52
Evaluating:  16%|█▌        | 52/321 [00:14<01:16,  3.53it/s]01/14/2022 16:15:54 - INFO - __main__ -   Batch number = 53
Evaluating:  17%|█▋        | 53/321 [00:15<01:15,  3.53it/s]01/14/2022 16:15:54 - INFO - __main__ -   Batch number = 54
Evaluating:  17%|█▋        | 54/321 [00:15<01:15,  3.53it/s]01/14/2022 16:15:54 - INFO - __main__ -   Batch number = 55
Evaluating:  17%|█▋        | 55/321 [00:15<01:15,  3.53it/s]01/14/2022 16:15:54 - INFO - __main__ -   Batch number = 56
Evaluating:  17%|█▋        | 56/321 [00:16<01:15,  3.53it/s]01/14/2022 16:15:55 - INFO - __main__ -   Batch number = 57
Evaluating:  18%|█▊        | 57/321 [00:16<01:14,  3.53it/s]01/14/2022 16:15:55 - INFO - __main__ -   Batch number = 58
Evaluating:  18%|█▊        | 58/321 [00:16<01:14,  3.53it/s]01/14/2022 16:15:55 - INFO - __main__ -   Batch number = 59
Evaluating:  18%|█▊        | 59/321 [00:16<01:14,  3.53it/s]01/14/2022 16:15:56 - INFO - __main__ -   Batch number = 60
Evaluating:  19%|█▊        | 60/321 [00:17<01:14,  3.53it/s]01/14/2022 16:15:56 - INFO - __main__ -   Batch number = 61
Evaluating:  19%|█▉        | 61/321 [00:17<01:13,  3.52it/s]01/14/2022 16:15:56 - INFO - __main__ -   Batch number = 62
Evaluating:  19%|█▉        | 62/321 [00:17<01:13,  3.52it/s]01/14/2022 16:15:56 - INFO - __main__ -   Batch number = 63
Evaluating:  20%|█▉        | 63/321 [00:18<01:13,  3.51it/s]01/14/2022 16:15:57 - INFO - __main__ -   Batch number = 64
Evaluating:  20%|█▉        | 64/321 [00:18<01:13,  3.51it/s]01/14/2022 16:15:57 - INFO - __main__ -   Batch number = 65
Evaluating:  20%|██        | 65/321 [00:18<01:13,  3.51it/s]01/14/2022 16:15:57 - INFO - __main__ -   Batch number = 66
Evaluating:  21%|██        | 66/321 [00:18<01:12,  3.51it/s]01/14/2022 16:15:58 - INFO - __main__ -   Batch number = 67
Evaluating:  21%|██        | 67/321 [00:19<01:12,  3.51it/s]01/14/2022 16:15:58 - INFO - __main__ -   Batch number = 68
Evaluating:  21%|██        | 68/321 [00:19<01:12,  3.51it/s]01/14/2022 16:15:58 - INFO - __main__ -   Batch number = 69
Evaluating:  21%|██▏       | 69/321 [00:19<01:11,  3.51it/s]01/14/2022 16:15:58 - INFO - __main__ -   Batch number = 70
Evaluating:  22%|██▏       | 70/321 [00:20<01:11,  3.51it/s]01/14/2022 16:15:59 - INFO - __main__ -   Batch number = 71
Evaluating:  22%|██▏       | 71/321 [00:20<01:11,  3.50it/s]01/14/2022 16:15:59 - INFO - __main__ -   Batch number = 72
Evaluating:  22%|██▏       | 72/321 [00:20<01:11,  3.49it/s]01/14/2022 16:15:59 - INFO - __main__ -   Batch number = 73
Evaluating:  23%|██▎       | 73/321 [00:20<01:10,  3.49it/s]01/14/2022 16:16:00 - INFO - __main__ -   Batch number = 74
Evaluating:  23%|██▎       | 74/321 [00:21<01:16,  3.24it/s]01/14/2022 16:16:00 - INFO - __main__ -   Batch number = 75
Evaluating:  23%|██▎       | 75/321 [00:21<01:14,  3.31it/s]01/14/2022 16:16:00 - INFO - __main__ -   Batch number = 76
Evaluating:  24%|██▎       | 76/321 [00:21<01:12,  3.37it/s]01/14/2022 16:16:00 - INFO - __main__ -   Batch number = 77
Evaluating:  24%|██▍       | 77/321 [00:22<01:11,  3.40it/s]01/14/2022 16:16:01 - INFO - __main__ -   Batch number = 78
Evaluating:  24%|██▍       | 78/321 [00:22<01:11,  3.42it/s]01/14/2022 16:16:01 - INFO - __main__ -   Batch number = 79
Evaluating:  25%|██▍       | 79/321 [00:22<01:10,  3.45it/s]01/14/2022 16:16:01 - INFO - __main__ -   Batch number = 80
Evaluating:  25%|██▍       | 80/321 [00:23<01:09,  3.46it/s]01/14/2022 16:16:02 - INFO - __main__ -   Batch number = 81
Evaluating:  25%|██▌       | 81/321 [00:23<01:09,  3.48it/s]01/14/2022 16:16:02 - INFO - __main__ -   Batch number = 82
Evaluating:  26%|██▌       | 82/321 [00:23<01:08,  3.47it/s]01/14/2022 16:16:02 - INFO - __main__ -   Batch number = 83
Evaluating:  26%|██▌       | 83/321 [00:23<01:08,  3.46it/s]01/14/2022 16:16:02 - INFO - __main__ -   Batch number = 84
Evaluating:  26%|██▌       | 84/321 [00:24<01:08,  3.46it/s]01/14/2022 16:16:03 - INFO - __main__ -   Batch number = 85
Evaluating:  26%|██▋       | 85/321 [00:24<01:08,  3.46it/s]01/14/2022 16:16:03 - INFO - __main__ -   Batch number = 86
Evaluating:  27%|██▋       | 86/321 [00:24<01:07,  3.46it/s]01/14/2022 16:16:03 - INFO - __main__ -   Batch number = 87
Evaluating:  27%|██▋       | 87/321 [00:25<01:07,  3.47it/s]01/14/2022 16:16:04 - INFO - __main__ -   Batch number = 88
Evaluating:  27%|██▋       | 88/321 [00:25<01:06,  3.48it/s]01/14/2022 16:16:04 - INFO - __main__ -   Batch number = 89
Evaluating:  28%|██▊       | 89/321 [00:25<01:06,  3.48it/s]01/14/2022 16:16:04 - INFO - __main__ -   Batch number = 90
Evaluating:  28%|██▊       | 90/321 [00:25<01:06,  3.48it/s]01/14/2022 16:16:04 - INFO - __main__ -   Batch number = 91
Evaluating:  28%|██▊       | 91/321 [00:26<01:06,  3.47it/s]01/14/2022 16:16:05 - INFO - __main__ -   Batch number = 92
Evaluating:  29%|██▊       | 92/321 [00:26<01:06,  3.46it/s]01/14/2022 16:16:05 - INFO - __main__ -   Batch number = 93
Evaluating:  29%|██▉       | 93/321 [00:26<01:05,  3.47it/s]01/14/2022 16:16:05 - INFO - __main__ -   Batch number = 94
Evaluating:  29%|██▉       | 94/321 [00:27<01:05,  3.47it/s]01/14/2022 16:16:06 - INFO - __main__ -   Batch number = 95
Evaluating:  30%|██▉       | 95/321 [00:27<01:05,  3.44it/s]01/14/2022 16:16:06 - INFO - __main__ -   Batch number = 96
Evaluating:  30%|██▉       | 96/321 [00:27<01:05,  3.44it/s]01/14/2022 16:16:06 - INFO - __main__ -   Batch number = 97
Evaluating:  30%|███       | 97/321 [00:27<01:05,  3.44it/s]01/14/2022 16:16:07 - INFO - __main__ -   Batch number = 98
Evaluating:  31%|███       | 98/321 [00:28<01:04,  3.44it/s]01/14/2022 16:16:07 - INFO - __main__ -   Batch number = 99
Evaluating:  31%|███       | 99/321 [00:28<01:04,  3.43it/s]01/14/2022 16:16:07 - INFO - __main__ -   Batch number = 100
Evaluating:  31%|███       | 100/321 [00:28<01:04,  3.42it/s]01/14/2022 16:16:07 - INFO - __main__ -   Batch number = 101
Evaluating:  31%|███▏      | 101/321 [00:29<01:04,  3.40it/s]01/14/2022 16:16:08 - INFO - __main__ -   Batch number = 102
Evaluating:  32%|███▏      | 102/321 [00:29<01:04,  3.38it/s]01/14/2022 16:16:08 - INFO - __main__ -   Batch number = 103
Evaluating:  32%|███▏      | 103/321 [00:29<01:04,  3.37it/s]01/14/2022 16:16:08 - INFO - __main__ -   Batch number = 104
Evaluating:  32%|███▏      | 104/321 [00:30<01:04,  3.37it/s]01/14/2022 16:16:09 - INFO - __main__ -   Batch number = 105
Evaluating:  33%|███▎      | 105/321 [00:30<01:04,  3.36it/s]01/14/2022 16:16:09 - INFO - __main__ -   Batch number = 106
Evaluating:  33%|███▎      | 106/321 [00:30<01:04,  3.35it/s]01/14/2022 16:16:09 - INFO - __main__ -   Batch number = 107
Evaluating:  33%|███▎      | 107/321 [00:30<01:03,  3.34it/s]01/14/2022 16:16:09 - INFO - __main__ -   Batch number = 108
Evaluating:  34%|███▎      | 108/321 [00:31<01:03,  3.34it/s]01/14/2022 16:16:10 - INFO - __main__ -   Batch number = 109
Evaluating:  34%|███▍      | 109/321 [00:31<01:03,  3.33it/s]01/14/2022 16:16:10 - INFO - __main__ -   Batch number = 110
Evaluating:  34%|███▍      | 110/321 [00:31<01:04,  3.29it/s]01/14/2022 16:16:10 - INFO - __main__ -   Batch number = 111
Evaluating:  35%|███▍      | 111/321 [00:32<01:04,  3.27it/s]01/14/2022 16:16:11 - INFO - __main__ -   Batch number = 112
Evaluating:  35%|███▍      | 112/321 [00:32<01:04,  3.25it/s]01/14/2022 16:16:11 - INFO - __main__ -   Batch number = 113
Evaluating:  35%|███▌      | 113/321 [00:32<01:04,  3.25it/s]01/14/2022 16:16:11 - INFO - __main__ -   Batch number = 114
Evaluating:  36%|███▌      | 114/321 [00:33<01:03,  3.27it/s]01/14/2022 16:16:12 - INFO - __main__ -   Batch number = 115
Evaluating:  36%|███▌      | 115/321 [00:33<01:02,  3.31it/s]01/14/2022 16:16:12 - INFO - __main__ -   Batch number = 116
Evaluating:  36%|███▌      | 116/321 [00:33<01:01,  3.33it/s]01/14/2022 16:16:12 - INFO - __main__ -   Batch number = 117
Evaluating:  36%|███▋      | 117/321 [00:33<01:01,  3.33it/s]01/14/2022 16:16:13 - INFO - __main__ -   Batch number = 118
Evaluating:  37%|███▋      | 118/321 [00:34<01:00,  3.33it/s]01/14/2022 16:16:13 - INFO - __main__ -   Batch number = 119
Evaluating:  37%|███▋      | 119/321 [00:34<01:00,  3.32it/s]01/14/2022 16:16:13 - INFO - __main__ -   Batch number = 120
Evaluating:  37%|███▋      | 120/321 [00:34<01:00,  3.31it/s]01/14/2022 16:16:13 - INFO - __main__ -   Batch number = 121
Evaluating:  38%|███▊      | 121/321 [00:35<01:00,  3.29it/s]01/14/2022 16:16:14 - INFO - __main__ -   Batch number = 122
Evaluating:  38%|███▊      | 122/321 [00:35<01:00,  3.29it/s]01/14/2022 16:16:14 - INFO - __main__ -   Batch number = 123
Evaluating:  38%|███▊      | 123/321 [00:35<01:00,  3.27it/s]01/14/2022 16:16:14 - INFO - __main__ -   Batch number = 124
Evaluating:  39%|███▊      | 124/321 [00:36<01:00,  3.26it/s]01/14/2022 16:16:15 - INFO - __main__ -   Batch number = 125
Evaluating:  39%|███▉      | 125/321 [00:36<01:00,  3.26it/s]01/14/2022 16:16:15 - INFO - __main__ -   Batch number = 126
Evaluating:  39%|███▉      | 126/321 [00:36<00:59,  3.26it/s]01/14/2022 16:16:15 - INFO - __main__ -   Batch number = 127
Evaluating:  40%|███▉      | 127/321 [00:37<00:59,  3.26it/s]01/14/2022 16:16:16 - INFO - __main__ -   Batch number = 128
Evaluating:  40%|███▉      | 128/321 [00:37<00:59,  3.25it/s]01/14/2022 16:16:16 - INFO - __main__ -   Batch number = 129
Evaluating:  40%|████      | 129/321 [00:37<00:59,  3.24it/s]01/14/2022 16:16:16 - INFO - __main__ -   Batch number = 130
Evaluating:  40%|████      | 130/321 [00:37<00:59,  3.23it/s]01/14/2022 16:16:17 - INFO - __main__ -   Batch number = 131
Evaluating:  41%|████      | 131/321 [00:38<00:59,  3.22it/s]01/14/2022 16:16:17 - INFO - __main__ -   Batch number = 132
Evaluating:  41%|████      | 132/321 [00:38<00:58,  3.22it/s]01/14/2022 16:16:17 - INFO - __main__ -   Batch number = 133
Evaluating:  41%|████▏     | 133/321 [00:38<00:58,  3.23it/s]01/14/2022 16:16:17 - INFO - __main__ -   Batch number = 134
Evaluating:  42%|████▏     | 134/321 [00:39<00:58,  3.21it/s]01/14/2022 16:16:18 - INFO - __main__ -   Batch number = 135
Evaluating:  42%|████▏     | 135/321 [00:39<00:57,  3.21it/s]01/14/2022 16:16:18 - INFO - __main__ -   Batch number = 136
Evaluating:  42%|████▏     | 136/321 [00:39<00:57,  3.21it/s]01/14/2022 16:16:18 - INFO - __main__ -   Batch number = 137
Evaluating:  43%|████▎     | 137/321 [00:40<00:57,  3.21it/s]01/14/2022 16:16:19 - INFO - __main__ -   Batch number = 138
Evaluating:  43%|████▎     | 138/321 [00:40<00:56,  3.22it/s]01/14/2022 16:16:19 - INFO - __main__ -   Batch number = 139
Evaluating:  43%|████▎     | 139/321 [00:40<00:55,  3.25it/s]01/14/2022 16:16:19 - INFO - __main__ -   Batch number = 140
Evaluating:  44%|████▎     | 140/321 [00:41<00:55,  3.29it/s]01/14/2022 16:16:20 - INFO - __main__ -   Batch number = 141
Evaluating:  44%|████▍     | 141/321 [00:41<00:57,  3.14it/s]01/14/2022 16:16:20 - INFO - __main__ -   Batch number = 142
Evaluating:  44%|████▍     | 142/321 [00:41<00:55,  3.22it/s]01/14/2022 16:16:20 - INFO - __main__ -   Batch number = 143
Evaluating:  45%|████▍     | 143/321 [00:41<00:54,  3.27it/s]01/14/2022 16:16:21 - INFO - __main__ -   Batch number = 144
Evaluating:  45%|████▍     | 144/321 [00:42<00:53,  3.29it/s]01/14/2022 16:16:21 - INFO - __main__ -   Batch number = 145
Evaluating:  45%|████▌     | 145/321 [00:42<00:53,  3.32it/s]01/14/2022 16:16:21 - INFO - __main__ -   Batch number = 146
Evaluating:  45%|████▌     | 146/321 [00:42<00:52,  3.32it/s]01/14/2022 16:16:21 - INFO - __main__ -   Batch number = 147
Evaluating:  46%|████▌     | 147/321 [00:43<00:53,  3.27it/s]01/14/2022 16:16:22 - INFO - __main__ -   Batch number = 148
Evaluating:  46%|████▌     | 148/321 [00:43<00:53,  3.24it/s]01/14/2022 16:16:22 - INFO - __main__ -   Batch number = 149
Evaluating:  46%|████▋     | 149/321 [00:43<00:53,  3.23it/s]01/14/2022 16:16:22 - INFO - __main__ -   Batch number = 150
Evaluating:  47%|████▋     | 150/321 [00:44<00:52,  3.24it/s]01/14/2022 16:16:23 - INFO - __main__ -   Batch number = 151
Evaluating:  47%|████▋     | 151/321 [00:44<00:52,  3.25it/s]01/14/2022 16:16:23 - INFO - __main__ -   Batch number = 152
Evaluating:  47%|████▋     | 152/321 [00:44<00:52,  3.24it/s]01/14/2022 16:16:23 - INFO - __main__ -   Batch number = 153
Evaluating:  48%|████▊     | 153/321 [00:45<00:52,  3.23it/s]01/14/2022 16:16:24 - INFO - __main__ -   Batch number = 154
Evaluating:  48%|████▊     | 154/321 [00:45<00:51,  3.23it/s]01/14/2022 16:16:24 - INFO - __main__ -   Batch number = 155
Evaluating:  48%|████▊     | 155/321 [00:45<00:51,  3.23it/s]01/14/2022 16:16:24 - INFO - __main__ -   Batch number = 156
Evaluating:  49%|████▊     | 156/321 [00:45<00:51,  3.23it/s]01/14/2022 16:16:25 - INFO - __main__ -   Batch number = 157
Evaluating:  49%|████▉     | 157/321 [00:46<00:55,  2.93it/s]01/14/2022 16:16:25 - INFO - __main__ -   Batch number = 158
Evaluating:  49%|████▉     | 158/321 [00:46<00:54,  3.02it/s]01/14/2022 16:16:25 - INFO - __main__ -   Batch number = 159
Evaluating:  50%|████▉     | 159/321 [00:47<00:52,  3.08it/s]01/14/2022 16:16:26 - INFO - __main__ -   Batch number = 160
Evaluating:  50%|████▉     | 160/321 [00:47<00:50,  3.16it/s]01/14/2022 16:16:26 - INFO - __main__ -   Batch number = 161
Evaluating:  50%|█████     | 161/321 [00:47<00:49,  3.22it/s]01/14/2022 16:16:26 - INFO - __main__ -   Batch number = 162
Evaluating:  50%|█████     | 162/321 [00:47<00:48,  3.27it/s]01/14/2022 16:16:26 - INFO - __main__ -   Batch number = 163
Evaluating:  51%|█████     | 163/321 [00:48<00:47,  3.31it/s]01/14/2022 16:16:27 - INFO - __main__ -   Batch number = 164
Evaluating:  51%|█████     | 164/321 [00:48<00:47,  3.33it/s]01/14/2022 16:16:27 - INFO - __main__ -   Batch number = 165
Evaluating:  51%|█████▏    | 165/321 [00:48<00:46,  3.35it/s]01/14/2022 16:16:27 - INFO - __main__ -   Batch number = 166
Evaluating:  52%|█████▏    | 166/321 [00:49<00:46,  3.37it/s]01/14/2022 16:16:28 - INFO - __main__ -   Batch number = 167
Evaluating:  52%|█████▏    | 167/321 [00:49<00:46,  3.34it/s]01/14/2022 16:16:28 - INFO - __main__ -   Batch number = 168
Evaluating:  52%|█████▏    | 168/321 [00:49<00:45,  3.35it/s]01/14/2022 16:16:28 - INFO - __main__ -   Batch number = 169
Evaluating:  53%|█████▎    | 169/321 [00:49<00:45,  3.37it/s]01/14/2022 16:16:29 - INFO - __main__ -   Batch number = 170
Evaluating:  53%|█████▎    | 170/321 [00:50<00:44,  3.38it/s]01/14/2022 16:16:29 - INFO - __main__ -   Batch number = 171
Evaluating:  53%|█████▎    | 171/321 [00:50<00:44,  3.38it/s]01/14/2022 16:16:29 - INFO - __main__ -   Batch number = 172
Evaluating:  54%|█████▎    | 172/321 [00:50<00:44,  3.38it/s]01/14/2022 16:16:29 - INFO - __main__ -   Batch number = 173
Evaluating:  54%|█████▍    | 173/321 [00:51<00:43,  3.37it/s]01/14/2022 16:16:30 - INFO - __main__ -   Batch number = 174
Evaluating:  54%|█████▍    | 174/321 [00:51<00:43,  3.38it/s]01/14/2022 16:16:30 - INFO - __main__ -   Batch number = 175
Evaluating:  55%|█████▍    | 175/321 [00:51<00:43,  3.37it/s]01/14/2022 16:16:30 - INFO - __main__ -   Batch number = 176
Evaluating:  55%|█████▍    | 176/321 [00:52<00:43,  3.36it/s]01/14/2022 16:16:31 - INFO - __main__ -   Batch number = 177
Evaluating:  55%|█████▌    | 177/321 [00:52<00:42,  3.38it/s]01/14/2022 16:16:31 - INFO - __main__ -   Batch number = 178
Evaluating:  55%|█████▌    | 178/321 [00:52<00:42,  3.40it/s]01/14/2022 16:16:31 - INFO - __main__ -   Batch number = 179
Evaluating:  56%|█████▌    | 179/321 [00:52<00:41,  3.41it/s]01/14/2022 16:16:31 - INFO - __main__ -   Batch number = 180
Evaluating:  56%|█████▌    | 180/321 [00:53<00:41,  3.42it/s]01/14/2022 16:16:32 - INFO - __main__ -   Batch number = 181
Evaluating:  56%|█████▋    | 181/321 [00:53<00:40,  3.42it/s]01/14/2022 16:16:32 - INFO - __main__ -   Batch number = 182
Evaluating:  57%|█████▋    | 182/321 [00:53<00:40,  3.41it/s]01/14/2022 16:16:32 - INFO - __main__ -   Batch number = 183
Evaluating:  57%|█████▋    | 183/321 [00:54<00:40,  3.40it/s]01/14/2022 16:16:33 - INFO - __main__ -   Batch number = 184
Evaluating:  57%|█████▋    | 184/321 [00:54<00:40,  3.42it/s]01/14/2022 16:16:33 - INFO - __main__ -   Batch number = 185
Evaluating:  58%|█████▊    | 185/321 [00:54<00:39,  3.43it/s]01/14/2022 16:16:33 - INFO - __main__ -   Batch number = 186
Evaluating:  58%|█████▊    | 186/321 [00:54<00:39,  3.42it/s]01/14/2022 16:16:34 - INFO - __main__ -   Batch number = 187
Evaluating:  58%|█████▊    | 187/321 [00:55<00:39,  3.41it/s]01/14/2022 16:16:34 - INFO - __main__ -   Batch number = 188
Evaluating:  59%|█████▊    | 188/321 [00:55<00:39,  3.41it/s]01/14/2022 16:16:34 - INFO - __main__ -   Batch number = 189
Evaluating:  59%|█████▉    | 189/321 [00:55<00:38,  3.41it/s]01/14/2022 16:16:34 - INFO - __main__ -   Batch number = 190
Evaluating:  59%|█████▉    | 190/321 [00:56<00:38,  3.41it/s]01/14/2022 16:16:35 - INFO - __main__ -   Batch number = 191
Evaluating:  60%|█████▉    | 191/321 [00:56<00:38,  3.40it/s]01/14/2022 16:16:35 - INFO - __main__ -   Batch number = 192
Evaluating:  60%|█████▉    | 192/321 [00:56<00:37,  3.41it/s]01/14/2022 16:16:35 - INFO - __main__ -   Batch number = 193
Evaluating:  60%|██████    | 193/321 [00:57<00:37,  3.42it/s]01/14/2022 16:16:36 - INFO - __main__ -   Batch number = 194
Evaluating:  60%|██████    | 194/321 [00:57<00:37,  3.42it/s]01/14/2022 16:16:36 - INFO - __main__ -   Batch number = 195
Evaluating:  61%|██████    | 195/321 [00:57<00:37,  3.40it/s]01/14/2022 16:16:36 - INFO - __main__ -   Batch number = 196
Evaluating:  61%|██████    | 196/321 [00:57<00:37,  3.36it/s]01/14/2022 16:16:36 - INFO - __main__ -   Batch number = 197
Evaluating:  61%|██████▏   | 197/321 [00:58<00:37,  3.34it/s]01/14/2022 16:16:37 - INFO - __main__ -   Batch number = 198
Evaluating:  62%|██████▏   | 198/321 [00:58<00:37,  3.29it/s]01/14/2022 16:16:37 - INFO - __main__ -   Batch number = 199
Evaluating:  62%|██████▏   | 199/321 [00:58<00:37,  3.27it/s]01/14/2022 16:16:37 - INFO - __main__ -   Batch number = 200
Evaluating:  62%|██████▏   | 200/321 [00:59<00:37,  3.25it/s]01/14/2022 16:16:38 - INFO - __main__ -   Batch number = 201
Evaluating:  63%|██████▎   | 201/321 [00:59<00:37,  3.23it/s]01/14/2022 16:16:38 - INFO - __main__ -   Batch number = 202
Evaluating:  63%|██████▎   | 202/321 [00:59<00:37,  3.21it/s]01/14/2022 16:16:38 - INFO - __main__ -   Batch number = 203
Evaluating:  63%|██████▎   | 203/321 [01:00<00:36,  3.22it/s]01/14/2022 16:16:39 - INFO - __main__ -   Batch number = 204
Evaluating:  64%|██████▎   | 204/321 [01:00<00:36,  3.22it/s]01/14/2022 16:16:39 - INFO - __main__ -   Batch number = 205
Evaluating:  64%|██████▍   | 205/321 [01:00<00:36,  3.21it/s]01/14/2022 16:16:39 - INFO - __main__ -   Batch number = 206
Evaluating:  64%|██████▍   | 206/321 [01:01<00:36,  3.19it/s]01/14/2022 16:16:40 - INFO - __main__ -   Batch number = 207
Evaluating:  64%|██████▍   | 207/321 [01:01<00:40,  2.79it/s]01/14/2022 16:16:40 - INFO - __main__ -   Batch number = 208
Evaluating:  65%|██████▍   | 208/321 [01:01<00:38,  2.94it/s]01/14/2022 16:16:40 - INFO - __main__ -   Batch number = 209
Evaluating:  65%|██████▌   | 209/321 [01:02<00:36,  3.05it/s]01/14/2022 16:16:41 - INFO - __main__ -   Batch number = 210
Evaluating:  65%|██████▌   | 210/321 [01:02<00:35,  3.12it/s]01/14/2022 16:16:41 - INFO - __main__ -   Batch number = 211
Evaluating:  66%|██████▌   | 211/321 [01:02<00:34,  3.16it/s]01/14/2022 16:16:41 - INFO - __main__ -   Batch number = 212
Evaluating:  66%|██████▌   | 212/321 [01:03<00:33,  3.23it/s]01/14/2022 16:16:42 - INFO - __main__ -   Batch number = 213
Evaluating:  66%|██████▋   | 213/321 [01:03<00:32,  3.29it/s]01/14/2022 16:16:42 - INFO - __main__ -   Batch number = 214
Evaluating:  67%|██████▋   | 214/321 [01:03<00:32,  3.31it/s]01/14/2022 16:16:42 - INFO - __main__ -   Batch number = 215
Evaluating:  67%|██████▋   | 215/321 [01:03<00:31,  3.34it/s]01/14/2022 16:16:42 - INFO - __main__ -   Batch number = 216
Evaluating:  67%|██████▋   | 216/321 [01:04<00:31,  3.34it/s]01/14/2022 16:16:43 - INFO - __main__ -   Batch number = 217
Evaluating:  68%|██████▊   | 217/321 [01:04<00:31,  3.35it/s]01/14/2022 16:16:43 - INFO - __main__ -   Batch number = 218
Evaluating:  68%|██████▊   | 218/321 [01:04<00:30,  3.34it/s]01/14/2022 16:16:43 - INFO - __main__ -   Batch number = 219
Evaluating:  68%|██████▊   | 219/321 [01:05<00:30,  3.31it/s]01/14/2022 16:16:44 - INFO - __main__ -   Batch number = 220
Evaluating:  69%|██████▊   | 220/321 [01:05<00:30,  3.31it/s]01/14/2022 16:16:44 - INFO - __main__ -   Batch number = 221
Evaluating:  69%|██████▉   | 221/321 [01:05<00:30,  3.28it/s]01/14/2022 16:16:44 - INFO - __main__ -   Batch number = 222
Evaluating:  69%|██████▉   | 222/321 [01:06<00:30,  3.26it/s]01/14/2022 16:16:45 - INFO - __main__ -   Batch number = 223
Evaluating:  69%|██████▉   | 223/321 [01:06<00:30,  3.23it/s]01/14/2022 16:16:45 - INFO - __main__ -   Batch number = 224
Evaluating:  70%|██████▉   | 224/321 [01:06<00:30,  3.22it/s]01/14/2022 16:16:45 - INFO - __main__ -   Batch number = 225
Evaluating:  70%|███████   | 225/321 [01:06<00:29,  3.20it/s]01/14/2022 16:16:46 - INFO - __main__ -   Batch number = 226
Evaluating:  70%|███████   | 226/321 [01:07<00:29,  3.21it/s]01/14/2022 16:16:46 - INFO - __main__ -   Batch number = 227
Evaluating:  71%|███████   | 227/321 [01:07<00:29,  3.22it/s]01/14/2022 16:16:46 - INFO - __main__ -   Batch number = 228
Evaluating:  71%|███████   | 228/321 [01:07<00:28,  3.23it/s]01/14/2022 16:16:46 - INFO - __main__ -   Batch number = 229
Evaluating:  71%|███████▏  | 229/321 [01:08<00:28,  3.26it/s]01/14/2022 16:16:47 - INFO - __main__ -   Batch number = 230
Evaluating:  72%|███████▏  | 230/321 [01:08<00:27,  3.28it/s]01/14/2022 16:16:47 - INFO - __main__ -   Batch number = 231
Evaluating:  72%|███████▏  | 231/321 [01:08<00:27,  3.28it/s]01/14/2022 16:16:47 - INFO - __main__ -   Batch number = 232
Evaluating:  72%|███████▏  | 232/321 [01:09<00:27,  3.26it/s]01/14/2022 16:16:48 - INFO - __main__ -   Batch number = 233
Evaluating:  73%|███████▎  | 233/321 [01:09<00:27,  3.25it/s]01/14/2022 16:16:48 - INFO - __main__ -   Batch number = 234
Evaluating:  73%|███████▎  | 234/321 [01:09<00:26,  3.26it/s]01/14/2022 16:16:48 - INFO - __main__ -   Batch number = 235
Evaluating:  73%|███████▎  | 235/321 [01:10<00:26,  3.29it/s]01/14/2022 16:16:49 - INFO - __main__ -   Batch number = 236
Evaluating:  74%|███████▎  | 236/321 [01:10<00:25,  3.28it/s]01/14/2022 16:16:49 - INFO - __main__ -   Batch number = 237
Evaluating:  74%|███████▍  | 237/321 [01:10<00:25,  3.25it/s]01/14/2022 16:16:49 - INFO - __main__ -   Batch number = 238
Evaluating:  74%|███████▍  | 238/321 [01:10<00:25,  3.22it/s]01/14/2022 16:16:50 - INFO - __main__ -   Batch number = 239
Evaluating:  74%|███████▍  | 239/321 [01:11<00:25,  3.21it/s]01/14/2022 16:16:50 - INFO - __main__ -   Batch number = 240
Evaluating:  75%|███████▍  | 240/321 [01:11<00:25,  3.21it/s]01/14/2022 16:16:50 - INFO - __main__ -   Batch number = 241
Evaluating:  75%|███████▌  | 241/321 [01:11<00:24,  3.21it/s]01/14/2022 16:16:50 - INFO - __main__ -   Batch number = 242
Evaluating:  75%|███████▌  | 242/321 [01:12<00:24,  3.23it/s]01/14/2022 16:16:51 - INFO - __main__ -   Batch number = 243
Evaluating:  76%|███████▌  | 243/321 [01:12<00:23,  3.26it/s]01/14/2022 16:16:51 - INFO - __main__ -   Batch number = 244
Evaluating:  76%|███████▌  | 244/321 [01:12<00:23,  3.30it/s]01/14/2022 16:16:51 - INFO - __main__ -   Batch number = 245
Evaluating:  76%|███████▋  | 245/321 [01:13<00:22,  3.33it/s]01/14/2022 16:16:52 - INFO - __main__ -   Batch number = 246
Evaluating:  77%|███████▋  | 246/321 [01:13<00:22,  3.33it/s]01/14/2022 16:16:52 - INFO - __main__ -   Batch number = 247
Evaluating:  77%|███████▋  | 247/321 [01:13<00:22,  3.31it/s]01/14/2022 16:16:52 - INFO - __main__ -   Batch number = 248
Evaluating:  77%|███████▋  | 248/321 [01:14<00:22,  3.29it/s]01/14/2022 16:16:53 - INFO - __main__ -   Batch number = 249
Evaluating:  78%|███████▊  | 249/321 [01:14<00:22,  3.26it/s]01/14/2022 16:16:53 - INFO - __main__ -   Batch number = 250
Evaluating:  78%|███████▊  | 250/321 [01:14<00:21,  3.23it/s]01/14/2022 16:16:53 - INFO - __main__ -   Batch number = 251
Evaluating:  78%|███████▊  | 251/321 [01:14<00:21,  3.22it/s]01/14/2022 16:16:54 - INFO - __main__ -   Batch number = 252
Evaluating:  79%|███████▊  | 252/321 [01:15<00:21,  3.21it/s]01/14/2022 16:16:54 - INFO - __main__ -   Batch number = 253
Evaluating:  79%|███████▉  | 253/321 [01:15<00:21,  3.20it/s]01/14/2022 16:16:54 - INFO - __main__ -   Batch number = 254
Evaluating:  79%|███████▉  | 254/321 [01:15<00:20,  3.20it/s]01/14/2022 16:16:54 - INFO - __main__ -   Batch number = 255
Evaluating:  79%|███████▉  | 255/321 [01:16<00:20,  3.24it/s]01/14/2022 16:16:55 - INFO - __main__ -   Batch number = 256
Evaluating:  80%|███████▉  | 256/321 [01:16<00:19,  3.28it/s]01/14/2022 16:16:55 - INFO - __main__ -   Batch number = 257
Evaluating:  80%|████████  | 257/321 [01:16<00:19,  3.31it/s]01/14/2022 16:16:55 - INFO - __main__ -   Batch number = 258
Evaluating:  80%|████████  | 258/321 [01:17<00:18,  3.32it/s]01/14/2022 16:16:56 - INFO - __main__ -   Batch number = 259
Evaluating:  81%|████████  | 259/321 [01:17<00:18,  3.30it/s]01/14/2022 16:16:56 - INFO - __main__ -   Batch number = 260
Evaluating:  81%|████████  | 260/321 [01:17<00:18,  3.25it/s]01/14/2022 16:16:56 - INFO - __main__ -   Batch number = 261
Evaluating:  81%|████████▏ | 261/321 [01:18<00:18,  3.25it/s]01/14/2022 16:16:57 - INFO - __main__ -   Batch number = 262
Evaluating:  82%|████████▏ | 262/321 [01:18<00:18,  3.23it/s]01/14/2022 16:16:57 - INFO - __main__ -   Batch number = 263
Evaluating:  82%|████████▏ | 263/321 [01:18<00:17,  3.23it/s]01/14/2022 16:16:57 - INFO - __main__ -   Batch number = 264
Evaluating:  82%|████████▏ | 264/321 [01:18<00:17,  3.24it/s]01/14/2022 16:16:57 - INFO - __main__ -   Batch number = 265
Evaluating:  83%|████████▎ | 265/321 [01:19<00:17,  3.24it/s]01/14/2022 16:16:58 - INFO - __main__ -   Batch number = 266
Evaluating:  83%|████████▎ | 266/321 [01:19<00:17,  3.23it/s]01/14/2022 16:16:58 - INFO - __main__ -   Batch number = 267
Evaluating:  83%|████████▎ | 267/321 [01:19<00:16,  3.23it/s]01/14/2022 16:16:58 - INFO - __main__ -   Batch number = 268
Evaluating:  83%|████████▎ | 268/321 [01:20<00:16,  3.25it/s]01/14/2022 16:16:59 - INFO - __main__ -   Batch number = 269
Evaluating:  84%|████████▍ | 269/321 [01:20<00:15,  3.26it/s]01/14/2022 16:16:59 - INFO - __main__ -   Batch number = 270
Evaluating:  84%|████████▍ | 270/321 [01:20<00:15,  3.27it/s]01/14/2022 16:16:59 - INFO - __main__ -   Batch number = 271
Evaluating:  84%|████████▍ | 271/321 [01:21<00:15,  3.28it/s]01/14/2022 16:17:00 - INFO - __main__ -   Batch number = 272
Evaluating:  85%|████████▍ | 272/321 [01:21<00:16,  2.97it/s]01/14/2022 16:17:00 - INFO - __main__ -   Batch number = 273
Evaluating:  85%|████████▌ | 273/321 [01:21<00:15,  3.07it/s]01/14/2022 16:17:00 - INFO - __main__ -   Batch number = 274
Evaluating:  85%|████████▌ | 274/321 [01:22<00:15,  3.13it/s]01/14/2022 16:17:01 - INFO - __main__ -   Batch number = 275
Evaluating:  86%|████████▌ | 275/321 [01:22<00:14,  3.15it/s]01/14/2022 16:17:01 - INFO - __main__ -   Batch number = 276
Evaluating:  86%|████████▌ | 276/321 [01:22<00:14,  3.16it/s]01/14/2022 16:17:01 - INFO - __main__ -   Batch number = 277
Evaluating:  86%|████████▋ | 277/321 [01:23<00:13,  3.17it/s]01/14/2022 16:17:02 - INFO - __main__ -   Batch number = 278
Evaluating:  87%|████████▋ | 278/321 [01:23<00:13,  3.18it/s]01/14/2022 16:17:02 - INFO - __main__ -   Batch number = 279
Evaluating:  87%|████████▋ | 279/321 [01:23<00:13,  3.19it/s]01/14/2022 16:17:02 - INFO - __main__ -   Batch number = 280
Evaluating:  87%|████████▋ | 280/321 [01:23<00:12,  3.18it/s]01/14/2022 16:17:03 - INFO - __main__ -   Batch number = 281
Evaluating:  88%|████████▊ | 281/321 [01:24<00:12,  3.22it/s]01/14/2022 16:17:03 - INFO - __main__ -   Batch number = 282
Evaluating:  88%|████████▊ | 282/321 [01:24<00:11,  3.28it/s]01/14/2022 16:17:03 - INFO - __main__ -   Batch number = 283
Evaluating:  88%|████████▊ | 283/321 [01:24<00:11,  3.31it/s]01/14/2022 16:17:03 - INFO - __main__ -   Batch number = 284
Evaluating:  88%|████████▊ | 284/321 [01:25<00:11,  3.33it/s]01/14/2022 16:17:04 - INFO - __main__ -   Batch number = 285
Evaluating:  89%|████████▉ | 285/321 [01:25<00:10,  3.29it/s]01/14/2022 16:17:04 - INFO - __main__ -   Batch number = 286
Evaluating:  89%|████████▉ | 286/321 [01:25<00:10,  3.27it/s]01/14/2022 16:17:04 - INFO - __main__ -   Batch number = 287
Evaluating:  89%|████████▉ | 287/321 [01:26<00:10,  3.25it/s]01/14/2022 16:17:05 - INFO - __main__ -   Batch number = 288
Evaluating:  90%|████████▉ | 288/321 [01:26<00:10,  3.22it/s]01/14/2022 16:17:05 - INFO - __main__ -   Batch number = 289
Evaluating:  90%|█████████ | 289/321 [01:26<00:09,  3.21it/s]01/14/2022 16:17:05 - INFO - __main__ -   Batch number = 290
Evaluating:  90%|█████████ | 290/321 [01:27<00:09,  3.25it/s]01/14/2022 16:17:06 - INFO - __main__ -   Batch number = 291
Evaluating:  91%|█████████ | 291/321 [01:27<00:09,  3.27it/s]01/14/2022 16:17:06 - INFO - __main__ -   Batch number = 292
Evaluating:  91%|█████████ | 292/321 [01:27<00:08,  3.27it/s]01/14/2022 16:17:06 - INFO - __main__ -   Batch number = 293
Evaluating:  91%|█████████▏| 293/321 [01:27<00:08,  3.24it/s]01/14/2022 16:17:07 - INFO - __main__ -   Batch number = 294
Evaluating:  92%|█████████▏| 294/321 [01:28<00:08,  3.23it/s]01/14/2022 16:17:07 - INFO - __main__ -   Batch number = 295
Evaluating:  92%|█████████▏| 295/321 [01:28<00:08,  3.23it/s]01/14/2022 16:17:07 - INFO - __main__ -   Batch number = 296
Evaluating:  92%|█████████▏| 296/321 [01:28<00:07,  3.22it/s]01/14/2022 16:17:07 - INFO - __main__ -   Batch number = 297
Evaluating:  93%|█████████▎| 297/321 [01:29<00:07,  3.24it/s]01/14/2022 16:17:08 - INFO - __main__ -   Batch number = 298
Evaluating:  93%|█████████▎| 298/321 [01:29<00:07,  3.27it/s]01/14/2022 16:17:08 - INFO - __main__ -   Batch number = 299
Evaluating:  93%|█████████▎| 299/321 [01:29<00:06,  3.30it/s]01/14/2022 16:17:08 - INFO - __main__ -   Batch number = 300
Evaluating:  93%|█████████▎| 300/321 [01:30<00:06,  3.21it/s]01/14/2022 16:17:09 - INFO - __main__ -   Batch number = 301
Evaluating:  94%|█████████▍| 301/321 [01:30<00:06,  3.23it/s]01/14/2022 16:17:09 - INFO - __main__ -   Batch number = 302
Evaluating:  94%|█████████▍| 302/321 [01:30<00:05,  3.25it/s]01/14/2022 16:17:09 - INFO - __main__ -   Batch number = 303
Evaluating:  94%|█████████▍| 303/321 [01:31<00:05,  3.26it/s]01/14/2022 16:17:10 - INFO - __main__ -   Batch number = 304
Evaluating:  95%|█████████▍| 304/321 [01:31<00:05,  3.12it/s]01/14/2022 16:17:10 - INFO - __main__ -   Batch number = 305
Evaluating:  95%|█████████▌| 305/321 [01:31<00:05,  3.18it/s]01/14/2022 16:17:10 - INFO - __main__ -   Batch number = 306
Evaluating:  95%|█████████▌| 306/321 [01:31<00:04,  3.24it/s]01/14/2022 16:17:11 - INFO - __main__ -   Batch number = 307
Evaluating:  96%|█████████▌| 307/321 [01:32<00:04,  3.29it/s]01/14/2022 16:17:11 - INFO - __main__ -   Batch number = 308
Evaluating:  96%|█████████▌| 308/321 [01:32<00:03,  3.30it/s]01/14/2022 16:17:11 - INFO - __main__ -   Batch number = 309
Evaluating:  96%|█████████▋| 309/321 [01:32<00:03,  3.33it/s]01/14/2022 16:17:11 - INFO - __main__ -   Batch number = 310
Evaluating:  97%|█████████▋| 310/321 [01:33<00:03,  3.35it/s]01/14/2022 16:17:12 - INFO - __main__ -   Batch number = 311
Evaluating:  97%|█████████▋| 311/321 [01:33<00:02,  3.36it/s]01/14/2022 16:17:12 - INFO - __main__ -   Batch number = 312
Evaluating:  97%|█████████▋| 312/321 [01:33<00:02,  3.35it/s]01/14/2022 16:17:12 - INFO - __main__ -   Batch number = 313
Evaluating:  98%|█████████▊| 313/321 [01:34<00:02,  3.35it/s]01/14/2022 16:17:13 - INFO - __main__ -   Batch number = 314
Evaluating:  98%|█████████▊| 314/321 [01:34<00:02,  3.37it/s]01/14/2022 16:17:13 - INFO - __main__ -   Batch number = 315
Evaluating:  98%|█████████▊| 315/321 [01:34<00:01,  3.37it/s]01/14/2022 16:17:13 - INFO - __main__ -   Batch number = 316
Evaluating:  98%|█████████▊| 316/321 [01:34<00:01,  3.36it/s]01/14/2022 16:17:14 - INFO - __main__ -   Batch number = 317
Evaluating:  99%|█████████▉| 317/321 [01:35<00:01,  3.38it/s]01/14/2022 16:17:14 - INFO - __main__ -   Batch number = 318
Evaluating:  99%|█████████▉| 318/321 [01:35<00:00,  3.37it/s]01/14/2022 16:17:14 - INFO - __main__ -   Batch number = 319
Evaluating:  99%|█████████▉| 319/321 [01:35<00:00,  3.38it/s]01/14/2022 16:17:14 - INFO - __main__ -   Batch number = 320
Evaluating: 100%|█████████▉| 320/321 [01:36<00:00,  3.37it/s]01/14/2022 16:17:15 - INFO - __main__ -   Batch number = 321
Evaluating: 100%|██████████| 321/321 [01:36<00:00,  3.81it/s]Evaluating: 100%|██████████| 321/321 [01:36<00:00,  3.33it/s]
01/14/2022 16:17:17 - INFO - __main__ -   ***** Evaluation result  in zh *****
01/14/2022 16:17:17 - INFO - __main__ -     f1 = 0.33907065694939786
01/14/2022 16:17:17 - INFO - __main__ -     loss = 3.4539700096641375
01/14/2022 16:17:17 - INFO - __main__ -     precision = 0.25079328669189893
01/14/2022 16:17:17 - INFO - __main__ -     recall = 0.5232511765175082
107.67user 39.64system 2:13.29elapsed 110%CPU (0avgtext+0avgdata 4230548maxresident)k
0inputs+1880outputs (0major+2729106minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:17:20 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='zh', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:17:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:17:20 - INFO - __main__ -   Seed = 3
01/14/2022 16:17:20 - INFO - root -   save model
01/14/2022 16:17:20 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='zh', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:17:20 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:17:22 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:17:28 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:17:28 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:17:28 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:17:28 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:17:28 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:17:28 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,zh/wiki@ukp
01/14/2022 16:17:28 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'zh'], Length : 10
01/14/2022 16:17:28 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'zh/wiki@ukp'], Length : 10
01/14/2022 16:17:28 - INFO - __main__ -   Language = en
01/14/2022 16:17:28 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:17:29 - INFO - __main__ -   Language = pt
01/14/2022 16:17:29 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:17:31 - INFO - __main__ -   Language = id
01/14/2022 16:17:31 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:17:33 - INFO - __main__ -   Language = tr
01/14/2022 16:17:33 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:17:35 - INFO - __main__ -   Language = vi
01/14/2022 16:17:35 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:17:38 - INFO - __main__ -   Language = fa
01/14/2022 16:17:38 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:17:40 - INFO - __main__ -   Language = eu
01/14/2022 16:17:40 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:17:42 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:17:42 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:17:44 - INFO - __main__ -   Language = cs
01/14/2022 16:17:44 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:17:46 - INFO - __main__ -   Language = zh
01/14/2022 16:17:46 - INFO - __main__ -   Adapter Name = zh/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh/bert-base-multilingual-cased/pfeiffer/zh_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted/adapter_config.json
Adding adapter 'zh' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted/pytorch_adapter.bin
Some module weights could not be found in loaded weights file: encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.0.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.1.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.2.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.3.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.4.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.5.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.6.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.7.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.8.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.9.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.10.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_down.0.weight, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_down.0.bias, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_up.weight, encoder.layer.11.output.layer_text_lang_adapters.zh_yue.adapter_up.bias, invertible_lang_adapters.zh_yue.F.0.weight, invertible_lang_adapters.zh_yue.F.0.bias, invertible_lang_adapters.zh_yue.F.2.weight, invertible_lang_adapters.zh_yue.F.2.bias, invertible_lang_adapters.zh_yue.G.0.weight, invertible_lang_adapters.zh_yue.G.0.bias, invertible_lang_adapters.zh_yue.G.2.weight, invertible_lang_adapters.zh_yue.G.2.bias
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/6f2564c361bc79c3ea57846eaf144dcc612ca7882a3013f211ca168a6b3ee081-fe0c0730695790561f8ea222ddccd7cf7d222dd35f0b266559f463e9656eab36-extracted'
01/14/2022 16:17:50 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:17:50 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'zh']
01/14/2022 16:17:50 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:17:50 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:17:50 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:17:50 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_zh_bert-base-multilingual-cased_128
01/14/2022 16:17:51 - INFO - __main__ -   ***** Running evaluation  in zh *****
01/14/2022 16:17:51 - INFO - __main__ -     Num examples = 10257
01/14/2022 16:17:51 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/321 [00:00<?, ?it/s]01/14/2022 16:17:51 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/321 [00:00<01:38,  3.24it/s]01/14/2022 16:17:52 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/321 [00:00<01:33,  3.41it/s]01/14/2022 16:17:52 - INFO - __main__ -   Batch number = 3
Evaluating:   1%|          | 3/321 [00:00<01:31,  3.49it/s]01/14/2022 16:17:52 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/321 [00:01<01:29,  3.52it/s]01/14/2022 16:17:52 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/321 [00:01<01:29,  3.54it/s]01/14/2022 16:17:53 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/321 [00:01<01:28,  3.56it/s]01/14/2022 16:17:53 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/321 [00:01<01:27,  3.57it/s]01/14/2022 16:17:53 - INFO - __main__ -   Batch number = 8
Evaluating:   2%|▏         | 8/321 [00:02<01:27,  3.57it/s]01/14/2022 16:17:53 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/321 [00:02<01:27,  3.57it/s]01/14/2022 16:17:54 - INFO - __main__ -   Batch number = 10
Evaluating:   3%|▎         | 10/321 [00:02<01:26,  3.58it/s]01/14/2022 16:17:54 - INFO - __main__ -   Batch number = 11
Evaluating:   3%|▎         | 11/321 [00:03<01:26,  3.57it/s]01/14/2022 16:17:54 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▎         | 12/321 [00:03<01:26,  3.56it/s]01/14/2022 16:17:55 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/321 [00:03<01:54,  2.69it/s]01/14/2022 16:17:55 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/321 [00:04<01:45,  2.90it/s]01/14/2022 16:17:55 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/321 [00:04<01:39,  3.07it/s]01/14/2022 16:17:56 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▍         | 16/321 [00:04<01:35,  3.21it/s]01/14/2022 16:17:56 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/321 [00:05<01:31,  3.31it/s]01/14/2022 16:17:56 - INFO - __main__ -   Batch number = 18
Evaluating:   6%|▌         | 18/321 [00:05<01:29,  3.39it/s]01/14/2022 16:17:57 - INFO - __main__ -   Batch number = 19
Evaluating:   6%|▌         | 19/321 [00:05<01:27,  3.44it/s]01/14/2022 16:17:57 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▌         | 20/321 [00:05<01:26,  3.48it/s]01/14/2022 16:17:57 - INFO - __main__ -   Batch number = 21
Evaluating:   7%|▋         | 21/321 [00:06<01:25,  3.50it/s]01/14/2022 16:17:57 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/321 [00:06<01:25,  3.52it/s]01/14/2022 16:17:58 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/321 [00:06<01:24,  3.53it/s]01/14/2022 16:17:58 - INFO - __main__ -   Batch number = 24
Evaluating:   7%|▋         | 24/321 [00:07<01:23,  3.54it/s]01/14/2022 16:17:58 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/321 [00:07<01:23,  3.55it/s]01/14/2022 16:17:59 - INFO - __main__ -   Batch number = 26
Evaluating:   8%|▊         | 26/321 [00:07<01:22,  3.56it/s]01/14/2022 16:17:59 - INFO - __main__ -   Batch number = 27
Evaluating:   8%|▊         | 27/321 [00:07<01:22,  3.56it/s]01/14/2022 16:17:59 - INFO - __main__ -   Batch number = 28
Evaluating:   9%|▊         | 28/321 [00:08<01:22,  3.56it/s]01/14/2022 16:17:59 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▉         | 29/321 [00:08<01:22,  3.56it/s]01/14/2022 16:18:00 - INFO - __main__ -   Batch number = 30
Evaluating:   9%|▉         | 30/321 [00:08<01:21,  3.55it/s]01/14/2022 16:18:00 - INFO - __main__ -   Batch number = 31
Evaluating:  10%|▉         | 31/321 [00:09<01:21,  3.56it/s]01/14/2022 16:18:00 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|▉         | 32/321 [00:09<01:21,  3.56it/s]01/14/2022 16:18:01 - INFO - __main__ -   Batch number = 33
Evaluating:  10%|█         | 33/321 [00:09<01:21,  3.55it/s]01/14/2022 16:18:01 - INFO - __main__ -   Batch number = 34
Evaluating:  11%|█         | 34/321 [00:09<01:20,  3.55it/s]01/14/2022 16:18:01 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/321 [00:10<01:20,  3.55it/s]01/14/2022 16:18:01 - INFO - __main__ -   Batch number = 36
Evaluating:  11%|█         | 36/321 [00:10<01:20,  3.55it/s]01/14/2022 16:18:02 - INFO - __main__ -   Batch number = 37
Evaluating:  12%|█▏        | 37/321 [00:10<01:19,  3.55it/s]01/14/2022 16:18:02 - INFO - __main__ -   Batch number = 38
Evaluating:  12%|█▏        | 38/321 [00:10<01:19,  3.55it/s]01/14/2022 16:18:02 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/321 [00:11<01:19,  3.55it/s]01/14/2022 16:18:02 - INFO - __main__ -   Batch number = 40
Evaluating:  12%|█▏        | 40/321 [00:11<01:19,  3.55it/s]01/14/2022 16:18:03 - INFO - __main__ -   Batch number = 41
Evaluating:  13%|█▎        | 41/321 [00:11<01:18,  3.55it/s]01/14/2022 16:18:03 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/321 [00:12<01:18,  3.55it/s]01/14/2022 16:18:03 - INFO - __main__ -   Batch number = 43
Evaluating:  13%|█▎        | 43/321 [00:12<01:18,  3.55it/s]01/14/2022 16:18:04 - INFO - __main__ -   Batch number = 44
Evaluating:  14%|█▎        | 44/321 [00:12<01:18,  3.54it/s]01/14/2022 16:18:04 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▍        | 45/321 [00:12<01:18,  3.53it/s]01/14/2022 16:18:04 - INFO - __main__ -   Batch number = 46
Evaluating:  14%|█▍        | 46/321 [00:13<01:17,  3.53it/s]01/14/2022 16:18:04 - INFO - __main__ -   Batch number = 47
Evaluating:  15%|█▍        | 47/321 [00:13<01:17,  3.53it/s]01/14/2022 16:18:05 - INFO - __main__ -   Batch number = 48
Evaluating:  15%|█▍        | 48/321 [00:13<01:17,  3.52it/s]01/14/2022 16:18:05 - INFO - __main__ -   Batch number = 49
Evaluating:  15%|█▌        | 49/321 [00:14<01:17,  3.52it/s]01/14/2022 16:18:05 - INFO - __main__ -   Batch number = 50
Evaluating:  16%|█▌        | 50/321 [00:14<01:16,  3.52it/s]01/14/2022 16:18:06 - INFO - __main__ -   Batch number = 51
Evaluating:  16%|█▌        | 51/321 [00:14<01:16,  3.53it/s]01/14/2022 16:18:06 - INFO - __main__ -   Batch number = 52
Evaluating:  16%|█▌        | 52/321 [00:14<01:16,  3.52it/s]01/14/2022 16:18:06 - INFO - __main__ -   Batch number = 53
Evaluating:  17%|█▋        | 53/321 [00:15<01:16,  3.52it/s]01/14/2022 16:18:06 - INFO - __main__ -   Batch number = 54
Evaluating:  17%|█▋        | 54/321 [00:15<01:15,  3.52it/s]01/14/2022 16:18:07 - INFO - __main__ -   Batch number = 55
Evaluating:  17%|█▋        | 55/321 [00:15<01:15,  3.53it/s]01/14/2022 16:18:07 - INFO - __main__ -   Batch number = 56
Evaluating:  17%|█▋        | 56/321 [00:16<01:15,  3.53it/s]01/14/2022 16:18:07 - INFO - __main__ -   Batch number = 57
Evaluating:  18%|█▊        | 57/321 [00:16<01:14,  3.53it/s]01/14/2022 16:18:08 - INFO - __main__ -   Batch number = 58
Evaluating:  18%|█▊        | 58/321 [00:16<01:14,  3.53it/s]01/14/2022 16:18:08 - INFO - __main__ -   Batch number = 59
Evaluating:  18%|█▊        | 59/321 [00:16<01:14,  3.53it/s]01/14/2022 16:18:08 - INFO - __main__ -   Batch number = 60
Evaluating:  19%|█▊        | 60/321 [00:17<01:14,  3.52it/s]01/14/2022 16:18:08 - INFO - __main__ -   Batch number = 61
Evaluating:  19%|█▉        | 61/321 [00:17<01:14,  3.51it/s]01/14/2022 16:18:09 - INFO - __main__ -   Batch number = 62
Evaluating:  19%|█▉        | 62/321 [00:17<01:13,  3.52it/s]01/14/2022 16:18:09 - INFO - __main__ -   Batch number = 63
Evaluating:  20%|█▉        | 63/321 [00:18<01:13,  3.52it/s]01/14/2022 16:18:09 - INFO - __main__ -   Batch number = 64
Evaluating:  20%|█▉        | 64/321 [00:18<01:13,  3.52it/s]01/14/2022 16:18:10 - INFO - __main__ -   Batch number = 65
Evaluating:  20%|██        | 65/321 [00:18<01:22,  3.12it/s]01/14/2022 16:18:10 - INFO - __main__ -   Batch number = 66
Evaluating:  21%|██        | 66/321 [00:19<01:18,  3.23it/s]01/14/2022 16:18:10 - INFO - __main__ -   Batch number = 67
Evaluating:  21%|██        | 67/321 [00:19<01:16,  3.31it/s]01/14/2022 16:18:11 - INFO - __main__ -   Batch number = 68
Evaluating:  21%|██        | 68/321 [00:19<01:15,  3.37it/s]01/14/2022 16:18:11 - INFO - __main__ -   Batch number = 69
Evaluating:  21%|██▏       | 69/321 [00:19<01:13,  3.41it/s]01/14/2022 16:18:11 - INFO - __main__ -   Batch number = 70
Evaluating:  22%|██▏       | 70/321 [00:20<01:13,  3.43it/s]01/14/2022 16:18:11 - INFO - __main__ -   Batch number = 71
Evaluating:  22%|██▏       | 71/321 [00:20<01:12,  3.44it/s]01/14/2022 16:18:12 - INFO - __main__ -   Batch number = 72
Evaluating:  22%|██▏       | 72/321 [00:20<01:12,  3.44it/s]01/14/2022 16:18:12 - INFO - __main__ -   Batch number = 73
Evaluating:  23%|██▎       | 73/321 [00:21<01:11,  3.46it/s]01/14/2022 16:18:12 - INFO - __main__ -   Batch number = 74
Evaluating:  23%|██▎       | 74/321 [00:21<01:11,  3.47it/s]01/14/2022 16:18:13 - INFO - __main__ -   Batch number = 75
Evaluating:  23%|██▎       | 75/321 [00:21<01:10,  3.48it/s]01/14/2022 16:18:13 - INFO - __main__ -   Batch number = 76
Evaluating:  24%|██▎       | 76/321 [00:21<01:10,  3.48it/s]01/14/2022 16:18:13 - INFO - __main__ -   Batch number = 77
Evaluating:  24%|██▍       | 77/321 [00:22<01:10,  3.48it/s]01/14/2022 16:18:13 - INFO - __main__ -   Batch number = 78
Evaluating:  24%|██▍       | 78/321 [00:22<01:09,  3.48it/s]01/14/2022 16:18:14 - INFO - __main__ -   Batch number = 79
Evaluating:  25%|██▍       | 79/321 [00:22<01:09,  3.48it/s]01/14/2022 16:18:14 - INFO - __main__ -   Batch number = 80
Evaluating:  25%|██▍       | 80/321 [00:23<01:09,  3.49it/s]01/14/2022 16:18:14 - INFO - __main__ -   Batch number = 81
Evaluating:  25%|██▌       | 81/321 [00:23<01:08,  3.49it/s]01/14/2022 16:18:15 - INFO - __main__ -   Batch number = 82
Evaluating:  26%|██▌       | 82/321 [00:23<01:19,  3.01it/s]01/14/2022 16:18:15 - INFO - __main__ -   Batch number = 83
Evaluating:  26%|██▌       | 83/321 [00:24<01:16,  3.10it/s]01/14/2022 16:18:15 - INFO - __main__ -   Batch number = 84
Evaluating:  26%|██▌       | 84/321 [00:24<01:15,  3.15it/s]01/14/2022 16:18:16 - INFO - __main__ -   Batch number = 85
Evaluating:  26%|██▋       | 85/321 [00:24<01:14,  3.19it/s]01/14/2022 16:18:16 - INFO - __main__ -   Batch number = 86
Evaluating:  27%|██▋       | 86/321 [00:25<01:13,  3.22it/s]01/14/2022 16:18:16 - INFO - __main__ -   Batch number = 87
Evaluating:  27%|██▋       | 87/321 [00:25<01:12,  3.21it/s]01/14/2022 16:18:17 - INFO - __main__ -   Batch number = 88
Evaluating:  27%|██▋       | 88/321 [00:25<01:12,  3.23it/s]01/14/2022 16:18:17 - INFO - __main__ -   Batch number = 89
Evaluating:  28%|██▊       | 89/321 [00:25<01:11,  3.27it/s]01/14/2022 16:18:17 - INFO - __main__ -   Batch number = 90
Evaluating:  28%|██▊       | 90/321 [00:26<01:10,  3.30it/s]01/14/2022 16:18:17 - INFO - __main__ -   Batch number = 91
Evaluating:  28%|██▊       | 91/321 [00:26<01:09,  3.32it/s]01/14/2022 16:18:18 - INFO - __main__ -   Batch number = 92
Evaluating:  29%|██▊       | 92/321 [00:26<01:08,  3.34it/s]01/14/2022 16:18:18 - INFO - __main__ -   Batch number = 93
Evaluating:  29%|██▉       | 93/321 [00:27<01:08,  3.35it/s]01/14/2022 16:18:18 - INFO - __main__ -   Batch number = 94
Evaluating:  29%|██▉       | 94/321 [00:27<01:07,  3.37it/s]01/14/2022 16:18:19 - INFO - __main__ -   Batch number = 95
Evaluating:  30%|██▉       | 95/321 [00:27<01:06,  3.39it/s]01/14/2022 16:18:19 - INFO - __main__ -   Batch number = 96
Evaluating:  30%|██▉       | 96/321 [00:27<01:06,  3.39it/s]01/14/2022 16:18:19 - INFO - __main__ -   Batch number = 97
Evaluating:  30%|███       | 97/321 [00:28<01:06,  3.39it/s]01/14/2022 16:18:19 - INFO - __main__ -   Batch number = 98
Evaluating:  31%|███       | 98/321 [00:28<01:05,  3.40it/s]01/14/2022 16:18:20 - INFO - __main__ -   Batch number = 99
Evaluating:  31%|███       | 99/321 [00:28<01:09,  3.21it/s]01/14/2022 16:18:20 - INFO - __main__ -   Batch number = 100
Evaluating:  31%|███       | 100/321 [00:29<01:07,  3.29it/s]01/14/2022 16:18:20 - INFO - __main__ -   Batch number = 101
Evaluating:  31%|███▏      | 101/321 [00:29<01:05,  3.34it/s]01/14/2022 16:18:21 - INFO - __main__ -   Batch number = 102
Evaluating:  32%|███▏      | 102/321 [00:29<01:04,  3.37it/s]01/14/2022 16:18:21 - INFO - __main__ -   Batch number = 103
Evaluating:  32%|███▏      | 103/321 [00:30<01:04,  3.39it/s]01/14/2022 16:18:21 - INFO - __main__ -   Batch number = 104
Evaluating:  32%|███▏      | 104/321 [00:30<01:03,  3.40it/s]01/14/2022 16:18:22 - INFO - __main__ -   Batch number = 105
Evaluating:  33%|███▎      | 105/321 [00:30<01:03,  3.40it/s]01/14/2022 16:18:22 - INFO - __main__ -   Batch number = 106
Evaluating:  33%|███▎      | 106/321 [00:30<01:03,  3.39it/s]01/14/2022 16:18:22 - INFO - __main__ -   Batch number = 107
Evaluating:  33%|███▎      | 107/321 [00:31<01:03,  3.36it/s]01/14/2022 16:18:22 - INFO - __main__ -   Batch number = 108
Evaluating:  34%|███▎      | 108/321 [00:31<01:03,  3.33it/s]01/14/2022 16:18:23 - INFO - __main__ -   Batch number = 109
Evaluating:  34%|███▍      | 109/321 [00:31<01:04,  3.29it/s]01/14/2022 16:18:23 - INFO - __main__ -   Batch number = 110
Evaluating:  34%|███▍      | 110/321 [00:32<01:04,  3.28it/s]01/14/2022 16:18:23 - INFO - __main__ -   Batch number = 111
Evaluating:  35%|███▍      | 111/321 [00:32<01:04,  3.28it/s]01/14/2022 16:18:24 - INFO - __main__ -   Batch number = 112
Evaluating:  35%|███▍      | 112/321 [00:32<01:03,  3.27it/s]01/14/2022 16:18:24 - INFO - __main__ -   Batch number = 113
Evaluating:  35%|███▌      | 113/321 [00:33<01:03,  3.25it/s]01/14/2022 16:18:24 - INFO - __main__ -   Batch number = 114
Evaluating:  36%|███▌      | 114/321 [00:33<01:03,  3.24it/s]01/14/2022 16:18:25 - INFO - __main__ -   Batch number = 115
Evaluating:  36%|███▌      | 115/321 [00:33<01:06,  3.08it/s]01/14/2022 16:18:25 - INFO - __main__ -   Batch number = 116
Evaluating:  36%|███▌      | 116/321 [00:34<01:05,  3.14it/s]01/14/2022 16:18:25 - INFO - __main__ -   Batch number = 117
Evaluating:  36%|███▋      | 117/321 [00:34<01:03,  3.19it/s]01/14/2022 16:18:26 - INFO - __main__ -   Batch number = 118
Evaluating:  37%|███▋      | 118/321 [00:34<01:02,  3.24it/s]01/14/2022 16:18:26 - INFO - __main__ -   Batch number = 119
Evaluating:  37%|███▋      | 119/321 [00:34<01:01,  3.27it/s]01/14/2022 16:18:26 - INFO - __main__ -   Batch number = 120
Evaluating:  37%|███▋      | 120/321 [00:35<01:01,  3.29it/s]01/14/2022 16:18:27 - INFO - __main__ -   Batch number = 121
Evaluating:  38%|███▊      | 121/321 [00:35<01:00,  3.30it/s]01/14/2022 16:18:27 - INFO - __main__ -   Batch number = 122
Evaluating:  38%|███▊      | 122/321 [00:35<01:00,  3.30it/s]01/14/2022 16:18:27 - INFO - __main__ -   Batch number = 123
Evaluating:  38%|███▊      | 123/321 [00:36<00:59,  3.30it/s]01/14/2022 16:18:27 - INFO - __main__ -   Batch number = 124
Evaluating:  39%|███▊      | 124/321 [00:36<00:59,  3.31it/s]01/14/2022 16:18:28 - INFO - __main__ -   Batch number = 125
Evaluating:  39%|███▉      | 125/321 [00:36<00:59,  3.32it/s]01/14/2022 16:18:28 - INFO - __main__ -   Batch number = 126
Evaluating:  39%|███▉      | 126/321 [00:37<00:59,  3.29it/s]01/14/2022 16:18:28 - INFO - __main__ -   Batch number = 127
Evaluating:  40%|███▉      | 127/321 [00:37<00:59,  3.27it/s]01/14/2022 16:18:29 - INFO - __main__ -   Batch number = 128
Evaluating:  40%|███▉      | 128/321 [00:37<00:59,  3.25it/s]01/14/2022 16:18:29 - INFO - __main__ -   Batch number = 129
Evaluating:  40%|████      | 129/321 [00:38<00:59,  3.24it/s]01/14/2022 16:18:29 - INFO - __main__ -   Batch number = 130
Evaluating:  40%|████      | 130/321 [00:38<00:59,  3.24it/s]01/14/2022 16:18:30 - INFO - __main__ -   Batch number = 131
Evaluating:  41%|████      | 131/321 [00:38<01:02,  3.04it/s]01/14/2022 16:18:30 - INFO - __main__ -   Batch number = 132
Evaluating:  41%|████      | 132/321 [00:39<01:00,  3.14it/s]01/14/2022 16:18:30 - INFO - __main__ -   Batch number = 133
Evaluating:  41%|████▏     | 133/321 [00:39<00:58,  3.19it/s]01/14/2022 16:18:31 - INFO - __main__ -   Batch number = 134
Evaluating:  42%|████▏     | 134/321 [00:39<00:57,  3.25it/s]01/14/2022 16:18:31 - INFO - __main__ -   Batch number = 135
Evaluating:  42%|████▏     | 135/321 [00:39<00:56,  3.27it/s]01/14/2022 16:18:31 - INFO - __main__ -   Batch number = 136
Evaluating:  42%|████▏     | 136/321 [00:40<00:56,  3.28it/s]01/14/2022 16:18:31 - INFO - __main__ -   Batch number = 137
Evaluating:  43%|████▎     | 137/321 [00:40<00:56,  3.27it/s]01/14/2022 16:18:32 - INFO - __main__ -   Batch number = 138
Evaluating:  43%|████▎     | 138/321 [00:40<00:56,  3.26it/s]01/14/2022 16:18:32 - INFO - __main__ -   Batch number = 139
Evaluating:  43%|████▎     | 139/321 [00:41<00:55,  3.26it/s]01/14/2022 16:18:32 - INFO - __main__ -   Batch number = 140
Evaluating:  44%|████▎     | 140/321 [00:41<00:55,  3.26it/s]01/14/2022 16:18:33 - INFO - __main__ -   Batch number = 141
Evaluating:  44%|████▍     | 141/321 [00:41<00:55,  3.26it/s]01/14/2022 16:18:33 - INFO - __main__ -   Batch number = 142
Evaluating:  44%|████▍     | 142/321 [00:42<00:55,  3.24it/s]01/14/2022 16:18:33 - INFO - __main__ -   Batch number = 143
Evaluating:  45%|████▍     | 143/321 [00:42<00:55,  3.23it/s]01/14/2022 16:18:34 - INFO - __main__ -   Batch number = 144
Evaluating:  45%|████▍     | 144/321 [00:42<00:54,  3.22it/s]01/14/2022 16:18:34 - INFO - __main__ -   Batch number = 145
Evaluating:  45%|████▌     | 145/321 [00:43<00:54,  3.23it/s]01/14/2022 16:18:34 - INFO - __main__ -   Batch number = 146
Evaluating:  45%|████▌     | 146/321 [00:43<00:54,  3.23it/s]01/14/2022 16:18:35 - INFO - __main__ -   Batch number = 147
Evaluating:  46%|████▌     | 147/321 [00:43<00:53,  3.24it/s]01/14/2022 16:18:35 - INFO - __main__ -   Batch number = 148
Evaluating:  46%|████▌     | 148/321 [00:43<00:53,  3.25it/s]01/14/2022 16:18:35 - INFO - __main__ -   Batch number = 149
Evaluating:  46%|████▋     | 149/321 [00:44<00:52,  3.26it/s]01/14/2022 16:18:35 - INFO - __main__ -   Batch number = 150
Evaluating:  47%|████▋     | 150/321 [00:44<00:52,  3.28it/s]01/14/2022 16:18:36 - INFO - __main__ -   Batch number = 151
Evaluating:  47%|████▋     | 151/321 [00:44<00:51,  3.30it/s]01/14/2022 16:18:36 - INFO - __main__ -   Batch number = 152
Evaluating:  47%|████▋     | 152/321 [00:45<00:50,  3.32it/s]01/14/2022 16:18:36 - INFO - __main__ -   Batch number = 153
Evaluating:  48%|████▊     | 153/321 [00:45<00:50,  3.33it/s]01/14/2022 16:18:37 - INFO - __main__ -   Batch number = 154
Evaluating:  48%|████▊     | 154/321 [00:45<00:49,  3.35it/s]01/14/2022 16:18:37 - INFO - __main__ -   Batch number = 155
Evaluating:  48%|████▊     | 155/321 [00:46<00:49,  3.37it/s]01/14/2022 16:18:37 - INFO - __main__ -   Batch number = 156
Evaluating:  49%|████▊     | 156/321 [00:46<00:48,  3.39it/s]01/14/2022 16:18:38 - INFO - __main__ -   Batch number = 157
Evaluating:  49%|████▉     | 157/321 [00:46<00:48,  3.41it/s]01/14/2022 16:18:38 - INFO - __main__ -   Batch number = 158
Evaluating:  49%|████▉     | 158/321 [00:46<00:47,  3.43it/s]01/14/2022 16:18:38 - INFO - __main__ -   Batch number = 159
Evaluating:  50%|████▉     | 159/321 [00:47<00:47,  3.44it/s]01/14/2022 16:18:38 - INFO - __main__ -   Batch number = 160
Evaluating:  50%|████▉     | 160/321 [00:47<00:47,  3.42it/s]01/14/2022 16:18:39 - INFO - __main__ -   Batch number = 161
Evaluating:  50%|█████     | 161/321 [00:47<00:46,  3.44it/s]01/14/2022 16:18:39 - INFO - __main__ -   Batch number = 162
Evaluating:  50%|█████     | 162/321 [00:48<00:46,  3.43it/s]01/14/2022 16:18:39 - INFO - __main__ -   Batch number = 163
Evaluating:  51%|█████     | 163/321 [00:48<00:46,  3.42it/s]01/14/2022 16:18:40 - INFO - __main__ -   Batch number = 164
Evaluating:  51%|█████     | 164/321 [00:48<00:46,  3.41it/s]01/14/2022 16:18:40 - INFO - __main__ -   Batch number = 165
Evaluating:  51%|█████▏    | 165/321 [00:48<00:45,  3.40it/s]01/14/2022 16:18:40 - INFO - __main__ -   Batch number = 166
Evaluating:  52%|█████▏    | 166/321 [00:49<00:45,  3.40it/s]01/14/2022 16:18:40 - INFO - __main__ -   Batch number = 167
Evaluating:  52%|█████▏    | 167/321 [00:49<00:45,  3.40it/s]01/14/2022 16:18:41 - INFO - __main__ -   Batch number = 168
Evaluating:  52%|█████▏    | 168/321 [00:49<00:44,  3.42it/s]01/14/2022 16:18:41 - INFO - __main__ -   Batch number = 169
Evaluating:  53%|█████▎    | 169/321 [00:50<00:44,  3.43it/s]01/14/2022 16:18:41 - INFO - __main__ -   Batch number = 170
Evaluating:  53%|█████▎    | 170/321 [00:50<00:43,  3.44it/s]01/14/2022 16:18:42 - INFO - __main__ -   Batch number = 171
Evaluating:  53%|█████▎    | 171/321 [00:50<00:43,  3.44it/s]01/14/2022 16:18:42 - INFO - __main__ -   Batch number = 172
Evaluating:  54%|█████▎    | 172/321 [00:50<00:43,  3.44it/s]01/14/2022 16:18:42 - INFO - __main__ -   Batch number = 173
Evaluating:  54%|█████▍    | 173/321 [00:51<00:42,  3.44it/s]01/14/2022 16:18:42 - INFO - __main__ -   Batch number = 174
Evaluating:  54%|█████▍    | 174/321 [00:51<00:42,  3.44it/s]01/14/2022 16:18:43 - INFO - __main__ -   Batch number = 175
Evaluating:  55%|█████▍    | 175/321 [00:51<00:42,  3.45it/s]01/14/2022 16:18:43 - INFO - __main__ -   Batch number = 176
Evaluating:  55%|█████▍    | 176/321 [00:52<00:42,  3.44it/s]01/14/2022 16:18:43 - INFO - __main__ -   Batch number = 177
Evaluating:  55%|█████▌    | 177/321 [00:52<00:42,  3.42it/s]01/14/2022 16:18:44 - INFO - __main__ -   Batch number = 178
Evaluating:  55%|█████▌    | 178/321 [00:52<00:42,  3.39it/s]01/14/2022 16:18:44 - INFO - __main__ -   Batch number = 179
Evaluating:  56%|█████▌    | 179/321 [00:53<00:42,  3.38it/s]01/14/2022 16:18:44 - INFO - __main__ -   Batch number = 180
Evaluating:  56%|█████▌    | 180/321 [00:53<00:41,  3.36it/s]01/14/2022 16:18:45 - INFO - __main__ -   Batch number = 181
Evaluating:  56%|█████▋    | 181/321 [00:53<00:41,  3.34it/s]01/14/2022 16:18:45 - INFO - __main__ -   Batch number = 182
Evaluating:  57%|█████▋    | 182/321 [00:53<00:41,  3.33it/s]01/14/2022 16:18:45 - INFO - __main__ -   Batch number = 183
Evaluating:  57%|█████▋    | 183/321 [00:54<00:41,  3.33it/s]01/14/2022 16:18:45 - INFO - __main__ -   Batch number = 184
Evaluating:  57%|█████▋    | 184/321 [00:54<00:41,  3.33it/s]01/14/2022 16:18:46 - INFO - __main__ -   Batch number = 185
Evaluating:  58%|█████▊    | 185/321 [00:54<00:40,  3.33it/s]01/14/2022 16:18:46 - INFO - __main__ -   Batch number = 186
Evaluating:  58%|█████▊    | 186/321 [00:55<00:40,  3.32it/s]01/14/2022 16:18:46 - INFO - __main__ -   Batch number = 187
Evaluating:  58%|█████▊    | 187/321 [00:55<00:40,  3.29it/s]01/14/2022 16:18:47 - INFO - __main__ -   Batch number = 188
Evaluating:  59%|█████▊    | 188/321 [00:55<00:40,  3.26it/s]01/14/2022 16:18:47 - INFO - __main__ -   Batch number = 189
Evaluating:  59%|█████▉    | 189/321 [00:56<00:40,  3.24it/s]01/14/2022 16:18:47 - INFO - __main__ -   Batch number = 190
Evaluating:  59%|█████▉    | 190/321 [00:56<00:40,  3.23it/s]01/14/2022 16:18:48 - INFO - __main__ -   Batch number = 191
Evaluating:  60%|█████▉    | 191/321 [00:56<00:40,  3.22it/s]01/14/2022 16:18:48 - INFO - __main__ -   Batch number = 192
Evaluating:  60%|█████▉    | 192/321 [00:57<00:40,  3.22it/s]01/14/2022 16:18:48 - INFO - __main__ -   Batch number = 193
Evaluating:  60%|██████    | 193/321 [00:57<00:39,  3.22it/s]01/14/2022 16:18:49 - INFO - __main__ -   Batch number = 194
Evaluating:  60%|██████    | 194/321 [00:57<00:39,  3.20it/s]01/14/2022 16:18:49 - INFO - __main__ -   Batch number = 195
Evaluating:  61%|██████    | 195/321 [00:57<00:39,  3.18it/s]01/14/2022 16:18:49 - INFO - __main__ -   Batch number = 196
Evaluating:  61%|██████    | 196/321 [00:58<00:39,  3.18it/s]01/14/2022 16:18:49 - INFO - __main__ -   Batch number = 197
Evaluating:  61%|██████▏   | 197/321 [00:58<00:38,  3.19it/s]01/14/2022 16:18:50 - INFO - __main__ -   Batch number = 198
Evaluating:  62%|██████▏   | 198/321 [00:58<00:38,  3.22it/s]01/14/2022 16:18:50 - INFO - __main__ -   Batch number = 199
Evaluating:  62%|██████▏   | 199/321 [00:59<00:37,  3.23it/s]01/14/2022 16:18:50 - INFO - __main__ -   Batch number = 200
Evaluating:  62%|██████▏   | 200/321 [00:59<00:37,  3.24it/s]01/14/2022 16:18:51 - INFO - __main__ -   Batch number = 201
Evaluating:  63%|██████▎   | 201/321 [00:59<00:36,  3.28it/s]01/14/2022 16:18:51 - INFO - __main__ -   Batch number = 202
Evaluating:  63%|██████▎   | 202/321 [01:00<00:36,  3.30it/s]01/14/2022 16:18:51 - INFO - __main__ -   Batch number = 203
Evaluating:  63%|██████▎   | 203/321 [01:00<00:35,  3.32it/s]01/14/2022 16:18:52 - INFO - __main__ -   Batch number = 204
Evaluating:  64%|██████▎   | 204/321 [01:00<00:35,  3.34it/s]01/14/2022 16:18:52 - INFO - __main__ -   Batch number = 205
Evaluating:  64%|██████▍   | 205/321 [01:00<00:34,  3.37it/s]01/14/2022 16:18:52 - INFO - __main__ -   Batch number = 206
Evaluating:  64%|██████▍   | 206/321 [01:01<00:33,  3.39it/s]01/14/2022 16:18:52 - INFO - __main__ -   Batch number = 207
Evaluating:  64%|██████▍   | 207/321 [01:01<00:33,  3.39it/s]01/14/2022 16:18:53 - INFO - __main__ -   Batch number = 208
Evaluating:  65%|██████▍   | 208/321 [01:01<00:33,  3.36it/s]01/14/2022 16:18:53 - INFO - __main__ -   Batch number = 209
Evaluating:  65%|██████▌   | 209/321 [01:02<00:33,  3.36it/s]01/14/2022 16:18:53 - INFO - __main__ -   Batch number = 210
Evaluating:  65%|██████▌   | 210/321 [01:02<00:33,  3.36it/s]01/14/2022 16:18:54 - INFO - __main__ -   Batch number = 211
Evaluating:  66%|██████▌   | 211/321 [01:02<00:33,  3.33it/s]01/14/2022 16:18:54 - INFO - __main__ -   Batch number = 212
Evaluating:  66%|██████▌   | 212/321 [01:03<00:32,  3.33it/s]01/14/2022 16:18:54 - INFO - __main__ -   Batch number = 213
Evaluating:  66%|██████▋   | 213/321 [01:03<00:32,  3.35it/s]01/14/2022 16:18:55 - INFO - __main__ -   Batch number = 214
Evaluating:  67%|██████▋   | 214/321 [01:03<00:39,  2.73it/s]01/14/2022 16:18:55 - INFO - __main__ -   Batch number = 215
Evaluating:  67%|██████▋   | 215/321 [01:04<00:37,  2.86it/s]01/14/2022 16:18:55 - INFO - __main__ -   Batch number = 216
Evaluating:  67%|██████▋   | 216/321 [01:04<00:35,  2.97it/s]01/14/2022 16:18:56 - INFO - __main__ -   Batch number = 217
Evaluating:  68%|██████▊   | 217/321 [01:04<00:34,  3.04it/s]01/14/2022 16:18:56 - INFO - __main__ -   Batch number = 218
Evaluating:  68%|██████▊   | 218/321 [01:05<00:33,  3.10it/s]01/14/2022 16:18:56 - INFO - __main__ -   Batch number = 219
Evaluating:  68%|██████▊   | 219/321 [01:05<00:32,  3.17it/s]01/14/2022 16:18:57 - INFO - __main__ -   Batch number = 220
Evaluating:  69%|██████▊   | 220/321 [01:05<00:31,  3.23it/s]01/14/2022 16:18:57 - INFO - __main__ -   Batch number = 221
Evaluating:  69%|██████▉   | 221/321 [01:06<00:30,  3.28it/s]01/14/2022 16:18:57 - INFO - __main__ -   Batch number = 222
Evaluating:  69%|██████▉   | 222/321 [01:06<00:29,  3.32it/s]01/14/2022 16:18:58 - INFO - __main__ -   Batch number = 223
Evaluating:  69%|██████▉   | 223/321 [01:06<00:29,  3.34it/s]01/14/2022 16:18:58 - INFO - __main__ -   Batch number = 224
Evaluating:  70%|██████▉   | 224/321 [01:06<00:29,  3.34it/s]01/14/2022 16:18:58 - INFO - __main__ -   Batch number = 225
Evaluating:  70%|███████   | 225/321 [01:07<00:29,  3.31it/s]01/14/2022 16:18:58 - INFO - __main__ -   Batch number = 226
Evaluating:  70%|███████   | 226/321 [01:07<00:28,  3.29it/s]01/14/2022 16:18:59 - INFO - __main__ -   Batch number = 227
Evaluating:  71%|███████   | 227/321 [01:07<00:28,  3.29it/s]01/14/2022 16:18:59 - INFO - __main__ -   Batch number = 228
Evaluating:  71%|███████   | 228/321 [01:08<00:28,  3.29it/s]01/14/2022 16:18:59 - INFO - __main__ -   Batch number = 229
Evaluating:  71%|███████▏  | 229/321 [01:08<00:27,  3.29it/s]01/14/2022 16:19:00 - INFO - __main__ -   Batch number = 230
Evaluating:  72%|███████▏  | 230/321 [01:08<00:27,  3.27it/s]01/14/2022 16:19:00 - INFO - __main__ -   Batch number = 231
Evaluating:  72%|███████▏  | 231/321 [01:09<00:27,  3.25it/s]01/14/2022 16:19:00 - INFO - __main__ -   Batch number = 232
Evaluating:  72%|███████▏  | 232/321 [01:09<00:27,  3.23it/s]01/14/2022 16:19:01 - INFO - __main__ -   Batch number = 233
Evaluating:  73%|███████▎  | 233/321 [01:09<00:27,  3.23it/s]01/14/2022 16:19:01 - INFO - __main__ -   Batch number = 234
Evaluating:  73%|███████▎  | 234/321 [01:09<00:26,  3.22it/s]01/14/2022 16:19:01 - INFO - __main__ -   Batch number = 235
Evaluating:  73%|███████▎  | 235/321 [01:10<00:26,  3.22it/s]01/14/2022 16:19:02 - INFO - __main__ -   Batch number = 236
Evaluating:  74%|███████▎  | 236/321 [01:10<00:26,  3.20it/s]01/14/2022 16:19:02 - INFO - __main__ -   Batch number = 237
Evaluating:  74%|███████▍  | 237/321 [01:10<00:26,  3.21it/s]01/14/2022 16:19:02 - INFO - __main__ -   Batch number = 238
Evaluating:  74%|███████▍  | 238/321 [01:11<00:25,  3.23it/s]01/14/2022 16:19:02 - INFO - __main__ -   Batch number = 239
Evaluating:  74%|███████▍  | 239/321 [01:11<00:25,  3.26it/s]01/14/2022 16:19:03 - INFO - __main__ -   Batch number = 240
Evaluating:  75%|███████▍  | 240/321 [01:11<00:24,  3.27it/s]01/14/2022 16:19:03 - INFO - __main__ -   Batch number = 241
Evaluating:  75%|███████▌  | 241/321 [01:12<00:24,  3.28it/s]01/14/2022 16:19:03 - INFO - __main__ -   Batch number = 242
Evaluating:  75%|███████▌  | 242/321 [01:12<00:23,  3.30it/s]01/14/2022 16:19:04 - INFO - __main__ -   Batch number = 243
Evaluating:  76%|███████▌  | 243/321 [01:12<00:23,  3.29it/s]01/14/2022 16:19:04 - INFO - __main__ -   Batch number = 244
Evaluating:  76%|███████▌  | 244/321 [01:13<00:23,  3.27it/s]01/14/2022 16:19:04 - INFO - __main__ -   Batch number = 245
Evaluating:  76%|███████▋  | 245/321 [01:13<00:23,  3.27it/s]01/14/2022 16:19:05 - INFO - __main__ -   Batch number = 246
Evaluating:  77%|███████▋  | 246/321 [01:13<00:22,  3.28it/s]01/14/2022 16:19:05 - INFO - __main__ -   Batch number = 247
Evaluating:  77%|███████▋  | 247/321 [01:14<00:23,  3.14it/s]01/14/2022 16:19:05 - INFO - __main__ -   Batch number = 248
Evaluating:  77%|███████▋  | 248/321 [01:14<00:22,  3.22it/s]01/14/2022 16:19:06 - INFO - __main__ -   Batch number = 249
Evaluating:  78%|███████▊  | 249/321 [01:14<00:21,  3.28it/s]01/14/2022 16:19:06 - INFO - __main__ -   Batch number = 250
Evaluating:  78%|███████▊  | 250/321 [01:14<00:21,  3.32it/s]01/14/2022 16:19:06 - INFO - __main__ -   Batch number = 251
Evaluating:  78%|███████▊  | 251/321 [01:15<00:20,  3.34it/s]01/14/2022 16:19:06 - INFO - __main__ -   Batch number = 252
Evaluating:  79%|███████▊  | 252/321 [01:15<00:20,  3.34it/s]01/14/2022 16:19:07 - INFO - __main__ -   Batch number = 253
Evaluating:  79%|███████▉  | 253/321 [01:15<00:20,  3.33it/s]01/14/2022 16:19:07 - INFO - __main__ -   Batch number = 254
Evaluating:  79%|███████▉  | 254/321 [01:16<00:19,  3.36it/s]01/14/2022 16:19:07 - INFO - __main__ -   Batch number = 255
Evaluating:  79%|███████▉  | 255/321 [01:16<00:19,  3.37it/s]01/14/2022 16:19:08 - INFO - __main__ -   Batch number = 256
Evaluating:  80%|███████▉  | 256/321 [01:16<00:19,  3.39it/s]01/14/2022 16:19:08 - INFO - __main__ -   Batch number = 257
Evaluating:  80%|████████  | 257/321 [01:16<00:18,  3.40it/s]01/14/2022 16:19:08 - INFO - __main__ -   Batch number = 258
Evaluating:  80%|████████  | 258/321 [01:17<00:18,  3.41it/s]01/14/2022 16:19:08 - INFO - __main__ -   Batch number = 259
Evaluating:  81%|████████  | 259/321 [01:17<00:18,  3.38it/s]01/14/2022 16:19:09 - INFO - __main__ -   Batch number = 260
Evaluating:  81%|████████  | 260/321 [01:17<00:18,  3.37it/s]01/14/2022 16:19:09 - INFO - __main__ -   Batch number = 261
Evaluating:  81%|████████▏ | 261/321 [01:18<00:17,  3.37it/s]01/14/2022 16:19:09 - INFO - __main__ -   Batch number = 262
Evaluating:  82%|████████▏ | 262/321 [01:18<00:17,  3.35it/s]01/14/2022 16:19:10 - INFO - __main__ -   Batch number = 263
Evaluating:  82%|████████▏ | 263/321 [01:18<00:17,  3.36it/s]01/14/2022 16:19:10 - INFO - __main__ -   Batch number = 264
Evaluating:  82%|████████▏ | 264/321 [01:19<00:18,  3.01it/s]01/14/2022 16:19:10 - INFO - __main__ -   Batch number = 265
Evaluating:  83%|████████▎ | 265/321 [01:19<00:18,  3.11it/s]01/14/2022 16:19:11 - INFO - __main__ -   Batch number = 266
Evaluating:  83%|████████▎ | 266/321 [01:19<00:17,  3.19it/s]01/14/2022 16:19:11 - INFO - __main__ -   Batch number = 267
Evaluating:  83%|████████▎ | 267/321 [01:20<00:16,  3.26it/s]01/14/2022 16:19:11 - INFO - __main__ -   Batch number = 268
Evaluating:  83%|████████▎ | 268/321 [01:20<00:16,  3.29it/s]01/14/2022 16:19:12 - INFO - __main__ -   Batch number = 269
Evaluating:  84%|████████▍ | 269/321 [01:20<00:15,  3.31it/s]01/14/2022 16:19:12 - INFO - __main__ -   Batch number = 270
Evaluating:  84%|████████▍ | 270/321 [01:20<00:15,  3.33it/s]01/14/2022 16:19:12 - INFO - __main__ -   Batch number = 271
Evaluating:  84%|████████▍ | 271/321 [01:21<00:15,  3.31it/s]01/14/2022 16:19:12 - INFO - __main__ -   Batch number = 272
Evaluating:  85%|████████▍ | 272/321 [01:21<00:14,  3.30it/s]01/14/2022 16:19:13 - INFO - __main__ -   Batch number = 273
Evaluating:  85%|████████▌ | 273/321 [01:21<00:14,  3.30it/s]01/14/2022 16:19:13 - INFO - __main__ -   Batch number = 274
Evaluating:  85%|████████▌ | 274/321 [01:22<00:16,  2.84it/s]01/14/2022 16:19:14 - INFO - __main__ -   Batch number = 275
Evaluating:  86%|████████▌ | 275/321 [01:22<00:15,  2.96it/s]01/14/2022 16:19:14 - INFO - __main__ -   Batch number = 276
Evaluating:  86%|████████▌ | 276/321 [01:22<00:14,  3.07it/s]01/14/2022 16:19:14 - INFO - __main__ -   Batch number = 277
Evaluating:  86%|████████▋ | 277/321 [01:23<00:14,  3.09it/s]01/14/2022 16:19:14 - INFO - __main__ -   Batch number = 278
Evaluating:  87%|████████▋ | 278/321 [01:23<00:13,  3.19it/s]01/14/2022 16:19:15 - INFO - __main__ -   Batch number = 279
Evaluating:  87%|████████▋ | 279/321 [01:23<00:12,  3.26it/s]01/14/2022 16:19:15 - INFO - __main__ -   Batch number = 280
Evaluating:  87%|████████▋ | 280/321 [01:24<00:14,  2.86it/s]01/14/2022 16:19:15 - INFO - __main__ -   Batch number = 281
Evaluating:  88%|████████▊ | 281/321 [01:24<00:13,  3.01it/s]01/14/2022 16:19:16 - INFO - __main__ -   Batch number = 282
Evaluating:  88%|████████▊ | 282/321 [01:24<00:12,  3.12it/s]01/14/2022 16:19:16 - INFO - __main__ -   Batch number = 283
Evaluating:  88%|████████▊ | 283/321 [01:25<00:11,  3.21it/s]01/14/2022 16:19:16 - INFO - __main__ -   Batch number = 284
Evaluating:  88%|████████▊ | 284/321 [01:25<00:11,  3.26it/s]01/14/2022 16:19:17 - INFO - __main__ -   Batch number = 285
Evaluating:  89%|████████▉ | 285/321 [01:25<00:10,  3.30it/s]01/14/2022 16:19:17 - INFO - __main__ -   Batch number = 286
Evaluating:  89%|████████▉ | 286/321 [01:26<00:10,  3.33it/s]01/14/2022 16:19:17 - INFO - __main__ -   Batch number = 287
Evaluating:  89%|████████▉ | 287/321 [01:26<00:10,  3.35it/s]01/14/2022 16:19:18 - INFO - __main__ -   Batch number = 288
Evaluating:  90%|████████▉ | 288/321 [01:26<00:09,  3.37it/s]01/14/2022 16:19:18 - INFO - __main__ -   Batch number = 289
Evaluating:  90%|█████████ | 289/321 [01:26<00:09,  3.39it/s]01/14/2022 16:19:18 - INFO - __main__ -   Batch number = 290
Evaluating:  90%|█████████ | 290/321 [01:27<00:09,  3.40it/s]01/14/2022 16:19:18 - INFO - __main__ -   Batch number = 291
Evaluating:  91%|█████████ | 291/321 [01:27<00:08,  3.39it/s]01/14/2022 16:19:19 - INFO - __main__ -   Batch number = 292
Evaluating:  91%|█████████ | 292/321 [01:27<00:08,  3.35it/s]01/14/2022 16:19:19 - INFO - __main__ -   Batch number = 293
Evaluating:  91%|█████████▏| 293/321 [01:28<00:08,  3.30it/s]01/14/2022 16:19:19 - INFO - __main__ -   Batch number = 294
Evaluating:  92%|█████████▏| 294/321 [01:28<00:08,  3.26it/s]01/14/2022 16:19:20 - INFO - __main__ -   Batch number = 295
Evaluating:  92%|█████████▏| 295/321 [01:28<00:08,  3.23it/s]01/14/2022 16:19:20 - INFO - __main__ -   Batch number = 296
Evaluating:  92%|█████████▏| 296/321 [01:29<00:07,  3.22it/s]01/14/2022 16:19:20 - INFO - __main__ -   Batch number = 297
Evaluating:  93%|█████████▎| 297/321 [01:29<00:07,  3.22it/s]01/14/2022 16:19:21 - INFO - __main__ -   Batch number = 298
Evaluating:  93%|█████████▎| 298/321 [01:29<00:07,  3.25it/s]01/14/2022 16:19:21 - INFO - __main__ -   Batch number = 299
Evaluating:  93%|█████████▎| 299/321 [01:29<00:06,  3.29it/s]01/14/2022 16:19:21 - INFO - __main__ -   Batch number = 300
Evaluating:  93%|█████████▎| 300/321 [01:30<00:06,  3.29it/s]01/14/2022 16:19:21 - INFO - __main__ -   Batch number = 301
Evaluating:  94%|█████████▍| 301/321 [01:30<00:06,  3.29it/s]01/14/2022 16:19:22 - INFO - __main__ -   Batch number = 302
Evaluating:  94%|█████████▍| 302/321 [01:30<00:05,  3.26it/s]01/14/2022 16:19:22 - INFO - __main__ -   Batch number = 303
Evaluating:  94%|█████████▍| 303/321 [01:31<00:05,  3.26it/s]01/14/2022 16:19:22 - INFO - __main__ -   Batch number = 304
Evaluating:  95%|█████████▍| 304/321 [01:31<00:05,  3.24it/s]01/14/2022 16:19:23 - INFO - __main__ -   Batch number = 305
Evaluating:  95%|█████████▌| 305/321 [01:31<00:04,  3.22it/s]01/14/2022 16:19:23 - INFO - __main__ -   Batch number = 306
Evaluating:  95%|█████████▌| 306/321 [01:32<00:04,  3.22it/s]01/14/2022 16:19:23 - INFO - __main__ -   Batch number = 307
Evaluating:  96%|█████████▌| 307/321 [01:32<00:04,  3.23it/s]01/14/2022 16:19:24 - INFO - __main__ -   Batch number = 308
Evaluating:  96%|█████████▌| 308/321 [01:32<00:03,  3.25it/s]01/14/2022 16:19:24 - INFO - __main__ -   Batch number = 309
Evaluating:  96%|█████████▋| 309/321 [01:33<00:03,  3.27it/s]01/14/2022 16:19:24 - INFO - __main__ -   Batch number = 310
Evaluating:  97%|█████████▋| 310/321 [01:33<00:03,  3.27it/s]01/14/2022 16:19:25 - INFO - __main__ -   Batch number = 311
Evaluating:  97%|█████████▋| 311/321 [01:33<00:03,  3.31it/s]01/14/2022 16:19:25 - INFO - __main__ -   Batch number = 312
Evaluating:  97%|█████████▋| 312/321 [01:33<00:02,  3.30it/s]01/14/2022 16:19:25 - INFO - __main__ -   Batch number = 313
Evaluating:  98%|█████████▊| 313/321 [01:34<00:02,  3.32it/s]01/14/2022 16:19:25 - INFO - __main__ -   Batch number = 314
Evaluating:  98%|█████████▊| 314/321 [01:34<00:02,  3.31it/s]01/14/2022 16:19:26 - INFO - __main__ -   Batch number = 315
Evaluating:  98%|█████████▊| 315/321 [01:34<00:01,  3.29it/s]01/14/2022 16:19:26 - INFO - __main__ -   Batch number = 316
Evaluating:  98%|█████████▊| 316/321 [01:35<00:01,  3.32it/s]01/14/2022 16:19:26 - INFO - __main__ -   Batch number = 317
Evaluating:  99%|█████████▉| 317/321 [01:35<00:01,  3.32it/s]01/14/2022 16:19:27 - INFO - __main__ -   Batch number = 318
Evaluating:  99%|█████████▉| 318/321 [01:35<00:00,  3.35it/s]01/14/2022 16:19:27 - INFO - __main__ -   Batch number = 319
Evaluating:  99%|█████████▉| 319/321 [01:36<00:00,  3.37it/s]01/14/2022 16:19:27 - INFO - __main__ -   Batch number = 320
Evaluating: 100%|█████████▉| 320/321 [01:36<00:00,  3.36it/s]01/14/2022 16:19:28 - INFO - __main__ -   Batch number = 321
Evaluating: 100%|██████████| 321/321 [01:36<00:00,  3.86it/s]Evaluating: 100%|██████████| 321/321 [01:36<00:00,  3.33it/s]
01/14/2022 16:19:30 - INFO - __main__ -   ***** Evaluation result  in zh *****
01/14/2022 16:19:30 - INFO - __main__ -     f1 = 0.36124249009331455
01/14/2022 16:19:30 - INFO - __main__ -     loss = 3.883939821772115
01/14/2022 16:19:30 - INFO - __main__ -     precision = 0.265821356008729
01/14/2022 16:19:30 - INFO - __main__ -     recall = 0.5635319454414932
107.15user 40.03system 2:12.91elapsed 110%CPU (0avgtext+0avgdata 4226632maxresident)k
0inputs+1904outputs (0major+2496981minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:20:51 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:20:51 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:20:51 - INFO - __main__ -   Seed = 1
01/14/2022 16:20:51 - INFO - root -   save model
01/14/2022 16:20:51 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:20:51 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:20:53 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:20:59 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:20:59 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:20:59 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:20:59 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:20:59 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:20:59 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,ar/wiki@ukp
01/14/2022 16:20:59 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'ar'], Length : 10
01/14/2022 16:20:59 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'ar/wiki@ukp'], Length : 10
01/14/2022 16:20:59 - INFO - __main__ -   Language = en
01/14/2022 16:20:59 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:21:00 - INFO - __main__ -   Language = pt
01/14/2022 16:21:00 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:21:03 - INFO - __main__ -   Language = id
01/14/2022 16:21:03 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:21:05 - INFO - __main__ -   Language = cs
01/14/2022 16:21:05 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:21:08 - INFO - __main__ -   Language = tr
01/14/2022 16:21:08 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:21:10 - INFO - __main__ -   Language = eu
01/14/2022 16:21:10 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:21:13 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:21:13 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:21:15 - INFO - __main__ -   Language = vi
01/14/2022 16:21:15 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:21:18 - INFO - __main__ -   Language = fr
01/14/2022 16:21:18 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:21:19 - INFO - __main__ -   Language = ar
01/14/2022 16:21:19 - INFO - __main__ -   Adapter Name = ar/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ar/bert-base-multilingual-cased/pfeiffer/ar_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted/adapter_config.json
Adding adapter 'ar' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted'
01/14/2022 16:21:24 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:21:24 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'ar']
01/14/2022 16:21:24 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:21:24 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:21:24 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:21:24 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
01/14/2022 16:21:25 - INFO - __main__ -   ***** Running evaluation  in ar *****
01/14/2022 16:21:25 - INFO - __main__ -     Num examples = 10000
01/14/2022 16:21:25 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]01/14/2022 16:21:25 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/313 [00:00<01:35,  3.26it/s]01/14/2022 16:21:25 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/313 [00:00<01:30,  3.45it/s]01/14/2022 16:21:25 - INFO - __main__ -   Batch number = 3
Evaluating:   1%|          | 3/313 [00:00<01:27,  3.53it/s]01/14/2022 16:21:26 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|▏         | 4/313 [00:01<01:26,  3.57it/s]01/14/2022 16:21:26 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/313 [00:01<01:25,  3.60it/s]01/14/2022 16:21:26 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/313 [00:01<01:25,  3.61it/s]01/14/2022 16:21:26 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/313 [00:01<01:24,  3.61it/s]01/14/2022 16:21:27 - INFO - __main__ -   Batch number = 8
Evaluating:   3%|▎         | 8/313 [00:02<01:24,  3.61it/s]01/14/2022 16:21:27 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/313 [00:02<01:24,  3.61it/s]01/14/2022 16:21:27 - INFO - __main__ -   Batch number = 10
Evaluating:   3%|▎         | 10/313 [00:02<01:23,  3.62it/s]01/14/2022 16:21:27 - INFO - __main__ -   Batch number = 11
Evaluating:   4%|▎         | 11/313 [00:03<01:23,  3.62it/s]01/14/2022 16:21:28 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▍         | 12/313 [00:03<01:23,  3.62it/s]01/14/2022 16:21:28 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/313 [00:03<01:23,  3.61it/s]01/14/2022 16:21:28 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/313 [00:03<01:22,  3.61it/s]01/14/2022 16:21:29 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/313 [00:04<01:22,  3.61it/s]01/14/2022 16:21:29 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▌         | 16/313 [00:04<01:22,  3.61it/s]01/14/2022 16:21:29 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/313 [00:04<01:21,  3.61it/s]01/14/2022 16:21:29 - INFO - __main__ -   Batch number = 18
Evaluating:   6%|▌         | 18/313 [00:05<01:21,  3.61it/s]01/14/2022 16:21:30 - INFO - __main__ -   Batch number = 19
Evaluating:   6%|▌         | 19/313 [00:05<01:21,  3.62it/s]01/14/2022 16:21:30 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▋         | 20/313 [00:05<01:21,  3.61it/s]01/14/2022 16:21:30 - INFO - __main__ -   Batch number = 21
Evaluating:   7%|▋         | 21/313 [00:05<01:28,  3.29it/s]01/14/2022 16:21:31 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/313 [00:06<01:26,  3.38it/s]01/14/2022 16:21:31 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/313 [00:06<01:24,  3.44it/s]01/14/2022 16:21:31 - INFO - __main__ -   Batch number = 24
Evaluating:   8%|▊         | 24/313 [00:06<01:22,  3.49it/s]01/14/2022 16:21:31 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/313 [00:07<01:21,  3.52it/s]01/14/2022 16:21:32 - INFO - __main__ -   Batch number = 26
Evaluating:   8%|▊         | 26/313 [00:07<01:21,  3.54it/s]01/14/2022 16:21:32 - INFO - __main__ -   Batch number = 27
Evaluating:   9%|▊         | 27/313 [00:07<01:20,  3.56it/s]01/14/2022 16:21:32 - INFO - __main__ -   Batch number = 28
Evaluating:   9%|▉         | 28/313 [00:07<01:19,  3.58it/s]01/14/2022 16:21:33 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▉         | 29/313 [00:08<01:19,  3.58it/s]01/14/2022 16:21:33 - INFO - __main__ -   Batch number = 30
Evaluating:  10%|▉         | 30/313 [00:08<01:18,  3.59it/s]01/14/2022 16:21:33 - INFO - __main__ -   Batch number = 31
Evaluating:  10%|▉         | 31/313 [00:08<01:18,  3.60it/s]01/14/2022 16:21:33 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|█         | 32/313 [00:08<01:18,  3.60it/s]01/14/2022 16:21:34 - INFO - __main__ -   Batch number = 33
Evaluating:  11%|█         | 33/313 [00:09<01:17,  3.60it/s]01/14/2022 16:21:34 - INFO - __main__ -   Batch number = 34
Evaluating:  11%|█         | 34/313 [00:09<01:17,  3.60it/s]01/14/2022 16:21:34 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/313 [00:09<01:17,  3.60it/s]01/14/2022 16:21:35 - INFO - __main__ -   Batch number = 36
Evaluating:  12%|█▏        | 36/313 [00:10<01:16,  3.60it/s]01/14/2022 16:21:35 - INFO - __main__ -   Batch number = 37
Evaluating:  12%|█▏        | 37/313 [00:10<01:16,  3.59it/s]01/14/2022 16:21:35 - INFO - __main__ -   Batch number = 38
Evaluating:  12%|█▏        | 38/313 [00:10<01:16,  3.59it/s]01/14/2022 16:21:35 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/313 [00:11<01:24,  3.26it/s]01/14/2022 16:21:36 - INFO - __main__ -   Batch number = 40
Evaluating:  13%|█▎        | 40/313 [00:11<01:21,  3.35it/s]01/14/2022 16:21:36 - INFO - __main__ -   Batch number = 41
Evaluating:  13%|█▎        | 41/313 [00:11<01:19,  3.43it/s]01/14/2022 16:21:36 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/313 [00:11<01:17,  3.48it/s]01/14/2022 16:21:37 - INFO - __main__ -   Batch number = 43
Evaluating:  14%|█▎        | 43/313 [00:12<01:16,  3.51it/s]01/14/2022 16:21:37 - INFO - __main__ -   Batch number = 44
Evaluating:  14%|█▍        | 44/313 [00:12<01:16,  3.53it/s]01/14/2022 16:21:37 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▍        | 45/313 [00:12<01:15,  3.55it/s]01/14/2022 16:21:37 - INFO - __main__ -   Batch number = 46
Evaluating:  15%|█▍        | 46/313 [00:12<01:14,  3.57it/s]01/14/2022 16:21:38 - INFO - __main__ -   Batch number = 47
Evaluating:  15%|█▌        | 47/313 [00:13<01:14,  3.58it/s]01/14/2022 16:21:38 - INFO - __main__ -   Batch number = 48
Evaluating:  15%|█▌        | 48/313 [00:13<01:13,  3.58it/s]01/14/2022 16:21:38 - INFO - __main__ -   Batch number = 49
Evaluating:  16%|█▌        | 49/313 [00:13<01:13,  3.59it/s]01/14/2022 16:21:38 - INFO - __main__ -   Batch number = 50
Evaluating:  16%|█▌        | 50/313 [00:14<01:13,  3.59it/s]01/14/2022 16:21:39 - INFO - __main__ -   Batch number = 51
Evaluating:  16%|█▋        | 51/313 [00:14<01:13,  3.58it/s]01/14/2022 16:21:39 - INFO - __main__ -   Batch number = 52
Evaluating:  17%|█▋        | 52/313 [00:14<01:13,  3.58it/s]01/14/2022 16:21:39 - INFO - __main__ -   Batch number = 53
Evaluating:  17%|█▋        | 53/313 [00:14<01:12,  3.58it/s]01/14/2022 16:21:40 - INFO - __main__ -   Batch number = 54
Evaluating:  17%|█▋        | 54/313 [00:15<01:12,  3.57it/s]01/14/2022 16:21:40 - INFO - __main__ -   Batch number = 55
Evaluating:  18%|█▊        | 55/313 [00:15<01:12,  3.58it/s]01/14/2022 16:21:40 - INFO - __main__ -   Batch number = 56
Evaluating:  18%|█▊        | 56/313 [00:15<01:11,  3.57it/s]01/14/2022 16:21:40 - INFO - __main__ -   Batch number = 57
Evaluating:  18%|█▊        | 57/313 [00:16<01:19,  3.22it/s]01/14/2022 16:21:41 - INFO - __main__ -   Batch number = 58
Evaluating:  19%|█▊        | 58/313 [00:16<01:16,  3.32it/s]01/14/2022 16:21:41 - INFO - __main__ -   Batch number = 59
Evaluating:  19%|█▉        | 59/313 [00:16<01:14,  3.39it/s]01/14/2022 16:21:41 - INFO - __main__ -   Batch number = 60
Evaluating:  19%|█▉        | 60/313 [00:16<01:13,  3.44it/s]01/14/2022 16:21:42 - INFO - __main__ -   Batch number = 61
Evaluating:  19%|█▉        | 61/313 [00:17<01:12,  3.48it/s]01/14/2022 16:21:42 - INFO - __main__ -   Batch number = 62
Evaluating:  20%|█▉        | 62/313 [00:17<01:11,  3.51it/s]01/14/2022 16:21:42 - INFO - __main__ -   Batch number = 63
Evaluating:  20%|██        | 63/313 [00:17<01:11,  3.52it/s]01/14/2022 16:21:43 - INFO - __main__ -   Batch number = 64
Evaluating:  20%|██        | 64/313 [00:18<01:10,  3.53it/s]01/14/2022 16:21:43 - INFO - __main__ -   Batch number = 65
Evaluating:  21%|██        | 65/313 [00:18<01:10,  3.54it/s]01/14/2022 16:21:43 - INFO - __main__ -   Batch number = 66
Evaluating:  21%|██        | 66/313 [00:18<01:09,  3.55it/s]01/14/2022 16:21:43 - INFO - __main__ -   Batch number = 67
Evaluating:  21%|██▏       | 67/313 [00:18<01:09,  3.55it/s]01/14/2022 16:21:44 - INFO - __main__ -   Batch number = 68
Evaluating:  22%|██▏       | 68/313 [00:19<01:08,  3.56it/s]01/14/2022 16:21:44 - INFO - __main__ -   Batch number = 69
Evaluating:  22%|██▏       | 69/313 [00:19<01:08,  3.56it/s]01/14/2022 16:21:44 - INFO - __main__ -   Batch number = 70
Evaluating:  22%|██▏       | 70/313 [00:19<01:08,  3.56it/s]01/14/2022 16:21:44 - INFO - __main__ -   Batch number = 71
Evaluating:  23%|██▎       | 71/313 [00:20<01:07,  3.56it/s]01/14/2022 16:21:45 - INFO - __main__ -   Batch number = 72
Evaluating:  23%|██▎       | 72/313 [00:20<01:07,  3.57it/s]01/14/2022 16:21:45 - INFO - __main__ -   Batch number = 73
Evaluating:  23%|██▎       | 73/313 [00:20<01:07,  3.56it/s]01/14/2022 16:21:45 - INFO - __main__ -   Batch number = 74
Evaluating:  24%|██▎       | 74/313 [00:20<01:07,  3.57it/s]01/14/2022 16:21:46 - INFO - __main__ -   Batch number = 75
Evaluating:  24%|██▍       | 75/313 [00:21<01:10,  3.35it/s]01/14/2022 16:21:46 - INFO - __main__ -   Batch number = 76
Evaluating:  24%|██▍       | 76/313 [00:21<01:09,  3.40it/s]01/14/2022 16:21:46 - INFO - __main__ -   Batch number = 77
Evaluating:  25%|██▍       | 77/313 [00:21<01:08,  3.43it/s]01/14/2022 16:21:47 - INFO - __main__ -   Batch number = 78
Evaluating:  25%|██▍       | 78/313 [00:22<01:07,  3.47it/s]01/14/2022 16:21:47 - INFO - __main__ -   Batch number = 79
Evaluating:  25%|██▌       | 79/313 [00:22<01:06,  3.50it/s]01/14/2022 16:21:47 - INFO - __main__ -   Batch number = 80
Evaluating:  26%|██▌       | 80/313 [00:22<01:06,  3.51it/s]01/14/2022 16:21:47 - INFO - __main__ -   Batch number = 81
Evaluating:  26%|██▌       | 81/313 [00:22<01:05,  3.53it/s]01/14/2022 16:21:48 - INFO - __main__ -   Batch number = 82
Evaluating:  26%|██▌       | 82/313 [00:23<01:05,  3.53it/s]01/14/2022 16:21:48 - INFO - __main__ -   Batch number = 83
Evaluating:  27%|██▋       | 83/313 [00:23<01:04,  3.54it/s]01/14/2022 16:21:48 - INFO - __main__ -   Batch number = 84
Evaluating:  27%|██▋       | 84/313 [00:23<01:04,  3.55it/s]01/14/2022 16:21:48 - INFO - __main__ -   Batch number = 85
Evaluating:  27%|██▋       | 85/313 [00:24<01:04,  3.54it/s]01/14/2022 16:21:49 - INFO - __main__ -   Batch number = 86
Evaluating:  27%|██▋       | 86/313 [00:24<01:04,  3.54it/s]01/14/2022 16:21:49 - INFO - __main__ -   Batch number = 87
Evaluating:  28%|██▊       | 87/313 [00:24<01:03,  3.54it/s]01/14/2022 16:21:49 - INFO - __main__ -   Batch number = 88
Evaluating:  28%|██▊       | 88/313 [00:24<01:03,  3.55it/s]01/14/2022 16:21:50 - INFO - __main__ -   Batch number = 89
Evaluating:  28%|██▊       | 89/313 [00:25<01:03,  3.54it/s]01/14/2022 16:21:50 - INFO - __main__ -   Batch number = 90
Evaluating:  29%|██▉       | 90/313 [00:25<01:02,  3.54it/s]01/14/2022 16:21:50 - INFO - __main__ -   Batch number = 91
Evaluating:  29%|██▉       | 91/313 [00:25<01:02,  3.54it/s]01/14/2022 16:21:50 - INFO - __main__ -   Batch number = 92
Evaluating:  29%|██▉       | 92/313 [00:26<01:02,  3.54it/s]01/14/2022 16:21:51 - INFO - __main__ -   Batch number = 93
Evaluating:  30%|██▉       | 93/313 [00:26<01:02,  3.54it/s]01/14/2022 16:21:51 - INFO - __main__ -   Batch number = 94
Evaluating:  30%|███       | 94/313 [00:26<01:01,  3.55it/s]01/14/2022 16:21:51 - INFO - __main__ -   Batch number = 95
Evaluating:  30%|███       | 95/313 [00:26<01:01,  3.54it/s]01/14/2022 16:21:52 - INFO - __main__ -   Batch number = 96
Evaluating:  31%|███       | 96/313 [00:27<01:01,  3.55it/s]01/14/2022 16:21:52 - INFO - __main__ -   Batch number = 97
Evaluating:  31%|███       | 97/313 [00:27<01:00,  3.55it/s]01/14/2022 16:21:52 - INFO - __main__ -   Batch number = 98
Evaluating:  31%|███▏      | 98/313 [00:27<01:00,  3.55it/s]01/14/2022 16:21:52 - INFO - __main__ -   Batch number = 99
Evaluating:  32%|███▏      | 99/313 [00:28<01:00,  3.55it/s]01/14/2022 16:21:53 - INFO - __main__ -   Batch number = 100
Evaluating:  32%|███▏      | 100/313 [00:28<01:00,  3.54it/s]01/14/2022 16:21:53 - INFO - __main__ -   Batch number = 101
Evaluating:  32%|███▏      | 101/313 [00:28<00:59,  3.54it/s]01/14/2022 16:21:53 - INFO - __main__ -   Batch number = 102
Evaluating:  33%|███▎      | 102/313 [00:28<00:59,  3.54it/s]01/14/2022 16:21:54 - INFO - __main__ -   Batch number = 103
Evaluating:  33%|███▎      | 103/313 [00:29<00:59,  3.54it/s]01/14/2022 16:21:54 - INFO - __main__ -   Batch number = 104
Evaluating:  33%|███▎      | 104/313 [00:29<00:59,  3.53it/s]01/14/2022 16:21:54 - INFO - __main__ -   Batch number = 105
Evaluating:  34%|███▎      | 105/313 [00:29<00:59,  3.52it/s]01/14/2022 16:21:54 - INFO - __main__ -   Batch number = 106
Evaluating:  34%|███▍      | 106/313 [00:30<00:58,  3.52it/s]01/14/2022 16:21:55 - INFO - __main__ -   Batch number = 107
Evaluating:  34%|███▍      | 107/313 [00:30<00:58,  3.52it/s]01/14/2022 16:21:55 - INFO - __main__ -   Batch number = 108
Evaluating:  35%|███▍      | 108/313 [00:30<00:58,  3.53it/s]01/14/2022 16:21:55 - INFO - __main__ -   Batch number = 109
Evaluating:  35%|███▍      | 109/313 [00:30<00:57,  3.53it/s]01/14/2022 16:21:56 - INFO - __main__ -   Batch number = 110
Evaluating:  35%|███▌      | 110/313 [00:31<00:57,  3.53it/s]01/14/2022 16:21:56 - INFO - __main__ -   Batch number = 111
Evaluating:  35%|███▌      | 111/313 [00:31<00:57,  3.54it/s]01/14/2022 16:21:56 - INFO - __main__ -   Batch number = 112
Evaluating:  36%|███▌      | 112/313 [00:31<00:56,  3.54it/s]01/14/2022 16:21:56 - INFO - __main__ -   Batch number = 113
Evaluating:  36%|███▌      | 113/313 [00:31<00:56,  3.53it/s]01/14/2022 16:21:57 - INFO - __main__ -   Batch number = 114
Evaluating:  36%|███▋      | 114/313 [00:32<00:56,  3.52it/s]01/14/2022 16:21:57 - INFO - __main__ -   Batch number = 115
Evaluating:  37%|███▋      | 115/313 [00:32<00:56,  3.51it/s]01/14/2022 16:21:57 - INFO - __main__ -   Batch number = 116
Evaluating:  37%|███▋      | 116/313 [00:32<00:56,  3.49it/s]01/14/2022 16:21:58 - INFO - __main__ -   Batch number = 117
Evaluating:  37%|███▋      | 117/313 [00:33<00:56,  3.48it/s]01/14/2022 16:21:58 - INFO - __main__ -   Batch number = 118
Evaluating:  38%|███▊      | 118/313 [00:33<00:56,  3.46it/s]01/14/2022 16:21:58 - INFO - __main__ -   Batch number = 119
Evaluating:  38%|███▊      | 119/313 [00:33<00:56,  3.44it/s]01/14/2022 16:21:58 - INFO - __main__ -   Batch number = 120
Evaluating:  38%|███▊      | 120/313 [00:34<00:56,  3.43it/s]01/14/2022 16:21:59 - INFO - __main__ -   Batch number = 121
Evaluating:  39%|███▊      | 121/313 [00:34<00:56,  3.41it/s]01/14/2022 16:21:59 - INFO - __main__ -   Batch number = 122
Evaluating:  39%|███▉      | 122/313 [00:34<00:56,  3.39it/s]01/14/2022 16:21:59 - INFO - __main__ -   Batch number = 123
Evaluating:  39%|███▉      | 123/313 [00:34<00:55,  3.39it/s]01/14/2022 16:22:00 - INFO - __main__ -   Batch number = 124
Evaluating:  40%|███▉      | 124/313 [00:35<00:55,  3.41it/s]01/14/2022 16:22:00 - INFO - __main__ -   Batch number = 125
Evaluating:  40%|███▉      | 125/313 [00:35<00:55,  3.39it/s]01/14/2022 16:22:00 - INFO - __main__ -   Batch number = 126
Evaluating:  40%|████      | 126/313 [00:35<00:54,  3.42it/s]01/14/2022 16:22:00 - INFO - __main__ -   Batch number = 127
Evaluating:  41%|████      | 127/313 [00:36<00:54,  3.42it/s]01/14/2022 16:22:01 - INFO - __main__ -   Batch number = 128
Evaluating:  41%|████      | 128/313 [00:36<00:53,  3.44it/s]01/14/2022 16:22:01 - INFO - __main__ -   Batch number = 129
Evaluating:  41%|████      | 129/313 [00:36<00:53,  3.46it/s]01/14/2022 16:22:01 - INFO - __main__ -   Batch number = 130
Evaluating:  42%|████▏     | 130/313 [00:36<00:52,  3.46it/s]01/14/2022 16:22:02 - INFO - __main__ -   Batch number = 131
Evaluating:  42%|████▏     | 131/313 [00:37<00:52,  3.45it/s]01/14/2022 16:22:02 - INFO - __main__ -   Batch number = 132
Evaluating:  42%|████▏     | 132/313 [00:37<00:52,  3.46it/s]01/14/2022 16:22:02 - INFO - __main__ -   Batch number = 133
Evaluating:  42%|████▏     | 133/313 [00:37<00:52,  3.45it/s]01/14/2022 16:22:03 - INFO - __main__ -   Batch number = 134
Evaluating:  43%|████▎     | 134/313 [00:38<00:52,  3.44it/s]01/14/2022 16:22:03 - INFO - __main__ -   Batch number = 135
Evaluating:  43%|████▎     | 135/313 [00:38<00:51,  3.45it/s]01/14/2022 16:22:03 - INFO - __main__ -   Batch number = 136
Evaluating:  43%|████▎     | 136/313 [00:38<00:50,  3.47it/s]01/14/2022 16:22:03 - INFO - __main__ -   Batch number = 137
Evaluating:  44%|████▍     | 137/313 [00:38<00:50,  3.47it/s]01/14/2022 16:22:04 - INFO - __main__ -   Batch number = 138
Evaluating:  44%|████▍     | 138/313 [00:39<00:50,  3.48it/s]01/14/2022 16:22:04 - INFO - __main__ -   Batch number = 139
Evaluating:  44%|████▍     | 139/313 [00:39<00:50,  3.48it/s]01/14/2022 16:22:04 - INFO - __main__ -   Batch number = 140
Evaluating:  45%|████▍     | 140/313 [00:39<00:49,  3.46it/s]01/14/2022 16:22:05 - INFO - __main__ -   Batch number = 141
Evaluating:  45%|████▌     | 141/313 [00:40<00:49,  3.47it/s]01/14/2022 16:22:05 - INFO - __main__ -   Batch number = 142
Evaluating:  45%|████▌     | 142/313 [00:40<00:49,  3.48it/s]01/14/2022 16:22:05 - INFO - __main__ -   Batch number = 143
Evaluating:  46%|████▌     | 143/313 [00:40<00:48,  3.48it/s]01/14/2022 16:22:05 - INFO - __main__ -   Batch number = 144
Evaluating:  46%|████▌     | 144/313 [00:40<00:48,  3.48it/s]01/14/2022 16:22:06 - INFO - __main__ -   Batch number = 145
Evaluating:  46%|████▋     | 145/313 [00:41<00:48,  3.48it/s]01/14/2022 16:22:06 - INFO - __main__ -   Batch number = 146
Evaluating:  47%|████▋     | 146/313 [00:41<00:47,  3.48it/s]01/14/2022 16:22:06 - INFO - __main__ -   Batch number = 147
Evaluating:  47%|████▋     | 147/313 [00:41<00:47,  3.48it/s]01/14/2022 16:22:07 - INFO - __main__ -   Batch number = 148
Evaluating:  47%|████▋     | 148/313 [00:42<00:47,  3.48it/s]01/14/2022 16:22:07 - INFO - __main__ -   Batch number = 149
Evaluating:  48%|████▊     | 149/313 [00:42<00:47,  3.49it/s]01/14/2022 16:22:07 - INFO - __main__ -   Batch number = 150
Evaluating:  48%|████▊     | 150/313 [00:42<00:46,  3.47it/s]01/14/2022 16:22:07 - INFO - __main__ -   Batch number = 151
Evaluating:  48%|████▊     | 151/313 [00:42<00:46,  3.46it/s]01/14/2022 16:22:08 - INFO - __main__ -   Batch number = 152
Evaluating:  49%|████▊     | 152/313 [00:43<00:46,  3.44it/s]01/14/2022 16:22:08 - INFO - __main__ -   Batch number = 153
Evaluating:  49%|████▉     | 153/313 [00:43<00:46,  3.43it/s]01/14/2022 16:22:08 - INFO - __main__ -   Batch number = 154
Evaluating:  49%|████▉     | 154/313 [00:43<00:46,  3.40it/s]01/14/2022 16:22:09 - INFO - __main__ -   Batch number = 155
Evaluating:  50%|████▉     | 155/313 [00:44<00:47,  3.35it/s]01/14/2022 16:22:09 - INFO - __main__ -   Batch number = 156
Evaluating:  50%|████▉     | 156/313 [00:44<00:47,  3.34it/s]01/14/2022 16:22:09 - INFO - __main__ -   Batch number = 157
Evaluating:  50%|█████     | 157/313 [00:44<00:49,  3.17it/s]01/14/2022 16:22:10 - INFO - __main__ -   Batch number = 158
Evaluating:  50%|█████     | 158/313 [00:45<00:47,  3.26it/s]01/14/2022 16:22:10 - INFO - __main__ -   Batch number = 159
Evaluating:  51%|█████     | 159/313 [00:45<00:46,  3.33it/s]01/14/2022 16:22:10 - INFO - __main__ -   Batch number = 160
Evaluating:  51%|█████     | 160/313 [00:45<00:45,  3.37it/s]01/14/2022 16:22:10 - INFO - __main__ -   Batch number = 161
Evaluating:  51%|█████▏    | 161/313 [00:45<00:44,  3.39it/s]01/14/2022 16:22:11 - INFO - __main__ -   Batch number = 162
Evaluating:  52%|█████▏    | 162/313 [00:46<00:44,  3.42it/s]01/14/2022 16:22:11 - INFO - __main__ -   Batch number = 163
Evaluating:  52%|█████▏    | 163/313 [00:46<00:43,  3.43it/s]01/14/2022 16:22:11 - INFO - __main__ -   Batch number = 164
Evaluating:  52%|█████▏    | 164/313 [00:46<00:43,  3.44it/s]01/14/2022 16:22:12 - INFO - __main__ -   Batch number = 165
Evaluating:  53%|█████▎    | 165/313 [00:47<00:43,  3.43it/s]01/14/2022 16:22:12 - INFO - __main__ -   Batch number = 166
Evaluating:  53%|█████▎    | 166/313 [00:47<00:43,  3.41it/s]01/14/2022 16:22:12 - INFO - __main__ -   Batch number = 167
Evaluating:  53%|█████▎    | 167/313 [00:47<00:43,  3.39it/s]01/14/2022 16:22:12 - INFO - __main__ -   Batch number = 168
Evaluating:  54%|█████▎    | 168/313 [00:48<00:42,  3.39it/s]01/14/2022 16:22:13 - INFO - __main__ -   Batch number = 169
Evaluating:  54%|█████▍    | 169/313 [00:48<00:42,  3.40it/s]01/14/2022 16:22:13 - INFO - __main__ -   Batch number = 170
Evaluating:  54%|█████▍    | 170/313 [00:48<00:41,  3.41it/s]01/14/2022 16:22:13 - INFO - __main__ -   Batch number = 171
Evaluating:  55%|█████▍    | 171/313 [00:48<00:41,  3.43it/s]01/14/2022 16:22:14 - INFO - __main__ -   Batch number = 172
Evaluating:  55%|█████▍    | 172/313 [00:49<00:40,  3.44it/s]01/14/2022 16:22:14 - INFO - __main__ -   Batch number = 173
Evaluating:  55%|█████▌    | 173/313 [00:49<00:40,  3.45it/s]01/14/2022 16:22:14 - INFO - __main__ -   Batch number = 174
Evaluating:  56%|█████▌    | 174/313 [00:49<00:40,  3.46it/s]01/14/2022 16:22:14 - INFO - __main__ -   Batch number = 175
Evaluating:  56%|█████▌    | 175/313 [00:50<00:39,  3.46it/s]01/14/2022 16:22:15 - INFO - __main__ -   Batch number = 176
Evaluating:  56%|█████▌    | 176/313 [00:50<00:39,  3.45it/s]01/14/2022 16:22:15 - INFO - __main__ -   Batch number = 177
Evaluating:  57%|█████▋    | 177/313 [00:50<00:39,  3.41it/s]01/14/2022 16:22:15 - INFO - __main__ -   Batch number = 178
Evaluating:  57%|█████▋    | 178/313 [00:50<00:40,  3.37it/s]01/14/2022 16:22:16 - INFO - __main__ -   Batch number = 179
Evaluating:  57%|█████▋    | 179/313 [00:51<00:40,  3.33it/s]01/14/2022 16:22:16 - INFO - __main__ -   Batch number = 180
Evaluating:  58%|█████▊    | 180/313 [00:51<00:40,  3.31it/s]01/14/2022 16:22:16 - INFO - __main__ -   Batch number = 181
Evaluating:  58%|█████▊    | 181/313 [00:51<00:40,  3.29it/s]01/14/2022 16:22:17 - INFO - __main__ -   Batch number = 182
Evaluating:  58%|█████▊    | 182/313 [00:52<00:39,  3.30it/s]01/14/2022 16:22:17 - INFO - __main__ -   Batch number = 183
Evaluating:  58%|█████▊    | 183/313 [00:52<00:39,  3.31it/s]01/14/2022 16:22:17 - INFO - __main__ -   Batch number = 184
Evaluating:  59%|█████▉    | 184/313 [00:52<00:39,  3.29it/s]01/14/2022 16:22:17 - INFO - __main__ -   Batch number = 185
Evaluating:  59%|█████▉    | 185/313 [00:53<00:39,  3.25it/s]01/14/2022 16:22:18 - INFO - __main__ -   Batch number = 186
Evaluating:  59%|█████▉    | 186/313 [00:53<00:41,  3.04it/s]01/14/2022 16:22:18 - INFO - __main__ -   Batch number = 187
Evaluating:  60%|█████▉    | 187/313 [00:53<00:39,  3.15it/s]01/14/2022 16:22:18 - INFO - __main__ -   Batch number = 188
Evaluating:  60%|██████    | 188/313 [00:54<00:38,  3.23it/s]01/14/2022 16:22:19 - INFO - __main__ -   Batch number = 189
Evaluating:  60%|██████    | 189/313 [00:54<00:37,  3.28it/s]01/14/2022 16:22:19 - INFO - __main__ -   Batch number = 190
Evaluating:  61%|██████    | 190/313 [00:54<00:37,  3.32it/s]01/14/2022 16:22:19 - INFO - __main__ -   Batch number = 191
Evaluating:  61%|██████    | 191/313 [00:54<00:36,  3.35it/s]01/14/2022 16:22:20 - INFO - __main__ -   Batch number = 192
Evaluating:  61%|██████▏   | 192/313 [00:55<00:35,  3.37it/s]01/14/2022 16:22:20 - INFO - __main__ -   Batch number = 193
Evaluating:  62%|██████▏   | 193/313 [00:55<00:35,  3.36it/s]01/14/2022 16:22:20 - INFO - __main__ -   Batch number = 194
Evaluating:  62%|██████▏   | 194/313 [00:55<00:35,  3.34it/s]01/14/2022 16:22:21 - INFO - __main__ -   Batch number = 195
Evaluating:  62%|██████▏   | 195/313 [00:56<00:35,  3.32it/s]01/14/2022 16:22:21 - INFO - __main__ -   Batch number = 196
Evaluating:  63%|██████▎   | 196/313 [00:56<00:35,  3.30it/s]01/14/2022 16:22:21 - INFO - __main__ -   Batch number = 197
Evaluating:  63%|██████▎   | 197/313 [00:56<00:35,  3.26it/s]01/14/2022 16:22:21 - INFO - __main__ -   Batch number = 198
Evaluating:  63%|██████▎   | 198/313 [00:57<00:35,  3.24it/s]01/14/2022 16:22:22 - INFO - __main__ -   Batch number = 199
Evaluating:  64%|██████▎   | 199/313 [00:57<00:35,  3.23it/s]01/14/2022 16:22:22 - INFO - __main__ -   Batch number = 200
Evaluating:  64%|██████▍   | 200/313 [00:57<00:34,  3.25it/s]01/14/2022 16:22:22 - INFO - __main__ -   Batch number = 201
Evaluating:  64%|██████▍   | 201/313 [00:58<00:34,  3.27it/s]01/14/2022 16:22:23 - INFO - __main__ -   Batch number = 202
Evaluating:  65%|██████▍   | 202/313 [00:58<00:33,  3.29it/s]01/14/2022 16:22:23 - INFO - __main__ -   Batch number = 203
Evaluating:  65%|██████▍   | 203/313 [00:58<00:37,  2.95it/s]01/14/2022 16:22:23 - INFO - __main__ -   Batch number = 204
Evaluating:  65%|██████▌   | 204/313 [00:59<00:36,  3.02it/s]01/14/2022 16:22:24 - INFO - __main__ -   Batch number = 205
Evaluating:  65%|██████▌   | 205/313 [00:59<00:35,  3.08it/s]01/14/2022 16:22:24 - INFO - __main__ -   Batch number = 206
Evaluating:  66%|██████▌   | 206/313 [00:59<00:34,  3.12it/s]01/14/2022 16:22:24 - INFO - __main__ -   Batch number = 207
Evaluating:  66%|██████▌   | 207/313 [00:59<00:33,  3.16it/s]01/14/2022 16:22:25 - INFO - __main__ -   Batch number = 208
Evaluating:  66%|██████▋   | 208/313 [01:00<00:33,  3.18it/s]01/14/2022 16:22:25 - INFO - __main__ -   Batch number = 209
Evaluating:  67%|██████▋   | 209/313 [01:00<00:32,  3.19it/s]01/14/2022 16:22:25 - INFO - __main__ -   Batch number = 210
Evaluating:  67%|██████▋   | 210/313 [01:00<00:32,  3.21it/s]01/14/2022 16:22:26 - INFO - __main__ -   Batch number = 211
Evaluating:  67%|██████▋   | 211/313 [01:01<00:31,  3.25it/s]01/14/2022 16:22:26 - INFO - __main__ -   Batch number = 212
Evaluating:  68%|██████▊   | 212/313 [01:01<00:30,  3.26it/s]01/14/2022 16:22:26 - INFO - __main__ -   Batch number = 213
Evaluating:  68%|██████▊   | 213/313 [01:01<00:30,  3.25it/s]01/14/2022 16:22:27 - INFO - __main__ -   Batch number = 214
Evaluating:  68%|██████▊   | 214/313 [01:02<00:30,  3.24it/s]01/14/2022 16:22:27 - INFO - __main__ -   Batch number = 215
Evaluating:  69%|██████▊   | 215/313 [01:02<00:30,  3.26it/s]01/14/2022 16:22:27 - INFO - __main__ -   Batch number = 216
Evaluating:  69%|██████▉   | 216/313 [01:02<00:29,  3.28it/s]01/14/2022 16:22:27 - INFO - __main__ -   Batch number = 217
Evaluating:  69%|██████▉   | 217/313 [01:03<00:29,  3.28it/s]01/14/2022 16:22:28 - INFO - __main__ -   Batch number = 218
Evaluating:  70%|██████▉   | 218/313 [01:03<00:29,  3.26it/s]01/14/2022 16:22:28 - INFO - __main__ -   Batch number = 219
Evaluating:  70%|██████▉   | 219/313 [01:03<00:30,  3.13it/s]01/14/2022 16:22:28 - INFO - __main__ -   Batch number = 220
Evaluating:  70%|███████   | 220/313 [01:03<00:28,  3.22it/s]01/14/2022 16:22:29 - INFO - __main__ -   Batch number = 221
Evaluating:  71%|███████   | 221/313 [01:04<00:27,  3.30it/s]01/14/2022 16:22:29 - INFO - __main__ -   Batch number = 222
Evaluating:  71%|███████   | 222/313 [01:04<00:27,  3.35it/s]01/14/2022 16:22:29 - INFO - __main__ -   Batch number = 223
Evaluating:  71%|███████   | 223/313 [01:04<00:26,  3.37it/s]01/14/2022 16:22:30 - INFO - __main__ -   Batch number = 224
Evaluating:  72%|███████▏  | 224/313 [01:05<00:26,  3.40it/s]01/14/2022 16:22:30 - INFO - __main__ -   Batch number = 225
Evaluating:  72%|███████▏  | 225/313 [01:05<00:25,  3.40it/s]01/14/2022 16:22:30 - INFO - __main__ -   Batch number = 226
Evaluating:  72%|███████▏  | 226/313 [01:05<00:25,  3.42it/s]01/14/2022 16:22:30 - INFO - __main__ -   Batch number = 227
Evaluating:  73%|███████▎  | 227/313 [01:06<00:25,  3.44it/s]01/14/2022 16:22:31 - INFO - __main__ -   Batch number = 228
Evaluating:  73%|███████▎  | 228/313 [01:06<00:24,  3.45it/s]01/14/2022 16:22:31 - INFO - __main__ -   Batch number = 229
Evaluating:  73%|███████▎  | 229/313 [01:06<00:24,  3.46it/s]01/14/2022 16:22:31 - INFO - __main__ -   Batch number = 230
Evaluating:  73%|███████▎  | 230/313 [01:06<00:23,  3.46it/s]01/14/2022 16:22:32 - INFO - __main__ -   Batch number = 231
Evaluating:  74%|███████▍  | 231/313 [01:07<00:23,  3.46it/s]01/14/2022 16:22:32 - INFO - __main__ -   Batch number = 232
Evaluating:  74%|███████▍  | 232/313 [01:07<00:23,  3.45it/s]01/14/2022 16:22:32 - INFO - __main__ -   Batch number = 233
Evaluating:  74%|███████▍  | 233/313 [01:07<00:23,  3.44it/s]01/14/2022 16:22:32 - INFO - __main__ -   Batch number = 234
Evaluating:  75%|███████▍  | 234/313 [01:08<00:23,  3.42it/s]01/14/2022 16:22:33 - INFO - __main__ -   Batch number = 235
Evaluating:  75%|███████▌  | 235/313 [01:08<00:23,  3.37it/s]01/14/2022 16:22:33 - INFO - __main__ -   Batch number = 236
Evaluating:  75%|███████▌  | 236/313 [01:08<00:25,  3.03it/s]01/14/2022 16:22:33 - INFO - __main__ -   Batch number = 237
Evaluating:  76%|███████▌  | 237/313 [01:09<00:24,  3.08it/s]01/14/2022 16:22:34 - INFO - __main__ -   Batch number = 238
Evaluating:  76%|███████▌  | 238/313 [01:09<00:24,  3.12it/s]01/14/2022 16:22:34 - INFO - __main__ -   Batch number = 239
Evaluating:  76%|███████▋  | 239/313 [01:09<00:23,  3.16it/s]01/14/2022 16:22:34 - INFO - __main__ -   Batch number = 240
Evaluating:  77%|███████▋  | 240/313 [01:09<00:22,  3.20it/s]01/14/2022 16:22:35 - INFO - __main__ -   Batch number = 241
Evaluating:  77%|███████▋  | 241/313 [01:10<00:22,  3.25it/s]01/14/2022 16:22:35 - INFO - __main__ -   Batch number = 242
Evaluating:  77%|███████▋  | 242/313 [01:10<00:21,  3.30it/s]01/14/2022 16:22:35 - INFO - __main__ -   Batch number = 243
Evaluating:  78%|███████▊  | 243/313 [01:10<00:20,  3.34it/s]01/14/2022 16:22:36 - INFO - __main__ -   Batch number = 244
Evaluating:  78%|███████▊  | 244/313 [01:11<00:20,  3.38it/s]01/14/2022 16:22:36 - INFO - __main__ -   Batch number = 245
Evaluating:  78%|███████▊  | 245/313 [01:11<00:19,  3.40it/s]01/14/2022 16:22:36 - INFO - __main__ -   Batch number = 246
Evaluating:  79%|███████▊  | 246/313 [01:11<00:19,  3.41it/s]01/14/2022 16:22:36 - INFO - __main__ -   Batch number = 247
Evaluating:  79%|███████▉  | 247/313 [01:12<00:19,  3.39it/s]01/14/2022 16:22:37 - INFO - __main__ -   Batch number = 248
Evaluating:  79%|███████▉  | 248/313 [01:12<00:19,  3.40it/s]01/14/2022 16:22:37 - INFO - __main__ -   Batch number = 249
Evaluating:  80%|███████▉  | 249/313 [01:12<00:18,  3.40it/s]01/14/2022 16:22:37 - INFO - __main__ -   Batch number = 250
Evaluating:  80%|███████▉  | 250/313 [01:12<00:18,  3.41it/s]01/14/2022 16:22:38 - INFO - __main__ -   Batch number = 251
Evaluating:  80%|████████  | 251/313 [01:13<00:18,  3.42it/s]01/14/2022 16:22:38 - INFO - __main__ -   Batch number = 252
Evaluating:  81%|████████  | 252/313 [01:13<00:17,  3.42it/s]01/14/2022 16:22:38 - INFO - __main__ -   Batch number = 253
Evaluating:  81%|████████  | 253/313 [01:13<00:18,  3.21it/s]01/14/2022 16:22:39 - INFO - __main__ -   Batch number = 254
Evaluating:  81%|████████  | 254/313 [01:14<00:17,  3.28it/s]01/14/2022 16:22:39 - INFO - __main__ -   Batch number = 255
Evaluating:  81%|████████▏ | 255/313 [01:14<00:17,  3.34it/s]01/14/2022 16:22:39 - INFO - __main__ -   Batch number = 256
Evaluating:  82%|████████▏ | 256/313 [01:14<00:16,  3.38it/s]01/14/2022 16:22:39 - INFO - __main__ -   Batch number = 257
Evaluating:  82%|████████▏ | 257/313 [01:15<00:16,  3.38it/s]01/14/2022 16:22:40 - INFO - __main__ -   Batch number = 258
Evaluating:  82%|████████▏ | 258/313 [01:15<00:16,  3.37it/s]01/14/2022 16:22:40 - INFO - __main__ -   Batch number = 259
Evaluating:  83%|████████▎ | 259/313 [01:15<00:16,  3.37it/s]01/14/2022 16:22:40 - INFO - __main__ -   Batch number = 260
Evaluating:  83%|████████▎ | 260/313 [01:15<00:15,  3.37it/s]01/14/2022 16:22:41 - INFO - __main__ -   Batch number = 261
Evaluating:  83%|████████▎ | 261/313 [01:16<00:15,  3.37it/s]01/14/2022 16:22:41 - INFO - __main__ -   Batch number = 262
Evaluating:  84%|████████▎ | 262/313 [01:16<00:15,  3.37it/s]01/14/2022 16:22:41 - INFO - __main__ -   Batch number = 263
Evaluating:  84%|████████▍ | 263/313 [01:16<00:14,  3.37it/s]01/14/2022 16:22:41 - INFO - __main__ -   Batch number = 264
Evaluating:  84%|████████▍ | 264/313 [01:17<00:14,  3.37it/s]01/14/2022 16:22:42 - INFO - __main__ -   Batch number = 265
Evaluating:  85%|████████▍ | 265/313 [01:17<00:14,  3.38it/s]01/14/2022 16:22:42 - INFO - __main__ -   Batch number = 266
Evaluating:  85%|████████▍ | 266/313 [01:17<00:14,  3.35it/s]01/14/2022 16:22:42 - INFO - __main__ -   Batch number = 267
Evaluating:  85%|████████▌ | 267/313 [01:17<00:13,  3.32it/s]01/14/2022 16:22:43 - INFO - __main__ -   Batch number = 268
Evaluating:  86%|████████▌ | 268/313 [01:18<00:13,  3.28it/s]01/14/2022 16:22:43 - INFO - __main__ -   Batch number = 269
Evaluating:  86%|████████▌ | 269/313 [01:18<00:13,  3.27it/s]01/14/2022 16:22:43 - INFO - __main__ -   Batch number = 270
Evaluating:  86%|████████▋ | 270/313 [01:18<00:13,  3.26it/s]01/14/2022 16:22:44 - INFO - __main__ -   Batch number = 271
Evaluating:  87%|████████▋ | 271/313 [01:19<00:12,  3.26it/s]01/14/2022 16:22:44 - INFO - __main__ -   Batch number = 272
Evaluating:  87%|████████▋ | 272/313 [01:19<00:12,  3.26it/s]01/14/2022 16:22:44 - INFO - __main__ -   Batch number = 273
Evaluating:  87%|████████▋ | 273/313 [01:19<00:12,  3.29it/s]01/14/2022 16:22:45 - INFO - __main__ -   Batch number = 274
Evaluating:  88%|████████▊ | 274/313 [01:20<00:11,  3.29it/s]01/14/2022 16:22:45 - INFO - __main__ -   Batch number = 275
Evaluating:  88%|████████▊ | 275/313 [01:20<00:11,  3.27it/s]01/14/2022 16:22:45 - INFO - __main__ -   Batch number = 276
Evaluating:  88%|████████▊ | 276/313 [01:20<00:11,  3.24it/s]01/14/2022 16:22:45 - INFO - __main__ -   Batch number = 277
Evaluating:  88%|████████▊ | 277/313 [01:21<00:11,  3.24it/s]01/14/2022 16:22:46 - INFO - __main__ -   Batch number = 278
Evaluating:  89%|████████▉ | 278/313 [01:21<00:10,  3.26it/s]01/14/2022 16:22:46 - INFO - __main__ -   Batch number = 279
Evaluating:  89%|████████▉ | 279/313 [01:21<00:10,  3.29it/s]01/14/2022 16:22:46 - INFO - __main__ -   Batch number = 280
Evaluating:  89%|████████▉ | 280/313 [01:21<00:10,  3.27it/s]01/14/2022 16:22:47 - INFO - __main__ -   Batch number = 281
Evaluating:  90%|████████▉ | 281/313 [01:22<00:09,  3.24it/s]01/14/2022 16:22:47 - INFO - __main__ -   Batch number = 282
Evaluating:  90%|█████████ | 282/313 [01:22<00:09,  3.21it/s]01/14/2022 16:22:47 - INFO - __main__ -   Batch number = 283
Evaluating:  90%|█████████ | 283/313 [01:22<00:09,  3.22it/s]01/14/2022 16:22:48 - INFO - __main__ -   Batch number = 284
Evaluating:  91%|█████████ | 284/313 [01:23<00:08,  3.24it/s]01/14/2022 16:22:48 - INFO - __main__ -   Batch number = 285
Evaluating:  91%|█████████ | 285/313 [01:23<00:08,  3.27it/s]01/14/2022 16:22:48 - INFO - __main__ -   Batch number = 286
Evaluating:  91%|█████████▏| 286/313 [01:23<00:08,  3.29it/s]01/14/2022 16:22:49 - INFO - __main__ -   Batch number = 287
Evaluating:  92%|█████████▏| 287/313 [01:24<00:07,  3.32it/s]01/14/2022 16:22:49 - INFO - __main__ -   Batch number = 288
Evaluating:  92%|█████████▏| 288/313 [01:24<00:07,  3.34it/s]01/14/2022 16:22:49 - INFO - __main__ -   Batch number = 289
Evaluating:  92%|█████████▏| 289/313 [01:24<00:07,  3.35it/s]01/14/2022 16:22:49 - INFO - __main__ -   Batch number = 290
Evaluating:  93%|█████████▎| 290/313 [01:25<00:06,  3.37it/s]01/14/2022 16:22:50 - INFO - __main__ -   Batch number = 291
Evaluating:  93%|█████████▎| 291/313 [01:25<00:06,  3.37it/s]01/14/2022 16:22:50 - INFO - __main__ -   Batch number = 292
Evaluating:  93%|█████████▎| 292/313 [01:25<00:06,  3.37it/s]01/14/2022 16:22:50 - INFO - __main__ -   Batch number = 293
Evaluating:  94%|█████████▎| 293/313 [01:25<00:05,  3.36it/s]01/14/2022 16:22:51 - INFO - __main__ -   Batch number = 294
Evaluating:  94%|█████████▍| 294/313 [01:26<00:05,  3.37it/s]01/14/2022 16:22:51 - INFO - __main__ -   Batch number = 295
Evaluating:  94%|█████████▍| 295/313 [01:26<00:05,  3.35it/s]01/14/2022 16:22:51 - INFO - __main__ -   Batch number = 296
Evaluating:  95%|█████████▍| 296/313 [01:26<00:05,  3.31it/s]01/14/2022 16:22:52 - INFO - __main__ -   Batch number = 297
Evaluating:  95%|█████████▍| 297/313 [01:27<00:04,  3.26it/s]01/14/2022 16:22:52 - INFO - __main__ -   Batch number = 298
Evaluating:  95%|█████████▌| 298/313 [01:27<00:04,  3.23it/s]01/14/2022 16:22:52 - INFO - __main__ -   Batch number = 299
Evaluating:  96%|█████████▌| 299/313 [01:27<00:04,  3.22it/s]01/14/2022 16:22:52 - INFO - __main__ -   Batch number = 300
Evaluating:  96%|█████████▌| 300/313 [01:28<00:04,  3.23it/s]01/14/2022 16:22:53 - INFO - __main__ -   Batch number = 301
Evaluating:  96%|█████████▌| 301/313 [01:28<00:03,  3.25it/s]01/14/2022 16:22:53 - INFO - __main__ -   Batch number = 302
Evaluating:  96%|█████████▋| 302/313 [01:28<00:03,  3.28it/s]01/14/2022 16:22:53 - INFO - __main__ -   Batch number = 303
Evaluating:  97%|█████████▋| 303/313 [01:28<00:03,  3.31it/s]01/14/2022 16:22:54 - INFO - __main__ -   Batch number = 304
Evaluating:  97%|█████████▋| 304/313 [01:29<00:02,  3.34it/s]01/14/2022 16:22:54 - INFO - __main__ -   Batch number = 305
Evaluating:  97%|█████████▋| 305/313 [01:29<00:02,  3.33it/s]01/14/2022 16:22:54 - INFO - __main__ -   Batch number = 306
Evaluating:  98%|█████████▊| 306/313 [01:29<00:02,  3.32it/s]01/14/2022 16:22:55 - INFO - __main__ -   Batch number = 307
Evaluating:  98%|█████████▊| 307/313 [01:30<00:01,  3.32it/s]01/14/2022 16:22:55 - INFO - __main__ -   Batch number = 308
Evaluating:  98%|█████████▊| 308/313 [01:30<00:01,  3.32it/s]01/14/2022 16:22:55 - INFO - __main__ -   Batch number = 309
Evaluating:  99%|█████████▊| 309/313 [01:30<00:01,  3.33it/s]01/14/2022 16:22:55 - INFO - __main__ -   Batch number = 310
Evaluating:  99%|█████████▉| 310/313 [01:31<00:00,  3.34it/s]01/14/2022 16:22:56 - INFO - __main__ -   Batch number = 311
Evaluating:  99%|█████████▉| 311/313 [01:31<00:00,  3.34it/s]01/14/2022 16:22:56 - INFO - __main__ -   Batch number = 312
Evaluating: 100%|█████████▉| 312/313 [01:31<00:00,  3.35it/s]01/14/2022 16:22:56 - INFO - __main__ -   Batch number = 313
Evaluating: 100%|██████████| 313/313 [01:31<00:00,  3.87it/s]Evaluating: 100%|██████████| 313/313 [01:31<00:00,  3.41it/s]
01/14/2022 16:22:58 - INFO - __main__ -   ***** Evaluation result  in ar *****
01/14/2022 16:22:58 - INFO - __main__ -     f1 = 0.333161909659724
01/14/2022 16:22:58 - INFO - __main__ -     loss = 5.3353420271279335
01/14/2022 16:22:58 - INFO - __main__ -     precision = 0.3219047619047619
01/14/2022 16:22:58 - INFO - __main__ -     recall = 0.34523492317257304
101.53user 38.60system 2:09.30elapsed 108%CPU (0avgtext+0avgdata 4229096maxresident)k
0inputs+856outputs (0major+2504624minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:23:00 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:23:00 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:23:00 - INFO - __main__ -   Seed = 2
01/14/2022 16:23:00 - INFO - root -   save model
01/14/2022 16:23:00 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:23:00 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:23:03 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:23:08 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:23:08 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:23:08 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:23:08 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:23:08 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:23:08 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,ar/wiki@ukp
01/14/2022 16:23:08 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'ar'], Length : 10
01/14/2022 16:23:08 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'ar/wiki@ukp'], Length : 10
01/14/2022 16:23:08 - INFO - __main__ -   Language = en
01/14/2022 16:23:08 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:23:09 - INFO - __main__ -   Language = pt
01/14/2022 16:23:09 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:23:11 - INFO - __main__ -   Language = id
01/14/2022 16:23:11 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:23:12 - INFO - __main__ -   Language = tr
01/14/2022 16:23:12 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:23:14 - INFO - __main__ -   Language = cs
01/14/2022 16:23:14 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:23:15 - INFO - __main__ -   Language = vi
01/14/2022 16:23:15 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:23:17 - INFO - __main__ -   Language = eu
01/14/2022 16:23:17 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:23:19 - INFO - __main__ -   Language = fa
01/14/2022 16:23:19 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:23:20 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:23:20 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:23:22 - INFO - __main__ -   Language = ar
01/14/2022 16:23:22 - INFO - __main__ -   Adapter Name = ar/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ar/bert-base-multilingual-cased/pfeiffer/ar_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted/adapter_config.json
Adding adapter 'ar' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted'
01/14/2022 16:23:26 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:23:26 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'ar']
01/14/2022 16:23:26 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:23:26 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:23:26 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:23:26 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
01/14/2022 16:23:27 - INFO - __main__ -   ***** Running evaluation  in ar *****
01/14/2022 16:23:27 - INFO - __main__ -     Num examples = 10000
01/14/2022 16:23:27 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]01/14/2022 16:23:27 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/313 [00:00<01:34,  3.31it/s]01/14/2022 16:23:27 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/313 [00:00<01:29,  3.46it/s]01/14/2022 16:23:28 - INFO - __main__ -   Batch number = 3
Evaluating:   1%|          | 3/313 [00:01<01:50,  2.80it/s]01/14/2022 16:23:28 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|▏         | 4/313 [00:01<01:40,  3.07it/s]01/14/2022 16:23:28 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/313 [00:01<01:34,  3.25it/s]01/14/2022 16:23:29 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/313 [00:01<01:31,  3.36it/s]01/14/2022 16:23:29 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/313 [00:02<01:28,  3.44it/s]01/14/2022 16:23:29 - INFO - __main__ -   Batch number = 8
Evaluating:   3%|▎         | 8/313 [00:02<01:27,  3.50it/s]01/14/2022 16:23:29 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/313 [00:02<01:26,  3.53it/s]01/14/2022 16:23:30 - INFO - __main__ -   Batch number = 10
Evaluating:   3%|▎         | 10/313 [00:02<01:25,  3.55it/s]01/14/2022 16:23:30 - INFO - __main__ -   Batch number = 11
Evaluating:   4%|▎         | 11/313 [00:03<01:24,  3.56it/s]01/14/2022 16:23:30 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▍         | 12/313 [00:03<01:24,  3.57it/s]01/14/2022 16:23:31 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/313 [00:03<01:24,  3.56it/s]01/14/2022 16:23:31 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/313 [00:04<01:23,  3.58it/s]01/14/2022 16:23:31 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/313 [00:04<01:23,  3.58it/s]01/14/2022 16:23:31 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▌         | 16/313 [00:04<01:22,  3.58it/s]01/14/2022 16:23:32 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/313 [00:04<01:22,  3.59it/s]01/14/2022 16:23:32 - INFO - __main__ -   Batch number = 18
Evaluating:   6%|▌         | 18/313 [00:05<01:22,  3.59it/s]01/14/2022 16:23:32 - INFO - __main__ -   Batch number = 19
Evaluating:   6%|▌         | 19/313 [00:05<01:21,  3.59it/s]01/14/2022 16:23:33 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▋         | 20/313 [00:05<01:21,  3.59it/s]01/14/2022 16:23:33 - INFO - __main__ -   Batch number = 21
Evaluating:   7%|▋         | 21/313 [00:06<01:21,  3.58it/s]01/14/2022 16:23:33 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/313 [00:06<01:21,  3.57it/s]01/14/2022 16:23:33 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/313 [00:06<01:21,  3.57it/s]01/14/2022 16:23:34 - INFO - __main__ -   Batch number = 24
Evaluating:   8%|▊         | 24/313 [00:06<01:20,  3.57it/s]01/14/2022 16:23:34 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/313 [00:07<01:20,  3.57it/s]01/14/2022 16:23:34 - INFO - __main__ -   Batch number = 26
Evaluating:   8%|▊         | 26/313 [00:07<01:20,  3.57it/s]01/14/2022 16:23:35 - INFO - __main__ -   Batch number = 27
Evaluating:   9%|▊         | 27/313 [00:07<01:20,  3.57it/s]01/14/2022 16:23:35 - INFO - __main__ -   Batch number = 28
Evaluating:   9%|▉         | 28/313 [00:07<01:19,  3.57it/s]01/14/2022 16:23:35 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▉         | 29/313 [00:08<01:19,  3.57it/s]01/14/2022 16:23:35 - INFO - __main__ -   Batch number = 30
Evaluating:  10%|▉         | 30/313 [00:08<01:19,  3.57it/s]01/14/2022 16:23:36 - INFO - __main__ -   Batch number = 31
Evaluating:  10%|▉         | 31/313 [00:08<01:19,  3.56it/s]01/14/2022 16:23:36 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|█         | 32/313 [00:09<01:18,  3.57it/s]01/14/2022 16:23:36 - INFO - __main__ -   Batch number = 33
Evaluating:  11%|█         | 33/313 [00:09<01:18,  3.57it/s]01/14/2022 16:23:36 - INFO - __main__ -   Batch number = 34
Evaluating:  11%|█         | 34/313 [00:09<01:18,  3.58it/s]01/14/2022 16:23:37 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/313 [00:09<01:17,  3.58it/s]01/14/2022 16:23:37 - INFO - __main__ -   Batch number = 36
Evaluating:  12%|█▏        | 36/313 [00:10<01:17,  3.58it/s]01/14/2022 16:23:37 - INFO - __main__ -   Batch number = 37
Evaluating:  12%|█▏        | 37/313 [00:10<01:17,  3.58it/s]01/14/2022 16:23:38 - INFO - __main__ -   Batch number = 38
Evaluating:  12%|█▏        | 38/313 [00:10<01:16,  3.58it/s]01/14/2022 16:23:38 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/313 [00:11<01:21,  3.38it/s]01/14/2022 16:23:38 - INFO - __main__ -   Batch number = 40
Evaluating:  13%|█▎        | 40/313 [00:11<01:19,  3.43it/s]01/14/2022 16:23:38 - INFO - __main__ -   Batch number = 41
Evaluating:  13%|█▎        | 41/313 [00:11<01:18,  3.47it/s]01/14/2022 16:23:39 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/313 [00:11<01:17,  3.50it/s]01/14/2022 16:23:39 - INFO - __main__ -   Batch number = 43
Evaluating:  14%|█▎        | 43/313 [00:12<01:16,  3.52it/s]01/14/2022 16:23:39 - INFO - __main__ -   Batch number = 44
Evaluating:  14%|█▍        | 44/313 [00:12<01:16,  3.53it/s]01/14/2022 16:23:40 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▍        | 45/313 [00:12<01:15,  3.54it/s]01/14/2022 16:23:40 - INFO - __main__ -   Batch number = 46
Evaluating:  15%|█▍        | 46/313 [00:13<01:15,  3.55it/s]01/14/2022 16:23:40 - INFO - __main__ -   Batch number = 47
Evaluating:  15%|█▌        | 47/313 [00:13<01:14,  3.55it/s]01/14/2022 16:23:40 - INFO - __main__ -   Batch number = 48
Evaluating:  15%|█▌        | 48/313 [00:13<01:14,  3.55it/s]01/14/2022 16:23:41 - INFO - __main__ -   Batch number = 49
Evaluating:  16%|█▌        | 49/313 [00:13<01:14,  3.55it/s]01/14/2022 16:23:41 - INFO - __main__ -   Batch number = 50
Evaluating:  16%|█▌        | 50/313 [00:14<01:14,  3.55it/s]01/14/2022 16:23:41 - INFO - __main__ -   Batch number = 51
Evaluating:  16%|█▋        | 51/313 [00:14<01:13,  3.56it/s]01/14/2022 16:23:42 - INFO - __main__ -   Batch number = 52
Evaluating:  17%|█▋        | 52/313 [00:14<01:13,  3.56it/s]01/14/2022 16:23:42 - INFO - __main__ -   Batch number = 53
Evaluating:  17%|█▋        | 53/313 [00:15<01:12,  3.56it/s]01/14/2022 16:23:42 - INFO - __main__ -   Batch number = 54
Evaluating:  17%|█▋        | 54/313 [00:15<01:12,  3.55it/s]01/14/2022 16:23:42 - INFO - __main__ -   Batch number = 55
Evaluating:  18%|█▊        | 55/313 [00:15<01:12,  3.56it/s]01/14/2022 16:23:43 - INFO - __main__ -   Batch number = 56
Evaluating:  18%|█▊        | 56/313 [00:15<01:12,  3.55it/s]01/14/2022 16:23:43 - INFO - __main__ -   Batch number = 57
Evaluating:  18%|█▊        | 57/313 [00:16<01:18,  3.27it/s]01/14/2022 16:23:43 - INFO - __main__ -   Batch number = 58
Evaluating:  19%|█▊        | 58/313 [00:16<01:16,  3.35it/s]01/14/2022 16:23:44 - INFO - __main__ -   Batch number = 59
Evaluating:  19%|█▉        | 59/313 [00:16<01:14,  3.41it/s]01/14/2022 16:23:44 - INFO - __main__ -   Batch number = 60
Evaluating:  19%|█▉        | 60/313 [00:17<01:13,  3.45it/s]01/14/2022 16:23:44 - INFO - __main__ -   Batch number = 61
Evaluating:  19%|█▉        | 61/313 [00:17<01:12,  3.48it/s]01/14/2022 16:23:44 - INFO - __main__ -   Batch number = 62
Evaluating:  20%|█▉        | 62/313 [00:17<01:11,  3.50it/s]01/14/2022 16:23:45 - INFO - __main__ -   Batch number = 63
Evaluating:  20%|██        | 63/313 [00:17<01:11,  3.48it/s]01/14/2022 16:23:45 - INFO - __main__ -   Batch number = 64
Evaluating:  20%|██        | 64/313 [00:18<01:11,  3.48it/s]01/14/2022 16:23:45 - INFO - __main__ -   Batch number = 65
Evaluating:  21%|██        | 65/313 [00:18<01:10,  3.50it/s]01/14/2022 16:23:46 - INFO - __main__ -   Batch number = 66
Evaluating:  21%|██        | 66/313 [00:18<01:10,  3.50it/s]01/14/2022 16:23:46 - INFO - __main__ -   Batch number = 67
Evaluating:  21%|██▏       | 67/313 [00:19<01:10,  3.50it/s]01/14/2022 16:23:46 - INFO - __main__ -   Batch number = 68
Evaluating:  22%|██▏       | 68/313 [00:19<01:10,  3.49it/s]01/14/2022 16:23:46 - INFO - __main__ -   Batch number = 69
Evaluating:  22%|██▏       | 69/313 [00:19<01:09,  3.49it/s]01/14/2022 16:23:47 - INFO - __main__ -   Batch number = 70
Evaluating:  22%|██▏       | 70/313 [00:19<01:09,  3.51it/s]01/14/2022 16:23:47 - INFO - __main__ -   Batch number = 71
Evaluating:  23%|██▎       | 71/313 [00:20<01:08,  3.51it/s]01/14/2022 16:23:47 - INFO - __main__ -   Batch number = 72
Evaluating:  23%|██▎       | 72/313 [00:20<01:08,  3.52it/s]01/14/2022 16:23:48 - INFO - __main__ -   Batch number = 73
Evaluating:  23%|██▎       | 73/313 [00:20<01:08,  3.51it/s]01/14/2022 16:23:48 - INFO - __main__ -   Batch number = 74
Evaluating:  24%|██▎       | 74/313 [00:21<01:08,  3.50it/s]01/14/2022 16:23:48 - INFO - __main__ -   Batch number = 75
Evaluating:  24%|██▍       | 75/313 [00:21<01:13,  3.25it/s]01/14/2022 16:23:49 - INFO - __main__ -   Batch number = 76
Evaluating:  24%|██▍       | 76/313 [00:21<01:13,  3.23it/s]01/14/2022 16:23:49 - INFO - __main__ -   Batch number = 77
Evaluating:  25%|██▍       | 77/313 [00:22<01:13,  3.23it/s]01/14/2022 16:23:49 - INFO - __main__ -   Batch number = 78
Evaluating:  25%|██▍       | 78/313 [00:22<01:12,  3.23it/s]01/14/2022 16:23:49 - INFO - __main__ -   Batch number = 79
Evaluating:  25%|██▌       | 79/313 [00:22<01:12,  3.23it/s]01/14/2022 16:23:50 - INFO - __main__ -   Batch number = 80
Evaluating:  26%|██▌       | 80/313 [00:23<01:11,  3.25it/s]01/14/2022 16:23:50 - INFO - __main__ -   Batch number = 81
Evaluating:  26%|██▌       | 81/313 [00:23<01:10,  3.29it/s]01/14/2022 16:23:50 - INFO - __main__ -   Batch number = 82
Evaluating:  26%|██▌       | 82/313 [00:23<01:09,  3.33it/s]01/14/2022 16:23:51 - INFO - __main__ -   Batch number = 83
Evaluating:  27%|██▋       | 83/313 [00:23<01:08,  3.36it/s]01/14/2022 16:23:51 - INFO - __main__ -   Batch number = 84
Evaluating:  27%|██▋       | 84/313 [00:24<01:08,  3.35it/s]01/14/2022 16:23:51 - INFO - __main__ -   Batch number = 85
Evaluating:  27%|██▋       | 85/313 [00:24<01:08,  3.34it/s]01/14/2022 16:23:52 - INFO - __main__ -   Batch number = 86
Evaluating:  27%|██▋       | 86/313 [00:24<01:07,  3.34it/s]01/14/2022 16:23:52 - INFO - __main__ -   Batch number = 87
Evaluating:  28%|██▊       | 87/313 [00:25<01:07,  3.36it/s]01/14/2022 16:23:52 - INFO - __main__ -   Batch number = 88
Evaluating:  28%|██▊       | 88/313 [00:25<01:06,  3.37it/s]01/14/2022 16:23:52 - INFO - __main__ -   Batch number = 89
Evaluating:  28%|██▊       | 89/313 [00:25<01:05,  3.39it/s]01/14/2022 16:23:53 - INFO - __main__ -   Batch number = 90
Evaluating:  29%|██▉       | 90/313 [00:25<01:05,  3.42it/s]01/14/2022 16:23:53 - INFO - __main__ -   Batch number = 91
Evaluating:  29%|██▉       | 91/313 [00:26<01:04,  3.43it/s]01/14/2022 16:23:53 - INFO - __main__ -   Batch number = 92
Evaluating:  29%|██▉       | 92/313 [00:26<01:20,  2.76it/s]01/14/2022 16:23:54 - INFO - __main__ -   Batch number = 93
Evaluating:  30%|██▉       | 93/313 [00:27<01:16,  2.89it/s]01/14/2022 16:23:54 - INFO - __main__ -   Batch number = 94
Evaluating:  30%|███       | 94/313 [00:27<01:13,  2.99it/s]01/14/2022 16:23:54 - INFO - __main__ -   Batch number = 95
Evaluating:  30%|███       | 95/313 [00:27<01:10,  3.08it/s]01/14/2022 16:23:55 - INFO - __main__ -   Batch number = 96
Evaluating:  31%|███       | 96/313 [00:27<01:09,  3.14it/s]01/14/2022 16:23:55 - INFO - __main__ -   Batch number = 97
Evaluating:  31%|███       | 97/313 [00:28<01:07,  3.18it/s]01/14/2022 16:23:55 - INFO - __main__ -   Batch number = 98
Evaluating:  31%|███▏      | 98/313 [00:28<01:06,  3.21it/s]01/14/2022 16:23:56 - INFO - __main__ -   Batch number = 99
Evaluating:  32%|███▏      | 99/313 [00:28<01:06,  3.22it/s]01/14/2022 16:23:56 - INFO - __main__ -   Batch number = 100
Evaluating:  32%|███▏      | 100/313 [00:29<01:05,  3.24it/s]01/14/2022 16:23:56 - INFO - __main__ -   Batch number = 101
Evaluating:  32%|███▏      | 101/313 [00:29<01:05,  3.24it/s]01/14/2022 16:23:57 - INFO - __main__ -   Batch number = 102
Evaluating:  33%|███▎      | 102/313 [00:29<01:04,  3.25it/s]01/14/2022 16:23:57 - INFO - __main__ -   Batch number = 103
Evaluating:  33%|███▎      | 103/313 [00:30<01:04,  3.25it/s]01/14/2022 16:23:57 - INFO - __main__ -   Batch number = 104
Evaluating:  33%|███▎      | 104/313 [00:30<01:04,  3.25it/s]01/14/2022 16:23:58 - INFO - __main__ -   Batch number = 105
Evaluating:  34%|███▎      | 105/313 [00:30<01:04,  3.25it/s]01/14/2022 16:23:58 - INFO - __main__ -   Batch number = 106
Evaluating:  34%|███▍      | 106/313 [00:31<01:03,  3.25it/s]01/14/2022 16:23:58 - INFO - __main__ -   Batch number = 107
Evaluating:  34%|███▍      | 107/313 [00:31<01:03,  3.25it/s]01/14/2022 16:23:58 - INFO - __main__ -   Batch number = 108
Evaluating:  35%|███▍      | 108/313 [00:31<01:08,  3.00it/s]01/14/2022 16:23:59 - INFO - __main__ -   Batch number = 109
Evaluating:  35%|███▍      | 109/313 [00:32<01:05,  3.09it/s]01/14/2022 16:23:59 - INFO - __main__ -   Batch number = 110
Evaluating:  35%|███▌      | 110/313 [00:32<01:04,  3.16it/s]01/14/2022 16:23:59 - INFO - __main__ -   Batch number = 111
Evaluating:  35%|███▌      | 111/313 [00:32<01:02,  3.23it/s]01/14/2022 16:24:00 - INFO - __main__ -   Batch number = 112
Evaluating:  36%|███▌      | 112/313 [00:32<01:01,  3.27it/s]01/14/2022 16:24:00 - INFO - __main__ -   Batch number = 113
Evaluating:  36%|███▌      | 113/313 [00:33<01:00,  3.31it/s]01/14/2022 16:24:00 - INFO - __main__ -   Batch number = 114
Evaluating:  36%|███▋      | 114/313 [00:33<00:59,  3.34it/s]01/14/2022 16:24:01 - INFO - __main__ -   Batch number = 115
Evaluating:  37%|███▋      | 115/313 [00:33<00:59,  3.35it/s]01/14/2022 16:24:01 - INFO - __main__ -   Batch number = 116
Evaluating:  37%|███▋      | 116/313 [00:34<00:58,  3.34it/s]01/14/2022 16:24:01 - INFO - __main__ -   Batch number = 117
Evaluating:  37%|███▋      | 117/313 [00:34<00:58,  3.32it/s]01/14/2022 16:24:02 - INFO - __main__ -   Batch number = 118
Evaluating:  38%|███▊      | 118/313 [00:34<00:58,  3.31it/s]01/14/2022 16:24:02 - INFO - __main__ -   Batch number = 119
Evaluating:  38%|███▊      | 119/313 [00:35<00:58,  3.30it/s]01/14/2022 16:24:02 - INFO - __main__ -   Batch number = 120
Evaluating:  38%|███▊      | 120/313 [00:35<00:58,  3.28it/s]01/14/2022 16:24:02 - INFO - __main__ -   Batch number = 121
Evaluating:  39%|███▊      | 121/313 [00:35<00:58,  3.28it/s]01/14/2022 16:24:03 - INFO - __main__ -   Batch number = 122
Evaluating:  39%|███▉      | 122/313 [00:35<00:57,  3.32it/s]01/14/2022 16:24:03 - INFO - __main__ -   Batch number = 123
Evaluating:  39%|███▉      | 123/313 [00:36<00:56,  3.34it/s]01/14/2022 16:24:03 - INFO - __main__ -   Batch number = 124
Evaluating:  40%|███▉      | 124/313 [00:36<00:56,  3.37it/s]01/14/2022 16:24:04 - INFO - __main__ -   Batch number = 125
Evaluating:  40%|███▉      | 125/313 [00:36<00:55,  3.40it/s]01/14/2022 16:24:04 - INFO - __main__ -   Batch number = 126
Evaluating:  40%|████      | 126/313 [00:37<00:54,  3.42it/s]01/14/2022 16:24:04 - INFO - __main__ -   Batch number = 127
Evaluating:  41%|████      | 127/313 [00:37<00:54,  3.41it/s]01/14/2022 16:24:04 - INFO - __main__ -   Batch number = 128
Evaluating:  41%|████      | 128/313 [00:37<00:54,  3.39it/s]01/14/2022 16:24:05 - INFO - __main__ -   Batch number = 129
Evaluating:  41%|████      | 129/313 [00:38<00:54,  3.39it/s]01/14/2022 16:24:05 - INFO - __main__ -   Batch number = 130
Evaluating:  42%|████▏     | 130/313 [00:38<00:53,  3.39it/s]01/14/2022 16:24:05 - INFO - __main__ -   Batch number = 131
Evaluating:  42%|████▏     | 131/313 [00:38<00:53,  3.40it/s]01/14/2022 16:24:06 - INFO - __main__ -   Batch number = 132
Evaluating:  42%|████▏     | 132/313 [00:38<00:52,  3.42it/s]01/14/2022 16:24:06 - INFO - __main__ -   Batch number = 133
Evaluating:  42%|████▏     | 133/313 [00:39<00:52,  3.43it/s]01/14/2022 16:24:06 - INFO - __main__ -   Batch number = 134
Evaluating:  43%|████▎     | 134/313 [00:39<00:52,  3.42it/s]01/14/2022 16:24:07 - INFO - __main__ -   Batch number = 135
Evaluating:  43%|████▎     | 135/313 [00:39<00:52,  3.41it/s]01/14/2022 16:24:07 - INFO - __main__ -   Batch number = 136
Evaluating:  43%|████▎     | 136/313 [00:40<00:52,  3.39it/s]01/14/2022 16:24:07 - INFO - __main__ -   Batch number = 137
Evaluating:  44%|████▍     | 137/313 [00:40<00:52,  3.36it/s]01/14/2022 16:24:07 - INFO - __main__ -   Batch number = 138
Evaluating:  44%|████▍     | 138/313 [00:40<00:52,  3.35it/s]01/14/2022 16:24:08 - INFO - __main__ -   Batch number = 139
Evaluating:  44%|████▍     | 139/313 [00:40<00:52,  3.34it/s]01/14/2022 16:24:08 - INFO - __main__ -   Batch number = 140
Evaluating:  45%|████▍     | 140/313 [00:41<00:51,  3.33it/s]01/14/2022 16:24:08 - INFO - __main__ -   Batch number = 141
Evaluating:  45%|████▌     | 141/313 [00:41<00:51,  3.34it/s]01/14/2022 16:24:09 - INFO - __main__ -   Batch number = 142
Evaluating:  45%|████▌     | 142/313 [00:41<00:50,  3.36it/s]01/14/2022 16:24:09 - INFO - __main__ -   Batch number = 143
Evaluating:  46%|████▌     | 143/313 [00:42<00:50,  3.36it/s]01/14/2022 16:24:09 - INFO - __main__ -   Batch number = 144
Evaluating:  46%|████▌     | 144/313 [00:42<00:50,  3.35it/s]01/14/2022 16:24:10 - INFO - __main__ -   Batch number = 145
Evaluating:  46%|████▋     | 145/313 [00:42<00:50,  3.32it/s]01/14/2022 16:24:10 - INFO - __main__ -   Batch number = 146
Evaluating:  47%|████▋     | 146/313 [00:43<00:50,  3.30it/s]01/14/2022 16:24:10 - INFO - __main__ -   Batch number = 147
Evaluating:  47%|████▋     | 147/313 [00:43<00:50,  3.29it/s]01/14/2022 16:24:10 - INFO - __main__ -   Batch number = 148
Evaluating:  47%|████▋     | 148/313 [00:43<00:50,  3.29it/s]01/14/2022 16:24:11 - INFO - __main__ -   Batch number = 149
Evaluating:  48%|████▊     | 149/313 [00:43<00:49,  3.30it/s]01/14/2022 16:24:11 - INFO - __main__ -   Batch number = 150
Evaluating:  48%|████▊     | 150/313 [00:44<00:49,  3.30it/s]01/14/2022 16:24:11 - INFO - __main__ -   Batch number = 151
Evaluating:  48%|████▊     | 151/313 [00:44<00:49,  3.29it/s]01/14/2022 16:24:12 - INFO - __main__ -   Batch number = 152
Evaluating:  49%|████▊     | 152/313 [00:44<00:49,  3.27it/s]01/14/2022 16:24:12 - INFO - __main__ -   Batch number = 153
Evaluating:  49%|████▉     | 153/313 [00:45<00:49,  3.26it/s]01/14/2022 16:24:12 - INFO - __main__ -   Batch number = 154
Evaluating:  49%|████▉     | 154/313 [00:45<00:48,  3.25it/s]01/14/2022 16:24:13 - INFO - __main__ -   Batch number = 155
Evaluating:  50%|████▉     | 155/313 [00:45<00:48,  3.24it/s]01/14/2022 16:24:13 - INFO - __main__ -   Batch number = 156
Evaluating:  50%|████▉     | 156/313 [00:46<00:48,  3.24it/s]01/14/2022 16:24:13 - INFO - __main__ -   Batch number = 157
Evaluating:  50%|█████     | 157/313 [00:46<00:48,  3.23it/s]01/14/2022 16:24:14 - INFO - __main__ -   Batch number = 158
Evaluating:  50%|█████     | 158/313 [00:46<00:47,  3.24it/s]01/14/2022 16:24:14 - INFO - __main__ -   Batch number = 159
Evaluating:  51%|█████     | 159/313 [00:47<00:47,  3.27it/s]01/14/2022 16:24:14 - INFO - __main__ -   Batch number = 160
Evaluating:  51%|█████     | 160/313 [00:47<00:46,  3.31it/s]01/14/2022 16:24:14 - INFO - __main__ -   Batch number = 161
Evaluating:  51%|█████▏    | 161/313 [00:47<00:45,  3.31it/s]01/14/2022 16:24:15 - INFO - __main__ -   Batch number = 162
Evaluating:  52%|█████▏    | 162/313 [00:47<00:45,  3.29it/s]01/14/2022 16:24:15 - INFO - __main__ -   Batch number = 163
Evaluating:  52%|█████▏    | 163/313 [00:48<00:46,  3.26it/s]01/14/2022 16:24:15 - INFO - __main__ -   Batch number = 164
Evaluating:  52%|█████▏    | 164/313 [00:48<00:45,  3.27it/s]01/14/2022 16:24:16 - INFO - __main__ -   Batch number = 165
Evaluating:  53%|█████▎    | 165/313 [00:48<00:45,  3.26it/s]01/14/2022 16:24:16 - INFO - __main__ -   Batch number = 166
Evaluating:  53%|█████▎    | 166/313 [00:49<00:45,  3.25it/s]01/14/2022 16:24:16 - INFO - __main__ -   Batch number = 167
Evaluating:  53%|█████▎    | 167/313 [00:49<00:45,  3.24it/s]01/14/2022 16:24:17 - INFO - __main__ -   Batch number = 168
Evaluating:  54%|█████▎    | 168/313 [00:49<00:44,  3.24it/s]01/14/2022 16:24:17 - INFO - __main__ -   Batch number = 169
Evaluating:  54%|█████▍    | 169/313 [00:50<00:44,  3.23it/s]01/14/2022 16:24:17 - INFO - __main__ -   Batch number = 170
Evaluating:  54%|█████▍    | 170/313 [00:50<00:44,  3.23it/s]01/14/2022 16:24:18 - INFO - __main__ -   Batch number = 171
Evaluating:  55%|█████▍    | 171/313 [00:50<00:43,  3.23it/s]01/14/2022 16:24:18 - INFO - __main__ -   Batch number = 172
Evaluating:  55%|█████▍    | 172/313 [00:51<00:43,  3.23it/s]01/14/2022 16:24:18 - INFO - __main__ -   Batch number = 173
Evaluating:  55%|█████▌    | 173/313 [00:51<00:43,  3.24it/s]01/14/2022 16:24:18 - INFO - __main__ -   Batch number = 174
Evaluating:  56%|█████▌    | 174/313 [00:51<00:42,  3.27it/s]01/14/2022 16:24:19 - INFO - __main__ -   Batch number = 175
Evaluating:  56%|█████▌    | 175/313 [00:51<00:41,  3.30it/s]01/14/2022 16:24:19 - INFO - __main__ -   Batch number = 176
Evaluating:  56%|█████▌    | 176/313 [00:52<00:41,  3.32it/s]01/14/2022 16:24:19 - INFO - __main__ -   Batch number = 177
Evaluating:  57%|█████▋    | 177/313 [00:52<00:40,  3.34it/s]01/14/2022 16:24:20 - INFO - __main__ -   Batch number = 178
Evaluating:  57%|█████▋    | 178/313 [00:52<00:40,  3.35it/s]01/14/2022 16:24:20 - INFO - __main__ -   Batch number = 179
Evaluating:  57%|█████▋    | 179/313 [00:53<00:40,  3.34it/s]01/14/2022 16:24:20 - INFO - __main__ -   Batch number = 180
Evaluating:  58%|█████▊    | 180/313 [00:53<00:39,  3.35it/s]01/14/2022 16:24:21 - INFO - __main__ -   Batch number = 181
Evaluating:  58%|█████▊    | 181/313 [00:53<00:39,  3.35it/s]01/14/2022 16:24:21 - INFO - __main__ -   Batch number = 182
Evaluating:  58%|█████▊    | 182/313 [00:54<00:38,  3.36it/s]01/14/2022 16:24:21 - INFO - __main__ -   Batch number = 183
Evaluating:  58%|█████▊    | 183/313 [00:54<00:38,  3.37it/s]01/14/2022 16:24:21 - INFO - __main__ -   Batch number = 184
Evaluating:  59%|█████▉    | 184/313 [00:54<00:38,  3.34it/s]01/14/2022 16:24:22 - INFO - __main__ -   Batch number = 185
Evaluating:  59%|█████▉    | 185/313 [00:54<00:38,  3.33it/s]01/14/2022 16:24:22 - INFO - __main__ -   Batch number = 186
Evaluating:  59%|█████▉    | 186/313 [00:55<00:38,  3.33it/s]01/14/2022 16:24:22 - INFO - __main__ -   Batch number = 187
Evaluating:  60%|█████▉    | 187/313 [00:55<00:37,  3.32it/s]01/14/2022 16:24:23 - INFO - __main__ -   Batch number = 188
Evaluating:  60%|██████    | 188/313 [00:55<00:37,  3.30it/s]01/14/2022 16:24:23 - INFO - __main__ -   Batch number = 189
Evaluating:  60%|██████    | 189/313 [00:56<00:37,  3.29it/s]01/14/2022 16:24:23 - INFO - __main__ -   Batch number = 190
Evaluating:  61%|██████    | 190/313 [00:56<00:39,  3.14it/s]01/14/2022 16:24:24 - INFO - __main__ -   Batch number = 191
Evaluating:  61%|██████    | 191/313 [00:56<00:38,  3.18it/s]01/14/2022 16:24:24 - INFO - __main__ -   Batch number = 192
Evaluating:  61%|██████▏   | 192/313 [00:57<00:37,  3.21it/s]01/14/2022 16:24:24 - INFO - __main__ -   Batch number = 193
Evaluating:  62%|██████▏   | 193/313 [00:57<00:37,  3.23it/s]01/14/2022 16:24:25 - INFO - __main__ -   Batch number = 194
Evaluating:  62%|██████▏   | 194/313 [00:57<00:36,  3.24it/s]01/14/2022 16:24:25 - INFO - __main__ -   Batch number = 195
Evaluating:  62%|██████▏   | 195/313 [00:58<00:36,  3.27it/s]01/14/2022 16:24:25 - INFO - __main__ -   Batch number = 196
Evaluating:  63%|██████▎   | 196/313 [00:58<00:35,  3.29it/s]01/14/2022 16:24:25 - INFO - __main__ -   Batch number = 197
Evaluating:  63%|██████▎   | 197/313 [00:58<00:35,  3.29it/s]01/14/2022 16:24:26 - INFO - __main__ -   Batch number = 198
Evaluating:  63%|██████▎   | 198/313 [00:58<00:34,  3.30it/s]01/14/2022 16:24:26 - INFO - __main__ -   Batch number = 199
Evaluating:  64%|██████▎   | 199/313 [00:59<00:34,  3.34it/s]01/14/2022 16:24:26 - INFO - __main__ -   Batch number = 200
Evaluating:  64%|██████▍   | 200/313 [00:59<00:33,  3.35it/s]01/14/2022 16:24:27 - INFO - __main__ -   Batch number = 201
Evaluating:  64%|██████▍   | 201/313 [00:59<00:33,  3.32it/s]01/14/2022 16:24:27 - INFO - __main__ -   Batch number = 202
Evaluating:  65%|██████▍   | 202/313 [01:00<00:33,  3.31it/s]01/14/2022 16:24:27 - INFO - __main__ -   Batch number = 203
Evaluating:  65%|██████▍   | 203/313 [01:00<00:33,  3.31it/s]01/14/2022 16:24:28 - INFO - __main__ -   Batch number = 204
Evaluating:  65%|██████▌   | 204/313 [01:00<00:32,  3.32it/s]01/14/2022 16:24:28 - INFO - __main__ -   Batch number = 205
Evaluating:  65%|██████▌   | 205/313 [01:01<00:32,  3.32it/s]01/14/2022 16:24:28 - INFO - __main__ -   Batch number = 206
Evaluating:  66%|██████▌   | 206/313 [01:01<00:32,  3.33it/s]01/14/2022 16:24:28 - INFO - __main__ -   Batch number = 207
Evaluating:  66%|██████▌   | 207/313 [01:01<00:31,  3.34it/s]01/14/2022 16:24:29 - INFO - __main__ -   Batch number = 208
Evaluating:  66%|██████▋   | 208/313 [01:01<00:31,  3.35it/s]01/14/2022 16:24:29 - INFO - __main__ -   Batch number = 209
Evaluating:  67%|██████▋   | 209/313 [01:02<00:31,  3.35it/s]01/14/2022 16:24:29 - INFO - __main__ -   Batch number = 210
Evaluating:  67%|██████▋   | 210/313 [01:02<00:30,  3.33it/s]01/14/2022 16:24:30 - INFO - __main__ -   Batch number = 211
Evaluating:  67%|██████▋   | 211/313 [01:02<00:30,  3.33it/s]01/14/2022 16:24:30 - INFO - __main__ -   Batch number = 212
Evaluating:  68%|██████▊   | 212/313 [01:03<00:30,  3.33it/s]01/14/2022 16:24:30 - INFO - __main__ -   Batch number = 213
Evaluating:  68%|██████▊   | 213/313 [01:03<00:30,  3.30it/s]01/14/2022 16:24:31 - INFO - __main__ -   Batch number = 214
Evaluating:  68%|██████▊   | 214/313 [01:03<00:30,  3.28it/s]01/14/2022 16:24:31 - INFO - __main__ -   Batch number = 215
Evaluating:  69%|██████▊   | 215/313 [01:04<00:29,  3.28it/s]01/14/2022 16:24:31 - INFO - __main__ -   Batch number = 216
Evaluating:  69%|██████▉   | 216/313 [01:04<00:29,  3.26it/s]01/14/2022 16:24:31 - INFO - __main__ -   Batch number = 217
Evaluating:  69%|██████▉   | 217/313 [01:04<00:29,  3.24it/s]01/14/2022 16:24:32 - INFO - __main__ -   Batch number = 218
Evaluating:  70%|██████▉   | 218/313 [01:04<00:29,  3.24it/s]01/14/2022 16:24:32 - INFO - __main__ -   Batch number = 219
Evaluating:  70%|██████▉   | 219/313 [01:05<00:28,  3.24it/s]01/14/2022 16:24:32 - INFO - __main__ -   Batch number = 220
Evaluating:  70%|███████   | 220/313 [01:05<00:28,  3.24it/s]01/14/2022 16:24:33 - INFO - __main__ -   Batch number = 221
Evaluating:  71%|███████   | 221/313 [01:05<00:28,  3.25it/s]01/14/2022 16:24:33 - INFO - __main__ -   Batch number = 222
Evaluating:  71%|███████   | 222/313 [01:06<00:27,  3.26it/s]01/14/2022 16:24:33 - INFO - __main__ -   Batch number = 223
Evaluating:  71%|███████   | 223/313 [01:06<00:29,  3.05it/s]01/14/2022 16:24:34 - INFO - __main__ -   Batch number = 224
Evaluating:  72%|███████▏  | 224/313 [01:06<00:28,  3.11it/s]01/14/2022 16:24:34 - INFO - __main__ -   Batch number = 225
Evaluating:  72%|███████▏  | 225/313 [01:07<00:27,  3.16it/s]01/14/2022 16:24:34 - INFO - __main__ -   Batch number = 226
Evaluating:  72%|███████▏  | 226/313 [01:07<00:27,  3.19it/s]01/14/2022 16:24:35 - INFO - __main__ -   Batch number = 227
Evaluating:  73%|███████▎  | 227/313 [01:07<00:26,  3.20it/s]01/14/2022 16:24:35 - INFO - __main__ -   Batch number = 228
Evaluating:  73%|███████▎  | 228/313 [01:08<00:26,  3.22it/s]01/14/2022 16:24:35 - INFO - __main__ -   Batch number = 229
Evaluating:  73%|███████▎  | 229/313 [01:08<00:25,  3.25it/s]01/14/2022 16:24:36 - INFO - __main__ -   Batch number = 230
Evaluating:  73%|███████▎  | 230/313 [01:08<00:25,  3.27it/s]01/14/2022 16:24:36 - INFO - __main__ -   Batch number = 231
Evaluating:  74%|███████▍  | 231/313 [01:09<00:24,  3.29it/s]01/14/2022 16:24:36 - INFO - __main__ -   Batch number = 232
Evaluating:  74%|███████▍  | 232/313 [01:09<00:24,  3.31it/s]01/14/2022 16:24:36 - INFO - __main__ -   Batch number = 233
Evaluating:  74%|███████▍  | 233/313 [01:09<00:25,  3.10it/s]01/14/2022 16:24:37 - INFO - __main__ -   Batch number = 234
Evaluating:  75%|███████▍  | 234/313 [01:09<00:24,  3.21it/s]01/14/2022 16:24:37 - INFO - __main__ -   Batch number = 235
Evaluating:  75%|███████▌  | 235/313 [01:10<00:23,  3.28it/s]01/14/2022 16:24:37 - INFO - __main__ -   Batch number = 236
Evaluating:  75%|███████▌  | 236/313 [01:10<00:23,  3.34it/s]01/14/2022 16:24:38 - INFO - __main__ -   Batch number = 237
Evaluating:  76%|███████▌  | 237/313 [01:10<00:22,  3.37it/s]01/14/2022 16:24:38 - INFO - __main__ -   Batch number = 238
Evaluating:  76%|███████▌  | 238/313 [01:11<00:22,  3.40it/s]01/14/2022 16:24:38 - INFO - __main__ -   Batch number = 239
Evaluating:  76%|███████▋  | 239/313 [01:11<00:21,  3.42it/s]01/14/2022 16:24:39 - INFO - __main__ -   Batch number = 240
Evaluating:  77%|███████▋  | 240/313 [01:11<00:21,  3.44it/s]01/14/2022 16:24:39 - INFO - __main__ -   Batch number = 241
Evaluating:  77%|███████▋  | 241/313 [01:11<00:20,  3.45it/s]01/14/2022 16:24:39 - INFO - __main__ -   Batch number = 242
Evaluating:  77%|███████▋  | 242/313 [01:12<00:20,  3.45it/s]01/14/2022 16:24:39 - INFO - __main__ -   Batch number = 243
Evaluating:  78%|███████▊  | 243/313 [01:12<00:20,  3.46it/s]01/14/2022 16:24:40 - INFO - __main__ -   Batch number = 244
Evaluating:  78%|███████▊  | 244/313 [01:12<00:19,  3.46it/s]01/14/2022 16:24:40 - INFO - __main__ -   Batch number = 245
Evaluating:  78%|███████▊  | 245/313 [01:13<00:19,  3.47it/s]01/14/2022 16:24:40 - INFO - __main__ -   Batch number = 246
Evaluating:  79%|███████▊  | 246/313 [01:13<00:19,  3.46it/s]01/14/2022 16:24:41 - INFO - __main__ -   Batch number = 247
Evaluating:  79%|███████▉  | 247/313 [01:13<00:19,  3.44it/s]01/14/2022 16:24:41 - INFO - __main__ -   Batch number = 248
Evaluating:  79%|███████▉  | 248/313 [01:14<00:18,  3.45it/s]01/14/2022 16:24:41 - INFO - __main__ -   Batch number = 249
Evaluating:  80%|███████▉  | 249/313 [01:14<00:18,  3.46it/s]01/14/2022 16:24:41 - INFO - __main__ -   Batch number = 250
Evaluating:  80%|███████▉  | 250/313 [01:14<00:18,  3.46it/s]01/14/2022 16:24:42 - INFO - __main__ -   Batch number = 251
Evaluating:  80%|████████  | 251/313 [01:14<00:18,  3.43it/s]01/14/2022 16:24:42 - INFO - __main__ -   Batch number = 252
Evaluating:  81%|████████  | 252/313 [01:15<00:18,  3.38it/s]01/14/2022 16:24:42 - INFO - __main__ -   Batch number = 253
Evaluating:  81%|████████  | 253/313 [01:15<00:17,  3.34it/s]01/14/2022 16:24:43 - INFO - __main__ -   Batch number = 254
Evaluating:  81%|████████  | 254/313 [01:15<00:17,  3.30it/s]01/14/2022 16:24:43 - INFO - __main__ -   Batch number = 255
Evaluating:  81%|████████▏ | 255/313 [01:16<00:17,  3.27it/s]01/14/2022 16:24:43 - INFO - __main__ -   Batch number = 256
Evaluating:  82%|████████▏ | 256/313 [01:16<00:17,  3.26it/s]01/14/2022 16:24:44 - INFO - __main__ -   Batch number = 257
Evaluating:  82%|████████▏ | 257/313 [01:16<00:18,  3.09it/s]01/14/2022 16:24:44 - INFO - __main__ -   Batch number = 258
Evaluating:  82%|████████▏ | 258/313 [01:17<00:17,  3.17it/s]01/14/2022 16:24:44 - INFO - __main__ -   Batch number = 259
Evaluating:  83%|████████▎ | 259/313 [01:17<00:16,  3.23it/s]01/14/2022 16:24:44 - INFO - __main__ -   Batch number = 260
Evaluating:  83%|████████▎ | 260/313 [01:17<00:16,  3.27it/s]01/14/2022 16:24:45 - INFO - __main__ -   Batch number = 261
Evaluating:  83%|████████▎ | 261/313 [01:17<00:15,  3.30it/s]01/14/2022 16:24:45 - INFO - __main__ -   Batch number = 262
Evaluating:  84%|████████▎ | 262/313 [01:18<00:15,  3.31it/s]01/14/2022 16:24:45 - INFO - __main__ -   Batch number = 263
Evaluating:  84%|████████▍ | 263/313 [01:18<00:15,  3.33it/s]01/14/2022 16:24:46 - INFO - __main__ -   Batch number = 264
Evaluating:  84%|████████▍ | 264/313 [01:18<00:14,  3.34it/s]01/14/2022 16:24:46 - INFO - __main__ -   Batch number = 265
Evaluating:  85%|████████▍ | 265/313 [01:19<00:14,  3.32it/s]01/14/2022 16:24:46 - INFO - __main__ -   Batch number = 266
Evaluating:  85%|████████▍ | 266/313 [01:19<00:14,  3.29it/s]01/14/2022 16:24:47 - INFO - __main__ -   Batch number = 267
Evaluating:  85%|████████▌ | 267/313 [01:19<00:14,  3.26it/s]01/14/2022 16:24:48 - INFO - __main__ -   Batch number = 268
Evaluating:  86%|████████▌ | 268/313 [01:20<00:23,  1.93it/s]01/14/2022 16:24:48 - INFO - __main__ -   Batch number = 269
Evaluating:  86%|████████▌ | 269/313 [01:21<00:20,  2.19it/s]01/14/2022 16:24:48 - INFO - __main__ -   Batch number = 270
Evaluating:  86%|████████▋ | 270/313 [01:21<00:17,  2.42it/s]01/14/2022 16:24:49 - INFO - __main__ -   Batch number = 271
Evaluating:  87%|████████▋ | 271/313 [01:21<00:16,  2.61it/s]01/14/2022 16:24:49 - INFO - __main__ -   Batch number = 272
Evaluating:  87%|████████▋ | 272/313 [01:22<00:14,  2.77it/s]01/14/2022 16:24:49 - INFO - __main__ -   Batch number = 273
Evaluating:  87%|████████▋ | 273/313 [01:22<00:13,  2.90it/s]01/14/2022 16:24:49 - INFO - __main__ -   Batch number = 274
Evaluating:  88%|████████▊ | 274/313 [01:22<00:13,  2.99it/s]01/14/2022 16:24:50 - INFO - __main__ -   Batch number = 275
Evaluating:  88%|████████▊ | 275/313 [01:23<00:12,  3.05it/s]01/14/2022 16:24:50 - INFO - __main__ -   Batch number = 276
Evaluating:  88%|████████▊ | 276/313 [01:23<00:11,  3.10it/s]01/14/2022 16:24:50 - INFO - __main__ -   Batch number = 277
Evaluating:  88%|████████▊ | 277/313 [01:23<00:11,  3.13it/s]01/14/2022 16:24:51 - INFO - __main__ -   Batch number = 278
Evaluating:  89%|████████▉ | 278/313 [01:23<00:11,  3.16it/s]01/14/2022 16:24:51 - INFO - __main__ -   Batch number = 279
Evaluating:  89%|████████▉ | 279/313 [01:24<00:10,  3.18it/s]01/14/2022 16:24:51 - INFO - __main__ -   Batch number = 280
Evaluating:  89%|████████▉ | 280/313 [01:24<00:10,  3.23it/s]01/14/2022 16:24:52 - INFO - __main__ -   Batch number = 281
Evaluating:  90%|████████▉ | 281/313 [01:24<00:09,  3.28it/s]01/14/2022 16:24:52 - INFO - __main__ -   Batch number = 282
Evaluating:  90%|█████████ | 282/313 [01:25<00:09,  3.31it/s]01/14/2022 16:24:52 - INFO - __main__ -   Batch number = 283
Evaluating:  90%|█████████ | 283/313 [01:25<00:09,  3.33it/s]01/14/2022 16:24:53 - INFO - __main__ -   Batch number = 284
Evaluating:  91%|█████████ | 284/313 [01:25<00:08,  3.33it/s]01/14/2022 16:24:53 - INFO - __main__ -   Batch number = 285
Evaluating:  91%|█████████ | 285/313 [01:26<00:08,  3.24it/s]01/14/2022 16:24:53 - INFO - __main__ -   Batch number = 286
Evaluating:  91%|█████████▏| 286/313 [01:26<00:08,  3.27it/s]01/14/2022 16:24:53 - INFO - __main__ -   Batch number = 287
Evaluating:  92%|█████████▏| 287/313 [01:26<00:07,  3.26it/s]01/14/2022 16:24:54 - INFO - __main__ -   Batch number = 288
Evaluating:  92%|█████████▏| 288/313 [01:26<00:07,  3.27it/s]01/14/2022 16:24:54 - INFO - __main__ -   Batch number = 289
Evaluating:  92%|█████████▏| 289/313 [01:27<00:07,  3.28it/s]01/14/2022 16:24:54 - INFO - __main__ -   Batch number = 290
Evaluating:  93%|█████████▎| 290/313 [01:27<00:06,  3.31it/s]01/14/2022 16:24:55 - INFO - __main__ -   Batch number = 291
Evaluating:  93%|█████████▎| 291/313 [01:27<00:06,  3.32it/s]01/14/2022 16:24:55 - INFO - __main__ -   Batch number = 292
Evaluating:  93%|█████████▎| 292/313 [01:28<00:06,  3.35it/s]01/14/2022 16:24:55 - INFO - __main__ -   Batch number = 293
Evaluating:  94%|█████████▎| 293/313 [01:28<00:05,  3.37it/s]01/14/2022 16:24:56 - INFO - __main__ -   Batch number = 294
Evaluating:  94%|█████████▍| 294/313 [01:28<00:05,  3.38it/s]01/14/2022 16:24:56 - INFO - __main__ -   Batch number = 295
Evaluating:  94%|█████████▍| 295/313 [01:29<00:05,  3.39it/s]01/14/2022 16:24:56 - INFO - __main__ -   Batch number = 296
Evaluating:  95%|█████████▍| 296/313 [01:29<00:04,  3.41it/s]01/14/2022 16:24:56 - INFO - __main__ -   Batch number = 297
Evaluating:  95%|█████████▍| 297/313 [01:29<00:04,  3.41it/s]01/14/2022 16:24:57 - INFO - __main__ -   Batch number = 298
Evaluating:  95%|█████████▌| 298/313 [01:29<00:04,  3.40it/s]01/14/2022 16:24:57 - INFO - __main__ -   Batch number = 299
Evaluating:  96%|█████████▌| 299/313 [01:30<00:04,  3.41it/s]01/14/2022 16:24:57 - INFO - __main__ -   Batch number = 300
Evaluating:  96%|█████████▌| 300/313 [01:30<00:03,  3.42it/s]01/14/2022 16:24:58 - INFO - __main__ -   Batch number = 301
Evaluating:  96%|█████████▌| 301/313 [01:30<00:03,  3.42it/s]01/14/2022 16:24:58 - INFO - __main__ -   Batch number = 302
Evaluating:  96%|█████████▋| 302/313 [01:31<00:03,  3.42it/s]01/14/2022 16:24:58 - INFO - __main__ -   Batch number = 303
Evaluating:  97%|█████████▋| 303/313 [01:31<00:02,  3.42it/s]01/14/2022 16:24:58 - INFO - __main__ -   Batch number = 304
Evaluating:  97%|█████████▋| 304/313 [01:31<00:02,  3.39it/s]01/14/2022 16:24:59 - INFO - __main__ -   Batch number = 305
Evaluating:  97%|█████████▋| 305/313 [01:31<00:02,  3.37it/s]01/14/2022 16:24:59 - INFO - __main__ -   Batch number = 306
Evaluating:  98%|█████████▊| 306/313 [01:32<00:02,  3.38it/s]01/14/2022 16:24:59 - INFO - __main__ -   Batch number = 307
Evaluating:  98%|█████████▊| 307/313 [01:32<00:01,  3.38it/s]01/14/2022 16:25:00 - INFO - __main__ -   Batch number = 308
Evaluating:  98%|█████████▊| 308/313 [01:32<00:01,  3.37it/s]01/14/2022 16:25:00 - INFO - __main__ -   Batch number = 309
Evaluating:  99%|█████████▊| 309/313 [01:33<00:01,  3.35it/s]01/14/2022 16:25:00 - INFO - __main__ -   Batch number = 310
Evaluating:  99%|█████████▉| 310/313 [01:33<00:00,  3.37it/s]01/14/2022 16:25:01 - INFO - __main__ -   Batch number = 311
Evaluating:  99%|█████████▉| 311/313 [01:33<00:00,  3.39it/s]01/14/2022 16:25:01 - INFO - __main__ -   Batch number = 312
Evaluating: 100%|█████████▉| 312/313 [01:34<00:00,  3.38it/s]01/14/2022 16:25:01 - INFO - __main__ -   Batch number = 313
Evaluating: 100%|██████████| 313/313 [01:34<00:00,  3.91it/s]Evaluating: 100%|██████████| 313/313 [01:34<00:00,  3.32it/s]
01/14/2022 16:25:03 - INFO - __main__ -   ***** Evaluation result  in ar *****
01/14/2022 16:25:03 - INFO - __main__ -     f1 = 0.3475425870079061
01/14/2022 16:25:03 - INFO - __main__ -     loss = 5.097786715236335
01/14/2022 16:25:03 - INFO - __main__ -     precision = 0.32110851720762107
01/14/2022 16:25:03 - INFO - __main__ -     recall = 0.37871924682476243
99.02user 38.90system 2:04.83elapsed 110%CPU (0avgtext+0avgdata 4234124maxresident)k
0inputs+880outputs (0major+2426731minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:25:05 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:25:05 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:25:05 - INFO - __main__ -   Seed = 3
01/14/2022 16:25:05 - INFO - root -   save model
01/14/2022 16:25:05 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:25:05 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:25:07 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:25:13 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:25:13 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:25:13 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:25:13 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:25:13 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:25:13 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,ar/wiki@ukp
01/14/2022 16:25:13 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'ar'], Length : 10
01/14/2022 16:25:13 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'ar/wiki@ukp'], Length : 10
01/14/2022 16:25:13 - INFO - __main__ -   Language = en
01/14/2022 16:25:13 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:25:14 - INFO - __main__ -   Language = pt
01/14/2022 16:25:14 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:25:15 - INFO - __main__ -   Language = id
01/14/2022 16:25:15 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:25:17 - INFO - __main__ -   Language = tr
01/14/2022 16:25:17 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:25:19 - INFO - __main__ -   Language = vi
01/14/2022 16:25:19 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
PyTorch version 1.10.1+cu102 available.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:25:21 - INFO - __main__ -   Language = fa
01/14/2022 16:25:21 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
01/14/2022 16:25:21 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='jv', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:25:21 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:25:21 - INFO - __main__ -   Seed = 1
01/14/2022 16:25:21 - INFO - root -   save model
01/14/2022 16:25:21 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='jv', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:25:21 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:25:22 - INFO - __main__ -   Language = eu
01/14/2022 16:25:22 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:25:23 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:25:24 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:25:24 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:25:25 - INFO - __main__ -   Language = cs
01/14/2022 16:25:25 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:25:27 - INFO - __main__ -   Language = ar
01/14/2022 16:25:27 - INFO - __main__ -   Adapter Name = ar/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ar/bert-base-multilingual-cased/pfeiffer/ar_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted/adapter_config.json
Adding adapter 'ar' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/0b2a547243e82d816959cbe6c9a814aee3716c08d62584aebd7a9044229cc8a8-1ec0387460c90e04c5e70048e0981620ddf52d228c8f806eca3ce770b10ed331-extracted'
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:25:29 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:25:29 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:25:29 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:25:29 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:25:29 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:25:29 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,jv/wiki@ukp
01/14/2022 16:25:29 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'jv'], Length : 10
01/14/2022 16:25:29 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'jv/wiki@ukp'], Length : 10
01/14/2022 16:25:29 - INFO - __main__ -   Language = en
01/14/2022 16:25:29 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:25:31 - INFO - __main__ -   Language = pt
01/14/2022 16:25:31 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
01/14/2022 16:25:31 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:25:31 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'ar']
01/14/2022 16:25:31 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:25:31 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:25:31 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:25:31 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
01/14/2022 16:25:32 - INFO - __main__ -   ***** Running evaluation  in ar *****
01/14/2022 16:25:32 - INFO - __main__ -     Num examples = 10000
01/14/2022 16:25:32 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]01/14/2022 16:25:32 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/313 [00:00<01:34,  3.28it/s]01/14/2022 16:25:33 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/313 [00:00<01:29,  3.46it/s]01/14/2022 16:25:33 - INFO - __main__ -   Batch number = 3
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:25:33 - INFO - __main__ -   Language = id
01/14/2022 16:25:33 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Evaluating:   1%|          | 3/313 [00:00<01:27,  3.54it/s]01/14/2022 16:25:33 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|▏         | 4/313 [00:01<01:26,  3.57it/s]01/14/2022 16:25:33 - INFO - __main__ -   Batch number = 5
Evaluating:   2%|▏         | 5/313 [00:01<01:25,  3.59it/s]01/14/2022 16:25:34 - INFO - __main__ -   Batch number = 6
Evaluating:   2%|▏         | 6/313 [00:01<01:25,  3.60it/s]01/14/2022 16:25:34 - INFO - __main__ -   Batch number = 7
Evaluating:   2%|▏         | 7/313 [00:01<01:25,  3.60it/s]01/14/2022 16:25:34 - INFO - __main__ -   Batch number = 8
Evaluating:   3%|▎         | 8/313 [00:02<01:24,  3.60it/s]01/14/2022 16:25:35 - INFO - __main__ -   Batch number = 9
Evaluating:   3%|▎         | 9/313 [00:02<01:24,  3.60it/s]01/14/2022 16:25:35 - INFO - __main__ -   Batch number = 10
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Evaluating:   3%|▎         | 10/313 [00:02<01:24,  3.60it/s]01/14/2022 16:25:35 - INFO - __main__ -   Batch number = 11
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:25:35 - INFO - __main__ -   Language = cs
01/14/2022 16:25:35 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Evaluating:   4%|▎         | 11/313 [00:03<01:24,  3.59it/s]01/14/2022 16:25:35 - INFO - __main__ -   Batch number = 12
Evaluating:   4%|▍         | 12/313 [00:03<01:23,  3.59it/s]01/14/2022 16:25:36 - INFO - __main__ -   Batch number = 13
Evaluating:   4%|▍         | 13/313 [00:03<01:23,  3.58it/s]01/14/2022 16:25:36 - INFO - __main__ -   Batch number = 14
Evaluating:   4%|▍         | 14/313 [00:03<01:23,  3.58it/s]01/14/2022 16:25:36 - INFO - __main__ -   Batch number = 15
Evaluating:   5%|▍         | 15/313 [00:04<01:23,  3.58it/s]01/14/2022 16:25:36 - INFO - __main__ -   Batch number = 16
Evaluating:   5%|▌         | 16/313 [00:04<01:22,  3.58it/s]01/14/2022 16:25:37 - INFO - __main__ -   Batch number = 17
Evaluating:   5%|▌         | 17/313 [00:04<01:22,  3.58it/s]01/14/2022 16:25:37 - INFO - __main__ -   Batch number = 18
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Evaluating:   6%|▌         | 18/313 [00:05<01:22,  3.58it/s]01/14/2022 16:25:37 - INFO - __main__ -   Batch number = 19
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:25:37 - INFO - __main__ -   Language = tr
01/14/2022 16:25:37 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Evaluating:   6%|▌         | 19/313 [00:05<01:22,  3.58it/s]01/14/2022 16:25:38 - INFO - __main__ -   Batch number = 20
Evaluating:   6%|▋         | 20/313 [00:05<01:21,  3.58it/s]01/14/2022 16:25:38 - INFO - __main__ -   Batch number = 21
Evaluating:   7%|▋         | 21/313 [00:05<01:21,  3.57it/s]01/14/2022 16:25:38 - INFO - __main__ -   Batch number = 22
Evaluating:   7%|▋         | 22/313 [00:06<01:21,  3.58it/s]01/14/2022 16:25:38 - INFO - __main__ -   Batch number = 23
Evaluating:   7%|▋         | 23/313 [00:06<01:21,  3.58it/s]01/14/2022 16:25:39 - INFO - __main__ -   Batch number = 24
Evaluating:   8%|▊         | 24/313 [00:06<01:20,  3.58it/s]01/14/2022 16:25:39 - INFO - __main__ -   Batch number = 25
Evaluating:   8%|▊         | 25/313 [00:06<01:20,  3.57it/s]01/14/2022 16:25:39 - INFO - __main__ -   Batch number = 26
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:25:39 - INFO - __main__ -   Language = eu
01/14/2022 16:25:39 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Evaluating:   8%|▊         | 26/313 [00:07<01:20,  3.56it/s]01/14/2022 16:25:40 - INFO - __main__ -   Batch number = 27
Evaluating:   9%|▊         | 27/313 [00:07<01:20,  3.56it/s]01/14/2022 16:25:40 - INFO - __main__ -   Batch number = 28
Evaluating:   9%|▉         | 28/313 [00:07<01:19,  3.57it/s]01/14/2022 16:25:40 - INFO - __main__ -   Batch number = 29
Evaluating:   9%|▉         | 29/313 [00:08<01:19,  3.57it/s]01/14/2022 16:25:41 - INFO - __main__ -   Batch number = 30
Evaluating:  10%|▉         | 30/313 [00:08<01:32,  3.06it/s]01/14/2022 16:25:41 - INFO - __main__ -   Batch number = 31
Evaluating:  10%|▉         | 31/313 [00:08<01:28,  3.19it/s]01/14/2022 16:25:41 - INFO - __main__ -   Batch number = 32
Evaluating:  10%|█         | 32/313 [00:09<01:25,  3.30it/s]01/14/2022 16:25:41 - INFO - __main__ -   Batch number = 33
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:25:42 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:25:42 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  11%|█         | 33/313 [00:09<01:22,  3.37it/s]01/14/2022 16:25:42 - INFO - __main__ -   Batch number = 34
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating:  11%|█         | 34/313 [00:09<01:21,  3.43it/s]01/14/2022 16:25:42 - INFO - __main__ -   Batch number = 35
Evaluating:  11%|█         | 35/313 [00:09<01:19,  3.48it/s]01/14/2022 16:25:42 - INFO - __main__ -   Batch number = 36
Evaluating:  12%|█▏        | 36/313 [00:10<01:19,  3.51it/s]01/14/2022 16:25:43 - INFO - __main__ -   Batch number = 37
Evaluating:  12%|█▏        | 37/313 [00:10<01:18,  3.53it/s]01/14/2022 16:25:43 - INFO - __main__ -   Batch number = 38
Evaluating:  12%|█▏        | 38/313 [00:10<01:17,  3.54it/s]01/14/2022 16:25:43 - INFO - __main__ -   Batch number = 39
Evaluating:  12%|█▏        | 39/313 [00:11<01:17,  3.55it/s]01/14/2022 16:25:43 - INFO - __main__ -   Batch number = 40
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Evaluating:  13%|█▎        | 40/313 [00:11<01:16,  3.55it/s]01/14/2022 16:25:44 - INFO - __main__ -   Batch number = 41
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:25:44 - INFO - __main__ -   Language = vi
01/14/2022 16:25:44 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Evaluating:  13%|█▎        | 41/313 [00:11<01:16,  3.56it/s]01/14/2022 16:25:44 - INFO - __main__ -   Batch number = 42
Evaluating:  13%|█▎        | 42/313 [00:11<01:16,  3.56it/s]01/14/2022 16:25:44 - INFO - __main__ -   Batch number = 43
Evaluating:  14%|█▎        | 43/313 [00:12<01:15,  3.56it/s]01/14/2022 16:25:44 - INFO - __main__ -   Batch number = 44
Evaluating:  14%|█▍        | 44/313 [00:12<01:15,  3.56it/s]01/14/2022 16:25:45 - INFO - __main__ -   Batch number = 45
Evaluating:  14%|█▍        | 45/313 [00:12<01:15,  3.56it/s]01/14/2022 16:25:45 - INFO - __main__ -   Batch number = 46
Evaluating:  15%|█▍        | 46/313 [00:13<01:15,  3.56it/s]01/14/2022 16:25:45 - INFO - __main__ -   Batch number = 47
Evaluating:  15%|█▌        | 47/313 [00:13<01:22,  3.24it/s]01/14/2022 16:25:46 - INFO - __main__ -   Batch number = 48
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:25:46 - INFO - __main__ -   Language = fr
01/14/2022 16:25:46 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Evaluating:  15%|█▌        | 48/313 [00:13<01:19,  3.32it/s]01/14/2022 16:25:46 - INFO - __main__ -   Batch number = 49
Evaluating:  16%|█▌        | 49/313 [00:13<01:18,  3.38it/s]01/14/2022 16:25:46 - INFO - __main__ -   Batch number = 50
Evaluating:  16%|█▌        | 50/313 [00:14<01:16,  3.43it/s]01/14/2022 16:25:47 - INFO - __main__ -   Batch number = 51
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:25:47 - INFO - __main__ -   Language = jv
01/14/2022 16:25:47 - INFO - __main__ -   Adapter Name = jv/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  16%|█▋        | 51/313 [00:14<01:15,  3.45it/s]01/14/2022 16:25:47 - INFO - __main__ -   Batch number = 52
Evaluating:  17%|█▋        | 52/313 [00:14<01:15,  3.47it/s]01/14/2022 16:25:47 - INFO - __main__ -   Batch number = 53
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/jv/bert-base-multilingual-cased/pfeiffer/jv_relu_2.zip.
Evaluating:  17%|█▋        | 53/313 [00:15<01:14,  3.49it/s]01/14/2022 16:25:47 - INFO - __main__ -   Batch number = 54
Evaluating:  17%|█▋        | 54/313 [00:15<01:13,  3.50it/s]01/14/2022 16:25:48 - INFO - __main__ -   Batch number = 55
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted/adapter_config.json
Adding adapter 'jv' of type 'text_lang'.
Evaluating:  18%|█▊        | 55/313 [00:15<01:13,  3.52it/s]01/14/2022 16:25:48 - INFO - __main__ -   Batch number = 56
Loading module weights from /home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted'
Evaluating:  18%|█▊        | 56/313 [00:15<01:12,  3.53it/s]01/14/2022 16:25:48 - INFO - __main__ -   Batch number = 57
Evaluating:  18%|█▊        | 57/313 [00:16<01:12,  3.53it/s]01/14/2022 16:25:49 - INFO - __main__ -   Batch number = 58
Evaluating:  19%|█▊        | 58/313 [00:16<01:12,  3.54it/s]01/14/2022 16:25:49 - INFO - __main__ -   Batch number = 59
Evaluating:  19%|█▉        | 59/313 [00:16<01:11,  3.54it/s]01/14/2022 16:25:49 - INFO - __main__ -   Batch number = 60
Evaluating:  19%|█▉        | 60/313 [00:17<01:11,  3.54it/s]01/14/2022 16:25:49 - INFO - __main__ -   Batch number = 61
Evaluating:  19%|█▉        | 61/313 [00:17<01:11,  3.55it/s]01/14/2022 16:25:50 - INFO - __main__ -   Batch number = 62
Evaluating:  20%|█▉        | 62/313 [00:17<01:10,  3.54it/s]01/14/2022 16:25:50 - INFO - __main__ -   Batch number = 63
Evaluating:  20%|██        | 63/313 [00:17<01:10,  3.52it/s]01/14/2022 16:25:50 - INFO - __main__ -   Batch number = 64
Evaluating:  20%|██        | 64/313 [00:18<01:10,  3.51it/s]01/14/2022 16:25:51 - INFO - __main__ -   Batch number = 65
Evaluating:  21%|██        | 65/313 [00:18<01:19,  3.10it/s]01/14/2022 16:25:51 - INFO - __main__ -   Batch number = 66
Evaluating:  21%|██        | 66/313 [00:18<01:16,  3.22it/s]01/14/2022 16:25:51 - INFO - __main__ -   Batch number = 67
Evaluating:  21%|██▏       | 67/313 [00:19<01:14,  3.29it/s]01/14/2022 16:25:51 - INFO - __main__ -   Batch number = 68
01/14/2022 16:25:52 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:25:52 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'jv']
01/14/2022 16:25:52 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:25:52 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:25:52 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:25:52 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_jv_bert-base-multilingual-cased_128
01/14/2022 16:25:52 - INFO - __main__ -   ***** Running evaluation  in jv *****
01/14/2022 16:25:52 - INFO - __main__ -     Num examples = 100
01/14/2022 16:25:52 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:25:52 - INFO - __main__ -   Batch number = 1
Evaluating:  22%|██▏       | 68/313 [00:19<01:13,  3.35it/s]01/14/2022 16:25:52 - INFO - __main__ -   Batch number = 69
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.27it/s]01/14/2022 16:25:52 - INFO - __main__ -   Batch number = 2
Evaluating:  22%|██▏       | 69/313 [00:19<01:11,  3.40it/s]01/14/2022 16:25:52 - INFO - __main__ -   Batch number = 70
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.46it/s]01/14/2022 16:25:52 - INFO - __main__ -   Batch number = 3
Evaluating:  22%|██▏       | 70/313 [00:20<01:10,  3.44it/s]01/14/2022 16:25:52 - INFO - __main__ -   Batch number = 71
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.56it/s]01/14/2022 16:25:53 - INFO - __main__ -   Batch number = 4
Evaluating:  23%|██▎       | 71/313 [00:20<01:10,  3.42it/s]01/14/2022 16:25:53 - INFO - __main__ -   Batch number = 72
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.42it/s]
01/14/2022 16:25:53 - INFO - __main__ -   ***** Evaluation result  in jv *****
01/14/2022 16:25:53 - INFO - __main__ -     f1 = 0.5912408759124088
01/14/2022 16:25:53 - INFO - __main__ -     loss = 2.6263967156410217
01/14/2022 16:25:53 - INFO - __main__ -     precision = 0.5159235668789809
01/14/2022 16:25:53 - INFO - __main__ -     recall = 0.6923076923076923
Evaluating:  23%|██▎       | 72/313 [00:20<01:10,  3.43it/s]01/14/2022 16:25:53 - INFO - __main__ -   Batch number = 73
Evaluating:  23%|██▎       | 73/313 [00:20<01:09,  3.45it/s]01/14/2022 16:25:53 - INFO - __main__ -   Batch number = 74
34.71user 13.46system 0:34.22elapsed 140%CPU (0avgtext+0avgdata 4224656maxresident)k
80inputs+72outputs (0major+2230377minor)pagefaults 0swaps
Evaluating:  24%|██▎       | 74/313 [00:21<01:08,  3.48it/s]01/14/2022 16:25:53 - INFO - __main__ -   Batch number = 75
Evaluating:  24%|██▍       | 75/313 [00:21<01:08,  3.48it/s]01/14/2022 16:25:54 - INFO - __main__ -   Batch number = 76
Evaluating:  24%|██▍       | 76/313 [00:21<01:07,  3.49it/s]01/14/2022 16:25:54 - INFO - __main__ -   Batch number = 77
Evaluating:  25%|██▍       | 77/313 [00:22<01:07,  3.49it/s]01/14/2022 16:25:54 - INFO - __main__ -   Batch number = 78
PyTorch version 1.10.1+cu102 available.
Evaluating:  25%|██▍       | 78/313 [00:22<01:07,  3.50it/s]01/14/2022 16:25:55 - INFO - __main__ -   Batch number = 79
01/14/2022 16:25:55 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='jv', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:25:55 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:25:55 - INFO - __main__ -   Seed = 2
01/14/2022 16:25:55 - INFO - root -   save model
01/14/2022 16:25:55 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='jv', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:25:55 - INFO - __main__ -   Loading pretrained model and tokenizer
Evaluating:  25%|██▌       | 79/313 [00:22<01:06,  3.51it/s]01/14/2022 16:25:55 - INFO - __main__ -   Batch number = 80
Evaluating:  26%|██▌       | 80/313 [00:22<01:06,  3.51it/s]01/14/2022 16:25:55 - INFO - __main__ -   Batch number = 81
Evaluating:  26%|██▌       | 81/313 [00:23<01:06,  3.51it/s]01/14/2022 16:25:55 - INFO - __main__ -   Batch number = 82
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  26%|██▌       | 82/313 [00:23<01:06,  3.48it/s]01/14/2022 16:25:56 - INFO - __main__ -   Batch number = 83
Evaluating:  27%|██▋       | 83/313 [00:23<01:06,  3.45it/s]01/14/2022 16:25:56 - INFO - __main__ -   Batch number = 84
Evaluating:  27%|██▋       | 84/313 [00:24<01:06,  3.44it/s]01/14/2022 16:25:56 - INFO - __main__ -   Batch number = 85
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  27%|██▋       | 85/313 [00:24<01:06,  3.44it/s]01/14/2022 16:25:57 - INFO - __main__ -   Batch number = 86
Evaluating:  27%|██▋       | 86/313 [00:24<01:06,  3.43it/s]01/14/2022 16:25:57 - INFO - __main__ -   Batch number = 87
Evaluating:  28%|██▊       | 87/313 [00:24<01:05,  3.45it/s]01/14/2022 16:25:57 - INFO - __main__ -   Batch number = 88
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:25:57 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Evaluating:  28%|██▊       | 88/313 [00:25<01:05,  3.45it/s]01/14/2022 16:25:58 - INFO - __main__ -   Batch number = 89
Evaluating:  28%|██▊       | 89/313 [00:25<01:05,  3.44it/s]01/14/2022 16:25:58 - INFO - __main__ -   Batch number = 90
Evaluating:  29%|██▉       | 90/313 [00:25<01:04,  3.44it/s]01/14/2022 16:25:58 - INFO - __main__ -   Batch number = 91
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Evaluating:  29%|██▉       | 91/313 [00:26<01:04,  3.45it/s]01/14/2022 16:25:58 - INFO - __main__ -   Batch number = 92
Evaluating:  29%|██▉       | 92/313 [00:26<01:03,  3.46it/s]01/14/2022 16:25:59 - INFO - __main__ -   Batch number = 93
Evaluating:  30%|██▉       | 93/313 [00:26<01:03,  3.46it/s]01/14/2022 16:25:59 - INFO - __main__ -   Batch number = 94
Evaluating:  30%|███       | 94/313 [00:26<01:03,  3.45it/s]01/14/2022 16:25:59 - INFO - __main__ -   Batch number = 95
Evaluating:  30%|███       | 95/313 [00:27<01:03,  3.45it/s]01/14/2022 16:26:00 - INFO - __main__ -   Batch number = 96
Evaluating:  31%|███       | 96/313 [00:27<01:02,  3.46it/s]01/14/2022 16:26:00 - INFO - __main__ -   Batch number = 97
Evaluating:  31%|███       | 97/313 [00:27<01:02,  3.47it/s]01/14/2022 16:26:00 - INFO - __main__ -   Batch number = 98
Evaluating:  31%|███▏      | 98/313 [00:28<01:01,  3.48it/s]01/14/2022 16:26:00 - INFO - __main__ -   Batch number = 99
Evaluating:  32%|███▏      | 99/313 [00:28<01:01,  3.47it/s]01/14/2022 16:26:01 - INFO - __main__ -   Batch number = 100
Evaluating:  32%|███▏      | 100/313 [00:28<01:01,  3.46it/s]01/14/2022 16:26:01 - INFO - __main__ -   Batch number = 101
Evaluating:  32%|███▏      | 101/313 [00:29<01:01,  3.46it/s]01/14/2022 16:26:01 - INFO - __main__ -   Batch number = 102
Evaluating:  33%|███▎      | 102/313 [00:29<01:00,  3.47it/s]01/14/2022 16:26:02 - INFO - __main__ -   Batch number = 103
Evaluating:  33%|███▎      | 103/313 [00:29<01:00,  3.49it/s]01/14/2022 16:26:02 - INFO - __main__ -   Batch number = 104
Evaluating:  33%|███▎      | 104/313 [00:29<00:59,  3.49it/s]01/14/2022 16:26:02 - INFO - __main__ -   Batch number = 105
Evaluating:  34%|███▎      | 105/313 [00:30<00:59,  3.49it/s]01/14/2022 16:26:02 - INFO - __main__ -   Batch number = 106
Evaluating:  34%|███▍      | 106/313 [00:30<00:59,  3.49it/s]01/14/2022 16:26:03 - INFO - __main__ -   Batch number = 107
Evaluating:  34%|███▍      | 107/313 [00:30<00:58,  3.50it/s]01/14/2022 16:26:03 - INFO - __main__ -   Batch number = 108
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:26:03 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:26:03 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:26:03 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:26:03 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:26:03 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:26:03 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,jv/wiki@ukp
01/14/2022 16:26:03 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'jv'], Length : 10
01/14/2022 16:26:03 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'jv/wiki@ukp'], Length : 10
01/14/2022 16:26:03 - INFO - __main__ -   Language = en
01/14/2022 16:26:03 - INFO - __main__ -   Adapter Name = en/wiki@ukp
Evaluating:  35%|███▍      | 108/313 [00:31<01:01,  3.35it/s]01/14/2022 16:26:03 - INFO - __main__ -   Batch number = 109
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  35%|███▍      | 109/313 [00:31<01:00,  3.39it/s]01/14/2022 16:26:04 - INFO - __main__ -   Batch number = 110
Evaluating:  35%|███▌      | 110/313 [00:31<00:59,  3.43it/s]01/14/2022 16:26:04 - INFO - __main__ -   Batch number = 111
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Evaluating:  35%|███▌      | 111/313 [00:31<00:58,  3.45it/s]01/14/2022 16:26:04 - INFO - __main__ -   Batch number = 112
Evaluating:  36%|███▌      | 112/313 [00:32<00:58,  3.46it/s]01/14/2022 16:26:04 - INFO - __main__ -   Batch number = 113
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:26:05 - INFO - __main__ -   Language = pt
01/14/2022 16:26:05 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
Evaluating:  36%|███▌      | 113/313 [00:32<00:57,  3.47it/s]01/14/2022 16:26:05 - INFO - __main__ -   Batch number = 114
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  36%|███▋      | 114/313 [00:32<00:57,  3.47it/s]01/14/2022 16:26:05 - INFO - __main__ -   Batch number = 115
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Evaluating:  37%|███▋      | 115/313 [00:33<00:57,  3.46it/s]01/14/2022 16:26:05 - INFO - __main__ -   Batch number = 116
Evaluating:  37%|███▋      | 116/313 [00:33<00:56,  3.46it/s]01/14/2022 16:26:06 - INFO - __main__ -   Batch number = 117
Evaluating:  37%|███▋      | 117/313 [00:33<00:56,  3.46it/s]01/14/2022 16:26:06 - INFO - __main__ -   Batch number = 118
Evaluating:  38%|███▊      | 118/313 [00:33<00:56,  3.47it/s]01/14/2022 16:26:06 - INFO - __main__ -   Batch number = 119
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Evaluating:  38%|███▊      | 119/313 [00:34<00:56,  3.43it/s]01/14/2022 16:26:07 - INFO - __main__ -   Batch number = 120
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:26:07 - INFO - __main__ -   Language = id
01/14/2022 16:26:07 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  38%|███▊      | 120/313 [00:34<00:56,  3.43it/s]01/14/2022 16:26:07 - INFO - __main__ -   Batch number = 121
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Evaluating:  39%|███▊      | 121/313 [00:34<00:55,  3.45it/s]01/14/2022 16:26:07 - INFO - __main__ -   Batch number = 122
Evaluating:  39%|███▉      | 122/313 [00:35<00:55,  3.46it/s]01/14/2022 16:26:07 - INFO - __main__ -   Batch number = 123
Evaluating:  39%|███▉      | 123/313 [00:35<00:54,  3.46it/s]01/14/2022 16:26:08 - INFO - __main__ -   Batch number = 124
Evaluating:  40%|███▉      | 124/313 [00:35<00:54,  3.45it/s]01/14/2022 16:26:08 - INFO - __main__ -   Batch number = 125
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Evaluating:  40%|███▉      | 125/313 [00:36<00:59,  3.17it/s]01/14/2022 16:26:08 - INFO - __main__ -   Batch number = 126
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:26:08 - INFO - __main__ -   Language = tr
01/14/2022 16:26:08 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  40%|████      | 126/313 [00:36<00:57,  3.27it/s]01/14/2022 16:26:09 - INFO - __main__ -   Batch number = 127
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Evaluating:  41%|████      | 127/313 [00:36<00:55,  3.34it/s]01/14/2022 16:26:09 - INFO - __main__ -   Batch number = 128
Evaluating:  41%|████      | 128/313 [00:36<00:54,  3.39it/s]01/14/2022 16:26:09 - INFO - __main__ -   Batch number = 129
Evaluating:  41%|████      | 129/313 [00:37<00:53,  3.42it/s]01/14/2022 16:26:09 - INFO - __main__ -   Batch number = 130
Evaluating:  42%|████▏     | 130/313 [00:37<00:53,  3.44it/s]01/14/2022 16:26:10 - INFO - __main__ -   Batch number = 131
Evaluating:  42%|████▏     | 131/313 [00:37<00:52,  3.44it/s]01/14/2022 16:26:10 - INFO - __main__ -   Batch number = 132
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:26:10 - INFO - __main__ -   Language = cs
01/14/2022 16:26:10 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  42%|████▏     | 132/313 [00:38<00:52,  3.42it/s]01/14/2022 16:26:10 - INFO - __main__ -   Batch number = 133
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Evaluating:  42%|████▏     | 133/313 [00:38<00:52,  3.42it/s]01/14/2022 16:26:11 - INFO - __main__ -   Batch number = 134
Evaluating:  43%|████▎     | 134/313 [00:38<00:52,  3.40it/s]01/14/2022 16:26:11 - INFO - __main__ -   Batch number = 135
Evaluating:  43%|████▎     | 135/313 [00:38<00:52,  3.39it/s]01/14/2022 16:26:11 - INFO - __main__ -   Batch number = 136
Evaluating:  43%|████▎     | 136/313 [00:39<00:52,  3.37it/s]01/14/2022 16:26:12 - INFO - __main__ -   Batch number = 137
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Evaluating:  44%|████▍     | 137/313 [00:39<00:52,  3.36it/s]01/14/2022 16:26:12 - INFO - __main__ -   Batch number = 138
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:26:12 - INFO - __main__ -   Language = vi
01/14/2022 16:26:12 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Evaluating:  44%|████▍     | 138/313 [00:39<00:52,  3.35it/s]01/14/2022 16:26:12 - INFO - __main__ -   Batch number = 139
Evaluating:  44%|████▍     | 139/313 [00:40<00:52,  3.33it/s]01/14/2022 16:26:12 - INFO - __main__ -   Batch number = 140
Evaluating:  45%|████▍     | 140/313 [00:40<00:52,  3.30it/s]01/14/2022 16:26:13 - INFO - __main__ -   Batch number = 141
Evaluating:  45%|████▌     | 141/313 [00:40<00:51,  3.31it/s]01/14/2022 16:26:13 - INFO - __main__ -   Batch number = 142
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:26:13 - INFO - __main__ -   Language = eu
01/14/2022 16:26:13 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  45%|████▌     | 142/313 [00:41<00:55,  3.09it/s]01/14/2022 16:26:13 - INFO - __main__ -   Batch number = 143
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Evaluating:  46%|████▌     | 143/313 [00:41<00:53,  3.20it/s]01/14/2022 16:26:14 - INFO - __main__ -   Batch number = 144
Evaluating:  46%|████▌     | 144/313 [00:41<00:51,  3.28it/s]01/14/2022 16:26:14 - INFO - __main__ -   Batch number = 145
Evaluating:  46%|████▋     | 145/313 [00:41<00:50,  3.34it/s]01/14/2022 16:26:14 - INFO - __main__ -   Batch number = 146
Evaluating:  47%|████▋     | 146/313 [00:42<00:49,  3.37it/s]01/14/2022 16:26:15 - INFO - __main__ -   Batch number = 147
Evaluating:  47%|████▋     | 147/313 [00:42<00:48,  3.39it/s]01/14/2022 16:26:15 - INFO - __main__ -   Batch number = 148
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:26:15 - INFO - __main__ -   Language = fa
01/14/2022 16:26:15 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Evaluating:  47%|████▋     | 148/313 [00:42<00:48,  3.39it/s]01/14/2022 16:26:15 - INFO - __main__ -   Batch number = 149
Evaluating:  48%|████▊     | 149/313 [00:43<00:48,  3.37it/s]01/14/2022 16:26:15 - INFO - __main__ -   Batch number = 150
Evaluating:  48%|████▊     | 150/313 [00:43<00:48,  3.37it/s]01/14/2022 16:26:16 - INFO - __main__ -   Batch number = 151
Evaluating:  48%|████▊     | 151/313 [00:43<00:48,  3.37it/s]01/14/2022 16:26:16 - INFO - __main__ -   Batch number = 152
Evaluating:  49%|████▊     | 152/313 [00:44<00:47,  3.37it/s]01/14/2022 16:26:16 - INFO - __main__ -   Batch number = 153
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:26:17 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:26:17 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
Evaluating:  49%|████▉     | 153/313 [00:44<00:47,  3.38it/s]01/14/2022 16:26:17 - INFO - __main__ -   Batch number = 154
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  49%|████▉     | 154/313 [00:44<00:46,  3.39it/s]01/14/2022 16:26:17 - INFO - __main__ -   Batch number = 155
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating:  50%|████▉     | 155/313 [00:44<00:46,  3.41it/s]01/14/2022 16:26:17 - INFO - __main__ -   Batch number = 156
Evaluating:  50%|████▉     | 156/313 [00:45<00:45,  3.43it/s]01/14/2022 16:26:18 - INFO - __main__ -   Batch number = 157
Evaluating:  50%|█████     | 157/313 [00:45<00:45,  3.43it/s]01/14/2022 16:26:18 - INFO - __main__ -   Batch number = 158
Evaluating:  50%|█████     | 158/313 [00:45<00:45,  3.42it/s]01/14/2022 16:26:18 - INFO - __main__ -   Batch number = 159
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Evaluating:  51%|█████     | 159/313 [00:46<00:48,  3.20it/s]01/14/2022 16:26:18 - INFO - __main__ -   Batch number = 160
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:26:19 - INFO - __main__ -   Language = jv
01/14/2022 16:26:19 - INFO - __main__ -   Adapter Name = jv/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/jv/bert-base-multilingual-cased/pfeiffer/jv_relu_2.zip.
Evaluating:  51%|█████     | 160/313 [00:46<00:47,  3.21it/s]01/14/2022 16:26:19 - INFO - __main__ -   Batch number = 161
Evaluating:  51%|█████▏    | 161/313 [00:46<00:47,  3.21it/s]01/14/2022 16:26:19 - INFO - __main__ -   Batch number = 162
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted/adapter_config.json
Adding adapter 'jv' of type 'text_lang'.
Evaluating:  52%|█████▏    | 162/313 [00:47<00:46,  3.21it/s]Loading module weights from /home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted/pytorch_adapter.bin
01/14/2022 16:26:19 - INFO - __main__ -   Batch number = 163
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted'
Evaluating:  52%|█████▏    | 163/313 [00:47<00:46,  3.22it/s]01/14/2022 16:26:20 - INFO - __main__ -   Batch number = 164
Evaluating:  52%|█████▏    | 164/313 [00:47<00:46,  3.23it/s]01/14/2022 16:26:20 - INFO - __main__ -   Batch number = 165
Evaluating:  53%|█████▎    | 165/313 [00:48<00:46,  3.22it/s]01/14/2022 16:26:20 - INFO - __main__ -   Batch number = 166
Evaluating:  53%|█████▎    | 166/313 [00:48<00:45,  3.25it/s]01/14/2022 16:26:21 - INFO - __main__ -   Batch number = 167
Evaluating:  53%|█████▎    | 167/313 [00:48<00:44,  3.30it/s]01/14/2022 16:26:21 - INFO - __main__ -   Batch number = 168
Evaluating:  54%|█████▎    | 168/313 [00:48<00:43,  3.36it/s]01/14/2022 16:26:21 - INFO - __main__ -   Batch number = 169
Evaluating:  54%|█████▍    | 169/313 [00:49<00:42,  3.38it/s]01/14/2022 16:26:21 - INFO - __main__ -   Batch number = 170
Evaluating:  54%|█████▍    | 170/313 [00:49<00:41,  3.41it/s]01/14/2022 16:26:22 - INFO - __main__ -   Batch number = 171
Evaluating:  55%|█████▍    | 171/313 [00:49<00:41,  3.43it/s]01/14/2022 16:26:22 - INFO - __main__ -   Batch number = 172
Evaluating:  55%|█████▍    | 172/313 [00:50<00:40,  3.45it/s]01/14/2022 16:26:22 - INFO - __main__ -   Batch number = 173
Evaluating:  55%|█████▌    | 173/313 [00:50<00:40,  3.46it/s]01/14/2022 16:26:23 - INFO - __main__ -   Batch number = 174
Evaluating:  56%|█████▌    | 174/313 [00:50<00:40,  3.46it/s]01/14/2022 16:26:23 - INFO - __main__ -   Batch number = 175
01/14/2022 16:26:23 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:26:23 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'jv']
01/14/2022 16:26:23 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:26:23 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:26:23 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:26:23 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_jv_bert-base-multilingual-cased_128
01/14/2022 16:26:23 - INFO - __main__ -   ***** Running evaluation  in jv *****
01/14/2022 16:26:23 - INFO - __main__ -     Num examples = 100
01/14/2022 16:26:23 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:26:23 - INFO - __main__ -   Batch number = 1
Evaluating:  56%|█████▌    | 175/313 [00:50<00:40,  3.45it/s]01/14/2022 16:26:23 - INFO - __main__ -   Batch number = 176
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.32it/s]01/14/2022 16:26:23 - INFO - __main__ -   Batch number = 2
Evaluating:  56%|█████▌    | 176/313 [00:51<00:39,  3.44it/s]01/14/2022 16:26:24 - INFO - __main__ -   Batch number = 177
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.49it/s]01/14/2022 16:26:24 - INFO - __main__ -   Batch number = 3
Evaluating:  57%|█████▋    | 177/313 [00:51<00:39,  3.43it/s]01/14/2022 16:26:24 - INFO - __main__ -   Batch number = 178
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.57it/s]01/14/2022 16:26:24 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.47it/s]
01/14/2022 16:26:24 - INFO - __main__ -   ***** Evaluation result  in jv *****
01/14/2022 16:26:24 - INFO - __main__ -     f1 = 0.6538461538461539
01/14/2022 16:26:24 - INFO - __main__ -     loss = 2.799691364169121
01/14/2022 16:26:24 - INFO - __main__ -     precision = 0.5944055944055944
01/14/2022 16:26:24 - INFO - __main__ -     recall = 0.7264957264957265
Evaluating:  57%|█████▋    | 178/313 [00:51<00:39,  3.41it/s]01/14/2022 16:26:24 - INFO - __main__ -   Batch number = 179
Evaluating:  57%|█████▋    | 179/313 [00:52<00:39,  3.39it/s]01/14/2022 16:26:24 - INFO - __main__ -   Batch number = 180
30.32user 13.36system 0:31.33elapsed 139%CPU (0avgtext+0avgdata 4224824maxresident)k
0inputs+72outputs (0major+2230986minor)pagefaults 0swaps
Evaluating:  58%|█████▊    | 180/313 [00:52<00:39,  3.38it/s]01/14/2022 16:26:25 - INFO - __main__ -   Batch number = 181
Evaluating:  58%|█████▊    | 181/313 [00:52<00:39,  3.35it/s]01/14/2022 16:26:25 - INFO - __main__ -   Batch number = 182
Evaluating:  58%|█████▊    | 182/313 [00:53<00:39,  3.31it/s]01/14/2022 16:26:25 - INFO - __main__ -   Batch number = 183
Evaluating:  58%|█████▊    | 183/313 [00:53<00:39,  3.27it/s]01/14/2022 16:26:26 - INFO - __main__ -   Batch number = 184
PyTorch version 1.10.1+cu102 available.
Evaluating:  59%|█████▉    | 184/313 [00:53<00:39,  3.25it/s]01/14/2022 16:26:26 - INFO - __main__ -   Batch number = 185
01/14/2022 16:26:26 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='jv', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:26:26 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:26:26 - INFO - __main__ -   Seed = 3
01/14/2022 16:26:26 - INFO - root -   save model
01/14/2022 16:26:26 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='jv', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:26:26 - INFO - __main__ -   Loading pretrained model and tokenizer
Evaluating:  59%|█████▉    | 185/313 [00:53<00:39,  3.24it/s]01/14/2022 16:26:26 - INFO - __main__ -   Batch number = 186
Evaluating:  59%|█████▉    | 186/313 [00:54<00:39,  3.25it/s]01/14/2022 16:26:27 - INFO - __main__ -   Batch number = 187
Evaluating:  60%|█████▉    | 187/313 [00:54<00:39,  3.20it/s]01/14/2022 16:26:27 - INFO - __main__ -   Batch number = 188
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  60%|██████    | 188/313 [00:54<00:38,  3.23it/s]01/14/2022 16:26:27 - INFO - __main__ -   Batch number = 189
Evaluating:  60%|██████    | 189/313 [00:55<00:37,  3.29it/s]01/14/2022 16:26:27 - INFO - __main__ -   Batch number = 190
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  61%|██████    | 190/313 [00:55<00:37,  3.32it/s]01/14/2022 16:26:28 - INFO - __main__ -   Batch number = 191
Evaluating:  61%|██████    | 191/313 [00:55<00:36,  3.31it/s]01/14/2022 16:26:28 - INFO - __main__ -   Batch number = 192
Evaluating:  61%|██████▏   | 192/313 [00:56<00:36,  3.29it/s]01/14/2022 16:26:28 - INFO - __main__ -   Batch number = 193
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:26:29 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Evaluating:  62%|██████▏   | 193/313 [00:56<00:40,  2.94it/s]01/14/2022 16:26:29 - INFO - __main__ -   Batch number = 194
Evaluating:  62%|██████▏   | 194/313 [00:56<00:38,  3.06it/s]01/14/2022 16:26:29 - INFO - __main__ -   Batch number = 195
Evaluating:  62%|██████▏   | 195/313 [00:57<00:37,  3.15it/s]01/14/2022 16:26:29 - INFO - __main__ -   Batch number = 196
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Evaluating:  63%|██████▎   | 196/313 [00:57<00:36,  3.19it/s]01/14/2022 16:26:30 - INFO - __main__ -   Batch number = 197
Evaluating:  63%|██████▎   | 197/313 [00:57<00:36,  3.21it/s]01/14/2022 16:26:30 - INFO - __main__ -   Batch number = 198
Evaluating:  63%|██████▎   | 198/313 [00:58<00:35,  3.23it/s]01/14/2022 16:26:30 - INFO - __main__ -   Batch number = 199
Evaluating:  64%|██████▎   | 199/313 [00:58<00:34,  3.27it/s]01/14/2022 16:26:31 - INFO - __main__ -   Batch number = 200
Evaluating:  64%|██████▍   | 200/313 [00:58<00:34,  3.30it/s]01/14/2022 16:26:31 - INFO - __main__ -   Batch number = 201
Evaluating:  64%|██████▍   | 201/313 [00:58<00:33,  3.33it/s]01/14/2022 16:26:31 - INFO - __main__ -   Batch number = 202
Evaluating:  65%|██████▍   | 202/313 [00:59<00:33,  3.36it/s]01/14/2022 16:26:31 - INFO - __main__ -   Batch number = 203
Evaluating:  65%|██████▍   | 203/313 [00:59<00:32,  3.39it/s]01/14/2022 16:26:32 - INFO - __main__ -   Batch number = 204
Evaluating:  65%|██████▌   | 204/313 [00:59<00:31,  3.41it/s]01/14/2022 16:26:32 - INFO - __main__ -   Batch number = 205
Evaluating:  65%|██████▌   | 205/313 [01:00<00:31,  3.42it/s]01/14/2022 16:26:32 - INFO - __main__ -   Batch number = 206
Evaluating:  66%|██████▌   | 206/313 [01:00<00:31,  3.42it/s]01/14/2022 16:26:33 - INFO - __main__ -   Batch number = 207
Evaluating:  66%|██████▌   | 207/313 [01:00<00:31,  3.42it/s]01/14/2022 16:26:33 - INFO - __main__ -   Batch number = 208
Evaluating:  66%|██████▋   | 208/313 [01:00<00:31,  3.37it/s]01/14/2022 16:26:33 - INFO - __main__ -   Batch number = 209
Evaluating:  67%|██████▋   | 209/313 [01:01<00:31,  3.34it/s]01/14/2022 16:26:34 - INFO - __main__ -   Batch number = 210
Evaluating:  67%|██████▋   | 210/313 [01:01<00:32,  3.17it/s]01/14/2022 16:26:34 - INFO - __main__ -   Batch number = 211
Evaluating:  67%|██████▋   | 211/313 [01:01<00:31,  3.25it/s]01/14/2022 16:26:34 - INFO - __main__ -   Batch number = 212
Evaluating:  68%|██████▊   | 212/313 [01:02<00:30,  3.31it/s]01/14/2022 16:26:34 - INFO - __main__ -   Batch number = 213
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:26:35 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:26:35 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:26:35 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:26:35 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:26:35 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:26:35 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,jv/wiki@ukp
01/14/2022 16:26:35 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'jv'], Length : 10
01/14/2022 16:26:35 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'jv/wiki@ukp'], Length : 10
01/14/2022 16:26:35 - INFO - __main__ -   Language = en
01/14/2022 16:26:35 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Evaluating:  68%|██████▊   | 213/313 [01:02<00:29,  3.35it/s]01/14/2022 16:26:35 - INFO - __main__ -   Batch number = 214
PyTorch version 1.10.1+cu102 available.
Evaluating:  68%|██████▊   | 214/313 [01:02<00:29,  3.37it/s]01/14/2022 16:26:35 - INFO - __main__ -   Batch number = 215
01/14/2022 16:26:35 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='sw', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:26:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:26:35 - INFO - __main__ -   Seed = 1
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
01/14/2022 16:26:35 - INFO - root -   save model
Adding adapter 'en' of type 'text_lang'.
01/14/2022 16:26:35 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='sw', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:26:35 - INFO - __main__ -   Loading pretrained model and tokenizer
Evaluating:  69%|██████▊   | 215/313 [01:03<00:28,  3.40it/s]01/14/2022 16:26:35 - INFO - __main__ -   Batch number = 216
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:26:35 - INFO - __main__ -   Language = pt
01/14/2022 16:26:35 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Evaluating:  69%|██████▉   | 216/313 [01:03<00:28,  3.42it/s]01/14/2022 16:26:36 - INFO - __main__ -   Batch number = 217
Evaluating:  69%|██████▉   | 217/313 [01:03<00:27,  3.43it/s]01/14/2022 16:26:36 - INFO - __main__ -   Batch number = 218
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  70%|██████▉   | 218/313 [01:03<00:27,  3.43it/s]01/14/2022 16:26:36 - INFO - __main__ -   Batch number = 219
Evaluating:  70%|██████▉   | 219/313 [01:04<00:27,  3.44it/s]01/14/2022 16:26:37 - INFO - __main__ -   Batch number = 220
Evaluating:  70%|███████   | 220/313 [01:04<00:27,  3.44it/s]01/14/2022 16:26:37 - INFO - __main__ -   Batch number = 221
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  71%|███████   | 221/313 [01:04<00:26,  3.43it/s]01/14/2022 16:26:37 - INFO - __main__ -   Batch number = 222
Evaluating:  71%|███████   | 222/313 [01:05<00:26,  3.43it/s]01/14/2022 16:26:37 - INFO - __main__ -   Batch number = 223
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:26:38 - INFO - __main__ -   Language = id
01/14/2022 16:26:38 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Evaluating:  71%|███████   | 223/313 [01:05<00:26,  3.42it/s]01/14/2022 16:26:38 - INFO - __main__ -   Batch number = 224
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Evaluating:  72%|███████▏  | 224/313 [01:05<00:26,  3.40it/s]01/14/2022 16:26:38 - INFO - __main__ -   Batch number = 225
01/14/2022 16:26:38 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Evaluating:  72%|███████▏  | 225/313 [01:05<00:25,  3.39it/s]01/14/2022 16:26:38 - INFO - __main__ -   Batch number = 226
Evaluating:  72%|███████▏  | 226/313 [01:06<00:25,  3.38it/s]01/14/2022 16:26:39 - INFO - __main__ -   Batch number = 227
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Evaluating:  73%|███████▎  | 227/313 [01:06<00:28,  3.07it/s]01/14/2022 16:26:39 - INFO - __main__ -   Batch number = 228
Evaluating:  73%|███████▎  | 228/313 [01:06<00:27,  3.12it/s]01/14/2022 16:26:39 - INFO - __main__ -   Batch number = 229
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Evaluating:  73%|███████▎  | 229/313 [01:07<00:26,  3.16it/s]01/14/2022 16:26:40 - INFO - __main__ -   Batch number = 230
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:26:40 - INFO - __main__ -   Language = tr
01/14/2022 16:26:40 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Evaluating:  73%|███████▎  | 230/313 [01:07<00:25,  3.20it/s]01/14/2022 16:26:40 - INFO - __main__ -   Batch number = 231
Evaluating:  74%|███████▍  | 231/313 [01:07<00:25,  3.27it/s]01/14/2022 16:26:40 - INFO - __main__ -   Batch number = 232
Evaluating:  74%|███████▍  | 232/313 [01:08<00:24,  3.32it/s]01/14/2022 16:26:40 - INFO - __main__ -   Batch number = 233
Evaluating:  74%|███████▍  | 233/313 [01:08<00:23,  3.35it/s]01/14/2022 16:26:41 - INFO - __main__ -   Batch number = 234
Evaluating:  75%|███████▍  | 234/313 [01:08<00:23,  3.38it/s]01/14/2022 16:26:41 - INFO - __main__ -   Batch number = 235
Evaluating:  75%|███████▌  | 235/313 [01:09<00:22,  3.40it/s]01/14/2022 16:26:41 - INFO - __main__ -   Batch number = 236
Evaluating:  75%|███████▌  | 236/313 [01:09<00:22,  3.43it/s]01/14/2022 16:26:42 - INFO - __main__ -   Batch number = 237
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:26:42 - INFO - __main__ -   Language = vi
01/14/2022 16:26:42 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  76%|███████▌  | 237/313 [01:09<00:22,  3.44it/s]01/14/2022 16:26:42 - INFO - __main__ -   Batch number = 238
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Evaluating:  76%|███████▌  | 238/313 [01:09<00:21,  3.44it/s]01/14/2022 16:26:42 - INFO - __main__ -   Batch number = 239
Evaluating:  76%|███████▋  | 239/313 [01:10<00:21,  3.45it/s]01/14/2022 16:26:42 - INFO - __main__ -   Batch number = 240
Evaluating:  77%|███████▋  | 240/313 [01:10<00:21,  3.45it/s]01/14/2022 16:26:43 - INFO - __main__ -   Batch number = 241
Evaluating:  77%|███████▋  | 241/313 [01:10<00:21,  3.43it/s]01/14/2022 16:26:43 - INFO - __main__ -   Batch number = 242
Evaluating:  77%|███████▋  | 242/313 [01:11<00:20,  3.42it/s]01/14/2022 16:26:43 - INFO - __main__ -   Batch number = 243
Evaluating:  78%|███████▊  | 243/313 [01:11<00:20,  3.43it/s]01/14/2022 16:26:44 - INFO - __main__ -   Batch number = 244
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:26:44 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:26:44 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:26:44 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:26:44 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:26:44 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:26:44 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,sw/wiki@ukp
01/14/2022 16:26:44 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'sw'], Length : 10
01/14/2022 16:26:44 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'sw/wiki@ukp'], Length : 10
01/14/2022 16:26:44 - INFO - __main__ -   Language = en
01/14/2022 16:26:44 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Evaluating:  78%|███████▊  | 244/313 [01:11<00:20,  3.33it/s]01/14/2022 16:26:44 - INFO - __main__ -   Batch number = 245
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:26:44 - INFO - __main__ -   Language = fa
01/14/2022 16:26:44 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
Evaluating:  78%|███████▊  | 245/313 [01:11<00:20,  3.37it/s]01/14/2022 16:26:44 - INFO - __main__ -   Batch number = 246
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Evaluating:  79%|███████▊  | 246/313 [01:12<00:19,  3.40it/s]01/14/2022 16:26:45 - INFO - __main__ -   Batch number = 247
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:26:45 - INFO - __main__ -   Language = pt
01/14/2022 16:26:45 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Evaluating:  79%|███████▉  | 247/313 [01:12<00:19,  3.40it/s]01/14/2022 16:26:45 - INFO - __main__ -   Batch number = 248
Evaluating:  79%|███████▉  | 248/313 [01:12<00:19,  3.41it/s]01/14/2022 16:26:45 - INFO - __main__ -   Batch number = 249
Evaluating:  80%|███████▉  | 249/313 [01:13<00:18,  3.41it/s]01/14/2022 16:26:45 - INFO - __main__ -   Batch number = 250
Evaluating:  80%|███████▉  | 250/313 [01:13<00:19,  3.30it/s]01/14/2022 16:26:46 - INFO - __main__ -   Batch number = 251
Evaluating:  80%|████████  | 251/313 [01:13<00:18,  3.29it/s]01/14/2022 16:26:46 - INFO - __main__ -   Batch number = 252
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:26:46 - INFO - __main__ -   Language = eu
01/14/2022 16:26:46 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
Evaluating:  81%|████████  | 252/313 [01:14<00:18,  3.34it/s]01/14/2022 16:26:46 - INFO - __main__ -   Batch number = 253
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Evaluating:  81%|████████  | 253/313 [01:14<00:17,  3.37it/s]01/14/2022 16:26:47 - INFO - __main__ -   Batch number = 254
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:26:47 - INFO - __main__ -   Language = id
01/14/2022 16:26:47 - INFO - __main__ -   Adapter Name = id/wiki@ukp
Evaluating:  81%|████████  | 254/313 [01:14<00:17,  3.40it/s]01/14/2022 16:26:47 - INFO - __main__ -   Batch number = 255
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Evaluating:  81%|████████▏ | 255/313 [01:14<00:16,  3.42it/s]01/14/2022 16:26:47 - INFO - __main__ -   Batch number = 256
Evaluating:  82%|████████▏ | 256/313 [01:15<00:16,  3.41it/s]01/14/2022 16:26:48 - INFO - __main__ -   Batch number = 257
Evaluating:  82%|████████▏ | 257/313 [01:15<00:16,  3.40it/s]01/14/2022 16:26:48 - INFO - __main__ -   Batch number = 258
Evaluating:  82%|████████▏ | 258/313 [01:15<00:16,  3.40it/s]01/14/2022 16:26:48 - INFO - __main__ -   Batch number = 259
Evaluating:  83%|████████▎ | 259/313 [01:16<00:15,  3.39it/s]01/14/2022 16:26:48 - INFO - __main__ -   Batch number = 260
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:26:49 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:26:49 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating:  83%|████████▎ | 260/313 [01:16<00:15,  3.40it/s]01/14/2022 16:26:49 - INFO - __main__ -   Batch number = 261
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:26:49 - INFO - __main__ -   Language = cs
01/14/2022 16:26:49 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  83%|████████▎ | 261/313 [01:16<00:15,  3.40it/s]01/14/2022 16:26:49 - INFO - __main__ -   Batch number = 262
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Evaluating:  84%|████████▎ | 262/313 [01:17<00:14,  3.42it/s]01/14/2022 16:26:49 - INFO - __main__ -   Batch number = 263
Evaluating:  84%|████████▍ | 263/313 [01:17<00:14,  3.43it/s]01/14/2022 16:26:50 - INFO - __main__ -   Batch number = 264
Evaluating:  84%|████████▍ | 264/313 [01:17<00:14,  3.43it/s]01/14/2022 16:26:50 - INFO - __main__ -   Batch number = 265
Evaluating:  85%|████████▍ | 265/313 [01:17<00:13,  3.43it/s]01/14/2022 16:26:50 - INFO - __main__ -   Batch number = 266
Evaluating:  85%|████████▍ | 266/313 [01:18<00:13,  3.44it/s]01/14/2022 16:26:50 - INFO - __main__ -   Batch number = 267
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Evaluating:  85%|████████▌ | 267/313 [01:18<00:13,  3.45it/s]01/14/2022 16:26:51 - INFO - __main__ -   Batch number = 268
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:26:51 - INFO - __main__ -   Language = cs
01/14/2022 16:26:51 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Evaluating:  86%|████████▌ | 268/313 [01:18<00:13,  3.45it/s]01/14/2022 16:26:51 - INFO - __main__ -   Batch number = 269
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:26:51 - INFO - __main__ -   Language = tr
01/14/2022 16:26:51 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Evaluating:  86%|████████▌ | 269/313 [01:19<00:12,  3.45it/s]01/14/2022 16:26:51 - INFO - __main__ -   Batch number = 270
Evaluating:  86%|████████▋ | 270/313 [01:19<00:12,  3.44it/s]01/14/2022 16:26:52 - INFO - __main__ -   Batch number = 271
Evaluating:  87%|████████▋ | 271/313 [01:19<00:12,  3.39it/s]01/14/2022 16:26:52 - INFO - __main__ -   Batch number = 272
Evaluating:  87%|████████▋ | 272/313 [01:19<00:12,  3.32it/s]01/14/2022 16:26:52 - INFO - __main__ -   Batch number = 273
Evaluating:  87%|████████▋ | 273/313 [01:20<00:12,  3.32it/s]01/14/2022 16:26:53 - INFO - __main__ -   Batch number = 274
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:26:53 - INFO - __main__ -   Language = jv
01/14/2022 16:26:53 - INFO - __main__ -   Adapter Name = jv/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  88%|████████▊ | 274/313 [01:20<00:11,  3.35it/s]01/14/2022 16:26:53 - INFO - __main__ -   Batch number = 275
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/jv/bert-base-multilingual-cased/pfeiffer/jv_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Evaluating:  88%|████████▊ | 275/313 [01:20<00:11,  3.37it/s]01/14/2022 16:26:53 - INFO - __main__ -   Batch number = 276
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:26:53 - INFO - __main__ -   Language = eu
01/14/2022 16:26:53 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Evaluating:  88%|████████▊ | 276/313 [01:21<00:10,  3.39it/s]01/14/2022 16:26:53 - INFO - __main__ -   Batch number = 277
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted/adapter_config.json
Adding adapter 'jv' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/6941802279903288ca526354db7f3d2dcd9de38afde2701527ba775bd134f8c4-90fa0934a71af4c2767d04f288f221fb83a267fa470e5e17832498344fee250c-extracted'
Evaluating:  88%|████████▊ | 277/313 [01:21<00:10,  3.40it/s]01/14/2022 16:26:54 - INFO - __main__ -   Batch number = 278
Evaluating:  89%|████████▉ | 278/313 [01:21<00:10,  3.42it/s]01/14/2022 16:26:54 - INFO - __main__ -   Batch number = 279
Evaluating:  89%|████████▉ | 279/313 [01:21<00:09,  3.41it/s]01/14/2022 16:26:54 - INFO - __main__ -   Batch number = 280
Evaluating:  89%|████████▉ | 280/313 [01:22<00:09,  3.38it/s]01/14/2022 16:26:55 - INFO - __main__ -   Batch number = 281
Evaluating:  90%|████████▉ | 281/313 [01:22<00:09,  3.38it/s]01/14/2022 16:26:55 - INFO - __main__ -   Batch number = 282
Evaluating:  90%|█████████ | 282/313 [01:22<00:09,  3.37it/s]01/14/2022 16:26:55 - INFO - __main__ -   Batch number = 283
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:26:55 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:26:55 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
Evaluating:  90%|█████████ | 283/313 [01:23<00:08,  3.38it/s]01/14/2022 16:26:55 - INFO - __main__ -   Batch number = 284
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating:  91%|█████████ | 284/313 [01:23<00:08,  3.39it/s]01/14/2022 16:26:56 - INFO - __main__ -   Batch number = 285
Evaluating:  91%|█████████ | 285/313 [01:23<00:08,  3.40it/s]01/14/2022 16:26:56 - INFO - __main__ -   Batch number = 286
Evaluating:  91%|█████████▏| 286/313 [01:24<00:07,  3.42it/s]01/14/2022 16:26:56 - INFO - __main__ -   Batch number = 287
Evaluating:  92%|█████████▏| 287/313 [01:24<00:07,  3.43it/s]01/14/2022 16:26:57 - INFO - __main__ -   Batch number = 288
Evaluating:  92%|█████████▏| 288/313 [01:24<00:07,  3.43it/s]01/14/2022 16:26:57 - INFO - __main__ -   Batch number = 289
Evaluating:  92%|█████████▏| 289/313 [01:24<00:07,  3.42it/s]01/14/2022 16:26:57 - INFO - __main__ -   Batch number = 290
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
01/14/2022 16:26:57 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:26:57 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'jv']
01/14/2022 16:26:57 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:26:57 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:26:57 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:26:57 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_jv_bert-base-multilingual-cased_128
01/14/2022 16:26:58 - INFO - __main__ -   ***** Running evaluation  in jv *****
01/14/2022 16:26:58 - INFO - __main__ -     Num examples = 100
01/14/2022 16:26:58 - INFO - __main__ -     Batch size = 32
Evaluating:  93%|█████████▎| 290/313 [01:25<00:06,  3.43it/s]01/14/2022 16:26:58 - INFO - __main__ -   Batch number = 291
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:26:58 - INFO - __main__ -   Batch number = 1
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:26:58 - INFO - __main__ -   Language = vi
01/14/2022 16:26:58 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Evaluating:  93%|█████████▎| 291/313 [01:25<00:06,  3.44it/s]01/14/2022 16:26:58 - INFO - __main__ -   Batch number = 292
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.22it/s]01/14/2022 16:26:58 - INFO - __main__ -   Batch number = 2
Evaluating:  93%|█████████▎| 292/313 [01:25<00:06,  3.44it/s]01/14/2022 16:26:58 - INFO - __main__ -   Batch number = 293
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.43it/s]01/14/2022 16:26:58 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.53it/s]01/14/2022 16:26:58 - INFO - __main__ -   Batch number = 4
Evaluating:  94%|█████████▎| 293/313 [01:26<00:05,  3.45it/s]01/14/2022 16:26:58 - INFO - __main__ -   Batch number = 294
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.41it/s]
01/14/2022 16:26:58 - INFO - __main__ -   ***** Evaluation result  in jv *****
01/14/2022 16:26:58 - INFO - __main__ -     f1 = 0.5555555555555556
01/14/2022 16:26:58 - INFO - __main__ -     loss = 3.3965357840061188
01/14/2022 16:26:58 - INFO - __main__ -     precision = 0.49019607843137253
01/14/2022 16:26:58 - INFO - __main__ -     recall = 0.6410256410256411
Evaluating:  94%|█████████▍| 294/313 [01:26<00:05,  3.36it/s]01/14/2022 16:26:59 - INFO - __main__ -   Batch number = 295
Evaluating:  94%|█████████▍| 295/313 [01:26<00:05,  3.31it/s]01/14/2022 16:26:59 - INFO - __main__ -   Batch number = 296
35.79user 13.81system 0:34.55elapsed 143%CPU (0avgtext+0avgdata 4225528maxresident)k
0inputs+88outputs (0major+2348032minor)pagefaults 0swaps
Evaluating:  95%|█████████▍| 296/313 [01:27<00:05,  3.29it/s]01/14/2022 16:26:59 - INFO - __main__ -   Batch number = 297
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Evaluating:  95%|█████████▍| 297/313 [01:27<00:04,  3.26it/s]01/14/2022 16:27:00 - INFO - __main__ -   Batch number = 298
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:27:00 - INFO - __main__ -   Language = fr
01/14/2022 16:27:00 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  95%|█████████▌| 298/313 [01:27<00:04,  3.23it/s]01/14/2022 16:27:00 - INFO - __main__ -   Batch number = 299
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Evaluating:  96%|█████████▌| 299/313 [01:27<00:04,  3.24it/s]01/14/2022 16:27:00 - INFO - __main__ -   Batch number = 300
Evaluating:  96%|█████████▌| 300/313 [01:28<00:03,  3.28it/s]01/14/2022 16:27:01 - INFO - __main__ -   Batch number = 301
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:27:01 - INFO - __main__ -   Language = sw
01/14/2022 16:27:01 - INFO - __main__ -   Adapter Name = sw/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  96%|█████████▌| 301/313 [01:28<00:03,  3.31it/s]01/14/2022 16:27:01 - INFO - __main__ -   Batch number = 302
Evaluating:  96%|█████████▋| 302/313 [01:28<00:03,  3.31it/s]01/14/2022 16:27:01 - INFO - __main__ -   Batch number = 303
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/sw/bert-base-multilingual-cased/pfeiffer/sw_pfeiffer_gelu_nd.zip.
Evaluating:  97%|█████████▋| 303/313 [01:29<00:03,  3.30it/s]01/14/2022 16:27:01 - INFO - __main__ -   Batch number = 304
Evaluating:  97%|█████████▋| 304/313 [01:29<00:02,  3.27it/s]01/14/2022 16:27:02 - INFO - __main__ -   Batch number = 305
Loading module configuration from /home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted/adapter_config.json
Adding adapter 'sw' of type 'text_lang'.
Evaluating:  97%|█████████▋| 305/313 [01:29<00:02,  3.25it/s]01/14/2022 16:27:02 - INFO - __main__ -   Batch number = 306
Evaluating:  98%|█████████▊| 306/313 [01:30<00:02,  3.23it/s]01/14/2022 16:27:02 - INFO - __main__ -   Batch number = 307
Loading module weights from /home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted'
Evaluating:  98%|█████████▊| 307/313 [01:30<00:01,  3.20it/s]01/14/2022 16:27:03 - INFO - __main__ -   Batch number = 308
Evaluating:  98%|█████████▊| 308/313 [01:30<00:01,  3.25it/s]01/14/2022 16:27:03 - INFO - __main__ -   Batch number = 309
Evaluating:  99%|█████████▊| 309/313 [01:31<00:01,  3.29it/s]01/14/2022 16:27:03 - INFO - __main__ -   Batch number = 310
Evaluating:  99%|█████████▉| 310/313 [01:31<00:00,  3.29it/s]01/14/2022 16:27:04 - INFO - __main__ -   Batch number = 311
Evaluating:  99%|█████████▉| 311/313 [01:31<00:00,  3.28it/s]01/14/2022 16:27:04 - INFO - __main__ -   Batch number = 312
Evaluating: 100%|█████████▉| 312/313 [01:31<00:00,  3.27it/s]01/14/2022 16:27:04 - INFO - __main__ -   Batch number = 313
Evaluating: 100%|██████████| 313/313 [01:32<00:00,  3.78it/s]Evaluating: 100%|██████████| 313/313 [01:32<00:00,  3.40it/s]
01/14/2022 16:27:06 - INFO - __main__ -   ***** Evaluation result  in ar *****
01/14/2022 16:27:06 - INFO - __main__ -     f1 = 0.36017038505335075
01/14/2022 16:27:06 - INFO - __main__ -     loss = 5.191140273889413
01/14/2022 16:27:06 - INFO - __main__ -     precision = 0.34291680051397366
01/14/2022 16:27:06 - INFO - __main__ -     recall = 0.37925215383248956
01/14/2022 16:27:06 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:27:06 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'sw']
01/14/2022 16:27:06 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:27:06 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:27:06 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:27:06 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_sw_bert-base-multilingual-cased_128
01/14/2022 16:27:06 - INFO - __main__ -   ***** Running evaluation  in sw *****
01/14/2022 16:27:06 - INFO - __main__ -     Num examples = 1000
01/14/2022 16:27:06 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]01/14/2022 16:27:06 - INFO - __main__ -   Batch number = 1
100.30user 38.03system 2:03.25elapsed 112%CPU (0avgtext+0avgdata 4224860maxresident)k
0inputs+872outputs (0major+2827497minor)pagefaults 0swaps
Evaluating:   3%|▎         | 1/32 [00:00<00:09,  3.42it/s]01/14/2022 16:27:07 - INFO - __main__ -   Batch number = 2
Evaluating:   6%|▋         | 2/32 [00:00<00:08,  3.52it/s]01/14/2022 16:27:07 - INFO - __main__ -   Batch number = 3
Evaluating:   9%|▉         | 3/32 [00:00<00:08,  3.56it/s]01/14/2022 16:27:07 - INFO - __main__ -   Batch number = 4
Evaluating:  12%|█▎        | 4/32 [00:01<00:07,  3.58it/s]01/14/2022 16:27:07 - INFO - __main__ -   Batch number = 5
Evaluating:  16%|█▌        | 5/32 [00:01<00:07,  3.58it/s]01/14/2022 16:27:08 - INFO - __main__ -   Batch number = 6
Evaluating:  19%|█▉        | 6/32 [00:01<00:07,  3.58it/s]01/14/2022 16:27:08 - INFO - __main__ -   Batch number = 7
Evaluating:  22%|██▏       | 7/32 [00:01<00:06,  3.59it/s]01/14/2022 16:27:08 - INFO - __main__ -   Batch number = 8
Evaluating:  25%|██▌       | 8/32 [00:02<00:06,  3.60it/s]01/14/2022 16:27:08 - INFO - __main__ -   Batch number = 9
Evaluating:  28%|██▊       | 9/32 [00:02<00:06,  3.60it/s]01/14/2022 16:27:09 - INFO - __main__ -   Batch number = 10
Evaluating:  31%|███▏      | 10/32 [00:02<00:06,  3.60it/s]01/14/2022 16:27:09 - INFO - __main__ -   Batch number = 11
Evaluating:  34%|███▍      | 11/32 [00:03<00:05,  3.60it/s]01/14/2022 16:27:09 - INFO - __main__ -   Batch number = 12
Evaluating:  38%|███▊      | 12/32 [00:03<00:05,  3.60it/s]01/14/2022 16:27:10 - INFO - __main__ -   Batch number = 13
Evaluating:  41%|████      | 13/32 [00:03<00:05,  3.60it/s]01/14/2022 16:27:10 - INFO - __main__ -   Batch number = 14
Evaluating:  44%|████▍     | 14/32 [00:03<00:05,  3.60it/s]01/14/2022 16:27:10 - INFO - __main__ -   Batch number = 15
Evaluating:  47%|████▋     | 15/32 [00:04<00:04,  3.59it/s]01/14/2022 16:27:10 - INFO - __main__ -   Batch number = 16
Evaluating:  50%|█████     | 16/32 [00:04<00:04,  3.59it/s]01/14/2022 16:27:11 - INFO - __main__ -   Batch number = 17
Evaluating:  53%|█████▎    | 17/32 [00:04<00:04,  3.59it/s]01/14/2022 16:27:11 - INFO - __main__ -   Batch number = 18
Evaluating:  56%|█████▋    | 18/32 [00:05<00:03,  3.59it/s]01/14/2022 16:27:11 - INFO - __main__ -   Batch number = 19
Evaluating:  59%|█████▉    | 19/32 [00:05<00:04,  3.22it/s]01/14/2022 16:27:12 - INFO - __main__ -   Batch number = 20
Evaluating:  62%|██████▎   | 20/32 [00:05<00:03,  3.33it/s]01/14/2022 16:27:12 - INFO - __main__ -   Batch number = 21
Evaluating:  66%|██████▌   | 21/32 [00:05<00:03,  3.39it/s]01/14/2022 16:27:12 - INFO - __main__ -   Batch number = 22
Evaluating:  69%|██████▉   | 22/32 [00:06<00:02,  3.44it/s]01/14/2022 16:27:12 - INFO - __main__ -   Batch number = 23
Evaluating:  72%|███████▏  | 23/32 [00:06<00:02,  3.47it/s]01/14/2022 16:27:13 - INFO - __main__ -   Batch number = 24
Evaluating:  75%|███████▌  | 24/32 [00:06<00:02,  3.50it/s]01/14/2022 16:27:13 - INFO - __main__ -   Batch number = 25
Evaluating:  78%|███████▊  | 25/32 [00:07<00:01,  3.52it/s]01/14/2022 16:27:13 - INFO - __main__ -   Batch number = 26
Evaluating:  81%|████████▏ | 26/32 [00:07<00:01,  3.53it/s]01/14/2022 16:27:14 - INFO - __main__ -   Batch number = 27
Evaluating:  84%|████████▍ | 27/32 [00:07<00:01,  3.53it/s]01/14/2022 16:27:14 - INFO - __main__ -   Batch number = 28
Evaluating:  88%|████████▊ | 28/32 [00:07<00:01,  3.54it/s]01/14/2022 16:27:14 - INFO - __main__ -   Batch number = 29
Evaluating:  91%|█████████ | 29/32 [00:08<00:00,  3.54it/s]01/14/2022 16:27:14 - INFO - __main__ -   Batch number = 30
Evaluating:  94%|█████████▍| 30/32 [00:08<00:00,  3.54it/s]01/14/2022 16:27:15 - INFO - __main__ -   Batch number = 31
Evaluating:  97%|█████████▋| 31/32 [00:08<00:00,  3.53it/s]01/14/2022 16:27:15 - INFO - __main__ -   Batch number = 32
Evaluating: 100%|██████████| 32/32 [00:08<00:00,  3.61it/s]
01/14/2022 16:27:15 - INFO - __main__ -   ***** Evaluation result  in sw *****
01/14/2022 16:27:15 - INFO - __main__ -     f1 = 0.6042823156225218
01/14/2022 16:27:15 - INFO - __main__ -     loss = 3.31079875677824
01/14/2022 16:27:15 - INFO - __main__ -     precision = 0.5737951807228916
01/14/2022 16:27:15 - INFO - __main__ -     recall = 0.6381909547738693
40.80user 14.79system 0:42.08elapsed 132%CPU (0avgtext+0avgdata 4227568maxresident)k
99512inputs+136outputs (0major+2169427minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:27:17 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='sw', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:27:17 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:27:17 - INFO - __main__ -   Seed = 2
01/14/2022 16:27:17 - INFO - root -   save model
01/14/2022 16:27:17 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='sw', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:27:17 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:27:20 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:27:26 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:27:26 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:27:26 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:27:26 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:27:26 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:27:26 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,sw/wiki@ukp
01/14/2022 16:27:26 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'sw'], Length : 10
01/14/2022 16:27:26 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'sw/wiki@ukp'], Length : 10
01/14/2022 16:27:26 - INFO - __main__ -   Language = en
01/14/2022 16:27:26 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:27:27 - INFO - __main__ -   Language = pt
01/14/2022 16:27:27 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:27:28 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='is', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:27:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:27:28 - INFO - __main__ -   Seed = 1
01/14/2022 16:27:28 - INFO - root -   save model
01/14/2022 16:27:28 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='is', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:27:28 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:27:29 - INFO - __main__ -   Language = id
01/14/2022 16:27:29 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:27:31 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:27:31 - INFO - __main__ -   Language = tr
01/14/2022 16:27:31 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:27:33 - INFO - __main__ -   Language = cs
01/14/2022 16:27:33 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:27:36 - INFO - __main__ -   Language = vi
01/14/2022 16:27:36 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:27:36 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:27:36 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:27:36 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:27:36 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:27:36 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:27:37 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,is/wiki@ukp
01/14/2022 16:27:37 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'is'], Length : 10
01/14/2022 16:27:37 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'is/wiki@ukp'], Length : 10
01/14/2022 16:27:37 - INFO - __main__ -   Language = en
01/14/2022 16:27:37 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:27:37 - INFO - __main__ -   Language = pt
01/14/2022 16:27:37 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:27:38 - INFO - __main__ -   Language = eu
01/14/2022 16:27:38 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:27:39 - INFO - __main__ -   Language = id
01/14/2022 16:27:39 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:27:40 - INFO - __main__ -   Language = fa
01/14/2022 16:27:40 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:27:42 - INFO - __main__ -   Language = cs
01/14/2022 16:27:42 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:27:42 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:27:42 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:27:44 - INFO - __main__ -   Language = tr
01/14/2022 16:27:44 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:27:44 - INFO - __main__ -   Language = sw
01/14/2022 16:27:44 - INFO - __main__ -   Adapter Name = sw/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/sw/bert-base-multilingual-cased/pfeiffer/sw_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted/adapter_config.json
Adding adapter 'sw' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:27:46 - INFO - __main__ -   Language = eu
01/14/2022 16:27:46 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:27:48 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:27:48 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
01/14/2022 16:27:49 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:27:49 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'sw']
01/14/2022 16:27:49 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:27:49 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:27:49 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:27:49 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_sw_bert-base-multilingual-cased_128
01/14/2022 16:27:49 - INFO - __main__ -   ***** Running evaluation  in sw *****
01/14/2022 16:27:49 - INFO - __main__ -     Num examples = 1000
01/14/2022 16:27:49 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]01/14/2022 16:27:49 - INFO - __main__ -   Batch number = 1
Evaluating:   3%|▎         | 1/32 [00:00<00:09,  3.25it/s]01/14/2022 16:27:49 - INFO - __main__ -   Batch number = 2
Evaluating:   6%|▋         | 2/32 [00:00<00:08,  3.43it/s]01/14/2022 16:27:49 - INFO - __main__ -   Batch number = 3
Evaluating:   9%|▉         | 3/32 [00:00<00:08,  3.50it/s]01/14/2022 16:27:49 - INFO - __main__ -   Batch number = 4
Evaluating:  12%|█▎        | 4/32 [00:01<00:07,  3.53it/s]01/14/2022 16:27:50 - INFO - __main__ -   Batch number = 5
Evaluating:  16%|█▌        | 5/32 [00:01<00:07,  3.56it/s]01/14/2022 16:27:50 - INFO - __main__ -   Batch number = 6
Evaluating:  19%|█▉        | 6/32 [00:01<00:07,  3.57it/s]01/14/2022 16:27:50 - INFO - __main__ -   Batch number = 7
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:27:51 - INFO - __main__ -   Language = vi
01/14/2022 16:27:51 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
Evaluating:  22%|██▏       | 7/32 [00:01<00:06,  3.58it/s]No exactly matching adapter config found for this specifier, falling back to default.
01/14/2022 16:27:51 - INFO - __main__ -   Batch number = 8
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Evaluating:  25%|██▌       | 8/32 [00:02<00:06,  3.58it/s]01/14/2022 16:27:51 - INFO - __main__ -   Batch number = 9
Evaluating:  28%|██▊       | 9/32 [00:02<00:06,  3.59it/s]01/14/2022 16:27:51 - INFO - __main__ -   Batch number = 10
Evaluating:  31%|███▏      | 10/32 [00:02<00:06,  3.59it/s]01/14/2022 16:27:51 - INFO - __main__ -   Batch number = 11
Evaluating:  34%|███▍      | 11/32 [00:03<00:05,  3.57it/s]01/14/2022 16:27:52 - INFO - __main__ -   Batch number = 12
Evaluating:  38%|███▊      | 12/32 [00:03<00:06,  3.04it/s]01/14/2022 16:27:52 - INFO - __main__ -   Batch number = 13
Evaluating:  41%|████      | 13/32 [00:03<00:05,  3.19it/s]01/14/2022 16:27:52 - INFO - __main__ -   Batch number = 14
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Evaluating:  44%|████▍     | 14/32 [00:04<00:05,  3.30it/s]01/14/2022 16:27:53 - INFO - __main__ -   Batch number = 15
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:27:53 - INFO - __main__ -   Language = fr
01/14/2022 16:27:53 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Evaluating:  47%|████▋     | 15/32 [00:04<00:05,  3.37it/s]01/14/2022 16:27:53 - INFO - __main__ -   Batch number = 16
Evaluating:  50%|█████     | 16/32 [00:04<00:04,  3.43it/s]01/14/2022 16:27:53 - INFO - __main__ -   Batch number = 17
Evaluating:  53%|█████▎    | 17/32 [00:04<00:04,  3.47it/s]01/14/2022 16:27:54 - INFO - __main__ -   Batch number = 18
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:27:54 - INFO - __main__ -   Language = is
01/14/2022 16:27:54 - INFO - __main__ -   Adapter Name = is/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  56%|█████▋    | 18/32 [00:05<00:04,  3.47it/s]01/14/2022 16:27:54 - INFO - __main__ -   Batch number = 19
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/is/bert-base-multilingual-cased/pfeiffer/is_pfeiffer_gelu_nd.zip.
Evaluating:  59%|█████▉    | 19/32 [00:05<00:03,  3.49it/s]01/14/2022 16:27:54 - INFO - __main__ -   Batch number = 20
Evaluating:  62%|██████▎   | 20/32 [00:05<00:03,  3.51it/s]01/14/2022 16:27:54 - INFO - __main__ -   Batch number = 21
Evaluating:  66%|██████▌   | 21/32 [00:06<00:03,  3.53it/s]01/14/2022 16:27:55 - INFO - __main__ -   Batch number = 22
Loading module configuration from /home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted/adapter_config.json
Adding adapter 'is' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted'
Evaluating:  69%|██████▉   | 22/32 [00:06<00:02,  3.52it/s]01/14/2022 16:27:55 - INFO - __main__ -   Batch number = 23
Evaluating:  72%|███████▏  | 23/32 [00:06<00:02,  3.53it/s]01/14/2022 16:27:55 - INFO - __main__ -   Batch number = 24
Evaluating:  75%|███████▌  | 24/32 [00:06<00:02,  3.53it/s]01/14/2022 16:27:56 - INFO - __main__ -   Batch number = 25
Evaluating:  78%|███████▊  | 25/32 [00:07<00:01,  3.54it/s]01/14/2022 16:27:56 - INFO - __main__ -   Batch number = 26
Evaluating:  81%|████████▏ | 26/32 [00:07<00:01,  3.53it/s]01/14/2022 16:27:56 - INFO - __main__ -   Batch number = 27
Evaluating:  84%|████████▍ | 27/32 [00:07<00:01,  3.53it/s]01/14/2022 16:27:56 - INFO - __main__ -   Batch number = 28
Evaluating:  88%|████████▊ | 28/32 [00:08<00:01,  3.54it/s]01/14/2022 16:27:57 - INFO - __main__ -   Batch number = 29
Evaluating:  91%|█████████ | 29/32 [00:08<00:00,  3.54it/s]01/14/2022 16:27:57 - INFO - __main__ -   Batch number = 30
Evaluating:  94%|█████████▍| 30/32 [00:08<00:00,  3.55it/s]01/14/2022 16:27:57 - INFO - __main__ -   Batch number = 31
Evaluating:  97%|█████████▋| 31/32 [00:08<00:00,  3.54it/s]01/14/2022 16:27:58 - INFO - __main__ -   Batch number = 32
Evaluating: 100%|██████████| 32/32 [00:08<00:00,  3.56it/s]
01/14/2022 16:27:58 - INFO - __main__ -   ***** Evaluation result  in sw *****
01/14/2022 16:27:58 - INFO - __main__ -     f1 = 0.6304769290422645
01/14/2022 16:27:58 - INFO - __main__ -     loss = 2.5837175473570824
01/14/2022 16:27:58 - INFO - __main__ -     precision = 0.5870036101083033
01/14/2022 16:27:58 - INFO - __main__ -     recall = 0.6809045226130653
41.28user 15.88system 0:42.63elapsed 134%CPU (0avgtext+0avgdata 4225356maxresident)k
0inputs+128outputs (0major+2362262minor)pagefaults 0swaps
01/14/2022 16:27:58 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:27:58 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'is']
01/14/2022 16:27:58 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:27:58 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:27:58 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:27:58 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_is_bert-base-multilingual-cased_128
01/14/2022 16:27:59 - INFO - __main__ -   ***** Running evaluation  in is *****
01/14/2022 16:27:59 - INFO - __main__ -     Num examples = 1000
01/14/2022 16:27:59 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]01/14/2022 16:27:59 - INFO - __main__ -   Batch number = 1
Evaluating:   3%|▎         | 1/32 [00:00<00:09,  3.38it/s]01/14/2022 16:27:59 - INFO - __main__ -   Batch number = 2
Evaluating:   6%|▋         | 2/32 [00:00<00:08,  3.52it/s]01/14/2022 16:27:59 - INFO - __main__ -   Batch number = 3
Evaluating:   9%|▉         | 3/32 [00:00<00:08,  3.57it/s]01/14/2022 16:27:59 - INFO - __main__ -   Batch number = 4
PyTorch version 1.10.1+cu102 available.
Evaluating:  12%|█▎        | 4/32 [00:01<00:07,  3.58it/s]01/14/2022 16:28:00 - INFO - __main__ -   Batch number = 5
01/14/2022 16:28:00 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='sw', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:28:00 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:28:00 - INFO - __main__ -   Seed = 3
01/14/2022 16:28:00 - INFO - root -   save model
01/14/2022 16:28:00 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='sw', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:28:00 - INFO - __main__ -   Loading pretrained model and tokenizer
Evaluating:  16%|█▌        | 5/32 [00:01<00:07,  3.59it/s]01/14/2022 16:28:00 - INFO - __main__ -   Batch number = 6
Evaluating:  19%|█▉        | 6/32 [00:01<00:07,  3.60it/s]01/14/2022 16:28:00 - INFO - __main__ -   Batch number = 7
Evaluating:  22%|██▏       | 7/32 [00:01<00:06,  3.60it/s]01/14/2022 16:28:01 - INFO - __main__ -   Batch number = 8
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  25%|██▌       | 8/32 [00:02<00:06,  3.61it/s]01/14/2022 16:28:01 - INFO - __main__ -   Batch number = 9
Evaluating:  28%|██▊       | 9/32 [00:02<00:06,  3.61it/s]01/14/2022 16:28:01 - INFO - __main__ -   Batch number = 10
Evaluating:  31%|███▏      | 10/32 [00:02<00:06,  3.60it/s]01/14/2022 16:28:01 - INFO - __main__ -   Batch number = 11
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  34%|███▍      | 11/32 [00:03<00:05,  3.60it/s]01/14/2022 16:28:02 - INFO - __main__ -   Batch number = 12
Evaluating:  38%|███▊      | 12/32 [00:03<00:05,  3.60it/s]01/14/2022 16:28:02 - INFO - __main__ -   Batch number = 13
Evaluating:  41%|████      | 13/32 [00:03<00:05,  3.60it/s]01/14/2022 16:28:02 - INFO - __main__ -   Batch number = 14
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Evaluating:  44%|████▍     | 14/32 [00:03<00:04,  3.60it/s]01/14/2022 16:28:03 - INFO - __main__ -   Batch number = 15
01/14/2022 16:28:03 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Evaluating:  47%|████▋     | 15/32 [00:04<00:04,  3.60it/s]01/14/2022 16:28:03 - INFO - __main__ -   Batch number = 16
Evaluating:  50%|█████     | 16/32 [00:04<00:04,  3.60it/s]01/14/2022 16:28:03 - INFO - __main__ -   Batch number = 17
Evaluating:  53%|█████▎    | 17/32 [00:04<00:04,  3.60it/s]01/14/2022 16:28:03 - INFO - __main__ -   Batch number = 18
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Evaluating:  56%|█████▋    | 18/32 [00:05<00:03,  3.60it/s]01/14/2022 16:28:04 - INFO - __main__ -   Batch number = 19
Evaluating:  59%|█████▉    | 19/32 [00:05<00:03,  3.60it/s]01/14/2022 16:28:04 - INFO - __main__ -   Batch number = 20
Evaluating:  62%|██████▎   | 20/32 [00:05<00:03,  3.60it/s]01/14/2022 16:28:04 - INFO - __main__ -   Batch number = 21
Evaluating:  66%|██████▌   | 21/32 [00:05<00:03,  3.60it/s]01/14/2022 16:28:04 - INFO - __main__ -   Batch number = 22
Evaluating:  69%|██████▉   | 22/32 [00:06<00:02,  3.59it/s]01/14/2022 16:28:05 - INFO - __main__ -   Batch number = 23
Evaluating:  72%|███████▏  | 23/32 [00:06<00:02,  3.59it/s]01/14/2022 16:28:05 - INFO - __main__ -   Batch number = 24
Evaluating:  75%|███████▌  | 24/32 [00:06<00:02,  3.59it/s]01/14/2022 16:28:05 - INFO - __main__ -   Batch number = 25
Evaluating:  78%|███████▊  | 25/32 [00:07<00:02,  3.16it/s]01/14/2022 16:28:06 - INFO - __main__ -   Batch number = 26
Evaluating:  81%|████████▏ | 26/32 [00:07<00:01,  3.28it/s]01/14/2022 16:28:06 - INFO - __main__ -   Batch number = 27
Evaluating:  84%|████████▍ | 27/32 [00:07<00:01,  3.36it/s]01/14/2022 16:28:06 - INFO - __main__ -   Batch number = 28
Evaluating:  88%|████████▊ | 28/32 [00:07<00:01,  3.43it/s]01/14/2022 16:28:07 - INFO - __main__ -   Batch number = 29
Evaluating:  91%|█████████ | 29/32 [00:08<00:00,  3.47it/s]01/14/2022 16:28:07 - INFO - __main__ -   Batch number = 30
Evaluating:  94%|█████████▍| 30/32 [00:08<00:00,  3.51it/s]01/14/2022 16:28:07 - INFO - __main__ -   Batch number = 31
Evaluating:  97%|█████████▋| 31/32 [00:08<00:00,  3.53it/s]01/14/2022 16:28:07 - INFO - __main__ -   Batch number = 32
Evaluating: 100%|██████████| 32/32 [00:08<00:00,  3.62it/s]
01/14/2022 16:28:08 - INFO - __main__ -   ***** Evaluation result  in is *****
01/14/2022 16:28:08 - INFO - __main__ -     f1 = 0.6669181440965674
01/14/2022 16:28:08 - INFO - __main__ -     loss = 1.2107287272810936
01/14/2022 16:28:08 - INFO - __main__ -     precision = 0.6199158485273493
01/14/2022 16:28:08 - INFO - __main__ -     recall = 0.7216326530612245
42.44user 15.76system 0:41.84elapsed 139%CPU (0avgtext+0avgdata 4227596maxresident)k
0inputs+152outputs (0major+2345242minor)pagefaults 0swaps
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:28:09 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:28:09 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:28:09 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:28:09 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:28:09 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:28:09 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,sw/wiki@ukp
01/14/2022 16:28:09 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'sw'], Length : 10
01/14/2022 16:28:09 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'sw/wiki@ukp'], Length : 10
01/14/2022 16:28:09 - INFO - __main__ -   Language = en
01/14/2022 16:28:09 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:28:10 - INFO - __main__ -   Language = pt
01/14/2022 16:28:10 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:28:10 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='is', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:28:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:28:10 - INFO - __main__ -   Seed = 2
01/14/2022 16:28:10 - INFO - root -   save model
01/14/2022 16:28:10 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='is', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:28:10 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:28:11 - INFO - __main__ -   Language = id
01/14/2022 16:28:11 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
01/14/2022 16:28:13 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:28:13 - INFO - __main__ -   Language = tr
01/14/2022 16:28:13 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:28:14 - INFO - __main__ -   Language = vi
01/14/2022 16:28:14 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:28:16 - INFO - __main__ -   Language = fa
01/14/2022 16:28:16 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:28:18 - INFO - __main__ -   Language = eu
01/14/2022 16:28:18 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:28:18 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:28:18 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:28:18 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:28:18 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:28:18 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:28:18 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,is/wiki@ukp
01/14/2022 16:28:18 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'is'], Length : 10
01/14/2022 16:28:18 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'is/wiki@ukp'], Length : 10
01/14/2022 16:28:18 - INFO - __main__ -   Language = en
01/14/2022 16:28:18 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:28:19 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:28:19 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:28:19 - INFO - __main__ -   Language = pt
01/14/2022 16:28:19 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:28:21 - INFO - __main__ -   Language = cs
01/14/2022 16:28:21 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:28:21 - INFO - __main__ -   Language = id
01/14/2022 16:28:21 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:28:22 - INFO - __main__ -   Language = sw
01/14/2022 16:28:22 - INFO - __main__ -   Adapter Name = sw/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/sw/bert-base-multilingual-cased/pfeiffer/sw_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted/adapter_config.json
Adding adapter 'sw' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/17b77d35afc2862c3a75535ade7c98533ed192d237a964c90622e66bf62a83e3-7835ea52f96f9a9f1c234507ef57ba5deef9c86e97aa05ab96de4f6504051475-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:28:24 - INFO - __main__ -   Language = tr
01/14/2022 16:28:24 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:28:26 - INFO - __main__ -   Language = cs
01/14/2022 16:28:26 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
01/14/2022 16:28:27 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:28:27 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'sw']
01/14/2022 16:28:27 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:28:27 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:28:27 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:28:27 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_sw_bert-base-multilingual-cased_128
01/14/2022 16:28:27 - INFO - __main__ -   ***** Running evaluation  in sw *****
01/14/2022 16:28:27 - INFO - __main__ -     Num examples = 1000
01/14/2022 16:28:27 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]01/14/2022 16:28:27 - INFO - __main__ -   Batch number = 1
Evaluating:   3%|▎         | 1/32 [00:00<00:09,  3.26it/s]01/14/2022 16:28:27 - INFO - __main__ -   Batch number = 2
Evaluating:   6%|▋         | 2/32 [00:00<00:08,  3.43it/s]01/14/2022 16:28:28 - INFO - __main__ -   Batch number = 3
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:28:28 - INFO - __main__ -   Language = vi
01/14/2022 16:28:28 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
Evaluating:   9%|▉         | 3/32 [00:00<00:08,  3.51it/s]01/14/2022 16:28:28 - INFO - __main__ -   Batch number = 4
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Evaluating:  12%|█▎        | 4/32 [00:01<00:07,  3.54it/s]01/14/2022 16:28:28 - INFO - __main__ -   Batch number = 5
Evaluating:  16%|█▌        | 5/32 [00:01<00:07,  3.55it/s]01/14/2022 16:28:28 - INFO - __main__ -   Batch number = 6
Evaluating:  19%|█▉        | 6/32 [00:01<00:07,  3.56it/s]01/14/2022 16:28:29 - INFO - __main__ -   Batch number = 7
Evaluating:  22%|██▏       | 7/32 [00:01<00:07,  3.57it/s]01/14/2022 16:28:29 - INFO - __main__ -   Batch number = 8
Evaluating:  25%|██▌       | 8/32 [00:02<00:07,  3.02it/s]01/14/2022 16:28:29 - INFO - __main__ -   Batch number = 9
Evaluating:  28%|██▊       | 9/32 [00:02<00:07,  3.17it/s]01/14/2022 16:28:30 - INFO - __main__ -   Batch number = 10
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Evaluating:  31%|███▏      | 10/32 [00:02<00:06,  3.29it/s]01/14/2022 16:28:30 - INFO - __main__ -   Batch number = 11
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:28:30 - INFO - __main__ -   Language = eu
01/14/2022 16:28:30 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Evaluating:  34%|███▍      | 11/32 [00:03<00:06,  3.38it/s]01/14/2022 16:28:30 - INFO - __main__ -   Batch number = 12
Evaluating:  38%|███▊      | 12/32 [00:03<00:05,  3.43it/s]01/14/2022 16:28:31 - INFO - __main__ -   Batch number = 13
Evaluating:  41%|████      | 13/32 [00:03<00:05,  3.47it/s]01/14/2022 16:28:31 - INFO - __main__ -   Batch number = 14
Evaluating:  44%|████▍     | 14/32 [00:04<00:05,  3.50it/s]01/14/2022 16:28:31 - INFO - __main__ -   Batch number = 15
Evaluating:  47%|████▋     | 15/32 [00:04<00:04,  3.52it/s]01/14/2022 16:28:31 - INFO - __main__ -   Batch number = 16
Evaluating:  50%|█████     | 16/32 [00:04<00:04,  3.54it/s]01/14/2022 16:28:32 - INFO - __main__ -   Batch number = 17
Evaluating:  53%|█████▎    | 17/32 [00:04<00:04,  3.55it/s]01/14/2022 16:28:32 - INFO - __main__ -   Batch number = 18
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:28:32 - INFO - __main__ -   Language = fa
01/14/2022 16:28:32 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  56%|█████▋    | 18/32 [00:05<00:03,  3.56it/s]01/14/2022 16:28:32 - INFO - __main__ -   Batch number = 19
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Evaluating:  59%|█████▉    | 19/32 [00:05<00:03,  3.56it/s]01/14/2022 16:28:33 - INFO - __main__ -   Batch number = 20
Evaluating:  62%|██████▎   | 20/32 [00:05<00:03,  3.56it/s]01/14/2022 16:28:33 - INFO - __main__ -   Batch number = 21
Evaluating:  66%|██████▌   | 21/32 [00:06<00:03,  3.56it/s]01/14/2022 16:28:33 - INFO - __main__ -   Batch number = 22
Evaluating:  69%|██████▉   | 22/32 [00:06<00:02,  3.54it/s]01/14/2022 16:28:33 - INFO - __main__ -   Batch number = 23
Evaluating:  72%|███████▏  | 23/32 [00:06<00:02,  3.54it/s]01/14/2022 16:28:34 - INFO - __main__ -   Batch number = 24
Evaluating:  75%|███████▌  | 24/32 [00:06<00:02,  3.55it/s]01/14/2022 16:28:34 - INFO - __main__ -   Batch number = 25
Evaluating:  78%|███████▊  | 25/32 [00:07<00:01,  3.55it/s]01/14/2022 16:28:34 - INFO - __main__ -   Batch number = 26
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Evaluating:  81%|████████▏ | 26/32 [00:07<00:01,  3.55it/s]01/14/2022 16:28:35 - INFO - __main__ -   Batch number = 27
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:28:35 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:28:35 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating:  84%|████████▍ | 27/32 [00:07<00:01,  3.55it/s]01/14/2022 16:28:35 - INFO - __main__ -   Batch number = 28
Evaluating:  88%|████████▊ | 28/32 [00:08<00:01,  3.55it/s]01/14/2022 16:28:35 - INFO - __main__ -   Batch number = 29
Evaluating:  91%|█████████ | 29/32 [00:08<00:00,  3.55it/s]01/14/2022 16:28:35 - INFO - __main__ -   Batch number = 30
Evaluating:  94%|█████████▍| 30/32 [00:08<00:00,  3.56it/s]01/14/2022 16:28:36 - INFO - __main__ -   Batch number = 31
Evaluating:  97%|█████████▋| 31/32 [00:08<00:00,  3.56it/s]01/14/2022 16:28:36 - INFO - __main__ -   Batch number = 32
Evaluating: 100%|██████████| 32/32 [00:08<00:00,  3.57it/s]
01/14/2022 16:28:36 - INFO - __main__ -   ***** Evaluation result  in sw *****
01/14/2022 16:28:36 - INFO - __main__ -     f1 = 0.6183115338882283
01/14/2022 16:28:36 - INFO - __main__ -     loss = 3.2396500781178474
01/14/2022 16:28:36 - INFO - __main__ -     precision = 0.5869074492099323
01/14/2022 16:28:36 - INFO - __main__ -     recall = 0.6532663316582915
36.83user 16.13system 0:38.30elapsed 138%CPU (0avgtext+0avgdata 4225908maxresident)k
0inputs+176outputs (0major+2209894minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:28:37 - INFO - __main__ -   Language = is
01/14/2022 16:28:37 - INFO - __main__ -   Adapter Name = is/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/is/bert-base-multilingual-cased/pfeiffer/is_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted/adapter_config.json
Adding adapter 'is' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted'
01/14/2022 16:28:41 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:28:41 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'is']
01/14/2022 16:28:41 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:28:41 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:28:41 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:28:41 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_is_bert-base-multilingual-cased_128
01/14/2022 16:28:41 - INFO - __main__ -   ***** Running evaluation  in is *****
01/14/2022 16:28:41 - INFO - __main__ -     Num examples = 1000
01/14/2022 16:28:41 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]01/14/2022 16:28:41 - INFO - __main__ -   Batch number = 1
Evaluating:   3%|▎         | 1/32 [00:00<00:09,  3.22it/s]01/14/2022 16:28:41 - INFO - __main__ -   Batch number = 2
Evaluating:   6%|▋         | 2/32 [00:00<00:08,  3.40it/s]01/14/2022 16:28:42 - INFO - __main__ -   Batch number = 3
Evaluating:   9%|▉         | 3/32 [00:00<00:09,  3.13it/s]01/14/2022 16:28:42 - INFO - __main__ -   Batch number = 4
Evaluating:  12%|█▎        | 4/32 [00:01<00:08,  3.29it/s]01/14/2022 16:28:42 - INFO - __main__ -   Batch number = 5
Evaluating:  16%|█▌        | 5/32 [00:01<00:07,  3.39it/s]01/14/2022 16:28:42 - INFO - __main__ -   Batch number = 6
Evaluating:  19%|█▉        | 6/32 [00:01<00:07,  3.46it/s]01/14/2022 16:28:43 - INFO - __main__ -   Batch number = 7
Evaluating:  22%|██▏       | 7/32 [00:02<00:07,  3.50it/s]01/14/2022 16:28:43 - INFO - __main__ -   Batch number = 8
Evaluating:  25%|██▌       | 8/32 [00:02<00:06,  3.53it/s]01/14/2022 16:28:43 - INFO - __main__ -   Batch number = 9
Evaluating:  28%|██▊       | 9/32 [00:02<00:06,  3.55it/s]01/14/2022 16:28:44 - INFO - __main__ -   Batch number = 10
Evaluating:  31%|███▏      | 10/32 [00:02<00:06,  3.56it/s]01/14/2022 16:28:44 - INFO - __main__ -   Batch number = 11
Evaluating:  34%|███▍      | 11/32 [00:03<00:05,  3.57it/s]01/14/2022 16:28:44 - INFO - __main__ -   Batch number = 12
Evaluating:  38%|███▊      | 12/32 [00:03<00:05,  3.58it/s]01/14/2022 16:28:44 - INFO - __main__ -   Batch number = 13
Evaluating:  41%|████      | 13/32 [00:03<00:05,  3.58it/s]01/14/2022 16:28:45 - INFO - __main__ -   Batch number = 14
Evaluating:  44%|████▍     | 14/32 [00:04<00:05,  3.58it/s]01/14/2022 16:28:45 - INFO - __main__ -   Batch number = 15
Evaluating:  47%|████▋     | 15/32 [00:04<00:04,  3.58it/s]01/14/2022 16:28:45 - INFO - __main__ -   Batch number = 16
Evaluating:  50%|█████     | 16/32 [00:04<00:04,  3.59it/s]01/14/2022 16:28:46 - INFO - __main__ -   Batch number = 17
Evaluating:  53%|█████▎    | 17/32 [00:04<00:04,  3.58it/s]01/14/2022 16:28:46 - INFO - __main__ -   Batch number = 18
Evaluating:  56%|█████▋    | 18/32 [00:05<00:03,  3.58it/s]01/14/2022 16:28:46 - INFO - __main__ -   Batch number = 19
Evaluating:  59%|█████▉    | 19/32 [00:05<00:03,  3.57it/s]01/14/2022 16:28:46 - INFO - __main__ -   Batch number = 20
Evaluating:  62%|██████▎   | 20/32 [00:05<00:03,  3.58it/s]01/14/2022 16:28:47 - INFO - __main__ -   Batch number = 21
Evaluating:  66%|██████▌   | 21/32 [00:05<00:03,  3.57it/s]01/14/2022 16:28:47 - INFO - __main__ -   Batch number = 22
Evaluating:  69%|██████▉   | 22/32 [00:06<00:02,  3.58it/s]01/14/2022 16:28:47 - INFO - __main__ -   Batch number = 23
Evaluating:  72%|███████▏  | 23/32 [00:06<00:02,  3.57it/s]01/14/2022 16:28:47 - INFO - __main__ -   Batch number = 24
Evaluating:  75%|███████▌  | 24/32 [00:06<00:02,  3.57it/s]01/14/2022 16:28:48 - INFO - __main__ -   Batch number = 25
Evaluating:  78%|███████▊  | 25/32 [00:07<00:01,  3.56it/s]01/14/2022 16:28:48 - INFO - __main__ -   Batch number = 26
Evaluating:  81%|████████▏ | 26/32 [00:07<00:01,  3.56it/s]01/14/2022 16:28:48 - INFO - __main__ -   Batch number = 27
Evaluating:  84%|████████▍ | 27/32 [00:07<00:01,  3.56it/s]01/14/2022 16:28:49 - INFO - __main__ -   Batch number = 28
Evaluating:  88%|████████▊ | 28/32 [00:07<00:01,  3.56it/s]01/14/2022 16:28:49 - INFO - __main__ -   Batch number = 29
Evaluating:  91%|█████████ | 29/32 [00:08<00:00,  3.56it/s]01/14/2022 16:28:49 - INFO - __main__ -   Batch number = 30
Evaluating:  94%|█████████▍| 30/32 [00:08<00:00,  3.56it/s]01/14/2022 16:28:49 - INFO - __main__ -   Batch number = 31
Evaluating:  97%|█████████▋| 31/32 [00:08<00:00,  3.34it/s]01/14/2022 16:28:50 - INFO - __main__ -   Batch number = 32
Evaluating: 100%|██████████| 32/32 [00:08<00:00,  3.59it/s]
01/14/2022 16:28:50 - INFO - __main__ -   ***** Evaluation result  in is *****
01/14/2022 16:28:50 - INFO - __main__ -     f1 = 0.6755521706016756
01/14/2022 16:28:50 - INFO - __main__ -     loss = 1.2199478317052126
01/14/2022 16:28:50 - INFO - __main__ -     precision = 0.6331192005710207
01/14/2022 16:28:50 - INFO - __main__ -     recall = 0.7240816326530612
42.17user 15.45system 0:42.38elapsed 135%CPU (0avgtext+0avgdata 4239068maxresident)k
0inputs+112outputs (0major+2405470minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:28:52 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='is', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:28:52 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:28:52 - INFO - __main__ -   Seed = 3
01/14/2022 16:28:52 - INFO - root -   save model
01/14/2022 16:28:52 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='is', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:28:52 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:28:55 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:29:00 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:29:00 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:29:00 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:29:00 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:29:00 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:29:00 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,is/wiki@ukp
01/14/2022 16:29:00 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'is'], Length : 10
01/14/2022 16:29:00 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'is/wiki@ukp'], Length : 10
01/14/2022 16:29:00 - INFO - __main__ -   Language = en
01/14/2022 16:29:00 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:29:01 - INFO - __main__ -   Language = pt
01/14/2022 16:29:01 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:29:03 - INFO - __main__ -   Language = id
01/14/2022 16:29:03 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:29:04 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:29:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:29:04 - INFO - __main__ -   Seed = 1
01/14/2022 16:29:04 - INFO - root -   save model
01/14/2022 16:29:04 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:29:04 - INFO - __main__ -   Loading pretrained model and tokenizer
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:29:05 - INFO - __main__ -   Language = tr
01/14/2022 16:29:05 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:29:07 - INFO - __main__ -   Language = vi
01/14/2022 16:29:07 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
01/14/2022 16:29:07 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:29:08 - INFO - __main__ -   Language = fa
01/14/2022 16:29:08 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:29:10 - INFO - __main__ -   Language = eu
01/14/2022 16:29:10 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:29:11 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:29:11 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:29:12 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:29:12 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:29:12 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:29:12 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:29:12 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:29:12 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,my/wiki@ukp
01/14/2022 16:29:12 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'my'], Length : 10
01/14/2022 16:29:12 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'my/wiki@ukp'], Length : 10
01/14/2022 16:29:12 - INFO - __main__ -   Language = en
01/14/2022 16:29:12 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:29:13 - INFO - __main__ -   Language = cs
01/14/2022 16:29:13 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:29:13 - INFO - __main__ -   Language = pt
01/14/2022 16:29:13 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:29:14 - INFO - __main__ -   Language = is
01/14/2022 16:29:14 - INFO - __main__ -   Adapter Name = is/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/is/bert-base-multilingual-cased/pfeiffer/is_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted/adapter_config.json
Adding adapter 'is' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/9e33d05df2faefa3bc0c9362c76f6d832a092fa705c554c913660889d25971bd-ca498748f27d97f5ac394ca8b673871d44c30209e39a0678c92f272435c2e7db-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:29:15 - INFO - __main__ -   Language = id
01/14/2022 16:29:15 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:29:18 - INFO - __main__ -   Language = cs
01/14/2022 16:29:18 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
01/14/2022 16:29:19 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:29:19 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'is']
01/14/2022 16:29:19 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:29:19 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:29:19 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:29:19 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_is_bert-base-multilingual-cased_128
01/14/2022 16:29:19 - INFO - __main__ -   ***** Running evaluation  in is *****
01/14/2022 16:29:19 - INFO - __main__ -     Num examples = 1000
01/14/2022 16:29:19 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]01/14/2022 16:29:19 - INFO - __main__ -   Batch number = 1
Evaluating:   3%|▎         | 1/32 [00:00<00:09,  3.23it/s]01/14/2022 16:29:19 - INFO - __main__ -   Batch number = 2
Evaluating:   6%|▋         | 2/32 [00:00<00:08,  3.40it/s]01/14/2022 16:29:19 - INFO - __main__ -   Batch number = 3
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:29:20 - INFO - __main__ -   Language = tr
01/14/2022 16:29:20 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:   9%|▉         | 3/32 [00:00<00:08,  3.49it/s]01/14/2022 16:29:20 - INFO - __main__ -   Batch number = 4
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Evaluating:  12%|█▎        | 4/32 [00:01<00:07,  3.53it/s]01/14/2022 16:29:20 - INFO - __main__ -   Batch number = 5
Evaluating:  16%|█▌        | 5/32 [00:01<00:07,  3.55it/s]01/14/2022 16:29:20 - INFO - __main__ -   Batch number = 6
Evaluating:  19%|█▉        | 6/32 [00:01<00:07,  3.57it/s]01/14/2022 16:29:21 - INFO - __main__ -   Batch number = 7
Evaluating:  22%|██▏       | 7/32 [00:01<00:06,  3.57it/s]01/14/2022 16:29:21 - INFO - __main__ -   Batch number = 8
Evaluating:  25%|██▌       | 8/32 [00:02<00:06,  3.58it/s]01/14/2022 16:29:21 - INFO - __main__ -   Batch number = 9
Evaluating:  28%|██▊       | 9/32 [00:02<00:06,  3.57it/s]01/14/2022 16:29:21 - INFO - __main__ -   Batch number = 10
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Evaluating:  31%|███▏      | 10/32 [00:02<00:06,  3.58it/s]01/14/2022 16:29:22 - INFO - __main__ -   Batch number = 11
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:29:22 - INFO - __main__ -   Language = eu
01/14/2022 16:29:22 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Evaluating:  34%|███▍      | 11/32 [00:03<00:05,  3.57it/s]01/14/2022 16:29:22 - INFO - __main__ -   Batch number = 12
Evaluating:  38%|███▊      | 12/32 [00:03<00:05,  3.57it/s]01/14/2022 16:29:22 - INFO - __main__ -   Batch number = 13
Evaluating:  41%|████      | 13/32 [00:03<00:05,  3.57it/s]01/14/2022 16:29:23 - INFO - __main__ -   Batch number = 14
Evaluating:  44%|████▍     | 14/32 [00:03<00:05,  3.57it/s]01/14/2022 16:29:23 - INFO - __main__ -   Batch number = 15
Evaluating:  47%|████▋     | 15/32 [00:04<00:04,  3.58it/s]01/14/2022 16:29:23 - INFO - __main__ -   Batch number = 16
Evaluating:  50%|█████     | 16/32 [00:04<00:05,  2.74it/s]01/14/2022 16:29:24 - INFO - __main__ -   Batch number = 17
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:29:24 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:29:24 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Evaluating:  53%|█████▎    | 17/32 [00:05<00:05,  2.95it/s]01/14/2022 16:29:24 - INFO - __main__ -   Batch number = 18
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating:  56%|█████▋    | 18/32 [00:05<00:04,  3.11it/s]01/14/2022 16:29:24 - INFO - __main__ -   Batch number = 19
Evaluating:  59%|█████▉    | 19/32 [00:05<00:04,  3.24it/s]01/14/2022 16:29:25 - INFO - __main__ -   Batch number = 20
Evaluating:  62%|██████▎   | 20/32 [00:05<00:03,  3.33it/s]01/14/2022 16:29:25 - INFO - __main__ -   Batch number = 21
Evaluating:  66%|██████▌   | 21/32 [00:06<00:03,  3.39it/s]01/14/2022 16:29:25 - INFO - __main__ -   Batch number = 22
Evaluating:  69%|██████▉   | 22/32 [00:06<00:02,  3.44it/s]01/14/2022 16:29:25 - INFO - __main__ -   Batch number = 23
Evaluating:  72%|███████▏  | 23/32 [00:06<00:02,  3.47it/s]01/14/2022 16:29:26 - INFO - __main__ -   Batch number = 24
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Evaluating:  75%|███████▌  | 24/32 [00:07<00:02,  3.50it/s]01/14/2022 16:29:26 - INFO - __main__ -   Batch number = 25
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:29:26 - INFO - __main__ -   Language = vi
01/14/2022 16:29:26 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Evaluating:  78%|███████▊  | 25/32 [00:07<00:01,  3.52it/s]01/14/2022 16:29:26 - INFO - __main__ -   Batch number = 26
Evaluating:  81%|████████▏ | 26/32 [00:07<00:01,  3.53it/s]01/14/2022 16:29:26 - INFO - __main__ -   Batch number = 27
Evaluating:  84%|████████▍ | 27/32 [00:07<00:01,  3.53it/s]01/14/2022 16:29:27 - INFO - __main__ -   Batch number = 28
Evaluating:  88%|████████▊ | 28/32 [00:08<00:01,  3.54it/s]01/14/2022 16:29:27 - INFO - __main__ -   Batch number = 29
Evaluating:  91%|█████████ | 29/32 [00:08<00:00,  3.55it/s]01/14/2022 16:29:27 - INFO - __main__ -   Batch number = 30
Evaluating:  94%|█████████▍| 30/32 [00:08<00:00,  3.55it/s]01/14/2022 16:29:28 - INFO - __main__ -   Batch number = 31
Evaluating:  97%|█████████▋| 31/32 [00:08<00:00,  3.56it/s]01/14/2022 16:29:28 - INFO - __main__ -   Batch number = 32
Evaluating: 100%|██████████| 32/32 [00:09<00:00,  3.53it/s]Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.

01/14/2022 16:29:28 - INFO - __main__ -   ***** Evaluation result  in is *****
01/14/2022 16:29:28 - INFO - __main__ -     f1 = 0.6454749439042633
01/14/2022 16:29:28 - INFO - __main__ -     loss = 1.452005023136735
01/14/2022 16:29:28 - INFO - __main__ -     precision = 0.5955831608005521
01/14/2022 16:29:28 - INFO - __main__ -     recall = 0.7044897959183674
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:29:28 - INFO - __main__ -   Language = fr
01/14/2022 16:29:28 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
36.83user 16.16system 0:38.12elapsed 139%CPU (0avgtext+0avgdata 4225552maxresident)k
0inputs+144outputs (0major+2237240minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:29:29 - INFO - __main__ -   Language = my
01/14/2022 16:29:29 - INFO - __main__ -   Adapter Name = my/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/my/bert-base-multilingual-cased/pfeiffer/my_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted/adapter_config.json
Adding adapter 'my' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted'
01/14/2022 16:29:34 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:29:34 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'my']
01/14/2022 16:29:34 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:29:34 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:29:34 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:29:34 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_my_bert-base-multilingual-cased_128
01/14/2022 16:29:34 - INFO - __main__ -   ***** Running evaluation  in my *****
01/14/2022 16:29:34 - INFO - __main__ -     Num examples = 110
01/14/2022 16:29:34 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:29:34 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.32it/s]01/14/2022 16:29:34 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.48it/s]01/14/2022 16:29:35 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.55it/s]01/14/2022 16:29:35 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.47it/s]Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.05it/s]
01/14/2022 16:29:35 - INFO - __main__ -   ***** Evaluation result  in my *****
01/14/2022 16:29:35 - INFO - __main__ -     f1 = 0.3986486486486487
01/14/2022 16:29:35 - INFO - __main__ -     loss = 3.202756881713867
01/14/2022 16:29:35 - INFO - __main__ -     precision = 0.3333333333333333
01/14/2022 16:29:35 - INFO - __main__ -     recall = 0.4957983193277311
33.94user 12.85system 0:33.14elapsed 141%CPU (0avgtext+0avgdata 4241764maxresident)k
109768inputs+88outputs (0major+2185309minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:29:37 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:29:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:29:37 - INFO - __main__ -   Seed = 2
01/14/2022 16:29:37 - INFO - root -   save model
01/14/2022 16:29:37 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:29:37 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:29:40 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:29:46 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:29:46 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:29:46 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:29:46 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:29:46 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:29:46 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,my/wiki@ukp
01/14/2022 16:29:46 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'my'], Length : 10
01/14/2022 16:29:46 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'my/wiki@ukp'], Length : 10
01/14/2022 16:29:46 - INFO - __main__ -   Language = en
01/14/2022 16:29:46 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:29:46 - INFO - __main__ -   Language = pt
01/14/2022 16:29:46 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:29:49 - INFO - __main__ -   Language = id
01/14/2022 16:29:49 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:29:51 - INFO - __main__ -   Language = tr
01/14/2022 16:29:51 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:29:53 - INFO - __main__ -   Language = cs
01/14/2022 16:29:53 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:29:55 - INFO - __main__ -   Language = vi
01/14/2022 16:29:55 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:29:57 - INFO - __main__ -   Language = eu
01/14/2022 16:29:57 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:30:00 - INFO - __main__ -   Language = fa
01/14/2022 16:30:00 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:30:02 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:30:02 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:30:04 - INFO - __main__ -   Language = my
01/14/2022 16:30:04 - INFO - __main__ -   Adapter Name = my/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/my/bert-base-multilingual-cased/pfeiffer/my_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted/adapter_config.json
Adding adapter 'my' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted'
01/14/2022 16:30:08 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:30:08 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'my']
01/14/2022 16:30:08 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:30:08 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:30:08 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:30:08 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_my_bert-base-multilingual-cased_128
01/14/2022 16:30:08 - INFO - __main__ -   ***** Running evaluation  in my *****
01/14/2022 16:30:08 - INFO - __main__ -     Num examples = 110
01/14/2022 16:30:08 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:30:08 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.37it/s]01/14/2022 16:30:08 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.85it/s]01/14/2022 16:30:09 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.16it/s]01/14/2022 16:30:09 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:01<00:00,  4.09it/s]Evaluating: 100%|██████████| 4/4 [00:01<00:00,  3.65it/s]
01/14/2022 16:30:09 - INFO - __main__ -   ***** Evaluation result  in my *****
01/14/2022 16:30:09 - INFO - __main__ -     f1 = 0.4317460317460317
01/14/2022 16:30:09 - INFO - __main__ -     loss = 3.3937275409698486
01/14/2022 16:30:09 - INFO - __main__ -     precision = 0.3469387755102041
01/14/2022 16:30:09 - INFO - __main__ -     recall = 0.5714285714285714
35.17user 13.73system 0:34.38elapsed 142%CPU (0avgtext+0avgdata 4228192maxresident)k
0inputs+80outputs (0major+2288698minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:30:11 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:30:11 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:30:11 - INFO - __main__ -   Seed = 3
01/14/2022 16:30:11 - INFO - root -   save model
01/14/2022 16:30:11 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:30:11 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:30:14 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:30:20 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:30:20 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:30:20 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:30:20 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:30:20 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:30:20 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,my/wiki@ukp
01/14/2022 16:30:20 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'my'], Length : 10
01/14/2022 16:30:20 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'my/wiki@ukp'], Length : 10
01/14/2022 16:30:20 - INFO - __main__ -   Language = en
01/14/2022 16:30:20 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:30:21 - INFO - __main__ -   Language = pt
01/14/2022 16:30:21 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:30:22 - INFO - __main__ -   Language = id
01/14/2022 16:30:22 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:30:24 - INFO - __main__ -   Language = tr
01/14/2022 16:30:24 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:30:26 - INFO - __main__ -   Language = vi
01/14/2022 16:30:26 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:30:27 - INFO - __main__ -   Language = fa
01/14/2022 16:30:27 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:30:29 - INFO - __main__ -   Language = eu
01/14/2022 16:30:29 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:30:31 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:30:31 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:30:32 - INFO - __main__ -   Language = cs
01/14/2022 16:30:32 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:30:34 - INFO - __main__ -   Language = my
01/14/2022 16:30:34 - INFO - __main__ -   Adapter Name = my/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/my/bert-base-multilingual-cased/pfeiffer/my_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted/adapter_config.json
Adding adapter 'my' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/fc89f68db5a10b3644a76d5e75ff7e133c90b61bab6ba045379895ee93102dd9-f06ec65e5829c5da4e63aa747aa76a3869cf9d294640f0ab53ec1f5cca085947-extracted'
01/14/2022 16:30:38 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:30:38 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'my']
01/14/2022 16:30:38 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:30:38 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:30:38 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:30:38 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_my_bert-base-multilingual-cased_128
01/14/2022 16:30:38 - INFO - __main__ -   ***** Running evaluation  in my *****
01/14/2022 16:30:38 - INFO - __main__ -     Num examples = 110
01/14/2022 16:30:38 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:30:38 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.59it/s]01/14/2022 16:30:39 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.61it/s]01/14/2022 16:30:39 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.62it/s]01/14/2022 16:30:39 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.56it/s]Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.16it/s]
01/14/2022 16:30:39 - INFO - __main__ -   ***** Evaluation result  in my *****
01/14/2022 16:30:39 - INFO - __main__ -     f1 = 0.43278688524590164
01/14/2022 16:30:39 - INFO - __main__ -     loss = 3.5076140761375427
01/14/2022 16:30:39 - INFO - __main__ -     precision = 0.3548387096774194
01/14/2022 16:30:39 - INFO - __main__ -     recall = 0.5546218487394958
30.78user 14.99system 0:29.98elapsed 152%CPU (0avgtext+0avgdata 4231556maxresident)k
0inputs+88outputs (0major+2194392minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:31:37 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:31:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:31:37 - INFO - __main__ -   Seed = 1
01/14/2022 16:31:37 - INFO - root -   save model
01/14/2022 16:31:37 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:31:37 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:31:40 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:31:46 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:31:46 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:31:46 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:31:46 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:31:46 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:31:46 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,qu/wiki@ukp
01/14/2022 16:31:46 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'qu'], Length : 10
01/14/2022 16:31:46 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'qu/wiki@ukp'], Length : 10
01/14/2022 16:31:46 - INFO - __main__ -   Language = en
01/14/2022 16:31:46 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:31:47 - INFO - __main__ -   Language = pt
01/14/2022 16:31:47 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:31:49 - INFO - __main__ -   Language = id
01/14/2022 16:31:49 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:31:52 - INFO - __main__ -   Language = cs
01/14/2022 16:31:52 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:31:54 - INFO - __main__ -   Language = tr
01/14/2022 16:31:54 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:31:57 - INFO - __main__ -   Language = eu
01/14/2022 16:31:57 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:31:59 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:31:59 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:32:02 - INFO - __main__ -   Language = vi
01/14/2022 16:32:02 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:32:04 - INFO - __main__ -   Language = fr
01/14/2022 16:32:04 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:32:05 - INFO - __main__ -   Language = qu
01/14/2022 16:32:05 - INFO - __main__ -   Adapter Name = qu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/qu/bert-base-multilingual-cased/pfeiffer/qu_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted/adapter_config.json
Adding adapter 'qu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted'
01/14/2022 16:32:10 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:32:10 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'qu']
01/14/2022 16:32:10 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:32:10 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:32:10 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:32:10 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_qu_bert-base-multilingual-cased_128
01/14/2022 16:32:10 - INFO - __main__ -   ***** Running evaluation  in qu *****
01/14/2022 16:32:10 - INFO - __main__ -     Num examples = 100
01/14/2022 16:32:10 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:32:10 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.26it/s]01/14/2022 16:32:11 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.43it/s]01/14/2022 16:32:11 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.51it/s]01/14/2022 16:32:11 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.38it/s]
01/14/2022 16:32:11 - INFO - __main__ -   ***** Evaluation result  in qu *****
01/14/2022 16:32:11 - INFO - __main__ -     f1 = 0.6024096385542169
01/14/2022 16:32:11 - INFO - __main__ -     loss = 4.390545547008514
01/14/2022 16:32:11 - INFO - __main__ -     precision = 0.5555555555555556
01/14/2022 16:32:11 - INFO - __main__ -     recall = 0.6578947368421053
36.30user 13.68system 0:36.29elapsed 137%CPU (0avgtext+0avgdata 4230500maxresident)k
101744inputs+112outputs (0major+2324873minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:32:13 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:13 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:32:13 - INFO - __main__ -   Seed = 1
01/14/2022 16:32:13 - INFO - root -   save model
01/14/2022 16:32:13 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:13 - INFO - __main__ -   Loading pretrained model and tokenizer
01/14/2022 16:32:14 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:14 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:32:14 - INFO - __main__ -   Seed = 2
01/14/2022 16:32:14 - INFO - root -   save model
01/14/2022 16:32:14 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:14 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:32:16 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/14/2022 16:32:16 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:32:22 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:32:22 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:32:22 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:32:22 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:32:22 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:32:22 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,cdo/wiki@ukp
01/14/2022 16:32:22 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'cdo'], Length : 10
01/14/2022 16:32:22 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'cdo/wiki@ukp'], Length : 10
01/14/2022 16:32:22 - INFO - __main__ -   Language = en
01/14/2022 16:32:22 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:32:22 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:32:22 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:32:22 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:32:22 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:32:22 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:32:22 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,qu/wiki@ukp
01/14/2022 16:32:22 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'qu'], Length : 10
01/14/2022 16:32:22 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'qu/wiki@ukp'], Length : 10
01/14/2022 16:32:22 - INFO - __main__ -   Language = en
01/14/2022 16:32:22 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:32:23 - INFO - __main__ -   Language = pt
01/14/2022 16:32:23 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:32:23 - INFO - __main__ -   Language = pt
01/14/2022 16:32:23 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:32:25 - INFO - __main__ -   Language = id
01/14/2022 16:32:25 - INFO - __main__ -   Adapter Name = id/wiki@ukp
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:32:25 - INFO - __main__ -   Language = id
01/14/2022 16:32:25 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:32:28 - INFO - __main__ -   Language = cs
01/14/2022 16:32:28 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:32:28 - INFO - __main__ -   Language = tr
01/14/2022 16:32:28 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:32:30 - INFO - __main__ -   Language = tr
01/14/2022 16:32:30 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:32:30 - INFO - __main__ -   Language = cs
01/14/2022 16:32:30 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:32:32 - INFO - __main__ -   Language = eu
01/14/2022 16:32:32 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:32:32 - INFO - __main__ -   Language = vi
01/14/2022 16:32:32 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:32:34 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:32:34 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:32:34 - INFO - __main__ -   Language = eu
01/14/2022 16:32:34 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:32:36 - INFO - __main__ -   Language = fa
01/14/2022 16:32:36 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:32:37 - INFO - __main__ -   Language = vi
01/14/2022 16:32:37 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:32:39 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:32:39 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:32:39 - INFO - __main__ -   Language = fr
01/14/2022 16:32:39 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:32:40 - INFO - __main__ -   Language = cdo
01/14/2022 16:32:40 - INFO - __main__ -   Adapter Name = cdo/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cdo/bert-base-multilingual-cased/pfeiffer/cdo_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:32:41 - INFO - __main__ -   Language = qu
01/14/2022 16:32:41 - INFO - __main__ -   Adapter Name = qu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/qu/bert-base-multilingual-cased/pfeiffer/qu_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted/adapter_config.json
Adding adapter 'cdo' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted/adapter_config.json
Adding adapter 'qu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted'
01/14/2022 16:32:45 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:32:45 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'cdo']
01/14/2022 16:32:45 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:32:45 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:32:45 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:32:45 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_cdo_bert-base-multilingual-cased_128
01/14/2022 16:32:45 - INFO - __main__ -   ***** Running evaluation  in cdo *****
01/14/2022 16:32:45 - INFO - __main__ -     Num examples = 101
01/14/2022 16:32:45 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:32:45 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.19it/s]01/14/2022 16:32:45 - INFO - __main__ -   Batch number = 2
01/14/2022 16:32:45 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:32:45 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'qu']
01/14/2022 16:32:45 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:32:45 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:32:45 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:32:45 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_qu_bert-base-multilingual-cased_128
01/14/2022 16:32:45 - INFO - __main__ -   ***** Running evaluation  in qu *****
01/14/2022 16:32:45 - INFO - __main__ -     Num examples = 100
01/14/2022 16:32:45 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:32:45 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.38it/s]01/14/2022 16:32:45 - INFO - __main__ -   Batch number = 3
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.30it/s]01/14/2022 16:32:45 - INFO - __main__ -   Batch number = 2
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.46it/s]01/14/2022 16:32:46 - INFO - __main__ -   Batch number = 4
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.47it/s]01/14/2022 16:32:46 - INFO - __main__ -   Batch number = 3
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.09it/s]
01/14/2022 16:32:46 - INFO - __main__ -   ***** Evaluation result  in cdo *****
01/14/2022 16:32:46 - INFO - __main__ -     f1 = 0.12669683257918551
01/14/2022 16:32:46 - INFO - __main__ -     loss = 2.535094916820526
01/14/2022 16:32:46 - INFO - __main__ -     precision = 0.13592233009708737
01/14/2022 16:32:46 - INFO - __main__ -     recall = 0.11864406779661017
PyTorch version 1.10.1+cu102 available.
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.53it/s]01/14/2022 16:32:46 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.43it/s]
01/14/2022 16:32:46 - INFO - __main__ -   ***** Evaluation result  in qu *****
01/14/2022 16:32:46 - INFO - __main__ -     f1 = 0.5873015873015873
01/14/2022 16:32:46 - INFO - __main__ -     loss = 3.8110600411891937
01/14/2022 16:32:46 - INFO - __main__ -     precision = 0.5362318840579711
01/14/2022 16:32:46 - INFO - __main__ -     recall = 0.6491228070175439
01/14/2022 16:32:46 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:32:46 - INFO - __main__ -   Seed = 1
01/14/2022 16:32:46 - INFO - root -   save model
01/14/2022 16:32:46 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:46 - INFO - __main__ -   Loading pretrained model and tokenizer
36.30user 13.14system 0:34.45elapsed 143%CPU (0avgtext+0avgdata 4229256maxresident)k
0inputs+104outputs (0major+2420287minor)pagefaults 0swaps
36.81user 14.03system 0:34.58elapsed 147%CPU (0avgtext+0avgdata 4225472maxresident)k
0inputs+56outputs (0major+2351001minor)pagefaults 0swaps
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

PyTorch version 1.10.1+cu102 available.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

PyTorch version 1.10.1+cu102 available.
01/14/2022 16:32:48 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:48 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:32:48 - INFO - __main__ -   Seed = 2
01/14/2022 16:32:48 - INFO - root -   save model
01/14/2022 16:32:48 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:48 - INFO - __main__ -   Loading pretrained model and tokenizer
01/14/2022 16:32:48 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:48 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:32:48 - INFO - __main__ -   Seed = 3
01/14/2022 16:32:48 - INFO - root -   save model
01/14/2022 16:32:48 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:32:48 - INFO - __main__ -   Loading pretrained model and tokenizer
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:32:49 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:32:51 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/14/2022 16:32:51 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Traceback (most recent call last):
  File "third_party/my_run_tag.py", line 1123, in <module>
    main()
  File "third_party/my_run_tag.py", line 1050, in main
    model, tokenizer, lang2id = load_model(args, num_labels)
  File "third_party/my_run_tag.py", line 803, in load_model
    cache_dir=args.cache_dir,
  File "/home/abhijeet/rohan/cloud-emea-copy/src/transformers/modeling_auto.py", line 1590, in from_pretrained
    pretrained_model_name_or_path, *model_args, config=config, **kwargs
  File "/home/abhijeet/rohan/cloud-emea-copy/src/transformers/modeling_utils.py", line 955, in from_pretrained
    state_dict = torch.load(resolved_archive_file, map_location="cpu")
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/torch/serialization.py", line 608, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/torch/serialization.py", line 794, in _legacy_load
    deserialized_objects[key]._set_from_file(f, offset, f_should_read_directly)
KeyboardInterrupt
Command terminated by signal 2
9.82user 8.65system 0:09.18elapsed 201%CPU (0avgtext+0avgdata 1405768maxresident)k
0inputs+32outputs (0major+460358minor)pagefaults 0swaps
Traceback (most recent call last):
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/numpy/compat/py3k.py", line 28, in <module>
    import pickle5 as pickle
ModuleNotFoundError: No module named 'pickle5'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "third_party/my_run_tag.py", line 30, in <module>
    import numpy as np
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/numpy/__init__.py", line 140, in <module>
    from . import core
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/numpy/core/__init__.py", line 22, in <module>
    from . import multiarray
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/numpy/core/multiarray.py", line 12, in <module>
    from . import overrides
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/numpy/core/overrides.py", line 9, in <module>
    from numpy.compat._inspect import getargspec
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/numpy/compat/__init__.py", line 12, in <module>
    from . import py3k
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/numpy/compat/py3k.py", line 30, in <module>
    import pickle
  File "/usr/lib/python3.6/pickle.py", line 1562, in <module>
    from _pickle import (
KeyboardInterrupt
Command exited with non-zero status 1
0.98user 1.32system 0:00.12elapsed 1803%CPU (0avgtext+0avgdata 20428maxresident)k
16inputs+8outputs (0major+3139minor)pagefaults 0swaps
Traceback (most recent call last):
  File "third_party/my_run_tag.py", line 32, in <module>
    import torch
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/torch/__init__.py", line 702, in <module>
    from torch import optim as optim
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/torch/optim/__init__.py", line 17, in <module>
    from .rprop import Rprop
  File "/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/torch/optim/rprop.py", line 2, in <module>
    from . import _functional as F
  File "<frozen importlib._bootstrap>", line 1020, in _handle_fromlist
KeyboardInterrupt
Command terminated by signal 2
3.23user 3.68system 0:00.76elapsed 907%CPU (0avgtext+0avgdata 218360maxresident)k
0inputs+0outputs (0major+27672minor)pagefaults 0swaps
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:32:57 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:32:57 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:32:57 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:32:57 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:32:57 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:32:57 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:32:57 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:32:57 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:32:57 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:32:57 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:32:57 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,qu/wiki@ukp
01/14/2022 16:32:57 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'qu'], Length : 10
01/14/2022 16:32:57 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'qu/wiki@ukp'], Length : 10
01/14/2022 16:32:57 - INFO - __main__ -   Language = en
01/14/2022 16:32:57 - INFO - __main__ -   Adapter Name = en/wiki@ukp
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:32:57 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,cdo/wiki@ukp
01/14/2022 16:32:57 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'cdo'], Length : 10
01/14/2022 16:32:57 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'cdo/wiki@ukp'], Length : 10
01/14/2022 16:32:57 - INFO - __main__ -   Language = en
01/14/2022 16:32:57 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:32:58 - INFO - __main__ -   Language = pt
01/14/2022 16:32:58 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:32:58 - INFO - __main__ -   Language = pt
01/14/2022 16:32:58 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:32:59 - INFO - __main__ -   Language = id
01/14/2022 16:32:59 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:33:00 - INFO - __main__ -   Language = id
01/14/2022 16:33:00 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:33:01 - INFO - __main__ -   Language = tr
01/14/2022 16:33:01 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:33:02 - INFO - __main__ -   Language = tr
01/14/2022 16:33:02 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:33:02 - INFO - __main__ -   Language = cs
01/14/2022 16:33:02 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:33:03 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:33:03 - INFO - __main__ -   Seed = 1
01/14/2022 16:33:03 - INFO - root -   save model
01/14/2022 16:33:03 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:03 - INFO - __main__ -   Loading pretrained model and tokenizer
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:33:04 - INFO - __main__ -   Language = vi
01/14/2022 16:33:04 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:33:04 - INFO - __main__ -   Language = vi
01/14/2022 16:33:04 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
No exactly matching adapter config found for this specifier, falling back to default.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:33:06 - INFO - __main__ -   Language = eu
01/14/2022 16:33:06 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:33:06 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:33:06 - INFO - __main__ -   Language = fa
01/14/2022 16:33:06 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:33:08 - INFO - __main__ -   Language = fa
01/14/2022 16:33:08 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:33:08 - INFO - __main__ -   Language = eu
01/14/2022 16:33:08 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:33:09 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:33:09 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:33:11 - INFO - __main__ -   Language = cdo
01/14/2022 16:33:11 - INFO - __main__ -   Adapter Name = cdo/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:33:11 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:33:11 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cdo/bert-base-multilingual-cased/pfeiffer/cdo_pfeiffer_gelu_nd.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted/adapter_config.json
Adding adapter 'cdo' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted'
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:33:12 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:33:12 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:33:12 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:33:12 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:33:12 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:33:12 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,ilo/wiki@ukp
01/14/2022 16:33:12 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'ilo'], Length : 10
01/14/2022 16:33:12 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'ilo/wiki@ukp'], Length : 10
01/14/2022 16:33:12 - INFO - __main__ -   Language = en
01/14/2022 16:33:12 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:33:13 - INFO - __main__ -   Language = pt
01/14/2022 16:33:13 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:33:13 - INFO - __main__ -   Language = cs
01/14/2022 16:33:13 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
01/14/2022 16:33:15 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:33:15 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'cdo']
01/14/2022 16:33:15 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:33:15 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:33:15 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:33:15 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_cdo_bert-base-multilingual-cased_128
01/14/2022 16:33:15 - INFO - __main__ -   ***** Running evaluation  in cdo *****
01/14/2022 16:33:15 - INFO - __main__ -     Num examples = 101
01/14/2022 16:33:15 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:33:15 - INFO - __main__ -   Batch number = 1
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:33:15 - INFO - __main__ -   Language = id
01/14/2022 16:33:15 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:33:15 - INFO - __main__ -   Language = qu
01/14/2022 16:33:15 - INFO - __main__ -   Adapter Name = qu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/qu/bert-base-multilingual-cased/pfeiffer/qu_pfeiffer_gelu_nd.zip.
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.27it/s]01/14/2022 16:33:15 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.45it/s]01/14/2022 16:33:15 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.51it/s]01/14/2022 16:33:16 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.34it/s]
01/14/2022 16:33:16 - INFO - __main__ -   ***** Evaluation result  in cdo *****
01/14/2022 16:33:16 - INFO - __main__ -     f1 = 0.11258278145695363
01/14/2022 16:33:16 - INFO - __main__ -     loss = 4.374813675880432
01/14/2022 16:33:16 - INFO - __main__ -     precision = 0.09239130434782608
01/14/2022 16:33:16 - INFO - __main__ -     recall = 0.1440677966101695
Loading module configuration from /home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted/adapter_config.json
Adding adapter 'qu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/1dcc4ff8eb752045bafab1b8b499413e72a936950e83465cbfe219f72273b3ca-af508eb36ab4c7abb503dda6ed8f4c39c2309733e473886c8d1c416316e254b7-extracted'
31.39user 13.40system 0:30.23elapsed 148%CPU (0avgtext+0avgdata 4232488maxresident)k
0inputs+104outputs (0major+2239578minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:33:17 - INFO - __main__ -   Language = cs
01/14/2022 16:33:17 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:33:18 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:18 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:33:18 - INFO - __main__ -   Seed = 3
01/14/2022 16:33:18 - INFO - root -   save model
01/14/2022 16:33:18 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:18 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:33:19 - INFO - __main__ -   Language = tr
01/14/2022 16:33:19 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
01/14/2022 16:33:20 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:33:20 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'qu']
01/14/2022 16:33:20 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:33:20 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:33:20 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:33:20 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_qu_bert-base-multilingual-cased_128
01/14/2022 16:33:20 - INFO - __main__ -   ***** Running evaluation  in qu *****
01/14/2022 16:33:20 - INFO - __main__ -     Num examples = 100
01/14/2022 16:33:20 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:33:20 - INFO - __main__ -   Batch number = 1
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.25it/s]01/14/2022 16:33:20 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.43it/s]01/14/2022 16:33:20 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.51it/s]01/14/2022 16:33:20 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.40it/s]
01/14/2022 16:33:21 - INFO - __main__ -   ***** Evaluation result  in qu *****
01/14/2022 16:33:21 - INFO - __main__ -     f1 = 0.5914396887159533
01/14/2022 16:33:21 - INFO - __main__ -     loss = 4.148501843214035
01/14/2022 16:33:21 - INFO - __main__ -     precision = 0.5314685314685315
01/14/2022 16:33:21 - INFO - __main__ -     recall = 0.6666666666666666
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:33:21 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
38.19user 13.50system 0:34.53elapsed 149%CPU (0avgtext+0avgdata 4227352maxresident)k
0inputs+48outputs (0major+2226423minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:33:22 - INFO - __main__ -   Language = eu
01/14/2022 16:33:22 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:33:24 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:33:24 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:33:26 - INFO - __main__ -   Language = vi
01/14/2022 16:33:26 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:33:27 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:33:27 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:33:27 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:33:27 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:33:27 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:33:27 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,cdo/wiki@ukp
01/14/2022 16:33:27 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'cdo'], Length : 10
01/14/2022 16:33:27 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'cdo/wiki@ukp'], Length : 10
01/14/2022 16:33:27 - INFO - __main__ -   Language = en
01/14/2022 16:33:27 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:33:28 - INFO - __main__ -   Language = pt
01/14/2022 16:33:28 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:33:28 - INFO - __main__ -   Language = fr
01/14/2022 16:33:28 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:33:29 - INFO - __main__ -   Language = ilo
01/14/2022 16:33:29 - INFO - __main__ -   Adapter Name = ilo/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ilo/bert-base-multilingual-cased/pfeiffer/ilo_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:33:30 - INFO - __main__ -   Language = id
01/14/2022 16:33:30 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted/adapter_config.json
Adding adapter 'ilo' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:33:32 - INFO - __main__ -   Language = tr
01/14/2022 16:33:32 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
01/14/2022 16:33:34 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:33:34 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'ilo']
01/14/2022 16:33:34 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:33:34 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:33:34 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:33:34 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ilo_bert-base-multilingual-cased_128
01/14/2022 16:33:34 - INFO - __main__ -   ***** Running evaluation  in ilo *****
01/14/2022 16:33:34 - INFO - __main__ -     Num examples = 100
01/14/2022 16:33:34 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:33:34 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.27it/s]01/14/2022 16:33:34 - INFO - __main__ -   Batch number = 2
PyTorch version 1.10.1+cu102 available.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.46it/s]01/14/2022 16:33:34 - INFO - __main__ -   Batch number = 3
01/14/2022 16:33:34 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:33:34 - INFO - __main__ -   Seed = 1
01/14/2022 16:33:34 - INFO - root -   save model
01/14/2022 16:33:34 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:34 - INFO - __main__ -   Loading pretrained model and tokenizer
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:33:34 - INFO - __main__ -   Language = vi
01/14/2022 16:33:34 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.54it/s]01/14/2022 16:33:35 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.42it/s]
01/14/2022 16:33:35 - INFO - __main__ -   ***** Evaluation result  in ilo *****
01/14/2022 16:33:35 - INFO - __main__ -     f1 = 0.5254237288135593
01/14/2022 16:33:35 - INFO - __main__ -     loss = 3.032944440841675
01/14/2022 16:33:35 - INFO - __main__ -     precision = 0.46616541353383456
01/14/2022 16:33:35 - INFO - __main__ -     recall = 0.6019417475728155
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

34.96user 13.35system 0:33.50elapsed 144%CPU (0avgtext+0avgdata 4225244maxresident)k
0inputs+72outputs (0major+2120304minor)pagefaults 0swaps
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

PyTorch version 1.10.1+cu102 available.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:33:37 - INFO - __main__ -   Language = fa
01/14/2022 16:33:37 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
01/14/2022 16:33:37 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:33:37 - INFO - __main__ -   Seed = 2
01/14/2022 16:33:37 - INFO - root -   save model
01/14/2022 16:33:37 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:37 - INFO - __main__ -   Loading pretrained model and tokenizer
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:33:37 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
01/14/2022 16:33:39 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:33:39 - INFO - __main__ -   Language = eu
01/14/2022 16:33:39 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:33:42 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:33:42 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:33:43 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:33:43 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:33:43 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:33:43 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:33:43 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:33:43 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,xmf/wiki@ukp
01/14/2022 16:33:43 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'xmf'], Length : 10
01/14/2022 16:33:43 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'xmf/wiki@ukp'], Length : 10
01/14/2022 16:33:43 - INFO - __main__ -   Language = en
01/14/2022 16:33:43 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:33:44 - INFO - __main__ -   Language = cs
01/14/2022 16:33:44 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:33:44 - INFO - __main__ -   Language = pt
01/14/2022 16:33:44 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:33:45 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:33:45 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:33:45 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:33:45 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:33:45 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:33:45 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,ilo/wiki@ukp
01/14/2022 16:33:45 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'ilo'], Length : 10
01/14/2022 16:33:45 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'ilo/wiki@ukp'], Length : 10
01/14/2022 16:33:45 - INFO - __main__ -   Language = en
01/14/2022 16:33:45 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:33:46 - INFO - __main__ -   Language = id
01/14/2022 16:33:46 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:33:46 - INFO - __main__ -   Language = pt
01/14/2022 16:33:46 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:33:46 - INFO - __main__ -   Language = cdo
01/14/2022 16:33:46 - INFO - __main__ -   Adapter Name = cdo/wiki@ukp
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cdo/bert-base-multilingual-cased/pfeiffer/cdo_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted/adapter_config.json
Adding adapter 'cdo' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/222cd73f61d6050d654f8c6c554dc74615a18a9cc7e4b15e4f7ccc5ee1fe14c2-e2ea95310a63dd763fa44908cd5ec6a0cbd7305b76c997ef625a70d77d1b2b59-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:33:47 - INFO - __main__ -   Language = cs
01/14/2022 16:33:47 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:33:48 - INFO - __main__ -   Language = id
01/14/2022 16:33:48 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:33:49 - INFO - __main__ -   Language = tr
01/14/2022 16:33:49 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:33:49 - INFO - __main__ -   Language = tr
01/14/2022 16:33:49 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:33:50 - INFO - __main__ -   Language = eu
01/14/2022 16:33:50 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
01/14/2022 16:33:51 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:33:51 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'cdo']
01/14/2022 16:33:51 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:33:51 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:33:51 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:33:51 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_cdo_bert-base-multilingual-cased_128
01/14/2022 16:33:51 - INFO - __main__ -   ***** Running evaluation  in cdo *****
01/14/2022 16:33:51 - INFO - __main__ -     Num examples = 101
01/14/2022 16:33:51 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:33:51 - INFO - __main__ -   Batch number = 1
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:33:51 - INFO - __main__ -   Language = cs
01/14/2022 16:33:51 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.21it/s]01/14/2022 16:33:51 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.45it/s]01/14/2022 16:33:51 - INFO - __main__ -   Batch number = 3
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:33:52 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:33:52 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
Evaluating:  75%|███████▌  | 3/4 [00:01<00:00,  2.86it/s]01/14/2022 16:33:52 - INFO - __main__ -   Batch number = 4
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating: 100%|██████████| 4/4 [00:01<00:00,  3.56it/s]
01/14/2022 16:33:52 - INFO - __main__ -   ***** Evaluation result  in cdo *****
01/14/2022 16:33:52 - INFO - __main__ -     f1 = 0.14705882352941174
01/14/2022 16:33:52 - INFO - __main__ -     loss = 2.6115408539772034
01/14/2022 16:33:52 - INFO - __main__ -     precision = 0.12987012987012986
01/14/2022 16:33:52 - INFO - __main__ -     recall = 0.1694915254237288
36.14user 13.97system 0:35.92elapsed 139%CPU (0avgtext+0avgdata 4239100maxresident)k
0inputs+80outputs (0major+2430882minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:33:53 - INFO - __main__ -   Language = vi
01/14/2022 16:33:53 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:33:53 - INFO - __main__ -   Language = vi
01/14/2022 16:33:53 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:33:54 - INFO - __main__ -   Language = eu
01/14/2022 16:33:54 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:33:55 - INFO - __main__ -   Language = fr
01/14/2022 16:33:55 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:33:56 - INFO - __main__ -   Language = xmf
01/14/2022 16:33:56 - INFO - __main__ -   Adapter Name = xmf/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:33:56 - INFO - __main__ -   Language = fa
01/14/2022 16:33:56 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/xmf/bert-base-multilingual-cased/pfeiffer/xmf_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted/adapter_config.json
Adding adapter 'xmf' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:33:58 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:33:58 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:33:58 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:58 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:33:58 - INFO - __main__ -   Seed = 1
01/14/2022 16:33:58 - INFO - root -   save model
01/14/2022 16:33:58 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:33:58 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:33:59 - INFO - __main__ -   Language = ilo
01/14/2022 16:33:59 - INFO - __main__ -   Adapter Name = ilo/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ilo/bert-base-multilingual-cased/pfeiffer/ilo_relu_2.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted/adapter_config.json
Adding adapter 'ilo' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted'
01/14/2022 16:34:00 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:34:00 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'xmf']
01/14/2022 16:34:00 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:34:00 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:34:00 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:34:00 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_xmf_bert-base-multilingual-cased_128
01/14/2022 16:34:00 - INFO - __main__ -   ***** Running evaluation  in xmf *****
01/14/2022 16:34:00 - INFO - __main__ -     Num examples = 100
01/14/2022 16:34:00 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:34:00 - INFO - __main__ -   Batch number = 1
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.25it/s]01/14/2022 16:34:01 - INFO - __main__ -   Batch number = 2
01/14/2022 16:34:01 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.42it/s]01/14/2022 16:34:01 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.50it/s]01/14/2022 16:34:01 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.39it/s]
01/14/2022 16:34:01 - INFO - __main__ -   ***** Evaluation result  in xmf *****
01/14/2022 16:34:01 - INFO - __main__ -     f1 = 0.3609022556390977
01/14/2022 16:34:01 - INFO - __main__ -     loss = 3.0546153783798218
01/14/2022 16:34:01 - INFO - __main__ -     precision = 0.3287671232876712
01/14/2022 16:34:01 - INFO - __main__ -     recall = 0.4
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
30.39user 13.07system 0:29.07elapsed 149%CPU (0avgtext+0avgdata 4224988maxresident)k
0inputs+88outputs (0major+2114264minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:34:03 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:34:03 - INFO - __main__ -   Seed = 2
01/14/2022 16:34:03 - INFO - root -   save model
01/14/2022 16:34:03 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:03 - INFO - __main__ -   Loading pretrained model and tokenizer
01/14/2022 16:34:04 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:34:04 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'ilo']
01/14/2022 16:34:04 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:34:04 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:34:04 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:34:04 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ilo_bert-base-multilingual-cased_128
01/14/2022 16:34:04 - INFO - __main__ -   ***** Running evaluation  in ilo *****
01/14/2022 16:34:04 - INFO - __main__ -     Num examples = 100
01/14/2022 16:34:04 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:34:04 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.45it/s]01/14/2022 16:34:04 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.56it/s]01/14/2022 16:34:04 - INFO - __main__ -   Batch number = 3
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.60it/s]01/14/2022 16:34:04 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.54it/s]
01/14/2022 16:34:04 - INFO - __main__ -   ***** Evaluation result  in ilo *****
01/14/2022 16:34:04 - INFO - __main__ -     f1 = 0.6098654708520179
01/14/2022 16:34:04 - INFO - __main__ -     loss = 2.545504331588745
01/14/2022 16:34:04 - INFO - __main__ -     precision = 0.5666666666666667
01/14/2022 16:34:04 - INFO - __main__ -     recall = 0.6601941747572816
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

30.90user 13.06system 0:29.77elapsed 147%CPU (0avgtext+0avgdata 4225128maxresident)k
0inputs+56outputs (0major+2160971minor)pagefaults 0swaps
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:34:06 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
PyTorch version 1.10.1+cu102 available.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:34:07 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:34:07 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:34:07 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:34:07 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:34:07 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
01/14/2022 16:34:07 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:07 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:34:07 - INFO - __main__ -   Seed = 3
01/14/2022 16:34:07 - INFO - root -   save model
01/14/2022 16:34:07 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:07 - INFO - __main__ -   Loading pretrained model and tokenizer
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:34:07 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,mi/wiki@ukp
01/14/2022 16:34:07 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'mi'], Length : 10
01/14/2022 16:34:07 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'mi/wiki@ukp'], Length : 10
01/14/2022 16:34:07 - INFO - __main__ -   Language = en
01/14/2022 16:34:07 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:34:07 - INFO - __main__ -   Language = pt
01/14/2022 16:34:07 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:34:09 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:34:10 - INFO - __main__ -   Language = id
01/14/2022 16:34:10 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:34:12 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:34:12 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:34:12 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:34:12 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:34:12 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:34:12 - INFO - __main__ -   Language = cs
01/14/2022 16:34:12 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:34:12 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,xmf/wiki@ukp
01/14/2022 16:34:12 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'xmf'], Length : 10
01/14/2022 16:34:12 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'xmf/wiki@ukp'], Length : 10
01/14/2022 16:34:12 - INFO - __main__ -   Language = en
01/14/2022 16:34:12 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:34:13 - INFO - __main__ -   Language = pt
01/14/2022 16:34:13 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:34:14 - INFO - __main__ -   Language = tr
01/14/2022 16:34:14 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:34:15 - INFO - __main__ -   Language = id
01/14/2022 16:34:15 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:34:15 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:34:15 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:34:15 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:34:15 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:34:15 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:34:15 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,ilo/wiki@ukp
01/14/2022 16:34:15 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'ilo'], Length : 10
01/14/2022 16:34:15 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'ilo/wiki@ukp'], Length : 10
01/14/2022 16:34:15 - INFO - __main__ -   Language = en
01/14/2022 16:34:15 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:34:16 - INFO - __main__ -   Language = pt
01/14/2022 16:34:16 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:34:16 - INFO - __main__ -   Language = eu
01/14/2022 16:34:16 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:34:17 - INFO - __main__ -   Language = tr
01/14/2022 16:34:17 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:34:18 - INFO - __main__ -   Language = id
01/14/2022 16:34:18 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:34:18 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:34:18 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:34:19 - INFO - __main__ -   Language = cs
01/14/2022 16:34:19 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:34:20 - INFO - __main__ -   Language = tr
01/14/2022 16:34:20 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:34:21 - INFO - __main__ -   Language = vi
01/14/2022 16:34:21 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:34:21 - INFO - __main__ -   Language = vi
01/14/2022 16:34:21 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:34:23 - INFO - __main__ -   Language = vi
01/14/2022 16:34:23 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:34:23 - INFO - __main__ -   Language = fr
01/14/2022 16:34:23 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:34:23 - INFO - __main__ -   Language = eu
01/14/2022 16:34:23 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:34:24 - INFO - __main__ -   Language = mi
01/14/2022 16:34:24 - INFO - __main__ -   Adapter Name = mi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/mi/bert-base-multilingual-cased/pfeiffer/mi_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:34:25 - INFO - __main__ -   Language = fa
01/14/2022 16:34:25 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted/adapter_config.json
Adding adapter 'mi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:34:26 - INFO - __main__ -   Language = fa
01/14/2022 16:34:26 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:34:27 - INFO - __main__ -   Language = eu
01/14/2022 16:34:27 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:34:28 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:34:28 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
01/14/2022 16:34:28 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:34:28 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'mi']
01/14/2022 16:34:28 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:34:28 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:34:28 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:34:28 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_mi_bert-base-multilingual-cased_128
01/14/2022 16:34:28 - INFO - __main__ -   ***** Running evaluation  in mi *****
01/14/2022 16:34:28 - INFO - __main__ -     Num examples = 100
01/14/2022 16:34:28 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:34:28 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.31it/s]01/14/2022 16:34:29 - INFO - __main__ -   Batch number = 2
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.48it/s]01/14/2022 16:34:29 - INFO - __main__ -   Batch number = 3
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:34:29 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:34:29 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.55it/s]01/14/2022 16:34:29 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.46it/s]
01/14/2022 16:34:29 - INFO - __main__ -   ***** Evaluation result  in mi *****
01/14/2022 16:34:29 - INFO - __main__ -     f1 = 0.251685393258427
01/14/2022 16:34:29 - INFO - __main__ -     loss = 3.8612669706344604
01/14/2022 16:34:29 - INFO - __main__ -     precision = 0.2
01/14/2022 16:34:29 - INFO - __main__ -     recall = 0.3393939393939394
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:34:30 - INFO - __main__ -   Language = xmf
01/14/2022 16:34:30 - INFO - __main__ -   Adapter Name = xmf/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/xmf/bert-base-multilingual-cased/pfeiffer/xmf_pfeiffer_gelu_nd.zip.
35.07user 13.36system 0:33.60elapsed 144%CPU (0avgtext+0avgdata 4232448maxresident)k
98040inputs+96outputs (0major+2243241minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted/adapter_config.json
Adding adapter 'xmf' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
PyTorch version 1.10.1+cu102 available.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:34:31 - INFO - __main__ -   Language = cs
01/14/2022 16:34:31 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
01/14/2022 16:34:32 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:32 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:34:32 - INFO - __main__ -   Seed = 2
01/14/2022 16:34:32 - INFO - root -   save model
01/14/2022 16:34:32 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:32 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:34:34 - INFO - __main__ -   Language = ilo
01/14/2022 16:34:34 - INFO - __main__ -   Adapter Name = ilo/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/ilo/bert-base-multilingual-cased/pfeiffer/ilo_relu_2.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:34:34 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted/adapter_config.json
Adding adapter 'ilo' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/2fe86ce2b22154a69443770d8fde7a60197ef0f5294e2b30733bc6dd44f57468-1b6834376c99dfbb4cae1c509c87188edd0c24a235ac25f351ef515c56aaed50-extracted'
01/14/2022 16:34:35 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:34:35 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'xmf']
01/14/2022 16:34:35 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:34:35 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:34:35 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:34:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_xmf_bert-base-multilingual-cased_128
01/14/2022 16:34:35 - INFO - __main__ -   ***** Running evaluation  in xmf *****
01/14/2022 16:34:35 - INFO - __main__ -     Num examples = 100
01/14/2022 16:34:35 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:34:35 - INFO - __main__ -   Batch number = 1
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.34it/s]01/14/2022 16:34:35 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.49it/s]01/14/2022 16:34:35 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.54it/s]01/14/2022 16:34:36 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.44it/s]
01/14/2022 16:34:36 - INFO - __main__ -   ***** Evaluation result  in xmf *****
01/14/2022 16:34:36 - INFO - __main__ -     f1 = 0.339622641509434
01/14/2022 16:34:36 - INFO - __main__ -     loss = 4.5591830015182495
01/14/2022 16:34:36 - INFO - __main__ -     precision = 0.2727272727272727
01/14/2022 16:34:36 - INFO - __main__ -     recall = 0.45
35.81user 13.72system 0:34.48elapsed 143%CPU (0avgtext+0avgdata 4227096maxresident)k
0inputs+80outputs (0major+2147708minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:34:38 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:38 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:34:38 - INFO - __main__ -   Seed = 3
01/14/2022 16:34:38 - INFO - root -   save model
01/14/2022 16:34:38 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:38 - INFO - __main__ -   Loading pretrained model and tokenizer
01/14/2022 16:34:38 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:34:38 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'ilo']
01/14/2022 16:34:38 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:34:38 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:34:38 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:34:38 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_ilo_bert-base-multilingual-cased_128
01/14/2022 16:34:38 - INFO - __main__ -   ***** Running evaluation  in ilo *****
01/14/2022 16:34:38 - INFO - __main__ -     Num examples = 100
01/14/2022 16:34:38 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:34:38 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.30it/s]01/14/2022 16:34:38 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.47it/s]01/14/2022 16:34:39 - INFO - __main__ -   Batch number = 3
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.54it/s]01/14/2022 16:34:39 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.44it/s]
01/14/2022 16:34:39 - INFO - __main__ -   ***** Evaluation result  in ilo *****
01/14/2022 16:34:39 - INFO - __main__ -     f1 = 0.6216216216216217
01/14/2022 16:34:39 - INFO - __main__ -     loss = 2.8508920669555664
01/14/2022 16:34:39 - INFO - __main__ -     precision = 0.5798319327731093
01/14/2022 16:34:39 - INFO - __main__ -     recall = 0.6699029126213593
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
35.70user 13.82system 0:34.48elapsed 143%CPU (0avgtext+0avgdata 4231252maxresident)k
0inputs+80outputs (0major+2437429minor)pagefaults 0swaps
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:34:40 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:34:40 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:34:40 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:34:40 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:34:40 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:34:40 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,mi/wiki@ukp
01/14/2022 16:34:40 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'mi'], Length : 10
01/14/2022 16:34:40 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'mi/wiki@ukp'], Length : 10
01/14/2022 16:34:40 - INFO - __main__ -   Language = en
01/14/2022 16:34:40 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:34:41 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:34:41 - INFO - __main__ -   Language = pt
01/14/2022 16:34:41 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:34:43 - INFO - __main__ -   Language = id
01/14/2022 16:34:43 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:34:46 - INFO - __main__ -   Language = tr
01/14/2022 16:34:46 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:34:47 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:34:47 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:34:47 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:34:47 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:34:47 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:34:47 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,xmf/wiki@ukp
01/14/2022 16:34:47 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'xmf'], Length : 10
01/14/2022 16:34:47 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'xmf/wiki@ukp'], Length : 10
01/14/2022 16:34:47 - INFO - __main__ -   Language = en
01/14/2022 16:34:47 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:34:48 - INFO - __main__ -   Language = pt
01/14/2022 16:34:48 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:34:48 - INFO - __main__ -   Language = cs
01/14/2022 16:34:48 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:34:49 - INFO - __main__ -   Language = id
01/14/2022 16:34:49 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:34:50 - INFO - __main__ -   Language = vi
01/14/2022 16:34:50 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:34:51 - INFO - __main__ -   Language = tr
01/14/2022 16:34:51 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:34:52 - INFO - __main__ -   Language = vi
01/14/2022 16:34:52 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:34:52 - INFO - __main__ -   Language = eu
01/14/2022 16:34:52 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
PyTorch version 1.10.1+cu102 available.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
01/14/2022 16:34:53 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:53 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:34:53 - INFO - __main__ -   Seed = 1
01/14/2022 16:34:53 - INFO - root -   save model
01/14/2022 16:34:53 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:34:53 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:34:54 - INFO - __main__ -   Language = fa
01/14/2022 16:34:54 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:34:54 - INFO - __main__ -   Language = fa
01/14/2022 16:34:54 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
01/14/2022 16:34:55 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:34:55 - INFO - __main__ -   Language = eu
01/14/2022 16:34:55 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:34:56 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:34:56 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:34:57 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:34:57 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:34:59 - INFO - __main__ -   Language = cs
01/14/2022 16:34:59 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:34:59 - INFO - __main__ -   Language = mi
01/14/2022 16:34:59 - INFO - __main__ -   Adapter Name = mi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/mi/bert-base-multilingual-cased/pfeiffer/mi_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted/adapter_config.json
Adding adapter 'mi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:35:00 - INFO - __main__ -   Language = xmf
01/14/2022 16:35:00 - INFO - __main__ -   Adapter Name = xmf/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/xmf/bert-base-multilingual-cased/pfeiffer/xmf_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted/adapter_config.json
Adding adapter 'xmf' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/de4cf7ebb957cc647355066066df3562022bd36d5e1fb267b268c73c885ba1b8-059cec88a14bf5e4aa255942ab8a6b7e4e2aefebfbf02361c648b5817e3184df-extracted'
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:35:01 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:35:01 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:35:01 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:35:01 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:35:01 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:35:01 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,mhr/wiki@ukp
01/14/2022 16:35:01 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'mhr'], Length : 10
01/14/2022 16:35:01 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'mhr/wiki@ukp'], Length : 10
01/14/2022 16:35:01 - INFO - __main__ -   Language = en
01/14/2022 16:35:01 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:35:02 - INFO - __main__ -   Language = pt
01/14/2022 16:35:02 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
01/14/2022 16:35:03 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:35:03 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'mi']
01/14/2022 16:35:03 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:35:03 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:35:03 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:35:03 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_mi_bert-base-multilingual-cased_128
01/14/2022 16:35:03 - INFO - __main__ -   ***** Running evaluation  in mi *****
01/14/2022 16:35:03 - INFO - __main__ -     Num examples = 100
01/14/2022 16:35:03 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:35:03 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.31it/s]01/14/2022 16:35:03 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.48it/s]01/14/2022 16:35:04 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.56it/s]01/14/2022 16:35:04 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.46it/s]
01/14/2022 16:35:04 - INFO - __main__ -   ***** Evaluation result  in mi *****
01/14/2022 16:35:04 - INFO - __main__ -     f1 = 0.10194174757281552
01/14/2022 16:35:04 - INFO - __main__ -     loss = 7.7254356145858765
01/14/2022 16:35:04 - INFO - __main__ -     precision = 0.08502024291497975
01/14/2022 16:35:04 - INFO - __main__ -     recall = 0.12727272727272726
01/14/2022 16:35:04 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:35:04 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'xmf']
01/14/2022 16:35:04 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:35:04 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:35:04 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:35:04 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_xmf_bert-base-multilingual-cased_128
01/14/2022 16:35:04 - INFO - __main__ -   ***** Running evaluation  in xmf *****
01/14/2022 16:35:04 - INFO - __main__ -     Num examples = 100
01/14/2022 16:35:04 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:35:04 - INFO - __main__ -   Batch number = 1
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:35:05 - INFO - __main__ -   Language = id
01/14/2022 16:35:05 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
35.58user 13.73system 0:34.67elapsed 142%CPU (0avgtext+0avgdata 4238216maxresident)k
0inputs+104outputs (0major+2315593minor)pagefaults 0swaps
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.27it/s]01/14/2022 16:35:05 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.43it/s]01/14/2022 16:35:05 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.50it/s]01/14/2022 16:35:05 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.40it/s]
01/14/2022 16:35:05 - INFO - __main__ -   ***** Evaluation result  in xmf *****
01/14/2022 16:35:05 - INFO - __main__ -     f1 = 0.2645161290322581
01/14/2022 16:35:05 - INFO - __main__ -     loss = 5.107606291770935
01/14/2022 16:35:05 - INFO - __main__ -     precision = 0.21578947368421053
01/14/2022 16:35:05 - INFO - __main__ -     recall = 0.3416666666666667
PyTorch version 1.10.1+cu102 available.
31.32user 13.45system 0:29.77elapsed 150%CPU (0avgtext+0avgdata 4228064maxresident)k
0inputs+72outputs (0major+2276976minor)pagefaults 0swaps
01/14/2022 16:35:06 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:35:06 - INFO - __main__ -   Seed = 3
01/14/2022 16:35:06 - INFO - root -   save model
01/14/2022 16:35:06 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:06 - INFO - __main__ -   Loading pretrained model and tokenizer
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:35:07 - INFO - __main__ -   Language = cs
01/14/2022 16:35:07 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
01/14/2022 16:35:09 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:35:09 - INFO - __main__ -   Language = tr
01/14/2022 16:35:09 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:35:11 - INFO - __main__ -   Language = eu
01/14/2022 16:35:11 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:35:14 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:35:14 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:35:14 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='tk', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:14 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:35:14 - INFO - __main__ -   Seed = 1
01/14/2022 16:35:14 - INFO - root -   save model
01/14/2022 16:35:14 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='tk', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:14 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:35:15 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:35:15 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:35:15 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:35:15 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:35:15 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:35:15 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,mi/wiki@ukp
01/14/2022 16:35:15 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'mi'], Length : 10
01/14/2022 16:35:15 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'mi/wiki@ukp'], Length : 10
01/14/2022 16:35:15 - INFO - __main__ -   Language = en
01/14/2022 16:35:15 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:35:16 - INFO - __main__ -   Language = vi
01/14/2022 16:35:16 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:35:16 - INFO - __main__ -   Language = pt
01/14/2022 16:35:16 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:35:17 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:35:18 - INFO - __main__ -   Language = id
01/14/2022 16:35:18 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:35:18 - INFO - __main__ -   Language = fr
01/14/2022 16:35:18 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:35:19 - INFO - __main__ -   Language = mhr
01/14/2022 16:35:19 - INFO - __main__ -   Adapter Name = mhr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/mhr/bert-base-multilingual-cased/pfeiffer/mhr_pfeiffer_gelu_nd.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:35:20 - INFO - __main__ -   Language = tr
01/14/2022 16:35:20 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted/adapter_config.json
Adding adapter 'mhr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:35:21 - INFO - __main__ -   Language = vi
01/14/2022 16:35:21 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:35:23 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:35:23 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:35:23 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:35:23 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:35:23 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:35:23 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,tk/wiki@ukp
01/14/2022 16:35:23 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'tk'], Length : 10
01/14/2022 16:35:23 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'tk/wiki@ukp'], Length : 10
01/14/2022 16:35:23 - INFO - __main__ -   Language = en
01/14/2022 16:35:23 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:35:23 - INFO - __main__ -   Language = fa
01/14/2022 16:35:23 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:35:24 - INFO - __main__ -   Language = pt
01/14/2022 16:35:24 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
01/14/2022 16:35:24 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:35:24 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'mhr']
01/14/2022 16:35:24 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:35:24 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:35:24 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:35:24 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_mhr_bert-base-multilingual-cased_128
01/14/2022 16:35:24 - INFO - __main__ -   ***** Running evaluation  in mhr *****
01/14/2022 16:35:24 - INFO - __main__ -     Num examples = 100
01/14/2022 16:35:24 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:35:24 - INFO - __main__ -   Batch number = 1
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.43it/s]01/14/2022 16:35:24 - INFO - __main__ -   Batch number = 2
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:35:24 - INFO - __main__ -   Language = eu
01/14/2022 16:35:24 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.52it/s]01/14/2022 16:35:25 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.55it/s]01/14/2022 16:35:25 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.48it/s]
01/14/2022 16:35:25 - INFO - __main__ -   ***** Evaluation result  in mhr *****
01/14/2022 16:35:25 - INFO - __main__ -     f1 = 0.462962962962963
01/14/2022 16:35:25 - INFO - __main__ -     loss = 2.1440657675266266
01/14/2022 16:35:25 - INFO - __main__ -     precision = 0.47619047619047616
01/14/2022 16:35:25 - INFO - __main__ -     recall = 0.45045045045045046
36.16user 13.31system 0:34.70elapsed 142%CPU (0avgtext+0avgdata 4230056maxresident)k
70984inputs+88outputs (0major+2360309minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:35:26 - INFO - __main__ -   Language = id
01/14/2022 16:35:26 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:35:26 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:35:26 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:35:27 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:27 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:35:27 - INFO - __main__ -   Seed = 2
01/14/2022 16:35:27 - INFO - root -   save model
01/14/2022 16:35:27 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:27 - INFO - __main__ -   Loading pretrained model and tokenizer
01/14/2022 16:35:27 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:27 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:35:27 - INFO - __main__ -   Seed = 1
01/14/2022 16:35:27 - INFO - root -   save model
01/14/2022 16:35:27 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:27 - INFO - __main__ -   Loading pretrained model and tokenizer
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:35:28 - INFO - __main__ -   Language = cs
01/14/2022 16:35:28 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:35:28 - INFO - __main__ -   Language = cs
01/14/2022 16:35:28 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:35:30 - INFO - __main__ -   Language = mi
01/14/2022 16:35:30 - INFO - __main__ -   Adapter Name = mi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/mi/bert-base-multilingual-cased/pfeiffer/mi_relu_2.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:35:30 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/14/2022 16:35:30 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted/adapter_config.json
Adding adapter 'mi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:35:30 - INFO - __main__ -   Language = tr
01/14/2022 16:35:30 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module weights from /home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted/pytorch_adapter.bin
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/e44d9c8ffbc892f46c831dddc5eee60033e59b7807954290ebc340b0fbffb425-425d99e14fa79b365809c6bf40002f1cdca22297a8e9c23ae0335e9f5288f86e-extracted'
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:35:33 - INFO - __main__ -   Language = eu
01/14/2022 16:35:33 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
01/14/2022 16:35:34 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:35:34 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'mi']
01/14/2022 16:35:34 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:35:34 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:35:34 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:35:34 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_mi_bert-base-multilingual-cased_128
01/14/2022 16:35:34 - INFO - __main__ -   ***** Running evaluation  in mi *****
01/14/2022 16:35:34 - INFO - __main__ -     Num examples = 100
01/14/2022 16:35:34 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:35:34 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.60it/s]01/14/2022 16:35:34 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.62it/s]01/14/2022 16:35:35 - INFO - __main__ -   Batch number = 3
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.63it/s]01/14/2022 16:35:35 - INFO - __main__ -   Batch number = 4
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:35:35 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:35:35 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.59it/s]No exactly matching adapter config found for this specifier, falling back to default.

01/14/2022 16:35:35 - INFO - __main__ -   ***** Evaluation result  in mi *****
01/14/2022 16:35:35 - INFO - __main__ -     f1 = 0.22222222222222224
01/14/2022 16:35:35 - INFO - __main__ -     loss = 3.913669526576996
01/14/2022 16:35:35 - INFO - __main__ -     precision = 0.16379310344827586
01/14/2022 16:35:35 - INFO - __main__ -     recall = 0.34545454545454546
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
32.45user 13.65system 0:30.97elapsed 148%CPU (0avgtext+0avgdata 4229224maxresident)k
0inputs+96outputs (0major+2222792minor)pagefaults 0swaps
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:35:36 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:35:36 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:35:36 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:35:36 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:35:36 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:35:36 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,mhr/wiki@ukp
01/14/2022 16:35:36 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'mhr'], Length : 10
01/14/2022 16:35:36 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'mhr/wiki@ukp'], Length : 10
01/14/2022 16:35:36 - INFO - __main__ -   Language = en
01/14/2022 16:35:36 - INFO - __main__ -   Adapter Name = en/wiki@ukp
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:35:36 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:35:36 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:35:36 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
01/14/2022 16:35:36 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:35:36 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
No exactly matching adapter config found for this specifier, falling back to default.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:35:36 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,cs/wiki@ukp,tr/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,vi/wiki@ukp,fr/wiki@ukp,gn/wiki@ukp
01/14/2022 16:35:36 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'gn'], Length : 10
01/14/2022 16:35:36 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'cs/wiki@ukp', 'tr/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'vi/wiki@ukp', 'fr/wiki@ukp', 'gn/wiki@ukp'], Length : 10
01/14/2022 16:35:36 - INFO - __main__ -   Language = en
01/14/2022 16:35:36 - INFO - __main__ -   Adapter Name = en/wiki@ukp
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:35:37 - INFO - __main__ -   Language = pt
01/14/2022 16:35:37 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:35:37 - INFO - __main__ -   Language = pt
01/14/2022 16:35:37 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:35:37 - INFO - __main__ -   Language = vi
01/14/2022 16:35:37 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:35:39 - INFO - __main__ -   Language = id
01/14/2022 16:35:39 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:35:39 - INFO - __main__ -   Language = fr
01/14/2022 16:35:39 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:35:39 - INFO - __main__ -   Language = id
01/14/2022 16:35:39 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:35:40 - INFO - __main__ -   Language = tk
01/14/2022 16:35:40 - INFO - __main__ -   Adapter Name = tk/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tk/bert-base-multilingual-cased/pfeiffer/tk_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted/adapter_config.json
Adding adapter 'tk' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted/pytorch_adapter.bin
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:35:43 - INFO - __main__ -   Language = tr
01/14/2022 16:35:43 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:35:43 - INFO - __main__ -   Language = cs
01/14/2022 16:35:43 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:35:45 - INFO - __main__ -   Language = tr
01/14/2022 16:35:45 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:35:45 - INFO - __main__ -   Language = cs
01/14/2022 16:35:45 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
01/14/2022 16:35:46 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:35:46 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'tk']
01/14/2022 16:35:46 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:35:46 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:35:46 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:35:46 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_tk_bert-base-multilingual-cased_128
01/14/2022 16:35:46 - INFO - __main__ -   ***** Running evaluation  in tk *****
01/14/2022 16:35:46 - INFO - __main__ -     Num examples = 101
01/14/2022 16:35:46 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:35:46 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.22it/s]01/14/2022 16:35:46 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  2.91it/s]01/14/2022 16:35:47 - INFO - __main__ -   Batch number = 3
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.16it/s]01/14/2022 16:35:47 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:01<00:00,  3.92it/s]
01/14/2022 16:35:47 - INFO - __main__ -   ***** Evaluation result  in tk *****
01/14/2022 16:35:47 - INFO - __main__ -     f1 = 0.5462555066079295
01/14/2022 16:35:47 - INFO - __main__ -     loss = 2.9477867484092712
01/14/2022 16:35:47 - INFO - __main__ -     precision = 0.5081967213114754
01/14/2022 16:35:47 - INFO - __main__ -     recall = 0.5904761904761905
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:35:47 - INFO - __main__ -   Language = eu
01/14/2022 16:35:47 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:35:48 - INFO - __main__ -   Language = vi
01/14/2022 16:35:48 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
47.18user 13.35system 0:35.50elapsed 170%CPU (0avgtext+0avgdata 4225040maxresident)k
56inputs+120outputs (0major+2178028minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:35:50 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:35:50 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
01/14/2022 16:35:50 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='tk', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:35:50 - INFO - __main__ -   Seed = 2
01/14/2022 16:35:50 - INFO - root -   save model
01/14/2022 16:35:50 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='tk', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:35:50 - INFO - __main__ -   Loading pretrained model and tokenizer
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:35:50 - INFO - __main__ -   Language = eu
01/14/2022 16:35:50 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
01/14/2022 16:35:52 - INFO - __main__ -   Language = fa
01/14/2022 16:35:52 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:35:52 - INFO - __main__ -   Language = vi
01/14/2022 16:35:52 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:35:52 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:35:54 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:35:54 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:35:54 - INFO - __main__ -   Language = fr
01/14/2022 16:35:54 - INFO - __main__ -   Adapter Name = fr/wiki@ukp
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fr/bert-base-multilingual-cased/pfeiffer/fr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/adapter_config.json
Adding adapter 'fr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/649821e7de439acb880a8e9d0322d00abd445c9de655cee124a4e03fef557a86-fc313c35adda41f0a19ce896c640341c8d3e4ed589cdb94a38da05472df87a8f-extracted'
01/14/2022 16:35:55 - INFO - __main__ -   Language = gn
01/14/2022 16:35:55 - INFO - __main__ -   Adapter Name = gn/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/gn/bert-base-multilingual-cased/pfeiffer/gn_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted/adapter_config.json
Adding adapter 'gn' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:35:56 - INFO - __main__ -   Language = mhr
01/14/2022 16:35:56 - INFO - __main__ -   Adapter Name = mhr/wiki@ukp
Loading module weights from /home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted'
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/mhr/bert-base-multilingual-cased/pfeiffer/mhr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted/adapter_config.json
Adding adapter 'mhr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted'
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:35:58 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:35:58 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:35:58 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:35:58 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:35:58 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:35:58 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,tk/wiki@ukp
01/14/2022 16:35:58 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'tk'], Length : 10
01/14/2022 16:35:58 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'tk/wiki@ukp'], Length : 10
01/14/2022 16:35:58 - INFO - __main__ -   Language = en
01/14/2022 16:35:58 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:35:59 - INFO - __main__ -   Language = pt
01/14/2022 16:35:59 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
01/14/2022 16:36:00 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:36:00 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'cs', 'tr', 'eu', 'zh_yue', 'vi', 'fr', 'gn']
01/14/2022 16:36:00 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:36:00 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:36:00 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:36:00 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_gn_bert-base-multilingual-cased_128
01/14/2022 16:36:00 - INFO - __main__ -   ***** Running evaluation  in gn *****
01/14/2022 16:36:00 - INFO - __main__ -     Num examples = 102
01/14/2022 16:36:00 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:36:00 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.19it/s]01/14/2022 16:36:00 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.39it/s]01/14/2022 16:36:00 - INFO - __main__ -   Batch number = 3
01/14/2022 16:36:01 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:36:01 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'mhr']
01/14/2022 16:36:01 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:36:01 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:36:01 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:36:01 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_mhr_bert-base-multilingual-cased_128
01/14/2022 16:36:01 - INFO - __main__ -   ***** Running evaluation  in mhr *****
01/14/2022 16:36:01 - INFO - __main__ -     Num examples = 100
01/14/2022 16:36:01 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:36:01 - INFO - __main__ -   Batch number = 1
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.48it/s]01/14/2022 16:36:01 - INFO - __main__ -   Batch number = 4
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.27it/s]
01/14/2022 16:36:01 - INFO - __main__ -   ***** Evaluation result  in gn *****
01/14/2022 16:36:01 - INFO - __main__ -     f1 = 0.45312500000000006
01/14/2022 16:36:01 - INFO - __main__ -     loss = 3.794823944568634
01/14/2022 16:36:01 - INFO - __main__ -     precision = 0.3841059602649007
01/14/2022 16:36:01 - INFO - __main__ -     recall = 0.5523809523809524
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.29it/s]01/14/2022 16:36:01 - INFO - __main__ -   Batch number = 2
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:36:01 - INFO - __main__ -   Language = id
01/14/2022 16:36:01 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.45it/s]01/14/2022 16:36:01 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.52it/s]01/14/2022 16:36:01 - INFO - __main__ -   Batch number = 4
48.43user 11.37system 0:35.84elapsed 166%CPU (0avgtext+0avgdata 4231036maxresident)k
0inputs+64outputs (0major+2336041minor)pagefaults 0swaps
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.21it/s]
01/14/2022 16:36:02 - INFO - __main__ -   ***** Evaluation result  in mhr *****
01/14/2022 16:36:02 - INFO - __main__ -     f1 = 0.5084745762711864
01/14/2022 16:36:02 - INFO - __main__ -     loss = 2.4748425483703613
01/14/2022 16:36:02 - INFO - __main__ -     precision = 0.48
01/14/2022 16:36:02 - INFO - __main__ -     recall = 0.5405405405405406
51.58user 12.77system 0:36.66elapsed 175%CPU (0avgtext+0avgdata 4228056maxresident)k
0inputs+80outputs (0major+2423773minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:36:03 - INFO - __main__ -   Language = tr
01/14/2022 16:36:03 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:36:03 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:36:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:36:03 - INFO - __main__ -   Seed = 2
01/14/2022 16:36:03 - INFO - root -   save model
01/14/2022 16:36:03 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:36:03 - INFO - __main__ -   Loading pretrained model and tokenizer
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:36:04 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:36:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:36:04 - INFO - __main__ -   Seed = 3
01/14/2022 16:36:04 - INFO - root -   save model
01/14/2022 16:36:04 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:36:04 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:36:04 - INFO - __main__ -   Language = cs
01/14/2022 16:36:04 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
01/14/2022 16:36:06 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:36:06 - INFO - __main__ -   Language = vi
01/14/2022 16:36:06 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:36:07 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:36:07 - INFO - __main__ -   Language = eu
01/14/2022 16:36:07 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:36:09 - INFO - __main__ -   Language = fa
01/14/2022 16:36:09 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:36:11 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:36:11 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:36:12 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:36:12 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:36:12 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
01/14/2022 16:36:12 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:36:12 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:36:12 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,cs/wiki@ukp,vi/wiki@ukp,eu/wiki@ukp,fa/wiki@ukp,zh_yue/wiki@ukp,gn/wiki@ukp
01/14/2022 16:36:12 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'gn'], Length : 10
01/14/2022 16:36:12 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'cs/wiki@ukp', 'vi/wiki@ukp', 'eu/wiki@ukp', 'fa/wiki@ukp', 'zh_yue/wiki@ukp', 'gn/wiki@ukp'], Length : 10
01/14/2022 16:36:12 - INFO - __main__ -   Language = en
01/14/2022 16:36:12 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:36:12 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:36:12 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:36:12 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:36:12 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:36:12 - INFO - root -   loading task adapter
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:36:12 - INFO - __main__ -   Language = tk
01/14/2022 16:36:12 - INFO - __main__ -   Adapter Name = tk/wiki@ukp
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:36:12 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,mhr/wiki@ukp
01/14/2022 16:36:12 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'mhr'], Length : 10
01/14/2022 16:36:12 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'mhr/wiki@ukp'], Length : 10
01/14/2022 16:36:12 - INFO - __main__ -   Language = en
01/14/2022 16:36:12 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tk/bert-base-multilingual-cased/pfeiffer/tk_pfeiffer_gelu_nd.zip.
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:36:13 - INFO - __main__ -   Language = pt
01/14/2022 16:36:13 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted/adapter_config.json
Adding adapter 'tk' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted'
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:36:13 - INFO - __main__ -   Language = pt
01/14/2022 16:36:13 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:36:14 - INFO - __main__ -   Language = id
01/14/2022 16:36:14 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:36:15 - INFO - __main__ -   Language = id
01/14/2022 16:36:15 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:36:16 - INFO - __main__ -   Language = tr
01/14/2022 16:36:16 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:36:16 - INFO - __main__ -   Language = tr
01/14/2022 16:36:16 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
01/14/2022 16:36:17 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:36:17 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'tk']
01/14/2022 16:36:17 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:36:17 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:36:17 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:36:17 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_tk_bert-base-multilingual-cased_128
01/14/2022 16:36:17 - INFO - __main__ -   ***** Running evaluation  in tk *****
01/14/2022 16:36:17 - INFO - __main__ -     Num examples = 101
01/14/2022 16:36:17 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:36:17 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.30it/s]01/14/2022 16:36:17 - INFO - __main__ -   Batch number = 2
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.44it/s]01/14/2022 16:36:17 - INFO - __main__ -   Batch number = 3
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:36:17 - INFO - __main__ -   Language = cs
01/14/2022 16:36:17 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.49it/s]01/14/2022 16:36:18 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.32it/s]
01/14/2022 16:36:18 - INFO - __main__ -   ***** Evaluation result  in tk *****
01/14/2022 16:36:18 - INFO - __main__ -     f1 = 0.5317460317460317
01/14/2022 16:36:18 - INFO - __main__ -     loss = 3.32015860080719
01/14/2022 16:36:18 - INFO - __main__ -     precision = 0.4557823129251701
01/14/2022 16:36:18 - INFO - __main__ -     recall = 0.638095238095238
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:36:18 - INFO - __main__ -   Language = vi
01/14/2022 16:36:18 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
29.73user 13.03system 0:30.34elapsed 140%CPU (0avgtext+0avgdata 4240112maxresident)k
0inputs+72outputs (0major+2182860minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:36:19 - INFO - __main__ -   Language = vi
01/14/2022 16:36:19 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
PyTorch version 1.10.1+cu102 available.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:36:20 - INFO - __main__ -   Language = fa
01/14/2022 16:36:20 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
01/14/2022 16:36:20 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='tk', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:36:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:36:20 - INFO - __main__ -   Seed = 3
01/14/2022 16:36:20 - INFO - root -   save model
01/14/2022 16:36:20 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='tk', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:36:20 - INFO - __main__ -   Loading pretrained model and tokenizer
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:36:21 - INFO - __main__ -   Language = eu
01/14/2022 16:36:21 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:36:22 - INFO - __main__ -   Language = eu
01/14/2022 16:36:22 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:36:22 - INFO - __main__ -   Language = fa
01/14/2022 16:36:22 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:36:23 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:36:23 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:36:23 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:36:24 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:36:24 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:36:25 - INFO - __main__ -   Language = cs
01/14/2022 16:36:25 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:36:25 - INFO - __main__ -   Language = gn
01/14/2022 16:36:25 - INFO - __main__ -   Adapter Name = gn/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/gn/bert-base-multilingual-cased/pfeiffer/gn_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted/adapter_config.json
Adding adapter 'gn' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted'
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:36:26 - INFO - __main__ -   Language = mhr
01/14/2022 16:36:26 - INFO - __main__ -   Adapter Name = mhr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/mhr/bert-base-multilingual-cased/pfeiffer/mhr_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted/adapter_config.json
Adding adapter 'mhr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/95e309f45b29471bda57d1f0977802037fce0a2fba4977153952a608fd32cbfb-14f5543602d279356f14343bcd82fd0f7a35d8f6b2654bed2a5e473ad6df0288-extracted'
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:36:29 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:36:29 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:36:29 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:36:29 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:36:29 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:36:29 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,tk/wiki@ukp
01/14/2022 16:36:29 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'tk'], Length : 10
01/14/2022 16:36:29 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'tk/wiki@ukp'], Length : 10
01/14/2022 16:36:29 - INFO - __main__ -   Language = en
01/14/2022 16:36:29 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:36:30 - INFO - __main__ -   Language = pt
01/14/2022 16:36:30 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
01/14/2022 16:36:30 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:36:30 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'cs', 'vi', 'eu', 'fa', 'zh_yue', 'gn']
01/14/2022 16:36:30 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:36:30 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:36:30 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:36:30 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_gn_bert-base-multilingual-cased_128
01/14/2022 16:36:30 - INFO - __main__ -   ***** Running evaluation  in gn *****
01/14/2022 16:36:30 - INFO - __main__ -     Num examples = 102
01/14/2022 16:36:30 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:36:30 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.55it/s]01/14/2022 16:36:30 - INFO - __main__ -   Batch number = 2
01/14/2022 16:36:30 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:36:30 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'mhr']
01/14/2022 16:36:30 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:36:30 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:36:30 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:36:30 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_mhr_bert-base-multilingual-cased_128
01/14/2022 16:36:30 - INFO - __main__ -   ***** Running evaluation  in mhr *****
01/14/2022 16:36:30 - INFO - __main__ -     Num examples = 100
01/14/2022 16:36:30 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:36:30 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.57it/s]01/14/2022 16:36:30 - INFO - __main__ -   Batch number = 3
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.25it/s]01/14/2022 16:36:31 - INFO - __main__ -   Batch number = 2
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.57it/s]01/14/2022 16:36:31 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.41it/s]
01/14/2022 16:36:31 - INFO - __main__ -   ***** Evaluation result  in gn *****
01/14/2022 16:36:31 - INFO - __main__ -     f1 = 0.4794007490636704
01/14/2022 16:36:31 - INFO - __main__ -     loss = 3.5714155435562134
01/14/2022 16:36:31 - INFO - __main__ -     precision = 0.3950617283950617
01/14/2022 16:36:31 - INFO - __main__ -     recall = 0.6095238095238096
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.45it/s]01/14/2022 16:36:31 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.51it/s]01/14/2022 16:36:31 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.40it/s]
01/14/2022 16:36:31 - INFO - __main__ -   ***** Evaluation result  in mhr *****
01/14/2022 16:36:31 - INFO - __main__ -     f1 = 0.4266666666666667
01/14/2022 16:36:31 - INFO - __main__ -     loss = 2.789973735809326
01/14/2022 16:36:31 - INFO - __main__ -     precision = 0.42105263157894735
01/14/2022 16:36:31 - INFO - __main__ -     recall = 0.43243243243243246
30.21user 12.28system 0:30.05elapsed 141%CPU (0avgtext+0avgdata 4225600maxresident)k
0inputs+56outputs (0major+2172127minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:36:32 - INFO - __main__ -   Language = id
01/14/2022 16:36:32 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
29.57user 12.79system 0:29.67elapsed 142%CPU (0avgtext+0avgdata 4225228maxresident)k
0inputs+96outputs (0major+2316248minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/14/2022 16:36:33 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:36:33 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/14/2022 16:36:33 - INFO - __main__ -   Seed = 3
01/14/2022 16:36:33 - INFO - root -   save model
01/14/2022 16:36:33 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_ensemble_en_top10_madx//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight='equal', lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/14/2022 16:36:33 - INFO - __main__ -   Loading pretrained model and tokenizer
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:36:34 - INFO - __main__ -   Language = tr
01/14/2022 16:36:34 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/14/2022 16:36:36 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:36:36 - INFO - __main__ -   Language = vi
01/14/2022 16:36:36 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:36:38 - INFO - __main__ -   Language = fa
01/14/2022 16:36:38 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:36:40 - INFO - __main__ -   Language = eu
01/14/2022 16:36:40 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/14/2022 16:36:41 - INFO - __main__ -   Using lang2id = None
01/14/2022 16:36:41 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/14/2022 16:36:41 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
01/14/2022 16:36:41 - INFO - root -   Trying to decide if add adapter
01/14/2022 16:36:41 - INFO - root -   loading task adapter
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/adapter_config.json
Adding adapter 'ner' of type 'text_task'.
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_adapter.bin
Loading module configuration from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/head_config.json
Loading module weights from output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/pytorch_model_head.bin
01/14/2022 16:36:41 - INFO - root -   loading lang adpater en/wiki@ukp,pt/wiki@ukp,id/wiki@ukp,tr/wiki@ukp,vi/wiki@ukp,fa/wiki@ukp,eu/wiki@ukp,zh_yue/wiki@ukp,cs/wiki@ukp,gn/wiki@ukp
01/14/2022 16:36:41 - INFO - __main__ -   Adapter Languages : ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'gn'], Length : 10
01/14/2022 16:36:41 - INFO - __main__ -   Adapter Names ['en/wiki@ukp', 'pt/wiki@ukp', 'id/wiki@ukp', 'tr/wiki@ukp', 'vi/wiki@ukp', 'fa/wiki@ukp', 'eu/wiki@ukp', 'zh_yue/wiki@ukp', 'cs/wiki@ukp', 'gn/wiki@ukp'], Length : 10
01/14/2022 16:36:41 - INFO - __main__ -   Language = en
01/14/2022 16:36:41 - INFO - __main__ -   Adapter Name = en/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/en/bert-base-multilingual-cased/pfeiffer/en_relu_2.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/adapter_config.json
Adding adapter 'en' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/209973079df3cb5d155df4e290ec86070f257721693ce7618ff84b89b4aae2cf-3bd7c13f02e43f33b6ab727158d366c50d676646774b1c975dea5f965352474a-extracted'
01/14/2022 16:36:42 - INFO - __main__ -   Language = pt
01/14/2022 16:36:42 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/pt/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_pt_pt_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:36:43 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:36:43 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/adapter_config.json
Adding adapter 'pt' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/4924e01fe99a0caebf1981f06377a5104fb3796cf7ec3b246e6315cfbefd695e-babbbc708158370b57817d59165808788458aebba22ae543528550fc8eeb099c-extracted/head_config.json
01/14/2022 16:36:44 - INFO - __main__ -   Language = id
01/14/2022 16:36:44 - INFO - __main__ -   Adapter Name = id/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/id/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_wiki_id_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:36:45 - INFO - __main__ -   Language = cs
01/14/2022 16:36:45 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/adapter_config.json
Adding adapter 'id' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/a35790907fed08fbe8567ddb42eaf99029e1b389458b3fa71f34d0dfcbde11ec-d5193b80938046db7118bf0fe97da3f8ae720f067ac22d0df16c9a965fa594d5-extracted/head_config.json
01/14/2022 16:36:45 - INFO - __main__ -   Language = tr
01/14/2022 16:36:45 - INFO - __main__ -   Adapter Name = tr/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tr/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_tr_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/adapter_config.json
Adding adapter 'tr' of type 'text_lang'.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:36:47 - INFO - __main__ -   Language = tk
01/14/2022 16:36:47 - INFO - __main__ -   Adapter Name = tk/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/tk/bert-base-multilingual-cased/pfeiffer/tk_pfeiffer_gelu_nd.zip.
Loading module weights from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/2aa8ac175583031cedf47ea5e7630625cbce5e0c192b2996e6ee77319acd094f-4f441ddc232e312b97eb1d8ec3329224e3295e344ff441583ee5a81d0002c032-extracted/head_config.json
01/14/2022 16:36:47 - INFO - __main__ -   Language = vi
01/14/2022 16:36:47 - INFO - __main__ -   Adapter Name = vi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/vi/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_vi_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted/adapter_config.json
Adding adapter 'tk' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/3c2101496d6740544ccbfa7d151e21783f1be3b94711b0d4284818b54198a97f-8b5a852e44e220894b1840513370b95dfe1e6dcb18b5153b747ad005decfdd14-extracted'
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/adapter_config.json
Adding adapter 'vi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/18756bce53f4786e3b4268b7f126da58449c5e39e04f36061090367d5f501141-b616bc9c3a27cc7cbd87bedefeafdcc534657ee68d76d194d6ad040c4f425f70-extracted/head_config.json
01/14/2022 16:36:49 - INFO - __main__ -   Language = fa
01/14/2022 16:36:49 - INFO - __main__ -   Adapter Name = fa/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/fa/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_fa_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/adapter_config.json
Adding adapter 'fa' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/296f12627758121353725aa5f652a1491e3085c15bdba1cbe63935c15744d934-a4aab0ed1e4f1435381e633ff51d9a2d3b6cf6f5731935ba176e044672e7aae9-extracted/head_config.json
01/14/2022 16:36:50 - INFO - __main__ -   Language = eu
01/14/2022 16:36:50 - INFO - __main__ -   Adapter Name = eu/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/eu/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_eu_wiki_pfeiffer.zip.
01/14/2022 16:36:52 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:36:52 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'tk']
01/14/2022 16:36:52 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:36:52 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:36:52 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:36:52 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_tk_bert-base-multilingual-cased_128
01/14/2022 16:36:52 - INFO - __main__ -   ***** Running evaluation  in tk *****
01/14/2022 16:36:52 - INFO - __main__ -     Num examples = 101
01/14/2022 16:36:52 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:36:52 - INFO - __main__ -   Batch number = 1
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/adapter_config.json
Adding adapter 'eu' of type 'text_lang'.
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.51it/s]01/14/2022 16:36:52 - INFO - __main__ -   Batch number = 2
Loading module weights from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/65a27bf4da01232353a8402b95c6e5b7d3e20fb0dc68a5262cfcbf375ecd754c-2c2a9a4b8e6f627345c66f9e3cfb257248b855395d028bb9ef4aaaa999d24fd4-extracted/head_config.json
01/14/2022 16:36:52 - INFO - __main__ -   Language = zh_yue
01/14/2022 16:36:52 - INFO - __main__ -   Adapter Name = zh_yue/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/zh_yue/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_zh_yue_wiki_pfeiffer.zip.
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.55it/s]01/14/2022 16:36:52 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.56it/s]01/14/2022 16:36:53 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.44it/s]
01/14/2022 16:36:53 - INFO - __main__ -   ***** Evaluation result  in tk *****
01/14/2022 16:36:53 - INFO - __main__ -     f1 = 0.4773662551440329
01/14/2022 16:36:53 - INFO - __main__ -     loss = 3.5105076134204865
01/14/2022 16:36:53 - INFO - __main__ -     precision = 0.42028985507246375
01/14/2022 16:36:53 - INFO - __main__ -     recall = 0.5523809523809524
36.43user 14.00system 0:34.95elapsed 144%CPU (0avgtext+0avgdata 4224856maxresident)k
0inputs+80outputs (0major+2143578minor)pagefaults 0swaps
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/adapter_config.json
Adding adapter 'zh_yue' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/bdf309fcf20afdf362a0c84276d8c0d0bde57872471ead4b73b49052f83b2a62-ce3eaa437644e4429f49eace36520e0c60129360bbb862d279447d82b25d7dcc-extracted/head_config.json
01/14/2022 16:36:54 - INFO - __main__ -   Language = cs
01/14/2022 16:36:54 - INFO - __main__ -   Adapter Name = cs/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/cs/bert-base-multilingual-cased/pfeiffer/bert-base-multilingual-cased_cs_wiki_pfeiffer.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/adapter_config.json
Adding adapter 'cs' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/pytorch_adapter.bin
Loading module configuration from /home/abhijeet/.cache/torch/adapters/6a2960229867d3f920b674d6f4f23e22c511f9f66431f4c2acf0a6019df19734-875886ddc9f7d0a0874b9a5219b12097e915aeb85831d0b6fd4686917d5bd0c6-extracted/head_config.json
01/14/2022 16:36:55 - INFO - __main__ -   Language = gn
01/14/2022 16:36:55 - INFO - __main__ -   Adapter Name = gn/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/gn/bert-base-multilingual-cased/pfeiffer/gn_pfeiffer_gelu_nd.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted/adapter_config.json
Adding adapter 'gn' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/8722796dd5ccefad307cf451b1cad13f8d36ae87addd356cec18caf511a276b3-2772f4dba9f6488d80def221d431679fb0dc7b1a898b82853861f6b02f9e107c-extracted'
01/14/2022 16:37:00 - INFO - __main__ -   Args Adapter Weight = equal
01/14/2022 16:37:00 - INFO - __main__ -   Adapter Languages = ['en', 'pt', 'id', 'tr', 'vi', 'fa', 'eu', 'zh_yue', 'cs', 'gn']
01/14/2022 16:37:00 - INFO - __main__ -   Adapter Weights = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
01/14/2022 16:37:00 - INFO - __main__ -   Sum of Adapter Weights = 0.9999999999999999
01/14/2022 16:37:00 - INFO - __main__ -   Length of Adapter Weights = 10
01/14/2022 16:37:00 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//panx/panx_processed_maxlen128/cached_test_gn_bert-base-multilingual-cased_128
01/14/2022 16:37:00 - INFO - __main__ -   ***** Running evaluation  in gn *****
01/14/2022 16:37:00 - INFO - __main__ -     Num examples = 102
01/14/2022 16:37:00 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]01/14/2022 16:37:00 - INFO - __main__ -   Batch number = 1
Evaluating:  25%|██▌       | 1/4 [00:00<00:00,  3.27it/s]01/14/2022 16:37:00 - INFO - __main__ -   Batch number = 2
Evaluating:  50%|█████     | 2/4 [00:00<00:00,  3.45it/s]01/14/2022 16:37:01 - INFO - __main__ -   Batch number = 3
Evaluating:  75%|███████▌  | 3/4 [00:00<00:00,  3.51it/s]01/14/2022 16:37:01 - INFO - __main__ -   Batch number = 4
Evaluating: 100%|██████████| 4/4 [00:00<00:00,  4.32it/s]
01/14/2022 16:37:01 - INFO - __main__ -   ***** Evaluation result  in gn *****
01/14/2022 16:37:01 - INFO - __main__ -     f1 = 0.4184397163120568
01/14/2022 16:37:01 - INFO - __main__ -     loss = 3.559912621974945
01/14/2022 16:37:01 - INFO - __main__ -     precision = 0.3333333333333333
01/14/2022 16:37:01 - INFO - __main__ -     recall = 0.5619047619047619
31.20user 14.04system 0:30.08elapsed 150%CPU (0avgtext+0avgdata 4225848maxresident)k
0inputs+80outputs (0major+2257822minor)pagefaults 0swaps
