12/26/2021 23:11:35 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:11:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:11:35 - INFO - __main__ -   Seed = 1
12/26/2021 23:11:35 - INFO - root -   save model
12/26/2021 23:11:35 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:11:35 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:11:39 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:11:46 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:11:46 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:11:46 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:11:46 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:11:46 - INFO - root -   loading task adapter
12/26/2021 23:11:46 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:11:46 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:11:46 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:11:46 - INFO - __main__ -   Language = pt
12/26/2021 23:11:46 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:11:54 - INFO - __main__ -   Language adapter for ar not found, using pt instead
12/26/2021 23:11:54 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:11:54 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:11:54 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:11:54 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
12/26/2021 23:11:55 - INFO - __main__ -   ***** Running evaluation  in ar *****
12/26/2021 23:11:55 - INFO - __main__ -     Num examples = 10000
12/26/2021 23:11:55 - INFO - __main__ -     Batch size = 32
12/26/2021 23:11:55 - INFO - __main__ -   Batch number = 1
12/26/2021 23:11:55 - INFO - __main__ -   Batch number = 2
12/26/2021 23:11:56 - INFO - __main__ -   Batch number = 3
12/26/2021 23:11:56 - INFO - __main__ -   Batch number = 4
12/26/2021 23:11:56 - INFO - __main__ -   Batch number = 5
12/26/2021 23:11:56 - INFO - __main__ -   Batch number = 6
12/26/2021 23:11:56 - INFO - __main__ -   Batch number = 7
12/26/2021 23:11:56 - INFO - __main__ -   Batch number = 8
12/26/2021 23:11:57 - INFO - __main__ -   Batch number = 9
12/26/2021 23:11:57 - INFO - __main__ -   Batch number = 10
12/26/2021 23:11:57 - INFO - __main__ -   Batch number = 11
12/26/2021 23:11:57 - INFO - __main__ -   Batch number = 12
12/26/2021 23:11:57 - INFO - __main__ -   Batch number = 13
12/26/2021 23:11:58 - INFO - __main__ -   Batch number = 14
12/26/2021 23:11:58 - INFO - __main__ -   Batch number = 15
12/26/2021 23:11:58 - INFO - __main__ -   Batch number = 16
12/26/2021 23:11:58 - INFO - __main__ -   Batch number = 17
12/26/2021 23:11:59 - INFO - __main__ -   Batch number = 18
12/26/2021 23:11:59 - INFO - __main__ -   Batch number = 19
12/26/2021 23:11:59 - INFO - __main__ -   Batch number = 20
12/26/2021 23:12:00 - INFO - __main__ -   Batch number = 21
12/26/2021 23:12:00 - INFO - __main__ -   Batch number = 22
12/26/2021 23:12:00 - INFO - __main__ -   Batch number = 23
12/26/2021 23:12:01 - INFO - __main__ -   Batch number = 24
12/26/2021 23:12:01 - INFO - __main__ -   Batch number = 25
12/26/2021 23:12:01 - INFO - __main__ -   Batch number = 26
12/26/2021 23:12:02 - INFO - __main__ -   Batch number = 27
12/26/2021 23:12:02 - INFO - __main__ -   Batch number = 28
12/26/2021 23:12:02 - INFO - __main__ -   Batch number = 29
12/26/2021 23:12:03 - INFO - __main__ -   Batch number = 30
12/26/2021 23:12:03 - INFO - __main__ -   Batch number = 31
12/26/2021 23:12:03 - INFO - __main__ -   Batch number = 32
12/26/2021 23:12:03 - INFO - __main__ -   Batch number = 33
12/26/2021 23:12:03 - INFO - __main__ -   Batch number = 34
12/26/2021 23:12:03 - INFO - __main__ -   Batch number = 35
12/26/2021 23:12:04 - INFO - __main__ -   Batch number = 36
12/26/2021 23:12:04 - INFO - __main__ -   Batch number = 37
12/26/2021 23:12:04 - INFO - __main__ -   Batch number = 38
12/26/2021 23:12:04 - INFO - __main__ -   Batch number = 39
12/26/2021 23:12:04 - INFO - __main__ -   Batch number = 40
12/26/2021 23:12:04 - INFO - __main__ -   Batch number = 41
12/26/2021 23:12:05 - INFO - __main__ -   Batch number = 42
12/26/2021 23:12:05 - INFO - __main__ -   Batch number = 43
12/26/2021 23:12:05 - INFO - __main__ -   Batch number = 44
12/26/2021 23:12:05 - INFO - __main__ -   Batch number = 45
12/26/2021 23:12:05 - INFO - __main__ -   Batch number = 46
12/26/2021 23:12:05 - INFO - __main__ -   Batch number = 47
12/26/2021 23:12:05 - INFO - __main__ -   Batch number = 48
12/26/2021 23:12:06 - INFO - __main__ -   Batch number = 49
12/26/2021 23:12:06 - INFO - __main__ -   Batch number = 50
12/26/2021 23:12:06 - INFO - __main__ -   Batch number = 51
12/26/2021 23:12:06 - INFO - __main__ -   Batch number = 52
12/26/2021 23:12:07 - INFO - __main__ -   Batch number = 53
12/26/2021 23:12:07 - INFO - __main__ -   Batch number = 54
12/26/2021 23:12:07 - INFO - __main__ -   Batch number = 55
12/26/2021 23:12:08 - INFO - __main__ -   Batch number = 56
12/26/2021 23:12:08 - INFO - __main__ -   Batch number = 57
12/26/2021 23:12:08 - INFO - __main__ -   Batch number = 58
12/26/2021 23:12:09 - INFO - __main__ -   Batch number = 59
12/26/2021 23:12:10 - INFO - __main__ -   Batch number = 60
12/26/2021 23:12:10 - INFO - __main__ -   Batch number = 61
12/26/2021 23:12:10 - INFO - __main__ -   Batch number = 62
12/26/2021 23:12:10 - INFO - __main__ -   Batch number = 63
12/26/2021 23:12:11 - INFO - __main__ -   Batch number = 64
12/26/2021 23:12:11 - INFO - __main__ -   Batch number = 65
12/26/2021 23:12:11 - INFO - __main__ -   Batch number = 66
12/26/2021 23:12:11 - INFO - __main__ -   Batch number = 67
12/26/2021 23:12:11 - INFO - __main__ -   Batch number = 68
12/26/2021 23:12:12 - INFO - __main__ -   Batch number = 69
12/26/2021 23:12:12 - INFO - __main__ -   Batch number = 70
12/26/2021 23:12:12 - INFO - __main__ -   Batch number = 71
12/26/2021 23:12:13 - INFO - __main__ -   Batch number = 72
12/26/2021 23:12:13 - INFO - __main__ -   Batch number = 73
12/26/2021 23:12:13 - INFO - __main__ -   Batch number = 74
12/26/2021 23:12:14 - INFO - __main__ -   Batch number = 75
12/26/2021 23:12:14 - INFO - __main__ -   Batch number = 76
12/26/2021 23:12:14 - INFO - __main__ -   Batch number = 77
12/26/2021 23:12:15 - INFO - __main__ -   Batch number = 78
12/26/2021 23:12:15 - INFO - __main__ -   Batch number = 79
12/26/2021 23:12:15 - INFO - __main__ -   Batch number = 80
12/26/2021 23:12:16 - INFO - __main__ -   Batch number = 81
12/26/2021 23:12:16 - INFO - __main__ -   Batch number = 82
12/26/2021 23:12:16 - INFO - __main__ -   Batch number = 83
12/26/2021 23:12:16 - INFO - __main__ -   Batch number = 84
12/26/2021 23:12:17 - INFO - __main__ -   Batch number = 85
12/26/2021 23:12:17 - INFO - __main__ -   Batch number = 86
12/26/2021 23:12:17 - INFO - __main__ -   Batch number = 87
12/26/2021 23:12:17 - INFO - __main__ -   Batch number = 88
12/26/2021 23:12:18 - INFO - __main__ -   Batch number = 89
12/26/2021 23:12:18 - INFO - __main__ -   Batch number = 90
12/26/2021 23:12:18 - INFO - __main__ -   Batch number = 91
12/26/2021 23:12:19 - INFO - __main__ -   Batch number = 92
12/26/2021 23:12:19 - INFO - __main__ -   Batch number = 93
12/26/2021 23:12:19 - INFO - __main__ -   Batch number = 94
12/26/2021 23:12:20 - INFO - __main__ -   Batch number = 95
12/26/2021 23:12:20 - INFO - __main__ -   Batch number = 96
12/26/2021 23:12:20 - INFO - __main__ -   Batch number = 97
12/26/2021 23:12:21 - INFO - __main__ -   Batch number = 98
12/26/2021 23:12:21 - INFO - __main__ -   Batch number = 99
12/26/2021 23:12:21 - INFO - __main__ -   Batch number = 100
12/26/2021 23:12:22 - INFO - __main__ -   Batch number = 101
12/26/2021 23:12:22 - INFO - __main__ -   Batch number = 102
12/26/2021 23:12:22 - INFO - __main__ -   Batch number = 103
12/26/2021 23:12:22 - INFO - __main__ -   Batch number = 104
12/26/2021 23:12:23 - INFO - __main__ -   Batch number = 105
12/26/2021 23:12:23 - INFO - __main__ -   Batch number = 106
12/26/2021 23:12:23 - INFO - __main__ -   Batch number = 107
12/26/2021 23:12:23 - INFO - __main__ -   Batch number = 108
12/26/2021 23:12:24 - INFO - __main__ -   Batch number = 109
12/26/2021 23:12:24 - INFO - __main__ -   Batch number = 110
12/26/2021 23:12:24 - INFO - __main__ -   Batch number = 111
12/26/2021 23:12:25 - INFO - __main__ -   Batch number = 112
12/26/2021 23:12:25 - INFO - __main__ -   Batch number = 113
12/26/2021 23:12:25 - INFO - __main__ -   Batch number = 114
12/26/2021 23:12:26 - INFO - __main__ -   Batch number = 115
12/26/2021 23:12:26 - INFO - __main__ -   Batch number = 116
12/26/2021 23:12:26 - INFO - __main__ -   Batch number = 117
12/26/2021 23:12:27 - INFO - __main__ -   Batch number = 118
12/26/2021 23:12:27 - INFO - __main__ -   Batch number = 119
12/26/2021 23:12:27 - INFO - __main__ -   Batch number = 120
12/26/2021 23:12:28 - INFO - __main__ -   Batch number = 121
12/26/2021 23:12:28 - INFO - __main__ -   Batch number = 122
12/26/2021 23:12:28 - INFO - __main__ -   Batch number = 123
12/26/2021 23:12:28 - INFO - __main__ -   Batch number = 124
12/26/2021 23:12:29 - INFO - __main__ -   Batch number = 125
12/26/2021 23:12:29 - INFO - __main__ -   Batch number = 126
12/26/2021 23:12:29 - INFO - __main__ -   Batch number = 127
12/26/2021 23:12:30 - INFO - __main__ -   Batch number = 128
12/26/2021 23:12:30 - INFO - __main__ -   Batch number = 129
12/26/2021 23:12:30 - INFO - __main__ -   Batch number = 130
12/26/2021 23:12:30 - INFO - __main__ -   Batch number = 131
12/26/2021 23:12:31 - INFO - __main__ -   Batch number = 132
12/26/2021 23:12:31 - INFO - __main__ -   Batch number = 133
12/26/2021 23:12:31 - INFO - __main__ -   Batch number = 134
12/26/2021 23:12:32 - INFO - __main__ -   Batch number = 135
12/26/2021 23:12:32 - INFO - __main__ -   Batch number = 136
12/26/2021 23:12:32 - INFO - __main__ -   Batch number = 137
12/26/2021 23:12:33 - INFO - __main__ -   Batch number = 138
12/26/2021 23:12:33 - INFO - __main__ -   Batch number = 139
12/26/2021 23:12:33 - INFO - __main__ -   Batch number = 140
12/26/2021 23:12:34 - INFO - __main__ -   Batch number = 141
12/26/2021 23:12:34 - INFO - __main__ -   Batch number = 142
12/26/2021 23:12:34 - INFO - __main__ -   Batch number = 143
12/26/2021 23:12:34 - INFO - __main__ -   Batch number = 144
12/26/2021 23:12:35 - INFO - __main__ -   Batch number = 145
12/26/2021 23:12:35 - INFO - __main__ -   Batch number = 146
12/26/2021 23:12:35 - INFO - __main__ -   Batch number = 147
12/26/2021 23:12:36 - INFO - __main__ -   Batch number = 148
12/26/2021 23:12:36 - INFO - __main__ -   Batch number = 149
12/26/2021 23:12:36 - INFO - __main__ -   Batch number = 150
12/26/2021 23:12:37 - INFO - __main__ -   Batch number = 151
12/26/2021 23:12:37 - INFO - __main__ -   Batch number = 152
12/26/2021 23:12:37 - INFO - __main__ -   Batch number = 153
12/26/2021 23:12:38 - INFO - __main__ -   Batch number = 154
12/26/2021 23:12:38 - INFO - __main__ -   Batch number = 155
12/26/2021 23:12:38 - INFO - __main__ -   Batch number = 156
12/26/2021 23:12:39 - INFO - __main__ -   Batch number = 157
12/26/2021 23:12:39 - INFO - __main__ -   Batch number = 158
12/26/2021 23:12:39 - INFO - __main__ -   Batch number = 159
12/26/2021 23:12:39 - INFO - __main__ -   Batch number = 160
12/26/2021 23:12:40 - INFO - __main__ -   Batch number = 161
12/26/2021 23:12:40 - INFO - __main__ -   Batch number = 162
12/26/2021 23:12:40 - INFO - __main__ -   Batch number = 163
12/26/2021 23:12:40 - INFO - __main__ -   Batch number = 164
12/26/2021 23:12:41 - INFO - __main__ -   Batch number = 165
12/26/2021 23:12:41 - INFO - __main__ -   Batch number = 166
12/26/2021 23:12:41 - INFO - __main__ -   Batch number = 167
12/26/2021 23:12:42 - INFO - __main__ -   Batch number = 168
12/26/2021 23:12:42 - INFO - __main__ -   Batch number = 169
12/26/2021 23:12:42 - INFO - __main__ -   Batch number = 170
12/26/2021 23:12:43 - INFO - __main__ -   Batch number = 171
12/26/2021 23:12:43 - INFO - __main__ -   Batch number = 172
12/26/2021 23:12:43 - INFO - __main__ -   Batch number = 173
12/26/2021 23:12:44 - INFO - __main__ -   Batch number = 174
12/26/2021 23:12:44 - INFO - __main__ -   Batch number = 175
12/26/2021 23:12:44 - INFO - __main__ -   Batch number = 176
12/26/2021 23:12:45 - INFO - __main__ -   Batch number = 177
12/26/2021 23:12:45 - INFO - __main__ -   Batch number = 178
12/26/2021 23:12:45 - INFO - __main__ -   Batch number = 179
12/26/2021 23:12:45 - INFO - __main__ -   Batch number = 180
12/26/2021 23:12:46 - INFO - __main__ -   Batch number = 181
12/26/2021 23:12:46 - INFO - __main__ -   Batch number = 182
12/26/2021 23:12:46 - INFO - __main__ -   Batch number = 183
12/26/2021 23:12:46 - INFO - __main__ -   Batch number = 184
12/26/2021 23:12:47 - INFO - __main__ -   Batch number = 185
12/26/2021 23:12:47 - INFO - __main__ -   Batch number = 186
12/26/2021 23:12:47 - INFO - __main__ -   Batch number = 187
12/26/2021 23:12:48 - INFO - __main__ -   Batch number = 188
12/26/2021 23:12:48 - INFO - __main__ -   Batch number = 189
12/26/2021 23:12:48 - INFO - __main__ -   Batch number = 190
12/26/2021 23:12:49 - INFO - __main__ -   Batch number = 191
12/26/2021 23:12:49 - INFO - __main__ -   Batch number = 192
12/26/2021 23:12:49 - INFO - __main__ -   Batch number = 193
12/26/2021 23:12:50 - INFO - __main__ -   Batch number = 194
12/26/2021 23:12:50 - INFO - __main__ -   Batch number = 195
12/26/2021 23:12:50 - INFO - __main__ -   Batch number = 196
12/26/2021 23:12:51 - INFO - __main__ -   Batch number = 197
12/26/2021 23:12:51 - INFO - __main__ -   Batch number = 198
12/26/2021 23:12:51 - INFO - __main__ -   Batch number = 199
12/26/2021 23:12:51 - INFO - __main__ -   Batch number = 200
12/26/2021 23:12:51 - INFO - __main__ -   Batch number = 201
12/26/2021 23:12:52 - INFO - __main__ -   Batch number = 202
12/26/2021 23:12:52 - INFO - __main__ -   Batch number = 203
12/26/2021 23:12:52 - INFO - __main__ -   Batch number = 204
12/26/2021 23:12:53 - INFO - __main__ -   Batch number = 205
12/26/2021 23:12:53 - INFO - __main__ -   Batch number = 206
12/26/2021 23:12:53 - INFO - __main__ -   Batch number = 207
12/26/2021 23:12:54 - INFO - __main__ -   Batch number = 208
12/26/2021 23:12:54 - INFO - __main__ -   Batch number = 209
12/26/2021 23:12:54 - INFO - __main__ -   Batch number = 210
12/26/2021 23:12:55 - INFO - __main__ -   Batch number = 211
12/26/2021 23:12:55 - INFO - __main__ -   Batch number = 212
12/26/2021 23:12:55 - INFO - __main__ -   Batch number = 213
12/26/2021 23:12:56 - INFO - __main__ -   Batch number = 214
12/26/2021 23:12:56 - INFO - __main__ -   Batch number = 215
12/26/2021 23:12:56 - INFO - __main__ -   Batch number = 216
12/26/2021 23:12:56 - INFO - __main__ -   Batch number = 217
12/26/2021 23:12:57 - INFO - __main__ -   Batch number = 218
12/26/2021 23:12:57 - INFO - __main__ -   Batch number = 219
12/26/2021 23:12:57 - INFO - __main__ -   Batch number = 220
12/26/2021 23:12:58 - INFO - __main__ -   Batch number = 221
12/26/2021 23:12:58 - INFO - __main__ -   Batch number = 222
12/26/2021 23:12:58 - INFO - __main__ -   Batch number = 223
12/26/2021 23:12:59 - INFO - __main__ -   Batch number = 224
12/26/2021 23:12:59 - INFO - __main__ -   Batch number = 225
12/26/2021 23:12:59 - INFO - __main__ -   Batch number = 226
12/26/2021 23:13:00 - INFO - __main__ -   Batch number = 227
12/26/2021 23:13:00 - INFO - __main__ -   Batch number = 228
12/26/2021 23:13:01 - INFO - __main__ -   Batch number = 229
12/26/2021 23:13:01 - INFO - __main__ -   Batch number = 230
12/26/2021 23:13:01 - INFO - __main__ -   Batch number = 231
12/26/2021 23:13:02 - INFO - __main__ -   Batch number = 232
12/26/2021 23:13:02 - INFO - __main__ -   Batch number = 233
12/26/2021 23:13:02 - INFO - __main__ -   Batch number = 234
12/26/2021 23:13:03 - INFO - __main__ -   Batch number = 235
12/26/2021 23:13:03 - INFO - __main__ -   Batch number = 236
12/26/2021 23:13:03 - INFO - __main__ -   Batch number = 237
12/26/2021 23:13:04 - INFO - __main__ -   Batch number = 238
12/26/2021 23:13:04 - INFO - __main__ -   Batch number = 239
12/26/2021 23:13:05 - INFO - __main__ -   Batch number = 240
12/26/2021 23:13:05 - INFO - __main__ -   Batch number = 241
12/26/2021 23:13:05 - INFO - __main__ -   Batch number = 242
12/26/2021 23:13:06 - INFO - __main__ -   Batch number = 243
12/26/2021 23:13:06 - INFO - __main__ -   Batch number = 244
12/26/2021 23:13:07 - INFO - __main__ -   Batch number = 245
12/26/2021 23:13:07 - INFO - __main__ -   Batch number = 246
12/26/2021 23:13:07 - INFO - __main__ -   Batch number = 247
12/26/2021 23:13:07 - INFO - __main__ -   Batch number = 248
12/26/2021 23:13:08 - INFO - __main__ -   Batch number = 249
12/26/2021 23:13:08 - INFO - __main__ -   Batch number = 250
12/26/2021 23:13:09 - INFO - __main__ -   Batch number = 251
12/26/2021 23:13:09 - INFO - __main__ -   Batch number = 252
12/26/2021 23:13:09 - INFO - __main__ -   Batch number = 253
12/26/2021 23:13:10 - INFO - __main__ -   Batch number = 254
12/26/2021 23:13:10 - INFO - __main__ -   Batch number = 255
12/26/2021 23:13:10 - INFO - __main__ -   Batch number = 256
12/26/2021 23:13:11 - INFO - __main__ -   Batch number = 257
12/26/2021 23:13:11 - INFO - __main__ -   Batch number = 258
12/26/2021 23:13:11 - INFO - __main__ -   Batch number = 259
12/26/2021 23:13:12 - INFO - __main__ -   Batch number = 260
12/26/2021 23:13:12 - INFO - __main__ -   Batch number = 261
12/26/2021 23:13:12 - INFO - __main__ -   Batch number = 262
12/26/2021 23:13:12 - INFO - __main__ -   Batch number = 263
12/26/2021 23:13:13 - INFO - __main__ -   Batch number = 264
12/26/2021 23:13:13 - INFO - __main__ -   Batch number = 265
12/26/2021 23:13:13 - INFO - __main__ -   Batch number = 266
12/26/2021 23:13:14 - INFO - __main__ -   Batch number = 267
12/26/2021 23:13:15 - INFO - __main__ -   Batch number = 268
12/26/2021 23:13:15 - INFO - __main__ -   Batch number = 269
12/26/2021 23:13:16 - INFO - __main__ -   Batch number = 270
12/26/2021 23:13:16 - INFO - __main__ -   Batch number = 271
12/26/2021 23:13:16 - INFO - __main__ -   Batch number = 272
12/26/2021 23:13:16 - INFO - __main__ -   Batch number = 273
12/26/2021 23:13:17 - INFO - __main__ -   Batch number = 274
12/26/2021 23:13:17 - INFO - __main__ -   Batch number = 275
12/26/2021 23:13:17 - INFO - __main__ -   Batch number = 276
12/26/2021 23:13:17 - INFO - __main__ -   Batch number = 277
12/26/2021 23:13:18 - INFO - __main__ -   Batch number = 278
12/26/2021 23:13:18 - INFO - __main__ -   Batch number = 279
12/26/2021 23:13:18 - INFO - __main__ -   Batch number = 280
12/26/2021 23:13:19 - INFO - __main__ -   Batch number = 281
12/26/2021 23:13:19 - INFO - __main__ -   Batch number = 282
12/26/2021 23:13:20 - INFO - __main__ -   Batch number = 283
12/26/2021 23:13:20 - INFO - __main__ -   Batch number = 284
12/26/2021 23:13:21 - INFO - __main__ -   Batch number = 285
12/26/2021 23:13:21 - INFO - __main__ -   Batch number = 286
12/26/2021 23:13:22 - INFO - __main__ -   Batch number = 287
12/26/2021 23:13:22 - INFO - __main__ -   Batch number = 288
12/26/2021 23:13:22 - INFO - __main__ -   Batch number = 289
12/26/2021 23:13:22 - INFO - __main__ -   Batch number = 290
12/26/2021 23:13:22 - INFO - __main__ -   Batch number = 291
12/26/2021 23:13:23 - INFO - __main__ -   Batch number = 292
12/26/2021 23:13:23 - INFO - __main__ -   Batch number = 293
12/26/2021 23:13:23 - INFO - __main__ -   Batch number = 294
12/26/2021 23:13:24 - INFO - __main__ -   Batch number = 295
12/26/2021 23:13:24 - INFO - __main__ -   Batch number = 296
12/26/2021 23:13:25 - INFO - __main__ -   Batch number = 297
12/26/2021 23:13:26 - INFO - __main__ -   Batch number = 298
12/26/2021 23:13:26 - INFO - __main__ -   Batch number = 299
12/26/2021 23:13:27 - INFO - __main__ -   Batch number = 300
12/26/2021 23:13:27 - INFO - __main__ -   Batch number = 301
12/26/2021 23:13:27 - INFO - __main__ -   Batch number = 302
12/26/2021 23:13:27 - INFO - __main__ -   Batch number = 303
12/26/2021 23:13:28 - INFO - __main__ -   Batch number = 304
12/26/2021 23:13:28 - INFO - __main__ -   Batch number = 305
12/26/2021 23:13:28 - INFO - __main__ -   Batch number = 306
12/26/2021 23:13:29 - INFO - __main__ -   Batch number = 307
12/26/2021 23:13:29 - INFO - __main__ -   Batch number = 308
12/26/2021 23:13:30 - INFO - __main__ -   Batch number = 309
12/26/2021 23:13:30 - INFO - __main__ -   Batch number = 310
12/26/2021 23:13:31 - INFO - __main__ -   Batch number = 311
12/26/2021 23:13:31 - INFO - __main__ -   Batch number = 312
12/26/2021 23:13:31 - INFO - __main__ -   Batch number = 313
12/26/2021 23:13:33 - INFO - __main__ -   ***** Evaluation result  in ar *****
12/26/2021 23:13:33 - INFO - __main__ -     f1 = 0.33872048233126784
12/26/2021 23:13:33 - INFO - __main__ -     loss = 5.488271574623669
12/26/2021 23:13:33 - INFO - __main__ -     precision = 0.3203960396039604
12/26/2021 23:13:33 - INFO - __main__ -     recall = 0.35926814104272137
12/26/2021 23:13:35 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:13:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:13:35 - INFO - __main__ -   Seed = 2
12/26/2021 23:13:35 - INFO - root -   save model
12/26/2021 23:13:35 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:13:35 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:13:39 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:13:46 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:13:46 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:13:46 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:13:46 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:13:46 - INFO - root -   loading task adapter
12/26/2021 23:13:46 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:13:46 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:13:46 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:13:46 - INFO - __main__ -   Language = pt
12/26/2021 23:13:46 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:13:55 - INFO - __main__ -   Language adapter for ar not found, using pt instead
12/26/2021 23:13:55 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:13:55 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:13:55 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:13:55 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
12/26/2021 23:13:56 - INFO - __main__ -   ***** Running evaluation  in ar *****
12/26/2021 23:13:56 - INFO - __main__ -     Num examples = 10000
12/26/2021 23:13:56 - INFO - __main__ -     Batch size = 32
12/26/2021 23:13:56 - INFO - __main__ -   Batch number = 1
12/26/2021 23:13:57 - INFO - __main__ -   Batch number = 2
12/26/2021 23:13:57 - INFO - __main__ -   Batch number = 3
12/26/2021 23:13:57 - INFO - __main__ -   Batch number = 4
12/26/2021 23:13:58 - INFO - __main__ -   Batch number = 5
12/26/2021 23:13:58 - INFO - __main__ -   Batch number = 6
12/26/2021 23:13:58 - INFO - __main__ -   Batch number = 7
12/26/2021 23:13:59 - INFO - __main__ -   Batch number = 8
12/26/2021 23:13:59 - INFO - __main__ -   Batch number = 9
12/26/2021 23:13:59 - INFO - __main__ -   Batch number = 10
12/26/2021 23:13:59 - INFO - __main__ -   Batch number = 11
12/26/2021 23:14:00 - INFO - __main__ -   Batch number = 12
12/26/2021 23:14:00 - INFO - __main__ -   Batch number = 13
12/26/2021 23:14:00 - INFO - __main__ -   Batch number = 14
12/26/2021 23:14:01 - INFO - __main__ -   Batch number = 15
12/26/2021 23:14:01 - INFO - __main__ -   Batch number = 16
12/26/2021 23:14:01 - INFO - __main__ -   Batch number = 17
12/26/2021 23:14:01 - INFO - __main__ -   Batch number = 18
12/26/2021 23:14:01 - INFO - __main__ -   Batch number = 19
12/26/2021 23:14:01 - INFO - __main__ -   Batch number = 20
12/26/2021 23:14:02 - INFO - __main__ -   Batch number = 21
12/26/2021 23:14:02 - INFO - __main__ -   Batch number = 22
12/26/2021 23:14:02 - INFO - __main__ -   Batch number = 23
12/26/2021 23:14:03 - INFO - __main__ -   Batch number = 24
12/26/2021 23:14:03 - INFO - __main__ -   Batch number = 25
12/26/2021 23:14:03 - INFO - __main__ -   Batch number = 26
12/26/2021 23:14:03 - INFO - __main__ -   Batch number = 27
12/26/2021 23:14:04 - INFO - __main__ -   Batch number = 28
12/26/2021 23:14:04 - INFO - __main__ -   Batch number = 29
12/26/2021 23:14:05 - INFO - __main__ -   Batch number = 30
12/26/2021 23:14:06 - INFO - __main__ -   Batch number = 31
12/26/2021 23:14:06 - INFO - __main__ -   Batch number = 32
12/26/2021 23:14:06 - INFO - __main__ -   Batch number = 33
12/26/2021 23:14:06 - INFO - __main__ -   Batch number = 34
12/26/2021 23:14:06 - INFO - __main__ -   Batch number = 35
12/26/2021 23:14:07 - INFO - __main__ -   Batch number = 36
12/26/2021 23:14:07 - INFO - __main__ -   Batch number = 37
12/26/2021 23:14:07 - INFO - __main__ -   Batch number = 38
12/26/2021 23:14:07 - INFO - __main__ -   Batch number = 39
12/26/2021 23:14:07 - INFO - __main__ -   Batch number = 40
12/26/2021 23:14:07 - INFO - __main__ -   Batch number = 41
12/26/2021 23:14:08 - INFO - __main__ -   Batch number = 42
12/26/2021 23:14:08 - INFO - __main__ -   Batch number = 43
12/26/2021 23:14:08 - INFO - __main__ -   Batch number = 44
12/26/2021 23:14:08 - INFO - __main__ -   Batch number = 45
12/26/2021 23:14:08 - INFO - __main__ -   Batch number = 46
12/26/2021 23:14:08 - INFO - __main__ -   Batch number = 47
12/26/2021 23:14:09 - INFO - __main__ -   Batch number = 48
12/26/2021 23:14:09 - INFO - __main__ -   Batch number = 49
12/26/2021 23:14:09 - INFO - __main__ -   Batch number = 50
12/26/2021 23:14:09 - INFO - __main__ -   Batch number = 51
12/26/2021 23:14:10 - INFO - __main__ -   Batch number = 52
12/26/2021 23:14:10 - INFO - __main__ -   Batch number = 53
12/26/2021 23:14:10 - INFO - __main__ -   Batch number = 54
12/26/2021 23:14:11 - INFO - __main__ -   Batch number = 55
12/26/2021 23:14:11 - INFO - __main__ -   Batch number = 56
12/26/2021 23:14:11 - INFO - __main__ -   Batch number = 57
12/26/2021 23:14:11 - INFO - __main__ -   Batch number = 58
12/26/2021 23:14:12 - INFO - __main__ -   Batch number = 59
12/26/2021 23:14:12 - INFO - __main__ -   Batch number = 60
12/26/2021 23:14:12 - INFO - __main__ -   Batch number = 61
12/26/2021 23:14:13 - INFO - __main__ -   Batch number = 62
12/26/2021 23:14:13 - INFO - __main__ -   Batch number = 63
12/26/2021 23:14:13 - INFO - __main__ -   Batch number = 64
12/26/2021 23:14:14 - INFO - __main__ -   Batch number = 65
12/26/2021 23:14:14 - INFO - __main__ -   Batch number = 66
12/26/2021 23:14:14 - INFO - __main__ -   Batch number = 67
12/26/2021 23:14:14 - INFO - __main__ -   Batch number = 68
12/26/2021 23:14:15 - INFO - __main__ -   Batch number = 69
12/26/2021 23:14:15 - INFO - __main__ -   Batch number = 70
12/26/2021 23:14:15 - INFO - __main__ -   Batch number = 71
12/26/2021 23:14:15 - INFO - __main__ -   Batch number = 72
12/26/2021 23:14:17 - INFO - __main__ -   Batch number = 73
12/26/2021 23:14:17 - INFO - __main__ -   Batch number = 74
12/26/2021 23:14:17 - INFO - __main__ -   Batch number = 75
12/26/2021 23:14:17 - INFO - __main__ -   Batch number = 76
12/26/2021 23:14:18 - INFO - __main__ -   Batch number = 77
12/26/2021 23:14:18 - INFO - __main__ -   Batch number = 78
12/26/2021 23:14:18 - INFO - __main__ -   Batch number = 79
12/26/2021 23:14:19 - INFO - __main__ -   Batch number = 80
12/26/2021 23:14:19 - INFO - __main__ -   Batch number = 81
12/26/2021 23:14:19 - INFO - __main__ -   Batch number = 82
12/26/2021 23:14:19 - INFO - __main__ -   Batch number = 83
12/26/2021 23:14:20 - INFO - __main__ -   Batch number = 84
12/26/2021 23:14:20 - INFO - __main__ -   Batch number = 85
12/26/2021 23:14:20 - INFO - __main__ -   Batch number = 86
12/26/2021 23:14:21 - INFO - __main__ -   Batch number = 87
12/26/2021 23:14:21 - INFO - __main__ -   Batch number = 88
12/26/2021 23:14:21 - INFO - __main__ -   Batch number = 89
12/26/2021 23:14:21 - INFO - __main__ -   Batch number = 90
12/26/2021 23:14:22 - INFO - __main__ -   Batch number = 91
12/26/2021 23:14:22 - INFO - __main__ -   Batch number = 92
12/26/2021 23:14:22 - INFO - __main__ -   Batch number = 93
12/26/2021 23:14:23 - INFO - __main__ -   Batch number = 94
12/26/2021 23:14:23 - INFO - __main__ -   Batch number = 95
12/26/2021 23:14:23 - INFO - __main__ -   Batch number = 96
12/26/2021 23:14:24 - INFO - __main__ -   Batch number = 97
12/26/2021 23:14:24 - INFO - __main__ -   Batch number = 98
12/26/2021 23:14:24 - INFO - __main__ -   Batch number = 99
12/26/2021 23:14:25 - INFO - __main__ -   Batch number = 100
12/26/2021 23:14:25 - INFO - __main__ -   Batch number = 101
12/26/2021 23:14:25 - INFO - __main__ -   Batch number = 102
12/26/2021 23:14:25 - INFO - __main__ -   Batch number = 103
12/26/2021 23:14:26 - INFO - __main__ -   Batch number = 104
12/26/2021 23:14:26 - INFO - __main__ -   Batch number = 105
12/26/2021 23:14:26 - INFO - __main__ -   Batch number = 106
12/26/2021 23:14:27 - INFO - __main__ -   Batch number = 107
12/26/2021 23:14:27 - INFO - __main__ -   Batch number = 108
12/26/2021 23:14:27 - INFO - __main__ -   Batch number = 109
12/26/2021 23:14:27 - INFO - __main__ -   Batch number = 110
12/26/2021 23:14:28 - INFO - __main__ -   Batch number = 111
12/26/2021 23:14:28 - INFO - __main__ -   Batch number = 112
12/26/2021 23:14:28 - INFO - __main__ -   Batch number = 113
12/26/2021 23:14:29 - INFO - __main__ -   Batch number = 114
12/26/2021 23:14:29 - INFO - __main__ -   Batch number = 115
12/26/2021 23:14:29 - INFO - __main__ -   Batch number = 116
12/26/2021 23:14:30 - INFO - __main__ -   Batch number = 117
12/26/2021 23:14:30 - INFO - __main__ -   Batch number = 118
12/26/2021 23:14:30 - INFO - __main__ -   Batch number = 119
12/26/2021 23:14:31 - INFO - __main__ -   Batch number = 120
12/26/2021 23:14:31 - INFO - __main__ -   Batch number = 121
12/26/2021 23:14:31 - INFO - __main__ -   Batch number = 122
12/26/2021 23:14:31 - INFO - __main__ -   Batch number = 123
12/26/2021 23:14:31 - INFO - __main__ -   Batch number = 124
12/26/2021 23:14:31 - INFO - __main__ -   Batch number = 125
12/26/2021 23:14:32 - INFO - __main__ -   Batch number = 126
12/26/2021 23:14:32 - INFO - __main__ -   Batch number = 127
12/26/2021 23:14:32 - INFO - __main__ -   Batch number = 128
12/26/2021 23:14:33 - INFO - __main__ -   Batch number = 129
12/26/2021 23:14:33 - INFO - __main__ -   Batch number = 130
12/26/2021 23:14:33 - INFO - __main__ -   Batch number = 131
12/26/2021 23:14:33 - INFO - __main__ -   Batch number = 132
12/26/2021 23:14:34 - INFO - __main__ -   Batch number = 133
12/26/2021 23:14:34 - INFO - __main__ -   Batch number = 134
12/26/2021 23:14:34 - INFO - __main__ -   Batch number = 135
12/26/2021 23:14:35 - INFO - __main__ -   Batch number = 136
12/26/2021 23:14:35 - INFO - __main__ -   Batch number = 137
12/26/2021 23:14:35 - INFO - __main__ -   Batch number = 138
12/26/2021 23:14:36 - INFO - __main__ -   Batch number = 139
12/26/2021 23:14:36 - INFO - __main__ -   Batch number = 140
12/26/2021 23:14:36 - INFO - __main__ -   Batch number = 141
12/26/2021 23:14:37 - INFO - __main__ -   Batch number = 142
12/26/2021 23:14:38 - INFO - __main__ -   Batch number = 143
12/26/2021 23:14:38 - INFO - __main__ -   Batch number = 144
12/26/2021 23:14:38 - INFO - __main__ -   Batch number = 145
12/26/2021 23:14:38 - INFO - __main__ -   Batch number = 146
12/26/2021 23:14:38 - INFO - __main__ -   Batch number = 147
12/26/2021 23:14:39 - INFO - __main__ -   Batch number = 148
12/26/2021 23:14:39 - INFO - __main__ -   Batch number = 149
12/26/2021 23:14:39 - INFO - __main__ -   Batch number = 150
12/26/2021 23:14:40 - INFO - __main__ -   Batch number = 151
12/26/2021 23:14:40 - INFO - __main__ -   Batch number = 152
12/26/2021 23:14:40 - INFO - __main__ -   Batch number = 153
12/26/2021 23:14:40 - INFO - __main__ -   Batch number = 154
12/26/2021 23:14:41 - INFO - __main__ -   Batch number = 155
12/26/2021 23:14:41 - INFO - __main__ -   Batch number = 156
12/26/2021 23:14:41 - INFO - __main__ -   Batch number = 157
12/26/2021 23:14:42 - INFO - __main__ -   Batch number = 158
12/26/2021 23:14:42 - INFO - __main__ -   Batch number = 159
12/26/2021 23:14:42 - INFO - __main__ -   Batch number = 160
12/26/2021 23:14:43 - INFO - __main__ -   Batch number = 161
12/26/2021 23:14:43 - INFO - __main__ -   Batch number = 162
12/26/2021 23:14:43 - INFO - __main__ -   Batch number = 163
12/26/2021 23:14:44 - INFO - __main__ -   Batch number = 164
12/26/2021 23:14:44 - INFO - __main__ -   Batch number = 165
12/26/2021 23:14:44 - INFO - __main__ -   Batch number = 166
12/26/2021 23:14:44 - INFO - __main__ -   Batch number = 167
12/26/2021 23:14:45 - INFO - __main__ -   Batch number = 168
12/26/2021 23:14:45 - INFO - __main__ -   Batch number = 169
12/26/2021 23:14:45 - INFO - __main__ -   Batch number = 170
12/26/2021 23:14:45 - INFO - __main__ -   Batch number = 171
12/26/2021 23:14:46 - INFO - __main__ -   Batch number = 172
12/26/2021 23:14:46 - INFO - __main__ -   Batch number = 173
12/26/2021 23:14:46 - INFO - __main__ -   Batch number = 174
12/26/2021 23:14:47 - INFO - __main__ -   Batch number = 175
12/26/2021 23:14:47 - INFO - __main__ -   Batch number = 176
12/26/2021 23:14:47 - INFO - __main__ -   Batch number = 177
12/26/2021 23:14:48 - INFO - __main__ -   Batch number = 178
12/26/2021 23:14:48 - INFO - __main__ -   Batch number = 179
12/26/2021 23:14:48 - INFO - __main__ -   Batch number = 180
12/26/2021 23:14:49 - INFO - __main__ -   Batch number = 181
12/26/2021 23:14:49 - INFO - __main__ -   Batch number = 182
12/26/2021 23:14:49 - INFO - __main__ -   Batch number = 183
12/26/2021 23:14:50 - INFO - __main__ -   Batch number = 184
12/26/2021 23:14:50 - INFO - __main__ -   Batch number = 185
12/26/2021 23:14:50 - INFO - __main__ -   Batch number = 186
12/26/2021 23:14:50 - INFO - __main__ -   Batch number = 187
12/26/2021 23:14:50 - INFO - __main__ -   Batch number = 188
12/26/2021 23:14:51 - INFO - __main__ -   Batch number = 189
12/26/2021 23:14:51 - INFO - __main__ -   Batch number = 190
12/26/2021 23:14:51 - INFO - __main__ -   Batch number = 191
12/26/2021 23:14:52 - INFO - __main__ -   Batch number = 192
12/26/2021 23:14:52 - INFO - __main__ -   Batch number = 193
12/26/2021 23:14:52 - INFO - __main__ -   Batch number = 194
12/26/2021 23:14:52 - INFO - __main__ -   Batch number = 195
12/26/2021 23:14:53 - INFO - __main__ -   Batch number = 196
12/26/2021 23:14:53 - INFO - __main__ -   Batch number = 197
12/26/2021 23:14:54 - INFO - __main__ -   Batch number = 198
12/26/2021 23:14:54 - INFO - __main__ -   Batch number = 199
12/26/2021 23:14:54 - INFO - __main__ -   Batch number = 200
12/26/2021 23:14:55 - INFO - __main__ -   Batch number = 201
12/26/2021 23:14:55 - INFO - __main__ -   Batch number = 202
12/26/2021 23:14:55 - INFO - __main__ -   Batch number = 203
12/26/2021 23:14:55 - INFO - __main__ -   Batch number = 204
12/26/2021 23:14:56 - INFO - __main__ -   Batch number = 205
12/26/2021 23:14:56 - INFO - __main__ -   Batch number = 206
12/26/2021 23:14:56 - INFO - __main__ -   Batch number = 207
12/26/2021 23:14:56 - INFO - __main__ -   Batch number = 208
12/26/2021 23:14:56 - INFO - __main__ -   Batch number = 209
12/26/2021 23:14:57 - INFO - __main__ -   Batch number = 210
12/26/2021 23:14:57 - INFO - __main__ -   Batch number = 211
12/26/2021 23:14:57 - INFO - __main__ -   Batch number = 212
12/26/2021 23:14:57 - INFO - __main__ -   Batch number = 213
12/26/2021 23:14:58 - INFO - __main__ -   Batch number = 214
12/26/2021 23:14:58 - INFO - __main__ -   Batch number = 215
12/26/2021 23:14:58 - INFO - __main__ -   Batch number = 216
12/26/2021 23:14:59 - INFO - __main__ -   Batch number = 217
12/26/2021 23:14:59 - INFO - __main__ -   Batch number = 218
12/26/2021 23:15:00 - INFO - __main__ -   Batch number = 219
12/26/2021 23:15:00 - INFO - __main__ -   Batch number = 220
12/26/2021 23:15:00 - INFO - __main__ -   Batch number = 221
12/26/2021 23:15:01 - INFO - __main__ -   Batch number = 222
12/26/2021 23:15:01 - INFO - __main__ -   Batch number = 223
12/26/2021 23:15:01 - INFO - __main__ -   Batch number = 224
12/26/2021 23:15:01 - INFO - __main__ -   Batch number = 225
12/26/2021 23:15:02 - INFO - __main__ -   Batch number = 226
12/26/2021 23:15:02 - INFO - __main__ -   Batch number = 227
12/26/2021 23:15:02 - INFO - __main__ -   Batch number = 228
12/26/2021 23:15:03 - INFO - __main__ -   Batch number = 229
12/26/2021 23:15:03 - INFO - __main__ -   Batch number = 230
12/26/2021 23:15:04 - INFO - __main__ -   Batch number = 231
12/26/2021 23:15:04 - INFO - __main__ -   Batch number = 232
12/26/2021 23:15:05 - INFO - __main__ -   Batch number = 233
12/26/2021 23:15:05 - INFO - __main__ -   Batch number = 234
12/26/2021 23:15:05 - INFO - __main__ -   Batch number = 235
12/26/2021 23:15:06 - INFO - __main__ -   Batch number = 236
12/26/2021 23:15:06 - INFO - __main__ -   Batch number = 237
12/26/2021 23:15:06 - INFO - __main__ -   Batch number = 238
12/26/2021 23:15:07 - INFO - __main__ -   Batch number = 239
12/26/2021 23:15:07 - INFO - __main__ -   Batch number = 240
12/26/2021 23:15:07 - INFO - __main__ -   Batch number = 241
12/26/2021 23:15:08 - INFO - __main__ -   Batch number = 242
12/26/2021 23:15:08 - INFO - __main__ -   Batch number = 243
12/26/2021 23:15:09 - INFO - __main__ -   Batch number = 244
12/26/2021 23:15:09 - INFO - __main__ -   Batch number = 245
12/26/2021 23:15:09 - INFO - __main__ -   Batch number = 246
12/26/2021 23:15:10 - INFO - __main__ -   Batch number = 247
12/26/2021 23:15:10 - INFO - __main__ -   Batch number = 248
12/26/2021 23:15:10 - INFO - __main__ -   Batch number = 249
12/26/2021 23:15:11 - INFO - __main__ -   Batch number = 250
12/26/2021 23:15:11 - INFO - __main__ -   Batch number = 251
12/26/2021 23:15:11 - INFO - __main__ -   Batch number = 252
12/26/2021 23:15:11 - INFO - __main__ -   Batch number = 253
12/26/2021 23:15:12 - INFO - __main__ -   Batch number = 254
12/26/2021 23:15:12 - INFO - __main__ -   Batch number = 255
12/26/2021 23:15:13 - INFO - __main__ -   Batch number = 256
12/26/2021 23:15:13 - INFO - __main__ -   Batch number = 257
12/26/2021 23:15:13 - INFO - __main__ -   Batch number = 258
12/26/2021 23:15:14 - INFO - __main__ -   Batch number = 259
12/26/2021 23:15:14 - INFO - __main__ -   Batch number = 260
12/26/2021 23:15:14 - INFO - __main__ -   Batch number = 261
12/26/2021 23:15:15 - INFO - __main__ -   Batch number = 262
12/26/2021 23:15:15 - INFO - __main__ -   Batch number = 263
12/26/2021 23:15:16 - INFO - __main__ -   Batch number = 264
12/26/2021 23:15:16 - INFO - __main__ -   Batch number = 265
12/26/2021 23:15:16 - INFO - __main__ -   Batch number = 266
12/26/2021 23:15:16 - INFO - __main__ -   Batch number = 267
12/26/2021 23:15:16 - INFO - __main__ -   Batch number = 268
12/26/2021 23:15:17 - INFO - __main__ -   Batch number = 269
12/26/2021 23:15:17 - INFO - __main__ -   Batch number = 270
12/26/2021 23:15:17 - INFO - __main__ -   Batch number = 271
12/26/2021 23:15:17 - INFO - __main__ -   Batch number = 272
12/26/2021 23:15:18 - INFO - __main__ -   Batch number = 273
12/26/2021 23:15:18 - INFO - __main__ -   Batch number = 274
12/26/2021 23:15:19 - INFO - __main__ -   Batch number = 275
12/26/2021 23:15:19 - INFO - __main__ -   Batch number = 276
12/26/2021 23:15:19 - INFO - __main__ -   Batch number = 277
12/26/2021 23:15:20 - INFO - __main__ -   Batch number = 278
12/26/2021 23:15:20 - INFO - __main__ -   Batch number = 279
12/26/2021 23:15:21 - INFO - __main__ -   Batch number = 280
12/26/2021 23:15:21 - INFO - __main__ -   Batch number = 281
12/26/2021 23:15:21 - INFO - __main__ -   Batch number = 282
12/26/2021 23:15:22 - INFO - __main__ -   Batch number = 283
12/26/2021 23:15:22 - INFO - __main__ -   Batch number = 284
12/26/2021 23:15:22 - INFO - __main__ -   Batch number = 285
12/26/2021 23:15:22 - INFO - __main__ -   Batch number = 286
12/26/2021 23:15:23 - INFO - __main__ -   Batch number = 287
12/26/2021 23:15:23 - INFO - __main__ -   Batch number = 288
12/26/2021 23:15:24 - INFO - __main__ -   Batch number = 289
12/26/2021 23:15:24 - INFO - __main__ -   Batch number = 290
12/26/2021 23:15:24 - INFO - __main__ -   Batch number = 291
12/26/2021 23:15:25 - INFO - __main__ -   Batch number = 292
12/26/2021 23:15:25 - INFO - __main__ -   Batch number = 293
12/26/2021 23:15:25 - INFO - __main__ -   Batch number = 294
12/26/2021 23:15:26 - INFO - __main__ -   Batch number = 295
12/26/2021 23:15:26 - INFO - __main__ -   Batch number = 296
12/26/2021 23:15:27 - INFO - __main__ -   Batch number = 297
12/26/2021 23:15:27 - INFO - __main__ -   Batch number = 298
12/26/2021 23:15:27 - INFO - __main__ -   Batch number = 299
12/26/2021 23:15:27 - INFO - __main__ -   Batch number = 300
12/26/2021 23:15:28 - INFO - __main__ -   Batch number = 301
12/26/2021 23:15:28 - INFO - __main__ -   Batch number = 302
12/26/2021 23:15:28 - INFO - __main__ -   Batch number = 303
12/26/2021 23:15:28 - INFO - __main__ -   Batch number = 304
12/26/2021 23:15:29 - INFO - __main__ -   Batch number = 305
12/26/2021 23:15:29 - INFO - __main__ -   Batch number = 306
12/26/2021 23:15:30 - INFO - __main__ -   Batch number = 307
12/26/2021 23:15:30 - INFO - __main__ -   Batch number = 308
12/26/2021 23:15:31 - INFO - __main__ -   Batch number = 309
12/26/2021 23:15:31 - INFO - __main__ -   Batch number = 310
12/26/2021 23:15:31 - INFO - __main__ -   Batch number = 311
12/26/2021 23:15:32 - INFO - __main__ -   Batch number = 312
12/26/2021 23:15:32 - INFO - __main__ -   Batch number = 313
12/26/2021 23:15:33 - INFO - __main__ -   ***** Evaluation result  in ar *****
12/26/2021 23:15:33 - INFO - __main__ -     f1 = 0.3182097123920959
12/26/2021 23:15:33 - INFO - __main__ -     loss = 5.038072746020918
12/26/2021 23:15:33 - INFO - __main__ -     precision = 0.29497876213592233
12/26/2021 23:15:33 - INFO - __main__ -     recall = 0.34541255884181543
12/26/2021 23:15:36 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:15:36 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:15:36 - INFO - __main__ -   Seed = 3
12/26/2021 23:15:36 - INFO - root -   save model
12/26/2021 23:15:36 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ar', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:15:36 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:15:40 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:15:47 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:15:47 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:15:47 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/26/2021 23:15:47 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:15:47 - INFO - root -   loading task adapter
12/26/2021 23:15:47 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:15:47 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:15:47 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:15:47 - INFO - __main__ -   Language = pt
12/26/2021 23:15:47 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:15:55 - INFO - __main__ -   Language adapter for ar not found, using pt instead
12/26/2021 23:15:55 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:15:55 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:15:55 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:15:55 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
12/26/2021 23:15:56 - INFO - __main__ -   ***** Running evaluation  in ar *****
12/26/2021 23:15:56 - INFO - __main__ -     Num examples = 10000
12/26/2021 23:15:56 - INFO - __main__ -     Batch size = 32
12/26/2021 23:15:56 - INFO - __main__ -   Batch number = 1
12/26/2021 23:15:56 - INFO - __main__ -   Batch number = 2
12/26/2021 23:15:57 - INFO - __main__ -   Batch number = 3
12/26/2021 23:15:57 - INFO - __main__ -   Batch number = 4
12/26/2021 23:15:57 - INFO - __main__ -   Batch number = 5
12/26/2021 23:15:58 - INFO - __main__ -   Batch number = 6
12/26/2021 23:15:58 - INFO - __main__ -   Batch number = 7
12/26/2021 23:15:58 - INFO - __main__ -   Batch number = 8
12/26/2021 23:15:59 - INFO - __main__ -   Batch number = 9
12/26/2021 23:15:59 - INFO - __main__ -   Batch number = 10
12/26/2021 23:15:59 - INFO - __main__ -   Batch number = 11
12/26/2021 23:16:00 - INFO - __main__ -   Batch number = 12
12/26/2021 23:16:00 - INFO - __main__ -   Batch number = 13
12/26/2021 23:16:00 - INFO - __main__ -   Batch number = 14
12/26/2021 23:16:00 - INFO - __main__ -   Batch number = 15
12/26/2021 23:16:01 - INFO - __main__ -   Batch number = 16
12/26/2021 23:16:01 - INFO - __main__ -   Batch number = 17
12/26/2021 23:16:01 - INFO - __main__ -   Batch number = 18
12/26/2021 23:16:01 - INFO - __main__ -   Batch number = 19
12/26/2021 23:16:02 - INFO - __main__ -   Batch number = 20
12/26/2021 23:16:02 - INFO - __main__ -   Batch number = 21
12/26/2021 23:16:02 - INFO - __main__ -   Batch number = 22
12/26/2021 23:16:03 - INFO - __main__ -   Batch number = 23
12/26/2021 23:16:03 - INFO - __main__ -   Batch number = 24
12/26/2021 23:16:03 - INFO - __main__ -   Batch number = 25
12/26/2021 23:16:04 - INFO - __main__ -   Batch number = 26
12/26/2021 23:16:04 - INFO - __main__ -   Batch number = 27
12/26/2021 23:16:04 - INFO - __main__ -   Batch number = 28
12/26/2021 23:16:04 - INFO - __main__ -   Batch number = 29
12/26/2021 23:16:05 - INFO - __main__ -   Batch number = 30
12/26/2021 23:16:05 - INFO - __main__ -   Batch number = 31
12/26/2021 23:16:05 - INFO - __main__ -   Batch number = 32
12/26/2021 23:16:06 - INFO - __main__ -   Batch number = 33
12/26/2021 23:16:06 - INFO - __main__ -   Batch number = 34
12/26/2021 23:16:06 - INFO - __main__ -   Batch number = 35
12/26/2021 23:16:06 - INFO - __main__ -   Batch number = 36
12/26/2021 23:16:07 - INFO - __main__ -   Batch number = 37
12/26/2021 23:16:07 - INFO - __main__ -   Batch number = 38
12/26/2021 23:16:07 - INFO - __main__ -   Batch number = 39
12/26/2021 23:16:08 - INFO - __main__ -   Batch number = 40
12/26/2021 23:16:08 - INFO - __main__ -   Batch number = 41
12/26/2021 23:16:08 - INFO - __main__ -   Batch number = 42
12/26/2021 23:16:08 - INFO - __main__ -   Batch number = 43
12/26/2021 23:16:09 - INFO - __main__ -   Batch number = 44
12/26/2021 23:16:09 - INFO - __main__ -   Batch number = 45
12/26/2021 23:16:09 - INFO - __main__ -   Batch number = 46
12/26/2021 23:16:10 - INFO - __main__ -   Batch number = 47
12/26/2021 23:16:10 - INFO - __main__ -   Batch number = 48
12/26/2021 23:16:10 - INFO - __main__ -   Batch number = 49
12/26/2021 23:16:11 - INFO - __main__ -   Batch number = 50
12/26/2021 23:16:11 - INFO - __main__ -   Batch number = 51
12/26/2021 23:16:11 - INFO - __main__ -   Batch number = 52
12/26/2021 23:16:12 - INFO - __main__ -   Batch number = 53
12/26/2021 23:16:12 - INFO - __main__ -   Batch number = 54
12/26/2021 23:16:12 - INFO - __main__ -   Batch number = 55
12/26/2021 23:16:12 - INFO - __main__ -   Batch number = 56
12/26/2021 23:16:13 - INFO - __main__ -   Batch number = 57
12/26/2021 23:16:13 - INFO - __main__ -   Batch number = 58
12/26/2021 23:16:13 - INFO - __main__ -   Batch number = 59
12/26/2021 23:16:13 - INFO - __main__ -   Batch number = 60
12/26/2021 23:16:14 - INFO - __main__ -   Batch number = 61
12/26/2021 23:16:14 - INFO - __main__ -   Batch number = 62
12/26/2021 23:16:14 - INFO - __main__ -   Batch number = 63
12/26/2021 23:16:15 - INFO - __main__ -   Batch number = 64
12/26/2021 23:16:15 - INFO - __main__ -   Batch number = 65
12/26/2021 23:16:15 - INFO - __main__ -   Batch number = 66
12/26/2021 23:16:16 - INFO - __main__ -   Batch number = 67
12/26/2021 23:16:16 - INFO - __main__ -   Batch number = 68
12/26/2021 23:16:16 - INFO - __main__ -   Batch number = 69
12/26/2021 23:16:17 - INFO - __main__ -   Batch number = 70
12/26/2021 23:16:17 - INFO - __main__ -   Batch number = 71
12/26/2021 23:16:17 - INFO - __main__ -   Batch number = 72
12/26/2021 23:16:17 - INFO - __main__ -   Batch number = 73
12/26/2021 23:16:18 - INFO - __main__ -   Batch number = 74
12/26/2021 23:16:18 - INFO - __main__ -   Batch number = 75
12/26/2021 23:16:18 - INFO - __main__ -   Batch number = 76
12/26/2021 23:16:18 - INFO - __main__ -   Batch number = 77
12/26/2021 23:16:19 - INFO - __main__ -   Batch number = 78
12/26/2021 23:16:19 - INFO - __main__ -   Batch number = 79
12/26/2021 23:16:19 - INFO - __main__ -   Batch number = 80
12/26/2021 23:16:20 - INFO - __main__ -   Batch number = 81
12/26/2021 23:16:20 - INFO - __main__ -   Batch number = 82
12/26/2021 23:16:20 - INFO - __main__ -   Batch number = 83
12/26/2021 23:16:21 - INFO - __main__ -   Batch number = 84
12/26/2021 23:16:21 - INFO - __main__ -   Batch number = 85
12/26/2021 23:16:21 - INFO - __main__ -   Batch number = 86
12/26/2021 23:16:22 - INFO - __main__ -   Batch number = 87
12/26/2021 23:16:22 - INFO - __main__ -   Batch number = 88
12/26/2021 23:16:22 - INFO - __main__ -   Batch number = 89
12/26/2021 23:16:23 - INFO - __main__ -   Batch number = 90
12/26/2021 23:16:23 - INFO - __main__ -   Batch number = 91
12/26/2021 23:16:23 - INFO - __main__ -   Batch number = 92
12/26/2021 23:16:23 - INFO - __main__ -   Batch number = 93
12/26/2021 23:16:24 - INFO - __main__ -   Batch number = 94
12/26/2021 23:16:24 - INFO - __main__ -   Batch number = 95
12/26/2021 23:16:24 - INFO - __main__ -   Batch number = 96
12/26/2021 23:16:25 - INFO - __main__ -   Batch number = 97
12/26/2021 23:16:25 - INFO - __main__ -   Batch number = 98
12/26/2021 23:16:25 - INFO - __main__ -   Batch number = 99
12/26/2021 23:16:26 - INFO - __main__ -   Batch number = 100
12/26/2021 23:16:26 - INFO - __main__ -   Batch number = 101
12/26/2021 23:16:26 - INFO - __main__ -   Batch number = 102
12/26/2021 23:16:27 - INFO - __main__ -   Batch number = 103
12/26/2021 23:16:27 - INFO - __main__ -   Batch number = 104
12/26/2021 23:16:27 - INFO - __main__ -   Batch number = 105
12/26/2021 23:16:28 - INFO - __main__ -   Batch number = 106
12/26/2021 23:16:28 - INFO - __main__ -   Batch number = 107
12/26/2021 23:16:28 - INFO - __main__ -   Batch number = 108
12/26/2021 23:16:28 - INFO - __main__ -   Batch number = 109
12/26/2021 23:16:29 - INFO - __main__ -   Batch number = 110
12/26/2021 23:16:29 - INFO - __main__ -   Batch number = 111
12/26/2021 23:16:29 - INFO - __main__ -   Batch number = 112
12/26/2021 23:16:29 - INFO - __main__ -   Batch number = 113
12/26/2021 23:16:30 - INFO - __main__ -   Batch number = 114
12/26/2021 23:16:30 - INFO - __main__ -   Batch number = 115
12/26/2021 23:16:30 - INFO - __main__ -   Batch number = 116
12/26/2021 23:16:31 - INFO - __main__ -   Batch number = 117
12/26/2021 23:16:31 - INFO - __main__ -   Batch number = 118
12/26/2021 23:16:31 - INFO - __main__ -   Batch number = 119
12/26/2021 23:16:32 - INFO - __main__ -   Batch number = 120
12/26/2021 23:16:32 - INFO - __main__ -   Batch number = 121
12/26/2021 23:16:32 - INFO - __main__ -   Batch number = 122
12/26/2021 23:16:33 - INFO - __main__ -   Batch number = 123
12/26/2021 23:16:33 - INFO - __main__ -   Batch number = 124
12/26/2021 23:16:33 - INFO - __main__ -   Batch number = 125
12/26/2021 23:16:34 - INFO - __main__ -   Batch number = 126
12/26/2021 23:16:34 - INFO - __main__ -   Batch number = 127
12/26/2021 23:16:34 - INFO - __main__ -   Batch number = 128
12/26/2021 23:16:34 - INFO - __main__ -   Batch number = 129
12/26/2021 23:16:34 - INFO - __main__ -   Batch number = 130
12/26/2021 23:16:35 - INFO - __main__ -   Batch number = 131
12/26/2021 23:16:35 - INFO - __main__ -   Batch number = 132
12/26/2021 23:16:35 - INFO - __main__ -   Batch number = 133
12/26/2021 23:16:35 - INFO - __main__ -   Batch number = 134
12/26/2021 23:16:36 - INFO - __main__ -   Batch number = 135
12/26/2021 23:16:36 - INFO - __main__ -   Batch number = 136
12/26/2021 23:16:36 - INFO - __main__ -   Batch number = 137
12/26/2021 23:16:37 - INFO - __main__ -   Batch number = 138
12/26/2021 23:16:37 - INFO - __main__ -   Batch number = 139
12/26/2021 23:16:37 - INFO - __main__ -   Batch number = 140
12/26/2021 23:16:38 - INFO - __main__ -   Batch number = 141
12/26/2021 23:16:38 - INFO - __main__ -   Batch number = 142
12/26/2021 23:16:38 - INFO - __main__ -   Batch number = 143
12/26/2021 23:16:39 - INFO - __main__ -   Batch number = 144
12/26/2021 23:16:39 - INFO - __main__ -   Batch number = 145
12/26/2021 23:16:39 - INFO - __main__ -   Batch number = 146
12/26/2021 23:16:40 - INFO - __main__ -   Batch number = 147
12/26/2021 23:16:40 - INFO - __main__ -   Batch number = 148
12/26/2021 23:16:40 - INFO - __main__ -   Batch number = 149
12/26/2021 23:16:40 - INFO - __main__ -   Batch number = 150
12/26/2021 23:16:40 - INFO - __main__ -   Batch number = 151
12/26/2021 23:16:41 - INFO - __main__ -   Batch number = 152
12/26/2021 23:16:41 - INFO - __main__ -   Batch number = 153
12/26/2021 23:16:41 - INFO - __main__ -   Batch number = 154
12/26/2021 23:16:41 - INFO - __main__ -   Batch number = 155
12/26/2021 23:16:42 - INFO - __main__ -   Batch number = 156
12/26/2021 23:16:42 - INFO - __main__ -   Batch number = 157
12/26/2021 23:16:42 - INFO - __main__ -   Batch number = 158
12/26/2021 23:16:43 - INFO - __main__ -   Batch number = 159
12/26/2021 23:16:43 - INFO - __main__ -   Batch number = 160
12/26/2021 23:16:43 - INFO - __main__ -   Batch number = 161
12/26/2021 23:16:44 - INFO - __main__ -   Batch number = 162
12/26/2021 23:16:44 - INFO - __main__ -   Batch number = 163
12/26/2021 23:16:44 - INFO - __main__ -   Batch number = 164
12/26/2021 23:16:45 - INFO - __main__ -   Batch number = 165
12/26/2021 23:16:45 - INFO - __main__ -   Batch number = 166
12/26/2021 23:16:45 - INFO - __main__ -   Batch number = 167
12/26/2021 23:16:46 - INFO - __main__ -   Batch number = 168
12/26/2021 23:16:46 - INFO - __main__ -   Batch number = 169
12/26/2021 23:16:46 - INFO - __main__ -   Batch number = 170
12/26/2021 23:16:46 - INFO - __main__ -   Batch number = 171
12/26/2021 23:16:47 - INFO - __main__ -   Batch number = 172
12/26/2021 23:16:47 - INFO - __main__ -   Batch number = 173
12/26/2021 23:16:47 - INFO - __main__ -   Batch number = 174
12/26/2021 23:16:47 - INFO - __main__ -   Batch number = 175
12/26/2021 23:16:48 - INFO - __main__ -   Batch number = 176
12/26/2021 23:16:48 - INFO - __main__ -   Batch number = 177
12/26/2021 23:16:48 - INFO - __main__ -   Batch number = 178
12/26/2021 23:16:49 - INFO - __main__ -   Batch number = 179
12/26/2021 23:16:49 - INFO - __main__ -   Batch number = 180
12/26/2021 23:16:49 - INFO - __main__ -   Batch number = 181
12/26/2021 23:16:50 - INFO - __main__ -   Batch number = 182
12/26/2021 23:16:50 - INFO - __main__ -   Batch number = 183
12/26/2021 23:16:50 - INFO - __main__ -   Batch number = 184
12/26/2021 23:16:51 - INFO - __main__ -   Batch number = 185
12/26/2021 23:16:51 - INFO - __main__ -   Batch number = 186
12/26/2021 23:16:51 - INFO - __main__ -   Batch number = 187
12/26/2021 23:16:52 - INFO - __main__ -   Batch number = 188
12/26/2021 23:16:52 - INFO - __main__ -   Batch number = 189
12/26/2021 23:16:52 - INFO - __main__ -   Batch number = 190
12/26/2021 23:16:52 - INFO - __main__ -   Batch number = 191
12/26/2021 23:16:53 - INFO - __main__ -   Batch number = 192
12/26/2021 23:16:53 - INFO - __main__ -   Batch number = 193
12/26/2021 23:16:53 - INFO - __main__ -   Batch number = 194
12/26/2021 23:16:53 - INFO - __main__ -   Batch number = 195
12/26/2021 23:16:54 - INFO - __main__ -   Batch number = 196
12/26/2021 23:16:54 - INFO - __main__ -   Batch number = 197
12/26/2021 23:16:54 - INFO - __main__ -   Batch number = 198
12/26/2021 23:16:55 - INFO - __main__ -   Batch number = 199
12/26/2021 23:16:55 - INFO - __main__ -   Batch number = 200
12/26/2021 23:16:55 - INFO - __main__ -   Batch number = 201
12/26/2021 23:16:56 - INFO - __main__ -   Batch number = 202
12/26/2021 23:16:56 - INFO - __main__ -   Batch number = 203
12/26/2021 23:16:56 - INFO - __main__ -   Batch number = 204
12/26/2021 23:16:57 - INFO - __main__ -   Batch number = 205
12/26/2021 23:16:57 - INFO - __main__ -   Batch number = 206
12/26/2021 23:16:57 - INFO - __main__ -   Batch number = 207
12/26/2021 23:16:57 - INFO - __main__ -   Batch number = 208
12/26/2021 23:16:58 - INFO - __main__ -   Batch number = 209
12/26/2021 23:16:58 - INFO - __main__ -   Batch number = 210
12/26/2021 23:16:58 - INFO - __main__ -   Batch number = 211
12/26/2021 23:16:59 - INFO - __main__ -   Batch number = 212
12/26/2021 23:16:59 - INFO - __main__ -   Batch number = 213
12/26/2021 23:16:59 - INFO - __main__ -   Batch number = 214
12/26/2021 23:16:59 - INFO - __main__ -   Batch number = 215
12/26/2021 23:17:00 - INFO - __main__ -   Batch number = 216
12/26/2021 23:17:00 - INFO - __main__ -   Batch number = 217
12/26/2021 23:17:00 - INFO - __main__ -   Batch number = 218
12/26/2021 23:17:01 - INFO - __main__ -   Batch number = 219
12/26/2021 23:17:01 - INFO - __main__ -   Batch number = 220
12/26/2021 23:17:02 - INFO - __main__ -   Batch number = 221
12/26/2021 23:17:02 - INFO - __main__ -   Batch number = 222
12/26/2021 23:17:02 - INFO - __main__ -   Batch number = 223
12/26/2021 23:17:02 - INFO - __main__ -   Batch number = 224
12/26/2021 23:17:03 - INFO - __main__ -   Batch number = 225
12/26/2021 23:17:03 - INFO - __main__ -   Batch number = 226
12/26/2021 23:17:03 - INFO - __main__ -   Batch number = 227
12/26/2021 23:17:04 - INFO - __main__ -   Batch number = 228
12/26/2021 23:17:04 - INFO - __main__ -   Batch number = 229
12/26/2021 23:17:04 - INFO - __main__ -   Batch number = 230
12/26/2021 23:17:04 - INFO - __main__ -   Batch number = 231
12/26/2021 23:17:05 - INFO - __main__ -   Batch number = 232
12/26/2021 23:17:05 - INFO - __main__ -   Batch number = 233
12/26/2021 23:17:05 - INFO - __main__ -   Batch number = 234
12/26/2021 23:17:06 - INFO - __main__ -   Batch number = 235
12/26/2021 23:17:06 - INFO - __main__ -   Batch number = 236
12/26/2021 23:17:07 - INFO - __main__ -   Batch number = 237
12/26/2021 23:17:07 - INFO - __main__ -   Batch number = 238
12/26/2021 23:17:07 - INFO - __main__ -   Batch number = 239
12/26/2021 23:17:08 - INFO - __main__ -   Batch number = 240
12/26/2021 23:17:08 - INFO - __main__ -   Batch number = 241
12/26/2021 23:17:08 - INFO - __main__ -   Batch number = 242
12/26/2021 23:17:08 - INFO - __main__ -   Batch number = 243
12/26/2021 23:17:08 - INFO - __main__ -   Batch number = 244
12/26/2021 23:17:09 - INFO - __main__ -   Batch number = 245
12/26/2021 23:17:09 - INFO - __main__ -   Batch number = 246
12/26/2021 23:17:09 - INFO - __main__ -   Batch number = 247
12/26/2021 23:17:10 - INFO - __main__ -   Batch number = 248
12/26/2021 23:17:11 - INFO - __main__ -   Batch number = 249
12/26/2021 23:17:11 - INFO - __main__ -   Batch number = 250
12/26/2021 23:17:11 - INFO - __main__ -   Batch number = 251
12/26/2021 23:17:11 - INFO - __main__ -   Batch number = 252
12/26/2021 23:17:12 - INFO - __main__ -   Batch number = 253
12/26/2021 23:17:12 - INFO - __main__ -   Batch number = 254
12/26/2021 23:17:13 - INFO - __main__ -   Batch number = 255
12/26/2021 23:17:13 - INFO - __main__ -   Batch number = 256
12/26/2021 23:17:13 - INFO - __main__ -   Batch number = 257
12/26/2021 23:17:13 - INFO - __main__ -   Batch number = 258
12/26/2021 23:17:13 - INFO - __main__ -   Batch number = 259
12/26/2021 23:17:14 - INFO - __main__ -   Batch number = 260
12/26/2021 23:17:14 - INFO - __main__ -   Batch number = 261
12/26/2021 23:17:15 - INFO - __main__ -   Batch number = 262
12/26/2021 23:17:15 - INFO - __main__ -   Batch number = 263
12/26/2021 23:17:16 - INFO - __main__ -   Batch number = 264
12/26/2021 23:17:16 - INFO - __main__ -   Batch number = 265
12/26/2021 23:17:16 - INFO - __main__ -   Batch number = 266
12/26/2021 23:17:17 - INFO - __main__ -   Batch number = 267
12/26/2021 23:17:17 - INFO - __main__ -   Batch number = 268
12/26/2021 23:17:17 - INFO - __main__ -   Batch number = 269
12/26/2021 23:17:18 - INFO - __main__ -   Batch number = 270
12/26/2021 23:17:18 - INFO - __main__ -   Batch number = 271
12/26/2021 23:17:18 - INFO - __main__ -   Batch number = 272
12/26/2021 23:17:19 - INFO - __main__ -   Batch number = 273
12/26/2021 23:17:19 - INFO - __main__ -   Batch number = 274
12/26/2021 23:17:19 - INFO - __main__ -   Batch number = 275
12/26/2021 23:17:19 - INFO - __main__ -   Batch number = 276
12/26/2021 23:17:19 - INFO - __main__ -   Batch number = 277
12/26/2021 23:17:20 - INFO - __main__ -   Batch number = 278
12/26/2021 23:17:20 - INFO - __main__ -   Batch number = 279
12/26/2021 23:17:20 - INFO - __main__ -   Batch number = 280
12/26/2021 23:17:21 - INFO - __main__ -   Batch number = 281
12/26/2021 23:17:21 - INFO - __main__ -   Batch number = 282
12/26/2021 23:17:21 - INFO - __main__ -   Batch number = 283
12/26/2021 23:17:22 - INFO - __main__ -   Batch number = 284
12/26/2021 23:17:22 - INFO - __main__ -   Batch number = 285
12/26/2021 23:17:22 - INFO - __main__ -   Batch number = 286
12/26/2021 23:17:23 - INFO - __main__ -   Batch number = 287
12/26/2021 23:17:23 - INFO - __main__ -   Batch number = 288
12/26/2021 23:17:23 - INFO - __main__ -   Batch number = 289
12/26/2021 23:17:24 - INFO - __main__ -   Batch number = 290
12/26/2021 23:17:24 - INFO - __main__ -   Batch number = 291
12/26/2021 23:17:24 - INFO - __main__ -   Batch number = 292
12/26/2021 23:17:25 - INFO - __main__ -   Batch number = 293
12/26/2021 23:17:25 - INFO - __main__ -   Batch number = 294
12/26/2021 23:17:25 - INFO - __main__ -   Batch number = 295
12/26/2021 23:17:25 - INFO - __main__ -   Batch number = 296
12/26/2021 23:17:26 - INFO - __main__ -   Batch number = 297
12/26/2021 23:17:26 - INFO - __main__ -   Batch number = 298
12/26/2021 23:17:26 - INFO - __main__ -   Batch number = 299
12/26/2021 23:17:27 - INFO - __main__ -   Batch number = 300
12/26/2021 23:17:27 - INFO - __main__ -   Batch number = 301
12/26/2021 23:17:27 - INFO - __main__ -   Batch number = 302
12/26/2021 23:17:28 - INFO - __main__ -   Batch number = 303
12/26/2021 23:17:28 - INFO - __main__ -   Batch number = 304
12/26/2021 23:17:28 - INFO - __main__ -   Batch number = 305
12/26/2021 23:17:29 - INFO - __main__ -   Batch number = 306
12/26/2021 23:17:29 - INFO - __main__ -   Batch number = 307
12/26/2021 23:17:29 - INFO - __main__ -   Batch number = 308
12/26/2021 23:17:30 - INFO - __main__ -   Batch number = 309
12/26/2021 23:17:30 - INFO - __main__ -   Batch number = 310
12/26/2021 23:17:30 - INFO - __main__ -   Batch number = 311
12/26/2021 23:17:30 - INFO - __main__ -   Batch number = 312
12/26/2021 23:17:31 - INFO - __main__ -   Batch number = 313
12/26/2021 23:17:32 - INFO - __main__ -   ***** Evaluation result  in ar *****
12/26/2021 23:17:32 - INFO - __main__ -     f1 = 0.32978591246014327
12/26/2021 23:17:32 - INFO - __main__ -     loss = 5.636599961180275
12/26/2021 23:17:32 - INFO - __main__ -     precision = 0.30892164468580297
12/26/2021 23:17:32 - INFO - __main__ -     recall = 0.3536726174615863
12/26/2021 23:20:06 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:20:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:20:06 - INFO - __main__ -   Seed = 1
12/26/2021 23:20:06 - INFO - root -   save model
12/26/2021 23:20:06 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:20:06 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:20:10 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:20:17 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:20:17 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:20:17 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:20:17 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:20:17 - INFO - root -   loading task adapter
12/26/2021 23:20:17 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:20:17 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:20:17 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:20:17 - INFO - __main__ -   Language = pt
12/26/2021 23:20:17 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:20:25 - INFO - __main__ -   Language mhr, split test does not exist
12/26/2021 23:20:27 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:20:27 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:20:27 - INFO - __main__ -   Seed = 2
12/26/2021 23:20:27 - INFO - root -   save model
12/26/2021 23:20:27 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:20:27 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:20:32 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:20:38 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:20:38 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:20:38 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:20:38 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:20:38 - INFO - root -   loading task adapter
12/26/2021 23:20:38 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:20:38 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:20:38 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:20:38 - INFO - __main__ -   Language = pt
12/26/2021 23:20:38 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:20:46 - INFO - __main__ -   Language mhr, split test does not exist
12/26/2021 23:20:49 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:20:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:20:49 - INFO - __main__ -   Seed = 3
12/26/2021 23:20:49 - INFO - root -   save model
12/26/2021 23:20:49 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mhr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:20:49 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:20:53 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:20:59 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:20:59 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:20:59 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/26/2021 23:20:59 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:20:59 - INFO - root -   loading task adapter
12/26/2021 23:21:00 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:21:00 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:21:00 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:21:00 - INFO - __main__ -   Language = pt
12/26/2021 23:21:00 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:21:07 - INFO - __main__ -   Language mhr, split test does not exist
12/26/2021 23:23:56 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:23:56 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:23:56 - INFO - __main__ -   Seed = 1
12/26/2021 23:23:56 - INFO - root -   save model
12/26/2021 23:23:56 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:23:56 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:24:00 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:24:07 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:24:07 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:24:07 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:24:07 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:24:07 - INFO - root -   loading task adapter
12/26/2021 23:24:07 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:24:07 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:24:07 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:24:07 - INFO - __main__ -   Language = pt
12/26/2021 23:24:07 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:24:15 - INFO - __main__ -   Language adapter for qu not found, using pt instead
12/26/2021 23:24:15 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:24:15 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:24:15 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:24:15 - INFO - __main__ -   all languages = qu
12/26/2021 23:24:15 - INFO - __main__ -   Creating features from dataset file at /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/qu/test.bert-base-multilingual-cased in language qu
12/26/2021 23:24:15 - INFO - utils_tag -   lang_id=0, lang=qu, lang2id=None
12/26/2021 23:24:15 - INFO - utils_tag -   Writing example 0 of 100
12/26/2021 23:24:15 - INFO - utils_tag -   *** Example ***
12/26/2021 23:24:15 - INFO - utils_tag -   guid: qu-1
12/26/2021 23:24:15 - INFO - utils_tag -   tokens: [CLS] Amir ##ika Mama ##lla ##q ##ta ##p Pac ##hak ##uti ##nap ##aq Hu ##ñu ##nak ##uy ##nin [SEP]
12/26/2021 23:24:15 - INFO - utils_tag -   input_ids: 101 51313 13060 35771 11083 11703 10213 10410 82376 46704 19065 57992 49277 43707 33791 12728 53452 11802 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   label_ids: -100 1 -100 4 -100 -100 -100 -100 4 -100 -100 -100 -100 4 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:24:15 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:24:15 - INFO - utils_tag -   *** Example ***
12/26/2021 23:24:15 - INFO - utils_tag -   guid: qu-2
12/26/2021 23:24:15 - INFO - utils_tag -   tokens: [CLS] Caja ##s mama ll ##aq ##ta park ##i [SEP]
12/26/2021 23:24:15 - INFO - utils_tag -   input_ids: 101 102693 10107 52758 22469 49277 10213 14900 10116 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   label_ids: -100 0 -100 3 3 -100 -100 3 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:24:15 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:24:15 - INFO - utils_tag -   *** Example ***
12/26/2021 23:24:15 - INFO - utils_tag -   guid: qu-3
12/26/2021 23:24:15 - INFO - utils_tag -   tokens: [CLS] ' ' ' John Quincy Adams ' ' ' [SEP]
12/26/2021 23:24:15 - INFO - utils_tag -   input_ids: 101 112 112 112 10421 60313 16955 112 112 112 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   label_ids: -100 6 6 -100 2 5 5 6 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:24:15 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:24:15 - INFO - utils_tag -   *** Example ***
12/26/2021 23:24:15 - INFO - utils_tag -   guid: qu-4
12/26/2021 23:24:15 - INFO - utils_tag -   tokens: [CLS] Lothar Matt ##h ##äus - 11 . [SEP]
12/26/2021 23:24:15 - INFO - utils_tag -   input_ids: 101 63423 16975 10237 98675 118 10193 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   label_ids: -100 2 5 -100 -100 6 6 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:24:15 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:24:15 - INFO - utils_tag -   *** Example ***
12/26/2021 23:24:15 - INFO - utils_tag -   guid: qu-5
12/26/2021 23:24:15 - INFO - utils_tag -   tokens: [CLS] P ##US ##AP ##UN ##A Chi ##kich ##as ##qa R ##ik ##ch ' aq P ##uka Su ##tis ##uy ##u [SEP]
12/26/2021 23:24:15 - INFO - utils_tag -   input_ids: 101 153 32612 38423 69849 10738 21946 25651 10403 35102 155 10896 10269 112 87487 153 24078 12271 13434 53452 10138 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:24:15 - INFO - utils_tag -   label_ids: -100 6 -100 -100 -100 -100 1 -100 -100 -100 4 -100 -100 -100 -100 4 -100 4 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:24:15 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:24:15 - INFO - __main__ -   Saving features into cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_qu_bert-base-multilingual-cased_128, len(features)=100
12/26/2021 23:24:15 - INFO - __main__ -   ***** Running evaluation  in qu *****
12/26/2021 23:24:15 - INFO - __main__ -     Num examples = 100
12/26/2021 23:24:15 - INFO - __main__ -     Batch size = 32
12/26/2021 23:24:15 - INFO - __main__ -   Batch number = 1
12/26/2021 23:24:15 - INFO - __main__ -   Batch number = 2
12/26/2021 23:24:16 - INFO - __main__ -   Batch number = 3
12/26/2021 23:24:16 - INFO - __main__ -   Batch number = 4
12/26/2021 23:24:16 - INFO - __main__ -   ***** Evaluation result  in qu *****
12/26/2021 23:24:16 - INFO - __main__ -     f1 = 0.5440613026819923
12/26/2021 23:24:16 - INFO - __main__ -     loss = 4.245404303073883
12/26/2021 23:24:16 - INFO - __main__ -     precision = 0.48299319727891155
12/26/2021 23:24:16 - INFO - __main__ -     recall = 0.6228070175438597
12/26/2021 23:24:18 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:24:18 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:24:18 - INFO - __main__ -   Seed = 2
12/26/2021 23:24:18 - INFO - root -   save model
12/26/2021 23:24:18 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:24:18 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:24:23 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:24:29 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:24:29 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:24:29 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:24:29 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:24:29 - INFO - root -   loading task adapter
12/26/2021 23:24:29 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:24:29 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:24:29 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:24:29 - INFO - __main__ -   Language = pt
12/26/2021 23:24:29 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:24:36 - INFO - __main__ -   Language adapter for qu not found, using pt instead
12/26/2021 23:24:36 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:24:36 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:24:36 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:24:36 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_qu_bert-base-multilingual-cased_128
12/26/2021 23:24:36 - INFO - __main__ -   ***** Running evaluation  in qu *****
12/26/2021 23:24:36 - INFO - __main__ -     Num examples = 100
12/26/2021 23:24:36 - INFO - __main__ -     Batch size = 32
12/26/2021 23:24:36 - INFO - __main__ -   Batch number = 1
12/26/2021 23:24:36 - INFO - __main__ -   Batch number = 2
12/26/2021 23:24:36 - INFO - __main__ -   Batch number = 3
12/26/2021 23:24:37 - INFO - __main__ -   Batch number = 4
12/26/2021 23:24:37 - INFO - __main__ -   ***** Evaluation result  in qu *****
12/26/2021 23:24:37 - INFO - __main__ -     f1 = 0.6016260162601625
12/26/2021 23:24:37 - INFO - __main__ -     loss = 4.448649883270264
12/26/2021 23:24:37 - INFO - __main__ -     precision = 0.5606060606060606
12/26/2021 23:24:37 - INFO - __main__ -     recall = 0.6491228070175439
12/26/2021 23:24:39 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:24:39 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:24:39 - INFO - __main__ -   Seed = 3
12/26/2021 23:24:39 - INFO - root -   save model
12/26/2021 23:24:39 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='qu', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:24:39 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:24:45 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:24:51 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:24:51 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:24:51 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/26/2021 23:24:51 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:24:51 - INFO - root -   loading task adapter
12/26/2021 23:24:51 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:24:51 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:24:51 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:24:51 - INFO - __main__ -   Language = pt
12/26/2021 23:24:51 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:24:59 - INFO - __main__ -   Language adapter for qu not found, using pt instead
12/26/2021 23:24:59 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:24:59 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:24:59 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:24:59 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_qu_bert-base-multilingual-cased_128
12/26/2021 23:24:59 - INFO - __main__ -   ***** Running evaluation  in qu *****
12/26/2021 23:24:59 - INFO - __main__ -     Num examples = 100
12/26/2021 23:24:59 - INFO - __main__ -     Batch size = 32
12/26/2021 23:24:59 - INFO - __main__ -   Batch number = 1
12/26/2021 23:24:59 - INFO - __main__ -   Batch number = 2
12/26/2021 23:24:59 - INFO - __main__ -   Batch number = 3
12/26/2021 23:24:59 - INFO - __main__ -   Batch number = 4
12/26/2021 23:24:59 - INFO - __main__ -   ***** Evaluation result  in qu *****
12/26/2021 23:24:59 - INFO - __main__ -     f1 = 0.5670498084291188
12/26/2021 23:24:59 - INFO - __main__ -     loss = 3.5588311553001404
12/26/2021 23:24:59 - INFO - __main__ -     precision = 0.5034013605442177
12/26/2021 23:24:59 - INFO - __main__ -     recall = 0.6491228070175439
12/26/2021 23:35:19 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:35:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:35:19 - INFO - __main__ -   Seed = 1
12/26/2021 23:35:19 - INFO - root -   save model
12/26/2021 23:35:19 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:35:19 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:35:23 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:35:29 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:35:29 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:35:29 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:35:29 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:35:29 - INFO - root -   loading task adapter
12/26/2021 23:35:29 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:35:29 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:35:29 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:35:29 - INFO - __main__ -   Language = pt
12/26/2021 23:35:29 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:35:37 - INFO - __main__ -   Language adapter for cdo not found, using pt instead
12/26/2021 23:35:37 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:35:37 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:35:37 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:35:37 - INFO - __main__ -   all languages = cdo
12/26/2021 23:35:37 - INFO - __main__ -   Creating features from dataset file at /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cdo/test.bert-base-multilingual-cased in language cdo
12/26/2021 23:35:37 - INFO - utils_tag -   lang_id=0, lang=cdo, lang2id=None
12/26/2021 23:35:37 - INFO - utils_tag -   Writing example 0 of 101
12/26/2021 23:35:37 - INFO - utils_tag -   *** Example ***
12/26/2021 23:35:37 - INFO - utils_tag -   guid: cdo-1
12/26/2021 23:35:37 - INFO - utils_tag -   tokens: [CLS] 重 定 向 [UNK] - [UNK] - [UNK] [SEP]
12/26/2021 23:35:37 - INFO - utils_tag -   input_ids: 101 7907 3388 2778 100 118 100 118 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   label_ids: -100 6 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:35:37 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:35:37 - INFO - utils_tag -   *** Example ***
12/26/2021 23:35:37 - INFO - utils_tag -   guid: cdo-2
12/26/2021 23:35:37 - INFO - utils_tag -   tokens: [CLS] 21 h . ) s ##ê [UNK] - [UNK] - [UNK] gì si ##ŏ ##h ci ##áh gái ##k - m ##ên ##g - g ##ă [UNK] c ##én ##g - d ##ê - g ##ă . [SEP]
12/26/2021 23:35:37 - INFO - utils_tag -   input_ids: 101 10296 176 119 114 187 15915 100 118 100 118 100 49309 10294 110959 10237 11322 103380 40200 10174 118 181 20270 10240 118 175 10471 100 171 13632 10240 118 172 15915 118 175 10471 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   label_ids: -100 6 6 -100 6 6 -100 0 -100 -100 -100 -100 6 6 -100 -100 6 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 6 6 -100 -100 -100 -100 -100 -100 -100 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:35:37 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:35:37 - INFO - utils_tag -   *** Example ***
12/26/2021 23:35:37 - INFO - utils_tag -   guid: cdo-3
12/26/2021 23:35:37 - INFO - utils_tag -   tokens: [CLS] ' ' ' Ū - ì - săn ##g - ch ##ê ' ' ' ( 武 夷 山 市 ) s ##ê N ##àng - b ##ì ##ng - ch ##ê â - [UNK] gì si ##ŏ ##h ci ##áh g ##â ##ing - g ##ék - ch ##ê , g ##ô - [UNK] [UNK] [UNK] ' ' ' S ##ùng - ăn ##g ' ' ' ( 崇 安 ) . [SEP]
12/26/2021 23:35:37 - INFO - utils_tag -   input_ids: 101 112 112 112 358 118 266 118 81376 10240 118 18643 15915 112 112 112 113 4794 3206 3504 3600 114 187 15915 151 51579 118 170 13306 10376 118 18643 15915 256 118 100 49309 10294 110959 10237 11322 103380 175 42560 10230 118 175 14093 118 18643 15915 117 175 16218 118 100 100 100 112 112 112 156 27787 118 23061 10240 112 112 112 113 3545 3378 114 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   label_ids: -100 6 6 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 6 -100 6 6 6 -100 -100 -100 6 6 -100 1 -100 -100 -100 -100 -100 -100 -100 -100 6 -100 -100 6 6 -100 -100 6 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 6 6 -100 -100 -100 6 6 6 6 -100 6 -100 -100 -100 -100 6 -100 6 6 6 -100 6 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:35:37 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:35:37 - INFO - utils_tag -   *** Example ***
12/26/2021 23:35:37 - INFO - utils_tag -   guid: cdo-4
12/26/2021 23:35:37 - INFO - utils_tag -   tokens: [CLS] [UNK] - i ##ók S ##én ##g - [UNK] [SEP]
12/26/2021 23:35:37 - INFO - utils_tag -   input_ids: 101 100 118 177 26484 156 13632 10240 118 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   label_ids: -100 1 -100 -100 -100 4 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:35:37 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:35:37 - INFO - utils_tag -   *** Example ***
12/26/2021 23:35:37 - INFO - utils_tag -   guid: cdo-5
12/26/2021 23:35:37 - INFO - utils_tag -   tokens: [CLS] ' ' ' Si ##é - c ##ŭ ##ng D ##ĕ ##k - bi ##ék [UNK] - dé - ch ##ê ' ' ' ( 세 ##종 ##특 ##별 ##자 ##치 ##시 , 世 宗 特 別 自 治 市 ) s ##ê D ##â ##i - hàng M ##ì ##ng - gu ##ók gì si ##ŏ ##h ci ##áh d ##ĕ ##k - bi ##ék [UNK] - dé - ch ##ê . [SEP]
12/26/2021 23:35:37 - INFO - utils_tag -   input_ids: 101 112 112 112 11741 10333 118 171 110972 10376 141 13765 10174 118 11342 14093 100 118 97184 118 18643 15915 112 112 112 113 9435 22200 119371 61844 13764 18622 14040 117 2087 3385 5410 2550 6621 4930 3600 114 187 15915 141 42560 10116 118 18031 150 13306 10376 118 75980 26484 49309 10294 110959 10237 11322 103380 172 13765 10174 118 11342 14093 100 118 97184 118 18643 15915 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:35:37 - INFO - utils_tag -   label_ids: -100 6 6 -100 6 -100 -100 -100 -100 -100 6 -100 -100 -100 -100 -100 6 -100 -100 -100 -100 -100 6 -100 6 6 6 -100 -100 -100 -100 -100 -100 6 6 -100 -100 -100 -100 -100 -100 6 6 -100 0 -100 -100 -100 -100 3 -100 -100 -100 -100 -100 6 6 -100 -100 6 -100 6 -100 -100 -100 -100 -100 6 -100 -100 -100 -100 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:35:37 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:35:37 - INFO - __main__ -   Saving features into cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_cdo_bert-base-multilingual-cased_128, len(features)=101
12/26/2021 23:35:37 - INFO - __main__ -   ***** Running evaluation  in cdo *****
12/26/2021 23:35:37 - INFO - __main__ -     Num examples = 101
12/26/2021 23:35:37 - INFO - __main__ -     Batch size = 32
12/26/2021 23:35:37 - INFO - __main__ -   Batch number = 1
12/26/2021 23:35:38 - INFO - __main__ -   Batch number = 2
12/26/2021 23:35:38 - INFO - __main__ -   Batch number = 3
12/26/2021 23:35:38 - INFO - __main__ -   Batch number = 4
12/26/2021 23:35:38 - INFO - __main__ -   ***** Evaluation result  in cdo *****
12/26/2021 23:35:38 - INFO - __main__ -     f1 = 0.13043478260869565
12/26/2021 23:35:38 - INFO - __main__ -     loss = 2.3931339979171753
12/26/2021 23:35:38 - INFO - __main__ -     precision = 0.13392857142857142
12/26/2021 23:35:38 - INFO - __main__ -     recall = 0.1271186440677966
12/26/2021 23:35:41 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:35:41 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:35:41 - INFO - __main__ -   Seed = 2
12/26/2021 23:35:41 - INFO - root -   save model
12/26/2021 23:35:41 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:35:41 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:35:45 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:35:50 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:35:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:35:50 - INFO - __main__ -   Seed = 1
12/26/2021 23:35:50 - INFO - root -   save model
12/26/2021 23:35:50 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:35:50 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:35:51 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:35:51 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:35:51 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:35:51 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:35:51 - INFO - root -   loading task adapter
12/26/2021 23:35:51 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:35:51 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:35:51 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:35:51 - INFO - __main__ -   Language = pt
12/26/2021 23:35:51 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:35:54 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:35:59 - INFO - __main__ -   Language adapter for cdo not found, using pt instead
12/26/2021 23:35:59 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:35:59 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:35:59 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:35:59 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_cdo_bert-base-multilingual-cased_128
12/26/2021 23:35:59 - INFO - __main__ -   ***** Running evaluation  in cdo *****
12/26/2021 23:35:59 - INFO - __main__ -     Num examples = 101
12/26/2021 23:35:59 - INFO - __main__ -     Batch size = 32
12/26/2021 23:35:59 - INFO - __main__ -   Batch number = 1
12/26/2021 23:35:59 - INFO - __main__ -   Batch number = 2
12/26/2021 23:35:59 - INFO - __main__ -   Batch number = 3
12/26/2021 23:36:00 - INFO - __main__ -   Batch number = 4
12/26/2021 23:36:00 - INFO - __main__ -   ***** Evaluation result  in cdo *****
12/26/2021 23:36:00 - INFO - __main__ -     f1 = 0.07166123778501628
12/26/2021 23:36:00 - INFO - __main__ -     loss = 3.8017508387565613
12/26/2021 23:36:00 - INFO - __main__ -     precision = 0.0582010582010582
12/26/2021 23:36:00 - INFO - __main__ -     recall = 0.09322033898305085
12/26/2021 23:36:01 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:36:01 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:36:01 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:36:01 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:36:01 - INFO - root -   loading task adapter
12/26/2021 23:36:01 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:36:01 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:36:01 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:36:01 - INFO - __main__ -   Language = pt
12/26/2021 23:36:01 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:36:02 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:02 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:36:02 - INFO - __main__ -   Seed = 3
12/26/2021 23:36:02 - INFO - root -   save model
12/26/2021 23:36:02 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='cdo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:02 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:36:07 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:36:08 - INFO - __main__ -   Language adapter for ilo not found, using pt instead
12/26/2021 23:36:08 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:36:08 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:36:08 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:36:08 - INFO - __main__ -   all languages = ilo
12/26/2021 23:36:08 - INFO - __main__ -   Creating features from dataset file at /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/ilo/test.bert-base-multilingual-cased in language ilo
12/26/2021 23:36:08 - INFO - utils_tag -   lang_id=0, lang=ilo, lang2id=None
12/26/2021 23:36:08 - INFO - utils_tag -   Writing example 0 of 100
12/26/2021 23:36:08 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:08 - INFO - utils_tag -   guid: ilo-1
12/26/2021 23:36:08 - INFO - utils_tag -   tokens: [CLS] Stamm ##ham ( 18 ) [SEP]
12/26/2021 23:36:08 - INFO - utils_tag -   input_ids: 101 94971 13196 113 10218 114 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   label_ids: -100 0 -100 6 6 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:08 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:08 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:08 - INFO - utils_tag -   guid: ilo-2
12/26/2021 23:36:08 - INFO - utils_tag -   tokens: [CLS] Ab ##asi ##da a Kali ##pato [SEP]
12/26/2021 23:36:08 - INFO - utils_tag -   input_ids: 101 15595 15525 10229 169 47322 75990 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   label_ids: -100 0 -100 -100 3 3 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:08 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:08 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:08 - INFO - utils_tag -   guid: ilo-3
12/26/2021 23:36:08 - INFO - utils_tag -   tokens: [CLS] Papa Pio VI [SEP]
12/26/2021 23:36:08 - INFO - utils_tag -   input_ids: 101 17429 42712 12262 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   label_ids: -100 2 5 5 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:08 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:08 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:08 - INFO - utils_tag -   guid: ilo-4
12/26/2021 23:36:08 - INFO - utils_tag -   tokens: [CLS] Papa Cali ##xt ##o I ( 217 [UNK] 222 ) [SEP]
12/26/2021 23:36:08 - INFO - utils_tag -   input_ids: 101 17429 65458 28883 10133 146 113 21651 100 22717 114 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   label_ids: -100 2 5 -100 -100 5 6 6 -100 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:08 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:08 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:08 - INFO - utils_tag -   guid: ilo-5
12/26/2021 23:36:08 - INFO - utils_tag -   tokens: [CLS] Pa ##gs ##asa ##o a G ##uara ##ni [SEP]
12/26/2021 23:36:08 - INFO - utils_tag -   input_ids: 101 26907 15703 23031 10133 169 144 66567 10342 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:08 - INFO - utils_tag -   label_ids: -100 1 -100 -100 -100 4 4 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:08 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:08 - INFO - __main__ -   Saving features into cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ilo_bert-base-multilingual-cased_128, len(features)=100
12/26/2021 23:36:08 - INFO - __main__ -   ***** Running evaluation  in ilo *****
12/26/2021 23:36:08 - INFO - __main__ -     Num examples = 100
12/26/2021 23:36:08 - INFO - __main__ -     Batch size = 32
12/26/2021 23:36:08 - INFO - __main__ -   Batch number = 1
12/26/2021 23:36:09 - INFO - __main__ -   Batch number = 2
12/26/2021 23:36:09 - INFO - __main__ -   Batch number = 3
12/26/2021 23:36:09 - INFO - __main__ -   Batch number = 4
12/26/2021 23:36:09 - INFO - __main__ -   ***** Evaluation result  in ilo *****
12/26/2021 23:36:09 - INFO - __main__ -     f1 = 0.384
12/26/2021 23:36:09 - INFO - __main__ -     loss = 3.398816704750061
12/26/2021 23:36:09 - INFO - __main__ -     precision = 0.32653061224489793
12/26/2021 23:36:09 - INFO - __main__ -     recall = 0.46601941747572817
12/26/2021 23:36:12 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:36:12 - INFO - __main__ -   Seed = 2
12/26/2021 23:36:12 - INFO - root -   save model
12/26/2021 23:36:12 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:12 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:36:13 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:36:13 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:36:13 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/26/2021 23:36:13 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:36:13 - INFO - root -   loading task adapter
12/26/2021 23:36:13 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:36:13 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:36:13 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:36:13 - INFO - __main__ -   Language = pt
12/26/2021 23:36:13 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:36:16 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:36:19 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:36:19 - INFO - __main__ -   Seed = 1
12/26/2021 23:36:19 - INFO - root -   save model
12/26/2021 23:36:19 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:19 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:36:20 - INFO - __main__ -   Language adapter for cdo not found, using pt instead
12/26/2021 23:36:20 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:36:20 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:36:20 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:36:20 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_cdo_bert-base-multilingual-cased_128
12/26/2021 23:36:20 - INFO - __main__ -   ***** Running evaluation  in cdo *****
12/26/2021 23:36:20 - INFO - __main__ -     Num examples = 101
12/26/2021 23:36:20 - INFO - __main__ -     Batch size = 32
12/26/2021 23:36:20 - INFO - __main__ -   Batch number = 1
12/26/2021 23:36:21 - INFO - __main__ -   Batch number = 2
12/26/2021 23:36:21 - INFO - __main__ -   Batch number = 3
12/26/2021 23:36:21 - INFO - __main__ -   Batch number = 4
12/26/2021 23:36:21 - INFO - __main__ -   ***** Evaluation result  in cdo *****
12/26/2021 23:36:21 - INFO - __main__ -     f1 = 0.08955223880597014
12/26/2021 23:36:21 - INFO - __main__ -     loss = 2.6316510438919067
12/26/2021 23:36:21 - INFO - __main__ -     precision = 0.08
12/26/2021 23:36:21 - INFO - __main__ -     recall = 0.1016949152542373
12/26/2021 23:36:23 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:36:23 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:36:23 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:36:23 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:36:23 - INFO - root -   loading task adapter
12/26/2021 23:36:23 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:36:23 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:36:23 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:36:23 - INFO - __main__ -   Language = pt
12/26/2021 23:36:23 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:36:23 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:36:30 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:36:30 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:36:30 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:36:30 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:36:30 - INFO - root -   loading task adapter
12/26/2021 23:36:30 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:36:30 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:36:30 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:36:30 - INFO - __main__ -   Language = pt
12/26/2021 23:36:30 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:36:31 - INFO - __main__ -   Language adapter for ilo not found, using pt instead
12/26/2021 23:36:31 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:36:31 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:36:31 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:36:31 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ilo_bert-base-multilingual-cased_128
12/26/2021 23:36:31 - INFO - __main__ -   ***** Running evaluation  in ilo *****
12/26/2021 23:36:31 - INFO - __main__ -     Num examples = 100
12/26/2021 23:36:31 - INFO - __main__ -     Batch size = 32
12/26/2021 23:36:31 - INFO - __main__ -   Batch number = 1
12/26/2021 23:36:31 - INFO - __main__ -   Batch number = 2
12/26/2021 23:36:32 - INFO - __main__ -   Batch number = 3
12/26/2021 23:36:32 - INFO - __main__ -   Batch number = 4
12/26/2021 23:36:32 - INFO - __main__ -   ***** Evaluation result  in ilo *****
12/26/2021 23:36:32 - INFO - __main__ -     f1 = 0.6098654708520179
12/26/2021 23:36:32 - INFO - __main__ -     loss = 2.309924066066742
12/26/2021 23:36:32 - INFO - __main__ -     precision = 0.5666666666666667
12/26/2021 23:36:32 - INFO - __main__ -     recall = 0.6601941747572816
12/26/2021 23:36:33 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:33 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:36:33 - INFO - __main__ -   Seed = 1
12/26/2021 23:36:33 - INFO - root -   save model
12/26/2021 23:36:33 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:33 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:36:35 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:36:35 - INFO - __main__ -   Seed = 3
12/26/2021 23:36:35 - INFO - root -   save model
12/26/2021 23:36:35 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='ilo', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:35 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:36:37 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:36:38 - INFO - __main__ -   Language xmf, split test does not exist
12/26/2021 23:36:39 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:36:40 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:40 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:36:40 - INFO - __main__ -   Seed = 2
12/26/2021 23:36:40 - INFO - root -   save model
12/26/2021 23:36:40 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:40 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:36:43 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:36:43 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:36:43 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:36:43 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:36:43 - INFO - root -   loading task adapter
12/26/2021 23:36:43 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:36:43 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:36:43 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:36:43 - INFO - __main__ -   Language = pt
12/26/2021 23:36:43 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:36:45 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:36:45 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:36:45 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:36:45 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/26/2021 23:36:45 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:36:45 - INFO - root -   loading task adapter
12/26/2021 23:36:45 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:36:45 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:36:45 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:36:45 - INFO - __main__ -   Language = pt
12/26/2021 23:36:45 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:36:51 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:36:51 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:36:51 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:36:51 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:36:51 - INFO - root -   loading task adapter
12/26/2021 23:36:51 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:36:51 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:36:51 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:36:51 - INFO - __main__ -   Language = pt
12/26/2021 23:36:51 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:36:51 - INFO - __main__ -   Language adapter for mi not found, using pt instead
12/26/2021 23:36:51 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:36:51 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:36:51 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:36:51 - INFO - __main__ -   all languages = mi
12/26/2021 23:36:51 - INFO - __main__ -   Creating features from dataset file at /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/mi/test.bert-base-multilingual-cased in language mi
12/26/2021 23:36:51 - INFO - utils_tag -   lang_id=0, lang=mi, lang2id=None
12/26/2021 23:36:51 - INFO - utils_tag -   Writing example 0 of 100
12/26/2021 23:36:51 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:51 - INFO - utils_tag -   guid: mi-1
12/26/2021 23:36:51 - INFO - utils_tag -   tokens: [CLS] Ko Te Tai - tok ##era ##u t ##ēta ##hi o ng ##ā taki ##w ##ā o Ao ##tea ##roa ; ko ##ia ton ##u te ro ##he o Ng ##ā P ##uh ##i me ē ##rā at ##u i ##wi ro ##ngo ##nu ##i o rei ##ra . [SEP]
12/26/2021 23:36:51 - INFO - utils_tag -   input_ids: 101 30186 21452 25633 118 18436 12015 10138 188 40085 11924 183 10743 11483 74628 10874 11483 183 17607 24259 44218 132 11252 10280 22464 10138 10361 25470 11643 183 72959 11483 153 18593 10116 10911 301 46665 10160 10138 177 15926 25470 32448 11147 10116 183 14243 10288 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   label_ids: -100 6 0 3 -100 -100 -100 -100 6 -100 -100 6 6 -100 6 -100 -100 6 0 -100 -100 6 6 -100 6 -100 6 6 -100 6 1 -100 4 -100 -100 6 6 -100 6 -100 6 -100 6 -100 -100 -100 6 6 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:51 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:51 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:51 - INFO - utils_tag -   guid: mi-2
12/26/2021 23:36:51 - INFO - utils_tag -   tokens: [CLS] Ko Te Tai - tok ##era ##u t ##ēta ##hi o ng ##ā taki ##w ##ā o Ao ##tea ##roa ; ko ##ia ton ##u te ro ##he o Ng ##ā P ##uh ##i me ē ##rā at ##u i ##wi ro ##ngo ##nu ##i o rei ##ra . [SEP]
12/26/2021 23:36:51 - INFO - utils_tag -   input_ids: 101 30186 21452 25633 118 18436 12015 10138 188 40085 11924 183 10743 11483 74628 10874 11483 183 17607 24259 44218 132 11252 10280 22464 10138 10361 25470 11643 183 72959 11483 153 18593 10116 10911 301 46665 10160 10138 177 15926 25470 32448 11147 10116 183 14243 10288 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   label_ids: -100 6 0 3 -100 -100 -100 -100 6 -100 -100 6 6 -100 6 -100 -100 6 0 -100 -100 6 6 -100 6 -100 6 6 -100 6 1 -100 4 -100 -100 6 6 -100 6 -100 6 -100 6 -100 -100 -100 6 6 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:51 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:51 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:51 - INFO - utils_tag -   guid: mi-3
12/26/2021 23:36:51 - INFO - utils_tag -   tokens: [CLS] Ko Te Tai - tok ##era ##u t ##ēta ##hi o ng ##ā taki ##w ##ā o Ao ##tea ##roa ; ko ##ia ton ##u te ro ##he o Ng ##ā P ##uh ##i me ē ##rā at ##u i ##wi ro ##ngo ##nu ##i o rei ##ra . [SEP]
12/26/2021 23:36:51 - INFO - utils_tag -   input_ids: 101 30186 21452 25633 118 18436 12015 10138 188 40085 11924 183 10743 11483 74628 10874 11483 183 17607 24259 44218 132 11252 10280 22464 10138 10361 25470 11643 183 72959 11483 153 18593 10116 10911 301 46665 10160 10138 177 15926 25470 32448 11147 10116 183 14243 10288 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   label_ids: -100 6 0 3 -100 -100 -100 -100 6 -100 -100 6 6 -100 6 -100 -100 6 0 -100 -100 6 6 -100 6 -100 6 6 -100 6 1 -100 4 -100 -100 6 6 -100 6 -100 6 -100 6 -100 -100 -100 6 6 -100 6 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:51 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:51 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:51 - INFO - utils_tag -   guid: mi-4
12/26/2021 23:36:51 - INFO - utils_tag -   tokens: [CLS] K ##ō ##rea - ki - te - ton ##ga [SEP]
12/26/2021 23:36:51 - INFO - utils_tag -   input_ids: 101 148 15381 13236 118 10879 118 10361 118 22464 10483 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   label_ids: -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:51 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:51 - INFO - utils_tag -   *** Example ***
12/26/2021 23:36:51 - INFO - utils_tag -   guid: mi-5
12/26/2021 23:36:51 - INFO - utils_tag -   tokens: [CLS] Ir ##ih ##ap ##eti te Tu ##aru ##a [SEP]
12/26/2021 23:36:51 - INFO - utils_tag -   input_ids: 101 61562 13187 16070 16490 10361 20108 41417 10113 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/26/2021 23:36:51 - INFO - utils_tag -   label_ids: -100 2 -100 -100 -100 5 5 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
12/26/2021 23:36:51 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
12/26/2021 23:36:52 - INFO - __main__ -   Saving features into cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_mi_bert-base-multilingual-cased_128, len(features)=100
12/26/2021 23:36:52 - INFO - __main__ -   ***** Running evaluation  in mi *****
12/26/2021 23:36:52 - INFO - __main__ -     Num examples = 100
12/26/2021 23:36:52 - INFO - __main__ -     Batch size = 32
12/26/2021 23:36:52 - INFO - __main__ -   Batch number = 1
12/26/2021 23:36:52 - INFO - __main__ -   Batch number = 2
12/26/2021 23:36:52 - INFO - __main__ -   Batch number = 3
12/26/2021 23:36:52 - INFO - __main__ -   Batch number = 4
12/26/2021 23:36:52 - INFO - __main__ -   ***** Evaluation result  in mi *****
12/26/2021 23:36:52 - INFO - __main__ -     f1 = 0.25806451612903225
12/26/2021 23:36:52 - INFO - __main__ -     loss = 3.7512837052345276
12/26/2021 23:36:52 - INFO - __main__ -     precision = 0.2184873949579832
12/26/2021 23:36:52 - INFO - __main__ -     recall = 0.3151515151515151
12/26/2021 23:36:54 - INFO - __main__ -   Language adapter for ilo not found, using pt instead
12/26/2021 23:36:54 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:36:54 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:36:54 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:36:54 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ilo_bert-base-multilingual-cased_128
12/26/2021 23:36:54 - INFO - __main__ -   ***** Running evaluation  in ilo *****
12/26/2021 23:36:54 - INFO - __main__ -     Num examples = 100
12/26/2021 23:36:54 - INFO - __main__ -     Batch size = 32
12/26/2021 23:36:54 - INFO - __main__ -   Batch number = 1
12/26/2021 23:36:55 - INFO - __main__ -   Batch number = 2
12/26/2021 23:36:55 - INFO - __main__ -   Batch number = 3
12/26/2021 23:36:55 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:55 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:36:55 - INFO - __main__ -   Seed = 2
12/26/2021 23:36:55 - INFO - root -   save model
12/26/2021 23:36:55 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:36:55 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:36:55 - INFO - __main__ -   Batch number = 4
12/26/2021 23:36:55 - INFO - __main__ -   ***** Evaluation result  in ilo *****
12/26/2021 23:36:55 - INFO - __main__ -     f1 = 0.6044444444444445
12/26/2021 23:36:55 - INFO - __main__ -     loss = 2.7033762335777283
12/26/2021 23:36:55 - INFO - __main__ -     precision = 0.5573770491803278
12/26/2021 23:36:55 - INFO - __main__ -     recall = 0.6601941747572816
12/26/2021 23:36:59 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:37:00 - INFO - __main__ -   Language xmf, split test does not exist
12/26/2021 23:37:02 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:37:02 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:37:02 - INFO - __main__ -   Seed = 3
12/26/2021 23:37:02 - INFO - root -   save model
12/26/2021 23:37:02 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:37:02 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:37:06 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:37:06 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:37:06 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:37:06 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:37:06 - INFO - root -   loading task adapter
12/26/2021 23:37:06 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:37:06 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:37:06 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:37:06 - INFO - __main__ -   Language = pt
12/26/2021 23:37:06 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:37:07 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:37:13 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:37:13 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:37:13 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/26/2021 23:37:13 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:37:13 - INFO - root -   loading task adapter
12/26/2021 23:37:13 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:37:13 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:37:13 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:37:13 - INFO - __main__ -   Language = pt
12/26/2021 23:37:13 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:37:13 - INFO - __main__ -   Language adapter for mi not found, using pt instead
12/26/2021 23:37:13 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:37:13 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:37:13 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:37:13 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_mi_bert-base-multilingual-cased_128
12/26/2021 23:37:13 - INFO - __main__ -   ***** Running evaluation  in mi *****
12/26/2021 23:37:13 - INFO - __main__ -     Num examples = 100
12/26/2021 23:37:13 - INFO - __main__ -     Batch size = 32
12/26/2021 23:37:13 - INFO - __main__ -   Batch number = 1
12/26/2021 23:37:14 - INFO - __main__ -   Batch number = 2
12/26/2021 23:37:14 - INFO - __main__ -   Batch number = 3
12/26/2021 23:37:14 - INFO - __main__ -   Batch number = 4
12/26/2021 23:37:14 - INFO - __main__ -   ***** Evaluation result  in mi *****
12/26/2021 23:37:14 - INFO - __main__ -     f1 = 0.1021897810218978
12/26/2021 23:37:14 - INFO - __main__ -     loss = 8.358527421951294
12/26/2021 23:37:14 - INFO - __main__ -     precision = 0.08536585365853659
12/26/2021 23:37:14 - INFO - __main__ -     recall = 0.12727272727272726
12/26/2021 23:37:17 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:37:17 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:37:17 - INFO - __main__ -   Seed = 3
12/26/2021 23:37:17 - INFO - root -   save model
12/26/2021 23:37:17 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:37:17 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:37:20 - INFO - __main__ -   Language xmf, split test does not exist
12/26/2021 23:37:21 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:37:27 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:37:27 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:37:27 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/26/2021 23:37:27 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:37:27 - INFO - root -   loading task adapter
12/26/2021 23:37:27 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:37:27 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:37:27 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:37:27 - INFO - __main__ -   Language = pt
12/26/2021 23:37:27 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:37:35 - INFO - __main__ -   Language adapter for mi not found, using pt instead
12/26/2021 23:37:35 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:37:35 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:37:35 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:37:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_mi_bert-base-multilingual-cased_128
12/26/2021 23:37:35 - INFO - __main__ -   ***** Running evaluation  in mi *****
12/26/2021 23:37:35 - INFO - __main__ -     Num examples = 100
12/26/2021 23:37:35 - INFO - __main__ -     Batch size = 32
12/26/2021 23:37:35 - INFO - __main__ -   Batch number = 1
12/26/2021 23:37:35 - INFO - __main__ -   Batch number = 2
12/26/2021 23:37:36 - INFO - __main__ -   Batch number = 3
12/26/2021 23:37:36 - INFO - __main__ -   Batch number = 4
12/26/2021 23:37:36 - INFO - __main__ -   ***** Evaluation result  in mi *****
12/26/2021 23:37:36 - INFO - __main__ -     f1 = 0.09251101321585903
12/26/2021 23:37:36 - INFO - __main__ -     loss = 4.281841158866882
12/26/2021 23:37:36 - INFO - __main__ -     precision = 0.0726643598615917
12/26/2021 23:37:36 - INFO - __main__ -     recall = 0.12727272727272726
12/26/2021 23:52:46 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf,mhr,tk,gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:52:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:52:46 - INFO - __main__ -   Seed = 1
12/26/2021 23:52:46 - INFO - root -   save model
12/26/2021 23:52:46 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf,mhr,tk,gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:52:46 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:52:50 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:52:56 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:52:56 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:52:56 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:52:56 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:52:56 - INFO - root -   loading task adapter
12/26/2021 23:52:56 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:52:56 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:52:56 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:52:56 - INFO - __main__ -   Language = pt
12/26/2021 23:52:56 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:53:01 - INFO - __main__ -   Language adapter for xmf not found, using pt instead
12/26/2021 23:53:01 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:01 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:01 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:01 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_xmf_bert-base-multilingual-cased_128
12/26/2021 23:53:01 - INFO - __main__ -   ***** Running evaluation  in xmf *****
12/26/2021 23:53:01 - INFO - __main__ -     Num examples = 100
12/26/2021 23:53:01 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:01 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:02 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:02 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:02 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:02 - INFO - __main__ -   ***** Evaluation result  in xmf *****
12/26/2021 23:53:02 - INFO - __main__ -     f1 = 0.29065743944636674
12/26/2021 23:53:02 - INFO - __main__ -     loss = 3.392916440963745
12/26/2021 23:53:02 - INFO - __main__ -     precision = 0.2485207100591716
12/26/2021 23:53:02 - INFO - __main__ -     recall = 0.35
12/26/2021 23:53:02 - INFO - __main__ -   Language adapter for mhr not found, using pt instead
12/26/2021 23:53:02 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:02 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:02 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:02 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_mhr_bert-base-multilingual-cased_128
12/26/2021 23:53:02 - INFO - __main__ -   ***** Running evaluation  in mhr *****
12/26/2021 23:53:02 - INFO - __main__ -     Num examples = 100
12/26/2021 23:53:02 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:02 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:02 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:02 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:02 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:02 - INFO - __main__ -   ***** Evaluation result  in mhr *****
12/26/2021 23:53:02 - INFO - __main__ -     f1 = 0.41777777777777775
12/26/2021 23:53:02 - INFO - __main__ -     loss = 2.1725651249289513
12/26/2021 23:53:02 - INFO - __main__ -     precision = 0.41228070175438597
12/26/2021 23:53:02 - INFO - __main__ -     recall = 0.42342342342342343
12/26/2021 23:53:02 - INFO - __main__ -   Language adapter for tk not found, using pt instead
12/26/2021 23:53:02 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:02 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:02 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:02 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_tk_bert-base-multilingual-cased_128
12/26/2021 23:53:02 - INFO - __main__ -   ***** Running evaluation  in tk *****
12/26/2021 23:53:02 - INFO - __main__ -     Num examples = 101
12/26/2021 23:53:02 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:02 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:03 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:03 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:03 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:03 - INFO - __main__ -   ***** Evaluation result  in tk *****
12/26/2021 23:53:03 - INFO - __main__ -     f1 = 0.49777777777777776
12/26/2021 23:53:03 - INFO - __main__ -     loss = 2.822235554456711
12/26/2021 23:53:03 - INFO - __main__ -     precision = 0.4666666666666667
12/26/2021 23:53:03 - INFO - __main__ -     recall = 0.5333333333333333
12/26/2021 23:53:03 - INFO - __main__ -   Language adapter for gn not found, using pt instead
12/26/2021 23:53:03 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:03 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:03 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:03 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_gn_bert-base-multilingual-cased_128
12/26/2021 23:53:03 - INFO - __main__ -   ***** Running evaluation  in gn *****
12/26/2021 23:53:03 - INFO - __main__ -     Num examples = 102
12/26/2021 23:53:03 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:03 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:03 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:03 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:03 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:03 - INFO - __main__ -   ***** Evaluation result  in gn *****
12/26/2021 23:53:03 - INFO - __main__ -     f1 = 0.44696969696969696
12/26/2021 23:53:03 - INFO - __main__ -     loss = 3.6060410141944885
12/26/2021 23:53:03 - INFO - __main__ -     precision = 0.3710691823899371
12/26/2021 23:53:03 - INFO - __main__ -     recall = 0.5619047619047619
12/26/2021 23:53:06 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf,mhr,tk,gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:53:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:53:06 - INFO - __main__ -   Seed = 2
12/26/2021 23:53:06 - INFO - root -   save model
12/26/2021 23:53:06 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf,mhr,tk,gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:53:06 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:53:10 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:53:16 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:53:16 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:53:16 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:53:16 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:53:16 - INFO - root -   loading task adapter
12/26/2021 23:53:16 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:53:16 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:53:16 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:53:16 - INFO - __main__ -   Language = pt
12/26/2021 23:53:16 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:53:21 - INFO - __main__ -   Language adapter for xmf not found, using pt instead
12/26/2021 23:53:21 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:21 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:21 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:21 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_xmf_bert-base-multilingual-cased_128
12/26/2021 23:53:21 - INFO - __main__ -   ***** Running evaluation  in xmf *****
12/26/2021 23:53:21 - INFO - __main__ -     Num examples = 100
12/26/2021 23:53:21 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:21 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:21 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:21 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:21 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:21 - INFO - __main__ -   ***** Evaluation result  in xmf *****
12/26/2021 23:53:21 - INFO - __main__ -     f1 = 0.3258785942492013
12/26/2021 23:53:21 - INFO - __main__ -     loss = 3.963180124759674
12/26/2021 23:53:21 - INFO - __main__ -     precision = 0.26424870466321243
12/26/2021 23:53:21 - INFO - __main__ -     recall = 0.425
12/26/2021 23:53:21 - INFO - __main__ -   Language adapter for mhr not found, using pt instead
12/26/2021 23:53:21 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:21 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:21 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:21 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_mhr_bert-base-multilingual-cased_128
12/26/2021 23:53:21 - INFO - __main__ -   ***** Running evaluation  in mhr *****
12/26/2021 23:53:21 - INFO - __main__ -     Num examples = 100
12/26/2021 23:53:21 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:21 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:21 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:21 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:22 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:22 - INFO - __main__ -   ***** Evaluation result  in mhr *****
12/26/2021 23:53:22 - INFO - __main__ -     f1 = 0.41880341880341876
12/26/2021 23:53:22 - INFO - __main__ -     loss = 2.8267130851745605
12/26/2021 23:53:22 - INFO - __main__ -     precision = 0.3983739837398374
12/26/2021 23:53:22 - INFO - __main__ -     recall = 0.44144144144144143
12/26/2021 23:53:22 - INFO - __main__ -   Language adapter for tk not found, using pt instead
12/26/2021 23:53:22 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:22 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:22 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:22 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_tk_bert-base-multilingual-cased_128
12/26/2021 23:53:22 - INFO - __main__ -   ***** Running evaluation  in tk *****
12/26/2021 23:53:22 - INFO - __main__ -     Num examples = 101
12/26/2021 23:53:22 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:22 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:22 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:22 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:22 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:22 - INFO - __main__ -   ***** Evaluation result  in tk *****
12/26/2021 23:53:22 - INFO - __main__ -     f1 = 0.46774193548387094
12/26/2021 23:53:22 - INFO - __main__ -     loss = 3.6631144285202026
12/26/2021 23:53:22 - INFO - __main__ -     precision = 0.40559440559440557
12/26/2021 23:53:22 - INFO - __main__ -     recall = 0.5523809523809524
12/26/2021 23:53:22 - INFO - __main__ -   Language adapter for gn not found, using pt instead
12/26/2021 23:53:22 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:22 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:22 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:22 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_gn_bert-base-multilingual-cased_128
12/26/2021 23:53:22 - INFO - __main__ -   ***** Running evaluation  in gn *****
12/26/2021 23:53:22 - INFO - __main__ -     Num examples = 102
12/26/2021 23:53:22 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:22 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:22 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:22 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:23 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:23 - INFO - __main__ -   ***** Evaluation result  in gn *****
12/26/2021 23:53:23 - INFO - __main__ -     f1 = 0.43939393939393945
12/26/2021 23:53:23 - INFO - __main__ -     loss = 3.864408493041992
12/26/2021 23:53:23 - INFO - __main__ -     precision = 0.36477987421383645
12/26/2021 23:53:23 - INFO - __main__ -     recall = 0.5523809523809524
12/26/2021 23:53:25 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf,mhr,tk,gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:53:25 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:53:25 - INFO - __main__ -   Seed = 3
12/26/2021 23:53:25 - INFO - root -   save model
12/26/2021 23:53:25 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='xmf,mhr,tk,gn', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:53:25 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:53:29 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:53:35 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:53:35 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:53:35 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/26/2021 23:53:35 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:53:35 - INFO - root -   loading task adapter
12/26/2021 23:53:35 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:53:35 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:53:35 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:53:35 - INFO - __main__ -   Language = pt
12/26/2021 23:53:35 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:53:40 - INFO - __main__ -   Language adapter for xmf not found, using pt instead
12/26/2021 23:53:40 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:40 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:40 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:40 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_xmf_bert-base-multilingual-cased_128
12/26/2021 23:53:40 - INFO - __main__ -   ***** Running evaluation  in xmf *****
12/26/2021 23:53:40 - INFO - __main__ -     Num examples = 100
12/26/2021 23:53:40 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:40 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:40 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:40 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:40 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:40 - INFO - __main__ -   ***** Evaluation result  in xmf *****
12/26/2021 23:53:40 - INFO - __main__ -     f1 = 0.24074074074074078
12/26/2021 23:53:40 - INFO - __main__ -     loss = 4.710685968399048
12/26/2021 23:53:40 - INFO - __main__ -     precision = 0.19117647058823528
12/26/2021 23:53:40 - INFO - __main__ -     recall = 0.325
12/26/2021 23:53:40 - INFO - __main__ -   Language adapter for mhr not found, using pt instead
12/26/2021 23:53:40 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:40 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:40 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:40 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_mhr_bert-base-multilingual-cased_128
12/26/2021 23:53:40 - INFO - __main__ -   ***** Running evaluation  in mhr *****
12/26/2021 23:53:40 - INFO - __main__ -     Num examples = 100
12/26/2021 23:53:40 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:40 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:41 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:41 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:41 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:41 - INFO - __main__ -   ***** Evaluation result  in mhr *****
12/26/2021 23:53:41 - INFO - __main__ -     f1 = 0.3859649122807018
12/26/2021 23:53:41 - INFO - __main__ -     loss = 2.6534631699323654
12/26/2021 23:53:41 - INFO - __main__ -     precision = 0.37606837606837606
12/26/2021 23:53:41 - INFO - __main__ -     recall = 0.3963963963963964
12/26/2021 23:53:41 - INFO - __main__ -   Language adapter for tk not found, using pt instead
12/26/2021 23:53:41 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:41 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:41 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:41 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_tk_bert-base-multilingual-cased_128
12/26/2021 23:53:41 - INFO - __main__ -   ***** Running evaluation  in tk *****
12/26/2021 23:53:41 - INFO - __main__ -     Num examples = 101
12/26/2021 23:53:41 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:41 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:41 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:41 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:41 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:41 - INFO - __main__ -   ***** Evaluation result  in tk *****
12/26/2021 23:53:41 - INFO - __main__ -     f1 = 0.448
12/26/2021 23:53:41 - INFO - __main__ -     loss = 3.0588616132736206
12/26/2021 23:53:41 - INFO - __main__ -     precision = 0.38620689655172413
12/26/2021 23:53:41 - INFO - __main__ -     recall = 0.5333333333333333
12/26/2021 23:53:41 - INFO - __main__ -   Language adapter for gn not found, using pt instead
12/26/2021 23:53:41 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:53:41 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:53:41 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:53:41 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_gn_bert-base-multilingual-cased_128
12/26/2021 23:53:41 - INFO - __main__ -   ***** Running evaluation  in gn *****
12/26/2021 23:53:41 - INFO - __main__ -     Num examples = 102
12/26/2021 23:53:41 - INFO - __main__ -     Batch size = 32
12/26/2021 23:53:41 - INFO - __main__ -   Batch number = 1
12/26/2021 23:53:42 - INFO - __main__ -   Batch number = 2
12/26/2021 23:53:42 - INFO - __main__ -   Batch number = 3
12/26/2021 23:53:42 - INFO - __main__ -   Batch number = 4
12/26/2021 23:53:42 - INFO - __main__ -   ***** Evaluation result  in gn *****
12/26/2021 23:53:42 - INFO - __main__ -     f1 = 0.36860068259385664
12/26/2021 23:53:42 - INFO - __main__ -     loss = 3.88584965467453
12/26/2021 23:53:42 - INFO - __main__ -     precision = 0.2872340425531915
12/26/2021 23:53:42 - INFO - __main__ -     recall = 0.5142857142857142
12/26/2021 23:56:42 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en,ja,zh,ar,jv,sw,is,my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:56:42 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:56:42 - INFO - __main__ -   Seed = 1
12/26/2021 23:56:42 - INFO - root -   save model
12/26/2021 23:56:42 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en,ja,zh,ar,jv,sw,is,my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:56:42 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:56:46 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:56:52 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:56:52 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:56:52 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/26/2021 23:56:52 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:56:52 - INFO - root -   loading task adapter
12/26/2021 23:56:52 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:56:52 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:56:52 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:56:52 - INFO - __main__ -   Language = pt
12/26/2021 23:56:52 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:56:58 - INFO - __main__ -   Language adapter for en not found, using pt instead
12/26/2021 23:56:58 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:56:58 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:56:58 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:56:58 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
12/26/2021 23:56:59 - INFO - __main__ -   ***** Running evaluation  in en *****
12/26/2021 23:56:59 - INFO - __main__ -     Num examples = 10004
12/26/2021 23:56:59 - INFO - __main__ -     Batch size = 32
12/26/2021 23:56:59 - INFO - __main__ -   Batch number = 1
12/26/2021 23:56:59 - INFO - __main__ -   Batch number = 2
12/26/2021 23:56:59 - INFO - __main__ -   Batch number = 3
12/26/2021 23:56:59 - INFO - __main__ -   Batch number = 4
12/26/2021 23:57:00 - INFO - __main__ -   Batch number = 5
12/26/2021 23:57:00 - INFO - __main__ -   Batch number = 6
12/26/2021 23:57:00 - INFO - __main__ -   Batch number = 7
12/26/2021 23:57:00 - INFO - __main__ -   Batch number = 8
12/26/2021 23:57:00 - INFO - __main__ -   Batch number = 9
12/26/2021 23:57:00 - INFO - __main__ -   Batch number = 10
12/26/2021 23:57:00 - INFO - __main__ -   Batch number = 11
12/26/2021 23:57:00 - INFO - __main__ -   Batch number = 12
12/26/2021 23:57:01 - INFO - __main__ -   Batch number = 13
12/26/2021 23:57:01 - INFO - __main__ -   Batch number = 14
12/26/2021 23:57:01 - INFO - __main__ -   Batch number = 15
12/26/2021 23:57:01 - INFO - __main__ -   Batch number = 16
12/26/2021 23:57:01 - INFO - __main__ -   Batch number = 17
12/26/2021 23:57:01 - INFO - __main__ -   Batch number = 18
12/26/2021 23:57:01 - INFO - __main__ -   Batch number = 19
12/26/2021 23:57:02 - INFO - __main__ -   Batch number = 20
12/26/2021 23:57:02 - INFO - __main__ -   Batch number = 21
12/26/2021 23:57:02 - INFO - __main__ -   Batch number = 22
12/26/2021 23:57:02 - INFO - __main__ -   Batch number = 23
12/26/2021 23:57:02 - INFO - __main__ -   Batch number = 24
12/26/2021 23:57:02 - INFO - __main__ -   Batch number = 25
12/26/2021 23:57:02 - INFO - __main__ -   Batch number = 26
12/26/2021 23:57:03 - INFO - __main__ -   Batch number = 27
12/26/2021 23:57:03 - INFO - __main__ -   Batch number = 28
12/26/2021 23:57:03 - INFO - __main__ -   Batch number = 29
12/26/2021 23:57:03 - INFO - __main__ -   Batch number = 30
12/26/2021 23:57:03 - INFO - __main__ -   Batch number = 31
12/26/2021 23:57:03 - INFO - __main__ -   Batch number = 32
12/26/2021 23:57:03 - INFO - __main__ -   Batch number = 33
12/26/2021 23:57:04 - INFO - __main__ -   Batch number = 34
12/26/2021 23:57:04 - INFO - __main__ -   Batch number = 35
12/26/2021 23:57:04 - INFO - __main__ -   Batch number = 36
12/26/2021 23:57:04 - INFO - __main__ -   Batch number = 37
12/26/2021 23:57:04 - INFO - __main__ -   Batch number = 38
12/26/2021 23:57:04 - INFO - __main__ -   Batch number = 39
12/26/2021 23:57:04 - INFO - __main__ -   Batch number = 40
12/26/2021 23:57:05 - INFO - __main__ -   Batch number = 41
12/26/2021 23:57:05 - INFO - __main__ -   Batch number = 42
12/26/2021 23:57:05 - INFO - __main__ -   Batch number = 43
12/26/2021 23:57:05 - INFO - __main__ -   Batch number = 44
12/26/2021 23:57:05 - INFO - __main__ -   Batch number = 45
12/26/2021 23:57:05 - INFO - __main__ -   Batch number = 46
12/26/2021 23:57:05 - INFO - __main__ -   Batch number = 47
12/26/2021 23:57:06 - INFO - __main__ -   Batch number = 48
12/26/2021 23:57:06 - INFO - __main__ -   Batch number = 49
12/26/2021 23:57:06 - INFO - __main__ -   Batch number = 50
12/26/2021 23:57:06 - INFO - __main__ -   Batch number = 51
12/26/2021 23:57:06 - INFO - __main__ -   Batch number = 52
12/26/2021 23:57:06 - INFO - __main__ -   Batch number = 53
12/26/2021 23:57:06 - INFO - __main__ -   Batch number = 54
12/26/2021 23:57:06 - INFO - __main__ -   Batch number = 55
12/26/2021 23:57:07 - INFO - __main__ -   Batch number = 56
12/26/2021 23:57:07 - INFO - __main__ -   Batch number = 57
12/26/2021 23:57:07 - INFO - __main__ -   Batch number = 58
12/26/2021 23:57:07 - INFO - __main__ -   Batch number = 59
12/26/2021 23:57:07 - INFO - __main__ -   Batch number = 60
12/26/2021 23:57:07 - INFO - __main__ -   Batch number = 61
12/26/2021 23:57:08 - INFO - __main__ -   Batch number = 62
12/26/2021 23:57:08 - INFO - __main__ -   Batch number = 63
12/26/2021 23:57:08 - INFO - __main__ -   Batch number = 64
12/26/2021 23:57:08 - INFO - __main__ -   Batch number = 65
12/26/2021 23:57:09 - INFO - __main__ -   Batch number = 66
12/26/2021 23:57:09 - INFO - __main__ -   Batch number = 67
12/26/2021 23:57:09 - INFO - __main__ -   Batch number = 68
12/26/2021 23:57:09 - INFO - __main__ -   Batch number = 69
12/26/2021 23:57:09 - INFO - __main__ -   Batch number = 70
12/26/2021 23:57:09 - INFO - __main__ -   Batch number = 71
12/26/2021 23:57:09 - INFO - __main__ -   Batch number = 72
12/26/2021 23:57:10 - INFO - __main__ -   Batch number = 73
12/26/2021 23:57:10 - INFO - __main__ -   Batch number = 74
12/26/2021 23:57:10 - INFO - __main__ -   Batch number = 75
12/26/2021 23:57:10 - INFO - __main__ -   Batch number = 76
12/26/2021 23:57:10 - INFO - __main__ -   Batch number = 77
12/26/2021 23:57:10 - INFO - __main__ -   Batch number = 78
12/26/2021 23:57:10 - INFO - __main__ -   Batch number = 79
12/26/2021 23:57:11 - INFO - __main__ -   Batch number = 80
12/26/2021 23:57:11 - INFO - __main__ -   Batch number = 81
12/26/2021 23:57:11 - INFO - __main__ -   Batch number = 82
12/26/2021 23:57:11 - INFO - __main__ -   Batch number = 83
12/26/2021 23:57:11 - INFO - __main__ -   Batch number = 84
12/26/2021 23:57:11 - INFO - __main__ -   Batch number = 85
12/26/2021 23:57:11 - INFO - __main__ -   Batch number = 86
12/26/2021 23:57:12 - INFO - __main__ -   Batch number = 87
12/26/2021 23:57:12 - INFO - __main__ -   Batch number = 88
12/26/2021 23:57:12 - INFO - __main__ -   Batch number = 89
12/26/2021 23:57:12 - INFO - __main__ -   Batch number = 90
12/26/2021 23:57:12 - INFO - __main__ -   Batch number = 91
12/26/2021 23:57:12 - INFO - __main__ -   Batch number = 92
12/26/2021 23:57:12 - INFO - __main__ -   Batch number = 93
12/26/2021 23:57:13 - INFO - __main__ -   Batch number = 94
12/26/2021 23:57:13 - INFO - __main__ -   Batch number = 95
12/26/2021 23:57:13 - INFO - __main__ -   Batch number = 96
12/26/2021 23:57:13 - INFO - __main__ -   Batch number = 97
12/26/2021 23:57:13 - INFO - __main__ -   Batch number = 98
12/26/2021 23:57:13 - INFO - __main__ -   Batch number = 99
12/26/2021 23:57:14 - INFO - __main__ -   Batch number = 100
12/26/2021 23:57:14 - INFO - __main__ -   Batch number = 101
12/26/2021 23:57:14 - INFO - __main__ -   Batch number = 102
12/26/2021 23:57:14 - INFO - __main__ -   Batch number = 103
12/26/2021 23:57:14 - INFO - __main__ -   Batch number = 104
12/26/2021 23:57:14 - INFO - __main__ -   Batch number = 105
12/26/2021 23:57:14 - INFO - __main__ -   Batch number = 106
12/26/2021 23:57:15 - INFO - __main__ -   Batch number = 107
12/26/2021 23:57:15 - INFO - __main__ -   Batch number = 108
12/26/2021 23:57:15 - INFO - __main__ -   Batch number = 109
12/26/2021 23:57:15 - INFO - __main__ -   Batch number = 110
12/26/2021 23:57:15 - INFO - __main__ -   Batch number = 111
12/26/2021 23:57:15 - INFO - __main__ -   Batch number = 112
12/26/2021 23:57:15 - INFO - __main__ -   Batch number = 113
12/26/2021 23:57:16 - INFO - __main__ -   Batch number = 114
12/26/2021 23:57:16 - INFO - __main__ -   Batch number = 115
12/26/2021 23:57:16 - INFO - __main__ -   Batch number = 116
12/26/2021 23:57:16 - INFO - __main__ -   Batch number = 117
12/26/2021 23:57:16 - INFO - __main__ -   Batch number = 118
12/26/2021 23:57:16 - INFO - __main__ -   Batch number = 119
12/26/2021 23:57:16 - INFO - __main__ -   Batch number = 120
12/26/2021 23:57:17 - INFO - __main__ -   Batch number = 121
12/26/2021 23:57:17 - INFO - __main__ -   Batch number = 122
12/26/2021 23:57:17 - INFO - __main__ -   Batch number = 123
12/26/2021 23:57:17 - INFO - __main__ -   Batch number = 124
12/26/2021 23:57:17 - INFO - __main__ -   Batch number = 125
12/26/2021 23:57:17 - INFO - __main__ -   Batch number = 126
12/26/2021 23:57:17 - INFO - __main__ -   Batch number = 127
12/26/2021 23:57:18 - INFO - __main__ -   Batch number = 128
12/26/2021 23:57:18 - INFO - __main__ -   Batch number = 129
12/26/2021 23:57:18 - INFO - __main__ -   Batch number = 130
12/26/2021 23:57:18 - INFO - __main__ -   Batch number = 131
12/26/2021 23:57:18 - INFO - __main__ -   Batch number = 132
12/26/2021 23:57:18 - INFO - __main__ -   Batch number = 133
12/26/2021 23:57:19 - INFO - __main__ -   Batch number = 134
12/26/2021 23:57:19 - INFO - __main__ -   Batch number = 135
12/26/2021 23:57:19 - INFO - __main__ -   Batch number = 136
12/26/2021 23:57:19 - INFO - __main__ -   Batch number = 137
12/26/2021 23:57:19 - INFO - __main__ -   Batch number = 138
12/26/2021 23:57:19 - INFO - __main__ -   Batch number = 139
12/26/2021 23:57:19 - INFO - __main__ -   Batch number = 140
12/26/2021 23:57:20 - INFO - __main__ -   Batch number = 141
12/26/2021 23:57:20 - INFO - __main__ -   Batch number = 142
12/26/2021 23:57:20 - INFO - __main__ -   Batch number = 143
12/26/2021 23:57:20 - INFO - __main__ -   Batch number = 144
12/26/2021 23:57:20 - INFO - __main__ -   Batch number = 145
12/26/2021 23:57:20 - INFO - __main__ -   Batch number = 146
12/26/2021 23:57:20 - INFO - __main__ -   Batch number = 147
12/26/2021 23:57:21 - INFO - __main__ -   Batch number = 148
12/26/2021 23:57:21 - INFO - __main__ -   Batch number = 149
12/26/2021 23:57:21 - INFO - __main__ -   Batch number = 150
12/26/2021 23:57:21 - INFO - __main__ -   Batch number = 151
12/26/2021 23:57:21 - INFO - __main__ -   Batch number = 152
12/26/2021 23:57:21 - INFO - __main__ -   Batch number = 153
12/26/2021 23:57:21 - INFO - __main__ -   Batch number = 154
12/26/2021 23:57:22 - INFO - __main__ -   Batch number = 155
12/26/2021 23:57:22 - INFO - __main__ -   Batch number = 156
12/26/2021 23:57:22 - INFO - __main__ -   Batch number = 157
12/26/2021 23:57:22 - INFO - __main__ -   Batch number = 158
12/26/2021 23:57:22 - INFO - __main__ -   Batch number = 159
12/26/2021 23:57:22 - INFO - __main__ -   Batch number = 160
12/26/2021 23:57:22 - INFO - __main__ -   Batch number = 161
12/26/2021 23:57:23 - INFO - __main__ -   Batch number = 162
12/26/2021 23:57:23 - INFO - __main__ -   Batch number = 163
12/26/2021 23:57:23 - INFO - __main__ -   Batch number = 164
12/26/2021 23:57:23 - INFO - __main__ -   Batch number = 165
12/26/2021 23:57:23 - INFO - __main__ -   Batch number = 166
12/26/2021 23:57:24 - INFO - __main__ -   Batch number = 167
12/26/2021 23:57:24 - INFO - __main__ -   Batch number = 168
12/26/2021 23:57:24 - INFO - __main__ -   Batch number = 169
12/26/2021 23:57:24 - INFO - __main__ -   Batch number = 170
12/26/2021 23:57:24 - INFO - __main__ -   Batch number = 171
12/26/2021 23:57:24 - INFO - __main__ -   Batch number = 172
12/26/2021 23:57:24 - INFO - __main__ -   Batch number = 173
12/26/2021 23:57:25 - INFO - __main__ -   Batch number = 174
12/26/2021 23:57:25 - INFO - __main__ -   Batch number = 175
12/26/2021 23:57:25 - INFO - __main__ -   Batch number = 176
12/26/2021 23:57:25 - INFO - __main__ -   Batch number = 177
12/26/2021 23:57:25 - INFO - __main__ -   Batch number = 178
12/26/2021 23:57:25 - INFO - __main__ -   Batch number = 179
12/26/2021 23:57:25 - INFO - __main__ -   Batch number = 180
12/26/2021 23:57:26 - INFO - __main__ -   Batch number = 181
12/26/2021 23:57:26 - INFO - __main__ -   Batch number = 182
12/26/2021 23:57:26 - INFO - __main__ -   Batch number = 183
12/26/2021 23:57:26 - INFO - __main__ -   Batch number = 184
12/26/2021 23:57:26 - INFO - __main__ -   Batch number = 185
12/26/2021 23:57:26 - INFO - __main__ -   Batch number = 186
12/26/2021 23:57:26 - INFO - __main__ -   Batch number = 187
12/26/2021 23:57:27 - INFO - __main__ -   Batch number = 188
12/26/2021 23:57:27 - INFO - __main__ -   Batch number = 189
12/26/2021 23:57:27 - INFO - __main__ -   Batch number = 190
12/26/2021 23:57:27 - INFO - __main__ -   Batch number = 191
12/26/2021 23:57:27 - INFO - __main__ -   Batch number = 192
12/26/2021 23:57:27 - INFO - __main__ -   Batch number = 193
12/26/2021 23:57:27 - INFO - __main__ -   Batch number = 194
12/26/2021 23:57:28 - INFO - __main__ -   Batch number = 195
12/26/2021 23:57:28 - INFO - __main__ -   Batch number = 196
12/26/2021 23:57:28 - INFO - __main__ -   Batch number = 197
12/26/2021 23:57:28 - INFO - __main__ -   Batch number = 198
12/26/2021 23:57:28 - INFO - __main__ -   Batch number = 199
12/26/2021 23:57:29 - INFO - __main__ -   Batch number = 200
12/26/2021 23:57:29 - INFO - __main__ -   Batch number = 201
12/26/2021 23:57:29 - INFO - __main__ -   Batch number = 202
12/26/2021 23:57:29 - INFO - __main__ -   Batch number = 203
12/26/2021 23:57:29 - INFO - __main__ -   Batch number = 204
12/26/2021 23:57:29 - INFO - __main__ -   Batch number = 205
12/26/2021 23:57:30 - INFO - __main__ -   Batch number = 206
12/26/2021 23:57:30 - INFO - __main__ -   Batch number = 207
12/26/2021 23:57:30 - INFO - __main__ -   Batch number = 208
12/26/2021 23:57:30 - INFO - __main__ -   Batch number = 209
12/26/2021 23:57:30 - INFO - __main__ -   Batch number = 210
12/26/2021 23:57:30 - INFO - __main__ -   Batch number = 211
12/26/2021 23:57:31 - INFO - __main__ -   Batch number = 212
12/26/2021 23:57:31 - INFO - __main__ -   Batch number = 213
12/26/2021 23:57:31 - INFO - __main__ -   Batch number = 214
12/26/2021 23:57:31 - INFO - __main__ -   Batch number = 215
12/26/2021 23:57:31 - INFO - __main__ -   Batch number = 216
12/26/2021 23:57:31 - INFO - __main__ -   Batch number = 217
12/26/2021 23:57:31 - INFO - __main__ -   Batch number = 218
12/26/2021 23:57:32 - INFO - __main__ -   Batch number = 219
12/26/2021 23:57:32 - INFO - __main__ -   Batch number = 220
12/26/2021 23:57:32 - INFO - __main__ -   Batch number = 221
12/26/2021 23:57:32 - INFO - __main__ -   Batch number = 222
12/26/2021 23:57:32 - INFO - __main__ -   Batch number = 223
12/26/2021 23:57:32 - INFO - __main__ -   Batch number = 224
12/26/2021 23:57:33 - INFO - __main__ -   Batch number = 225
12/26/2021 23:57:33 - INFO - __main__ -   Batch number = 226
12/26/2021 23:57:33 - INFO - __main__ -   Batch number = 227
12/26/2021 23:57:33 - INFO - __main__ -   Batch number = 228
12/26/2021 23:57:33 - INFO - __main__ -   Batch number = 229
12/26/2021 23:57:33 - INFO - __main__ -   Batch number = 230
12/26/2021 23:57:34 - INFO - __main__ -   Batch number = 231
12/26/2021 23:57:34 - INFO - __main__ -   Batch number = 232
12/26/2021 23:57:34 - INFO - __main__ -   Batch number = 233
12/26/2021 23:57:34 - INFO - __main__ -   Batch number = 234
12/26/2021 23:57:34 - INFO - __main__ -   Batch number = 235
12/26/2021 23:57:34 - INFO - __main__ -   Batch number = 236
12/26/2021 23:57:35 - INFO - __main__ -   Batch number = 237
12/26/2021 23:57:35 - INFO - __main__ -   Batch number = 238
12/26/2021 23:57:35 - INFO - __main__ -   Batch number = 239
12/26/2021 23:57:35 - INFO - __main__ -   Batch number = 240
12/26/2021 23:57:35 - INFO - __main__ -   Batch number = 241
12/26/2021 23:57:35 - INFO - __main__ -   Batch number = 242
12/26/2021 23:57:36 - INFO - __main__ -   Batch number = 243
12/26/2021 23:57:36 - INFO - __main__ -   Batch number = 244
12/26/2021 23:57:36 - INFO - __main__ -   Batch number = 245
12/26/2021 23:57:36 - INFO - __main__ -   Batch number = 246
12/26/2021 23:57:36 - INFO - __main__ -   Batch number = 247
12/26/2021 23:57:36 - INFO - __main__ -   Batch number = 248
12/26/2021 23:57:36 - INFO - __main__ -   Batch number = 249
12/26/2021 23:57:37 - INFO - __main__ -   Batch number = 250
12/26/2021 23:57:37 - INFO - __main__ -   Batch number = 251
12/26/2021 23:57:37 - INFO - __main__ -   Batch number = 252
12/26/2021 23:57:37 - INFO - __main__ -   Batch number = 253
12/26/2021 23:57:37 - INFO - __main__ -   Batch number = 254
12/26/2021 23:57:37 - INFO - __main__ -   Batch number = 255
12/26/2021 23:57:38 - INFO - __main__ -   Batch number = 256
12/26/2021 23:57:38 - INFO - __main__ -   Batch number = 257
12/26/2021 23:57:38 - INFO - __main__ -   Batch number = 258
12/26/2021 23:57:38 - INFO - __main__ -   Batch number = 259
12/26/2021 23:57:38 - INFO - __main__ -   Batch number = 260
12/26/2021 23:57:38 - INFO - __main__ -   Batch number = 261
12/26/2021 23:57:39 - INFO - __main__ -   Batch number = 262
12/26/2021 23:57:39 - INFO - __main__ -   Batch number = 263
12/26/2021 23:57:39 - INFO - __main__ -   Batch number = 264
12/26/2021 23:57:39 - INFO - __main__ -   Batch number = 265
12/26/2021 23:57:39 - INFO - __main__ -   Batch number = 266
12/26/2021 23:57:39 - INFO - __main__ -   Batch number = 267
12/26/2021 23:57:39 - INFO - __main__ -   Batch number = 268
12/26/2021 23:57:40 - INFO - __main__ -   Batch number = 269
12/26/2021 23:57:40 - INFO - __main__ -   Batch number = 270
12/26/2021 23:57:40 - INFO - __main__ -   Batch number = 271
12/26/2021 23:57:40 - INFO - __main__ -   Batch number = 272
12/26/2021 23:57:40 - INFO - __main__ -   Batch number = 273
12/26/2021 23:57:40 - INFO - __main__ -   Batch number = 274
12/26/2021 23:57:40 - INFO - __main__ -   Batch number = 275
12/26/2021 23:57:41 - INFO - __main__ -   Batch number = 276
12/26/2021 23:57:41 - INFO - __main__ -   Batch number = 277
12/26/2021 23:57:41 - INFO - __main__ -   Batch number = 278
12/26/2021 23:57:41 - INFO - __main__ -   Batch number = 279
12/26/2021 23:57:41 - INFO - __main__ -   Batch number = 280
12/26/2021 23:57:42 - INFO - __main__ -   Batch number = 281
12/26/2021 23:57:42 - INFO - __main__ -   Batch number = 282
12/26/2021 23:57:42 - INFO - __main__ -   Batch number = 283
12/26/2021 23:57:42 - INFO - __main__ -   Batch number = 284
12/26/2021 23:57:42 - INFO - __main__ -   Batch number = 285
12/26/2021 23:57:42 - INFO - __main__ -   Batch number = 286
12/26/2021 23:57:42 - INFO - __main__ -   Batch number = 287
12/26/2021 23:57:43 - INFO - __main__ -   Batch number = 288
12/26/2021 23:57:43 - INFO - __main__ -   Batch number = 289
12/26/2021 23:57:43 - INFO - __main__ -   Batch number = 290
12/26/2021 23:57:43 - INFO - __main__ -   Batch number = 291
12/26/2021 23:57:43 - INFO - __main__ -   Batch number = 292
12/26/2021 23:57:43 - INFO - __main__ -   Batch number = 293
12/26/2021 23:57:44 - INFO - __main__ -   Batch number = 294
12/26/2021 23:57:44 - INFO - __main__ -   Batch number = 295
12/26/2021 23:57:44 - INFO - __main__ -   Batch number = 296
12/26/2021 23:57:44 - INFO - __main__ -   Batch number = 297
12/26/2021 23:57:44 - INFO - __main__ -   Batch number = 298
12/26/2021 23:57:44 - INFO - __main__ -   Batch number = 299
12/26/2021 23:57:45 - INFO - __main__ -   Batch number = 300
12/26/2021 23:57:45 - INFO - __main__ -   Batch number = 301
12/26/2021 23:57:45 - INFO - __main__ -   Batch number = 302
12/26/2021 23:57:45 - INFO - __main__ -   Batch number = 303
12/26/2021 23:57:45 - INFO - __main__ -   Batch number = 304
12/26/2021 23:57:45 - INFO - __main__ -   Batch number = 305
12/26/2021 23:57:46 - INFO - __main__ -   Batch number = 306
12/26/2021 23:57:46 - INFO - __main__ -   Batch number = 307
12/26/2021 23:57:46 - INFO - __main__ -   Batch number = 308
12/26/2021 23:57:46 - INFO - __main__ -   Batch number = 309
12/26/2021 23:57:46 - INFO - __main__ -   Batch number = 310
12/26/2021 23:57:46 - INFO - __main__ -   Batch number = 311
12/26/2021 23:57:47 - INFO - __main__ -   Batch number = 312
12/26/2021 23:57:47 - INFO - __main__ -   Batch number = 313
12/26/2021 23:57:48 - INFO - __main__ -   ***** Evaluation result  in en *****
12/26/2021 23:57:48 - INFO - __main__ -     f1 = 0.7826420088461672
12/26/2021 23:57:48 - INFO - __main__ -     loss = 1.0368526690422346
12/26/2021 23:57:48 - INFO - __main__ -     precision = 0.7615561881523655
12/26/2021 23:57:48 - INFO - __main__ -     recall = 0.8049287198223368
12/26/2021 23:57:48 - INFO - __main__ -   Language adapter for ja not found, using pt instead
12/26/2021 23:57:48 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:57:48 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:57:48 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:57:48 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ja_bert-base-multilingual-cased_128
12/26/2021 23:57:50 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en,ja,zh,ar,jv,sw,is,my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:57:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/26/2021 23:57:50 - INFO - __main__ -   Seed = 2
12/26/2021 23:57:50 - INFO - root -   save model
12/26/2021 23:57:50 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en,ja,zh,ar,jv,sw,is,my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/26/2021 23:57:50 - INFO - __main__ -   Loading pretrained model and tokenizer
12/26/2021 23:57:54 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/26/2021 23:58:01 - INFO - __main__ -   Using lang2id = None
12/26/2021 23:58:01 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/26/2021 23:58:01 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s2/checkpoint-best/ner/
12/26/2021 23:58:01 - INFO - root -   Trying to decide if add adapter
12/26/2021 23:58:01 - INFO - root -   loading task adapter
12/26/2021 23:58:01 - INFO - root -   loading lang adpater pt/wiki@ukp
12/26/2021 23:58:01 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/26/2021 23:58:01 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/26/2021 23:58:01 - INFO - __main__ -   Language = pt
12/26/2021 23:58:01 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/26/2021 23:58:06 - INFO - __main__ -   Language adapter for en not found, using pt instead
12/26/2021 23:58:06 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:58:06 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:58:06 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:58:06 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
12/26/2021 23:58:07 - INFO - __main__ -   ***** Running evaluation  in en *****
12/26/2021 23:58:07 - INFO - __main__ -     Num examples = 10004
12/26/2021 23:58:07 - INFO - __main__ -     Batch size = 32
12/26/2021 23:58:07 - INFO - __main__ -   Batch number = 1
12/26/2021 23:58:07 - INFO - __main__ -   Batch number = 2
12/26/2021 23:58:07 - INFO - __main__ -   Batch number = 3
12/26/2021 23:58:08 - INFO - __main__ -   Batch number = 4
12/26/2021 23:58:08 - INFO - __main__ -   Batch number = 5
12/26/2021 23:58:08 - INFO - __main__ -   Batch number = 6
12/26/2021 23:58:08 - INFO - __main__ -   Batch number = 7
12/26/2021 23:58:08 - INFO - __main__ -   Batch number = 8
12/26/2021 23:58:08 - INFO - __main__ -   Batch number = 9
12/26/2021 23:58:08 - INFO - __main__ -   Batch number = 10
12/26/2021 23:58:09 - INFO - __main__ -   Batch number = 11
12/26/2021 23:58:09 - INFO - __main__ -   Batch number = 12
12/26/2021 23:58:09 - INFO - __main__ -   Batch number = 13
12/26/2021 23:58:09 - INFO - __main__ -   Batch number = 14
12/26/2021 23:58:09 - INFO - __main__ -   Batch number = 15
12/26/2021 23:58:09 - INFO - __main__ -   Batch number = 16
12/26/2021 23:58:09 - INFO - __main__ -   Batch number = 17
12/26/2021 23:58:10 - INFO - __main__ -   Batch number = 18
12/26/2021 23:58:10 - INFO - __main__ -   Batch number = 19
12/26/2021 23:58:10 - INFO - __main__ -   Batch number = 20
12/26/2021 23:58:10 - INFO - __main__ -   Batch number = 21
12/26/2021 23:58:10 - INFO - __main__ -   Batch number = 22
12/26/2021 23:58:10 - INFO - __main__ -   Batch number = 23
12/26/2021 23:58:10 - INFO - __main__ -   Batch number = 24
12/26/2021 23:58:11 - INFO - __main__ -   Batch number = 25
12/26/2021 23:58:11 - INFO - __main__ -   Batch number = 26
12/26/2021 23:58:11 - INFO - __main__ -   Batch number = 27
12/26/2021 23:58:11 - INFO - __main__ -   Batch number = 28
12/26/2021 23:58:11 - INFO - __main__ -   Batch number = 29
12/26/2021 23:58:11 - INFO - __main__ -   Batch number = 30
12/26/2021 23:58:12 - INFO - __main__ -   Batch number = 31
12/26/2021 23:58:12 - INFO - __main__ -   Batch number = 32
12/26/2021 23:58:12 - INFO - __main__ -   Batch number = 33
12/26/2021 23:58:12 - INFO - __main__ -   Batch number = 34
12/26/2021 23:58:12 - INFO - __main__ -   Batch number = 35
12/26/2021 23:58:12 - INFO - __main__ -   Batch number = 36
12/26/2021 23:58:12 - INFO - __main__ -   Batch number = 37
12/26/2021 23:58:13 - INFO - __main__ -   Batch number = 38
12/26/2021 23:58:13 - INFO - __main__ -   Batch number = 39
12/26/2021 23:58:13 - INFO - __main__ -   Batch number = 40
12/26/2021 23:58:13 - INFO - __main__ -   Batch number = 41
12/26/2021 23:58:13 - INFO - __main__ -   Batch number = 42
12/26/2021 23:58:13 - INFO - __main__ -   Batch number = 43
12/26/2021 23:58:13 - INFO - __main__ -   Batch number = 44
12/26/2021 23:58:14 - INFO - __main__ -   Batch number = 45
12/26/2021 23:58:14 - INFO - __main__ -   Batch number = 46
12/26/2021 23:58:14 - INFO - __main__ -   Batch number = 47
12/26/2021 23:58:14 - INFO - __main__ -   Batch number = 48
12/26/2021 23:58:14 - INFO - __main__ -   Batch number = 49
12/26/2021 23:58:14 - INFO - __main__ -   Batch number = 50
12/26/2021 23:58:14 - INFO - __main__ -   Batch number = 51
12/26/2021 23:58:15 - INFO - __main__ -   Batch number = 52
12/26/2021 23:58:15 - INFO - __main__ -   Batch number = 53
12/26/2021 23:58:15 - INFO - __main__ -   Batch number = 54
12/26/2021 23:58:15 - INFO - __main__ -   Batch number = 55
12/26/2021 23:58:15 - INFO - __main__ -   Batch number = 56
12/26/2021 23:58:15 - INFO - __main__ -   Batch number = 57
12/26/2021 23:58:15 - INFO - __main__ -   Batch number = 58
12/26/2021 23:58:16 - INFO - __main__ -   Batch number = 59
12/26/2021 23:58:16 - INFO - __main__ -   Batch number = 60
12/26/2021 23:58:16 - INFO - __main__ -   Batch number = 61
12/26/2021 23:58:16 - INFO - __main__ -   Batch number = 62
12/26/2021 23:58:16 - INFO - __main__ -   Batch number = 63
12/26/2021 23:58:17 - INFO - __main__ -   Batch number = 64
12/26/2021 23:58:17 - INFO - __main__ -   Batch number = 65
12/26/2021 23:58:17 - INFO - __main__ -   Batch number = 66
12/26/2021 23:58:17 - INFO - __main__ -   Batch number = 67
12/26/2021 23:58:17 - INFO - __main__ -   Batch number = 68
12/26/2021 23:58:17 - INFO - __main__ -   Batch number = 69
12/26/2021 23:58:17 - INFO - __main__ -   Batch number = 70
12/26/2021 23:58:18 - INFO - __main__ -   Batch number = 71
12/26/2021 23:58:18 - INFO - __main__ -   Batch number = 72
12/26/2021 23:58:18 - INFO - __main__ -   Batch number = 73
12/26/2021 23:58:18 - INFO - __main__ -   Batch number = 74
12/26/2021 23:58:18 - INFO - __main__ -   Batch number = 75
12/26/2021 23:58:18 - INFO - __main__ -   Batch number = 76
12/26/2021 23:58:18 - INFO - __main__ -   Batch number = 77
12/26/2021 23:58:19 - INFO - __main__ -   Batch number = 78
12/26/2021 23:58:19 - INFO - __main__ -   Batch number = 79
12/26/2021 23:58:19 - INFO - __main__ -   Batch number = 80
12/26/2021 23:58:19 - INFO - __main__ -   Batch number = 81
12/26/2021 23:58:19 - INFO - __main__ -   Batch number = 82
12/26/2021 23:58:19 - INFO - __main__ -   Batch number = 83
12/26/2021 23:58:19 - INFO - __main__ -   Batch number = 84
12/26/2021 23:58:20 - INFO - __main__ -   Batch number = 85
12/26/2021 23:58:20 - INFO - __main__ -   Batch number = 86
12/26/2021 23:58:20 - INFO - __main__ -   Batch number = 87
12/26/2021 23:58:20 - INFO - __main__ -   Batch number = 88
12/26/2021 23:58:20 - INFO - __main__ -   Batch number = 89
12/26/2021 23:58:20 - INFO - __main__ -   Batch number = 90
12/26/2021 23:58:20 - INFO - __main__ -   Batch number = 91
12/26/2021 23:58:21 - INFO - __main__ -   Batch number = 92
12/26/2021 23:58:21 - INFO - __main__ -   Batch number = 93
12/26/2021 23:58:21 - INFO - __main__ -   Batch number = 94
12/26/2021 23:58:21 - INFO - __main__ -   Batch number = 95
12/26/2021 23:58:21 - INFO - __main__ -   Batch number = 96
12/26/2021 23:58:22 - INFO - __main__ -   Batch number = 97
12/26/2021 23:58:22 - INFO - __main__ -   Batch number = 98
12/26/2021 23:58:22 - INFO - __main__ -   Batch number = 99
12/26/2021 23:58:22 - INFO - __main__ -   Batch number = 100
12/26/2021 23:58:22 - INFO - __main__ -   Batch number = 101
12/26/2021 23:58:22 - INFO - __main__ -   Batch number = 102
12/26/2021 23:58:23 - INFO - __main__ -   Batch number = 103
12/26/2021 23:58:23 - INFO - __main__ -   Batch number = 104
12/26/2021 23:58:23 - INFO - __main__ -   Batch number = 105
12/26/2021 23:58:23 - INFO - __main__ -   Batch number = 106
12/26/2021 23:58:23 - INFO - __main__ -   Batch number = 107
12/26/2021 23:58:23 - INFO - __main__ -   Batch number = 108
12/26/2021 23:58:23 - INFO - __main__ -   Batch number = 109
12/26/2021 23:58:24 - INFO - __main__ -   Batch number = 110
12/26/2021 23:58:24 - INFO - __main__ -   Batch number = 111
12/26/2021 23:58:24 - INFO - __main__ -   Batch number = 112
12/26/2021 23:58:24 - INFO - __main__ -   Batch number = 113
12/26/2021 23:58:24 - INFO - __main__ -   Batch number = 114
12/26/2021 23:58:24 - INFO - __main__ -   Batch number = 115
12/26/2021 23:58:24 - INFO - __main__ -   Batch number = 116
12/26/2021 23:58:25 - INFO - __main__ -   Batch number = 117
12/26/2021 23:58:25 - INFO - __main__ -   Batch number = 118
12/26/2021 23:58:25 - INFO - __main__ -   Batch number = 119
12/26/2021 23:58:25 - INFO - __main__ -   Batch number = 120
12/26/2021 23:58:25 - INFO - __main__ -   Batch number = 121
12/26/2021 23:58:25 - INFO - __main__ -   Batch number = 122
12/26/2021 23:58:26 - INFO - __main__ -   Batch number = 123
12/26/2021 23:58:26 - INFO - __main__ -   Batch number = 124
12/26/2021 23:58:26 - INFO - __main__ -   Batch number = 125
12/26/2021 23:58:26 - INFO - __main__ -   Batch number = 126
12/26/2021 23:58:26 - INFO - __main__ -   Batch number = 127
12/26/2021 23:58:27 - INFO - __main__ -   Batch number = 128
12/26/2021 23:58:27 - INFO - __main__ -   Batch number = 129
12/26/2021 23:58:27 - INFO - __main__ -   Batch number = 130
12/26/2021 23:58:27 - INFO - __main__ -   Batch number = 131
12/26/2021 23:58:27 - INFO - __main__ -   Batch number = 132
12/26/2021 23:58:27 - INFO - __main__ -   Batch number = 133
12/26/2021 23:58:27 - INFO - __main__ -   Batch number = 134
12/26/2021 23:58:28 - INFO - __main__ -   Batch number = 135
12/26/2021 23:58:28 - INFO - __main__ -   Batch number = 136
12/26/2021 23:58:28 - INFO - __main__ -   Batch number = 137
12/26/2021 23:58:28 - INFO - __main__ -   Batch number = 138
12/26/2021 23:58:28 - INFO - __main__ -   Batch number = 139
12/26/2021 23:58:28 - INFO - __main__ -   Batch number = 140
12/26/2021 23:58:29 - INFO - __main__ -   Batch number = 141
12/26/2021 23:58:29 - INFO - __main__ -   Batch number = 142
12/26/2021 23:58:29 - INFO - __main__ -   Batch number = 143
12/26/2021 23:58:29 - INFO - __main__ -   Batch number = 144
12/26/2021 23:58:29 - INFO - __main__ -   Batch number = 145
12/26/2021 23:58:29 - INFO - __main__ -   Batch number = 146
12/26/2021 23:58:29 - INFO - __main__ -   Batch number = 147
12/26/2021 23:58:30 - INFO - __main__ -   Batch number = 148
12/26/2021 23:58:30 - INFO - __main__ -   Batch number = 149
12/26/2021 23:58:30 - INFO - __main__ -   Batch number = 150
12/26/2021 23:58:30 - INFO - __main__ -   Batch number = 151
12/26/2021 23:58:30 - INFO - __main__ -   Batch number = 152
12/26/2021 23:58:30 - INFO - __main__ -   Batch number = 153
12/26/2021 23:58:31 - INFO - __main__ -   Batch number = 154
12/26/2021 23:58:31 - INFO - __main__ -   Batch number = 155
12/26/2021 23:58:31 - INFO - __main__ -   Batch number = 156
12/26/2021 23:58:31 - INFO - __main__ -   Batch number = 157
12/26/2021 23:58:31 - INFO - __main__ -   Batch number = 158
12/26/2021 23:58:31 - INFO - __main__ -   Batch number = 159
12/26/2021 23:58:32 - INFO - __main__ -   Batch number = 160
12/26/2021 23:58:32 - INFO - __main__ -   Batch number = 161
12/26/2021 23:58:32 - INFO - __main__ -   Batch number = 162
12/26/2021 23:58:32 - INFO - __main__ -   Batch number = 163
12/26/2021 23:58:32 - INFO - __main__ -   Batch number = 164
12/26/2021 23:58:32 - INFO - __main__ -   Batch number = 165
12/26/2021 23:58:32 - INFO - __main__ -   Batch number = 166
12/26/2021 23:58:33 - INFO - __main__ -   Batch number = 167
12/26/2021 23:58:33 - INFO - __main__ -   Batch number = 168
12/26/2021 23:58:33 - INFO - __main__ -   Batch number = 169
12/26/2021 23:58:33 - INFO - __main__ -   Batch number = 170
12/26/2021 23:58:33 - INFO - __main__ -   Batch number = 171
12/26/2021 23:58:33 - INFO - __main__ -   Batch number = 172
12/26/2021 23:58:33 - INFO - __main__ -   Batch number = 173
12/26/2021 23:58:34 - INFO - __main__ -   Batch number = 174
12/26/2021 23:58:34 - INFO - __main__ -   Batch number = 175
12/26/2021 23:58:34 - INFO - __main__ -   Batch number = 176
12/26/2021 23:58:34 - INFO - __main__ -   Batch number = 177
12/26/2021 23:58:34 - INFO - __main__ -   Batch number = 178
12/26/2021 23:58:34 - INFO - __main__ -   Batch number = 179
12/26/2021 23:58:34 - INFO - __main__ -   Batch number = 180
12/26/2021 23:58:35 - INFO - __main__ -   Batch number = 181
12/26/2021 23:58:35 - INFO - __main__ -   Batch number = 182
12/26/2021 23:58:35 - INFO - __main__ -   Batch number = 183
12/26/2021 23:58:35 - INFO - __main__ -   Batch number = 184
12/26/2021 23:58:35 - INFO - __main__ -   Batch number = 185
12/26/2021 23:58:35 - INFO - __main__ -   Batch number = 186
12/26/2021 23:58:36 - INFO - __main__ -   Batch number = 187
12/26/2021 23:58:36 - INFO - __main__ -   Batch number = 188
12/26/2021 23:58:36 - INFO - __main__ -   Batch number = 189
12/26/2021 23:58:36 - INFO - __main__ -   Batch number = 190
12/26/2021 23:58:36 - INFO - __main__ -   Batch number = 191
12/26/2021 23:58:36 - INFO - __main__ -   Batch number = 192
12/26/2021 23:58:37 - INFO - __main__ -   Batch number = 193
12/26/2021 23:58:37 - INFO - __main__ -   Batch number = 194
12/26/2021 23:58:37 - INFO - __main__ -   Batch number = 195
12/26/2021 23:58:37 - INFO - __main__ -   Batch number = 196
12/26/2021 23:58:37 - INFO - __main__ -   Batch number = 197
12/26/2021 23:58:37 - INFO - __main__ -   Batch number = 198
12/26/2021 23:58:38 - INFO - __main__ -   Batch number = 199
12/26/2021 23:58:38 - INFO - __main__ -   Batch number = 200
12/26/2021 23:58:38 - INFO - __main__ -   Batch number = 201
12/26/2021 23:58:38 - INFO - __main__ -   Batch number = 202
12/26/2021 23:58:38 - INFO - __main__ -   Batch number = 203
12/26/2021 23:58:38 - INFO - __main__ -   Batch number = 204
12/26/2021 23:58:39 - INFO - __main__ -   Batch number = 205
12/26/2021 23:58:39 - INFO - __main__ -   Batch number = 206
12/26/2021 23:58:39 - INFO - __main__ -   Batch number = 207
12/26/2021 23:58:39 - INFO - __main__ -   Batch number = 208
12/26/2021 23:58:39 - INFO - __main__ -   Batch number = 209
12/26/2021 23:58:39 - INFO - __main__ -   Batch number = 210
12/26/2021 23:58:39 - INFO - __main__ -   Batch number = 211
12/26/2021 23:58:40 - INFO - __main__ -   Batch number = 212
12/26/2021 23:58:40 - INFO - __main__ -   Batch number = 213
12/26/2021 23:58:40 - INFO - __main__ -   Batch number = 214
12/26/2021 23:58:40 - INFO - __main__ -   Batch number = 215
12/26/2021 23:58:40 - INFO - __main__ -   Batch number = 216
12/26/2021 23:58:40 - INFO - __main__ -   Batch number = 217
12/26/2021 23:58:41 - INFO - __main__ -   Batch number = 218
12/26/2021 23:58:41 - INFO - __main__ -   Batch number = 219
12/26/2021 23:58:41 - INFO - __main__ -   Batch number = 220
12/26/2021 23:58:41 - INFO - __main__ -   Batch number = 221
12/26/2021 23:58:41 - INFO - __main__ -   Batch number = 222
12/26/2021 23:58:41 - INFO - __main__ -   Batch number = 223
12/26/2021 23:58:42 - INFO - __main__ -   Batch number = 224
12/26/2021 23:58:42 - INFO - __main__ -   Batch number = 225
12/26/2021 23:58:42 - INFO - __main__ -   Batch number = 226
12/26/2021 23:58:42 - INFO - __main__ -   Batch number = 227
12/26/2021 23:58:42 - INFO - __main__ -   Batch number = 228
12/26/2021 23:58:42 - INFO - __main__ -   Batch number = 229
12/26/2021 23:58:42 - INFO - __main__ -   Batch number = 230
12/26/2021 23:58:43 - INFO - __main__ -   Batch number = 231
12/26/2021 23:58:43 - INFO - __main__ -   Batch number = 232
12/26/2021 23:58:43 - INFO - __main__ -   Batch number = 233
12/26/2021 23:58:43 - INFO - __main__ -   Batch number = 234
12/26/2021 23:58:43 - INFO - __main__ -   Batch number = 235
12/26/2021 23:58:43 - INFO - __main__ -   Batch number = 236
12/26/2021 23:58:44 - INFO - __main__ -   Batch number = 237
12/26/2021 23:58:44 - INFO - __main__ -   Batch number = 238
12/26/2021 23:58:44 - INFO - __main__ -   Batch number = 239
12/26/2021 23:58:44 - INFO - __main__ -   Batch number = 240
12/26/2021 23:58:44 - INFO - __main__ -   Batch number = 241
12/26/2021 23:58:44 - INFO - __main__ -   Batch number = 242
12/26/2021 23:58:44 - INFO - __main__ -   Batch number = 243
12/26/2021 23:58:45 - INFO - __main__ -   Batch number = 244
12/26/2021 23:58:45 - INFO - __main__ -   Batch number = 245
12/26/2021 23:58:45 - INFO - __main__ -   Batch number = 246
12/26/2021 23:58:45 - INFO - __main__ -   Batch number = 247
12/26/2021 23:58:45 - INFO - __main__ -   Batch number = 248
12/26/2021 23:58:45 - INFO - __main__ -   Batch number = 249
12/26/2021 23:58:45 - INFO - __main__ -   Batch number = 250
12/26/2021 23:58:46 - INFO - __main__ -   Batch number = 251
12/26/2021 23:58:46 - INFO - __main__ -   Batch number = 252
12/26/2021 23:58:46 - INFO - __main__ -   Batch number = 253
12/26/2021 23:58:46 - INFO - __main__ -   Batch number = 254
12/26/2021 23:58:46 - INFO - __main__ -   Batch number = 255
12/26/2021 23:58:46 - INFO - __main__ -   Batch number = 256
12/26/2021 23:58:47 - INFO - __main__ -   Batch number = 257
12/26/2021 23:58:47 - INFO - __main__ -   Batch number = 258
12/26/2021 23:58:47 - INFO - __main__ -   Batch number = 259
12/26/2021 23:58:47 - INFO - __main__ -   Batch number = 260
12/26/2021 23:58:47 - INFO - __main__ -   Batch number = 261
12/26/2021 23:58:47 - INFO - __main__ -   Batch number = 262
12/26/2021 23:58:47 - INFO - __main__ -   Batch number = 263
12/26/2021 23:58:48 - INFO - __main__ -   Batch number = 264
12/26/2021 23:58:48 - INFO - __main__ -   Batch number = 265
12/26/2021 23:58:48 - INFO - __main__ -   Batch number = 266
12/26/2021 23:58:48 - INFO - __main__ -   Batch number = 267
12/26/2021 23:58:48 - INFO - __main__ -   Batch number = 268
12/26/2021 23:58:49 - INFO - __main__ -   Batch number = 269
12/26/2021 23:58:49 - INFO - __main__ -   Batch number = 270
12/26/2021 23:58:49 - INFO - __main__ -   Batch number = 271
12/26/2021 23:58:49 - INFO - __main__ -   Batch number = 272
12/26/2021 23:58:49 - INFO - __main__ -   Batch number = 273
12/26/2021 23:58:49 - INFO - __main__ -   Batch number = 274
12/26/2021 23:58:49 - INFO - __main__ -   Batch number = 275
12/26/2021 23:58:50 - INFO - __main__ -   Batch number = 276
12/26/2021 23:58:50 - INFO - __main__ -   Batch number = 277
12/26/2021 23:58:50 - INFO - __main__ -   Batch number = 278
12/26/2021 23:58:50 - INFO - __main__ -   Batch number = 279
12/26/2021 23:58:50 - INFO - __main__ -   Batch number = 280
12/26/2021 23:58:50 - INFO - __main__ -   Batch number = 281
12/26/2021 23:58:51 - INFO - __main__ -   Batch number = 282
12/26/2021 23:58:51 - INFO - __main__ -   Batch number = 283
12/26/2021 23:58:51 - INFO - __main__ -   Batch number = 284
12/26/2021 23:58:51 - INFO - __main__ -   Batch number = 285
12/26/2021 23:58:51 - INFO - __main__ -   Batch number = 286
12/26/2021 23:58:51 - INFO - __main__ -   Batch number = 287
12/26/2021 23:58:51 - INFO - __main__ -   Batch number = 288
12/26/2021 23:58:52 - INFO - __main__ -   Batch number = 289
12/26/2021 23:58:52 - INFO - __main__ -   Batch number = 290
12/26/2021 23:58:52 - INFO - __main__ -   Batch number = 291
12/26/2021 23:58:52 - INFO - __main__ -   Batch number = 292
12/26/2021 23:58:52 - INFO - __main__ -   Batch number = 293
12/26/2021 23:58:52 - INFO - __main__ -   Batch number = 294
12/26/2021 23:58:52 - INFO - __main__ -   Batch number = 295
12/26/2021 23:58:53 - INFO - __main__ -   Batch number = 296
12/26/2021 23:58:53 - INFO - __main__ -   Batch number = 297
12/26/2021 23:58:53 - INFO - __main__ -   Batch number = 298
12/26/2021 23:58:53 - INFO - __main__ -   Batch number = 299
12/26/2021 23:58:53 - INFO - __main__ -   Batch number = 300
12/26/2021 23:58:54 - INFO - __main__ -   Batch number = 301
12/26/2021 23:58:54 - INFO - __main__ -   Batch number = 302
12/26/2021 23:58:54 - INFO - __main__ -   Batch number = 303
12/26/2021 23:58:54 - INFO - __main__ -   Batch number = 304
12/26/2021 23:58:54 - INFO - __main__ -   Batch number = 305
12/26/2021 23:58:55 - INFO - __main__ -   Batch number = 306
12/26/2021 23:58:55 - INFO - __main__ -   Batch number = 307
12/26/2021 23:58:55 - INFO - __main__ -   Batch number = 308
12/26/2021 23:58:55 - INFO - __main__ -   Batch number = 309
12/26/2021 23:58:55 - INFO - __main__ -   Batch number = 310
12/26/2021 23:58:55 - INFO - __main__ -   Batch number = 311
12/26/2021 23:58:56 - INFO - __main__ -   Batch number = 312
12/26/2021 23:58:56 - INFO - __main__ -   Batch number = 313
12/26/2021 23:58:57 - INFO - __main__ -   ***** Evaluation result  in en *****
12/26/2021 23:58:57 - INFO - __main__ -     f1 = 0.7969809210986093
12/26/2021 23:58:57 - INFO - __main__ -     loss = 1.029073115747672
12/26/2021 23:58:57 - INFO - __main__ -     precision = 0.777952111330923
12/26/2021 23:58:57 - INFO - __main__ -     recall = 0.8169639659001361
12/26/2021 23:58:57 - INFO - __main__ -   Language adapter for ja not found, using pt instead
12/26/2021 23:58:57 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:58:57 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:58:57 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:58:57 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ja_bert-base-multilingual-cased_128
12/26/2021 23:58:59 - INFO - __main__ -   ***** Running evaluation  in ja *****
12/26/2021 23:58:59 - INFO - __main__ -     Num examples = 10612
12/26/2021 23:58:59 - INFO - __main__ -     Batch size = 32
12/26/2021 23:58:59 - INFO - __main__ -   Batch number = 1
12/26/2021 23:58:59 - INFO - __main__ -   Batch number = 2
12/26/2021 23:58:59 - INFO - __main__ -   Batch number = 3
12/26/2021 23:58:59 - INFO - __main__ -   Batch number = 4
12/26/2021 23:58:59 - INFO - __main__ -   Batch number = 5
12/26/2021 23:58:59 - INFO - __main__ -   Batch number = 6
12/26/2021 23:58:59 - INFO - __main__ -   Batch number = 7
12/26/2021 23:59:00 - INFO - __main__ -   Batch number = 8
12/26/2021 23:59:00 - INFO - __main__ -   Batch number = 9
12/26/2021 23:59:00 - INFO - __main__ -   Batch number = 10
12/26/2021 23:59:00 - INFO - __main__ -   Batch number = 11
12/26/2021 23:59:00 - INFO - __main__ -   Batch number = 12
12/26/2021 23:59:00 - INFO - __main__ -   Batch number = 13
12/26/2021 23:59:01 - INFO - __main__ -   Batch number = 14
12/26/2021 23:59:01 - INFO - __main__ -   Batch number = 15
12/26/2021 23:59:01 - INFO - __main__ -   Batch number = 16
12/26/2021 23:59:01 - INFO - __main__ -   Batch number = 17
12/26/2021 23:59:01 - INFO - __main__ -   Batch number = 18
12/26/2021 23:59:01 - INFO - __main__ -   Batch number = 19
12/26/2021 23:59:01 - INFO - __main__ -   Batch number = 20
12/26/2021 23:59:02 - INFO - __main__ -   Batch number = 21
12/26/2021 23:59:02 - INFO - __main__ -   Batch number = 22
12/26/2021 23:59:02 - INFO - __main__ -   Batch number = 23
12/26/2021 23:59:02 - INFO - __main__ -   Batch number = 24
12/26/2021 23:59:02 - INFO - __main__ -   Batch number = 25
12/26/2021 23:59:02 - INFO - __main__ -   Batch number = 26
12/26/2021 23:59:02 - INFO - __main__ -   Batch number = 27
12/26/2021 23:59:03 - INFO - __main__ -   Batch number = 28
12/26/2021 23:59:03 - INFO - __main__ -   Batch number = 29
12/26/2021 23:59:03 - INFO - __main__ -   Batch number = 30
12/26/2021 23:59:03 - INFO - __main__ -   Batch number = 31
12/26/2021 23:59:03 - INFO - __main__ -   Batch number = 32
12/26/2021 23:59:03 - INFO - __main__ -   Batch number = 33
12/26/2021 23:59:03 - INFO - __main__ -   Batch number = 34
12/26/2021 23:59:04 - INFO - __main__ -   Batch number = 35
12/26/2021 23:59:04 - INFO - __main__ -   Batch number = 36
12/26/2021 23:59:04 - INFO - __main__ -   Batch number = 37
12/26/2021 23:59:04 - INFO - __main__ -   Batch number = 38
12/26/2021 23:59:04 - INFO - __main__ -   Batch number = 39
12/26/2021 23:59:04 - INFO - __main__ -   Batch number = 40
12/26/2021 23:59:05 - INFO - __main__ -   Batch number = 41
12/26/2021 23:59:05 - INFO - __main__ -   Batch number = 42
12/26/2021 23:59:05 - INFO - __main__ -   Batch number = 43
12/26/2021 23:59:05 - INFO - __main__ -   Batch number = 44
12/26/2021 23:59:05 - INFO - __main__ -   Batch number = 45
12/26/2021 23:59:06 - INFO - __main__ -   Batch number = 46
12/26/2021 23:59:06 - INFO - __main__ -   Batch number = 47
12/26/2021 23:59:06 - INFO - __main__ -   Batch number = 48
12/26/2021 23:59:06 - INFO - __main__ -   Batch number = 49
12/26/2021 23:59:06 - INFO - __main__ -   Batch number = 50
12/26/2021 23:59:06 - INFO - __main__ -   Batch number = 51
12/26/2021 23:59:07 - INFO - __main__ -   Batch number = 52
12/26/2021 23:59:07 - INFO - __main__ -   Batch number = 53
12/26/2021 23:59:07 - INFO - __main__ -   Batch number = 54
12/26/2021 23:59:07 - INFO - __main__ -   Batch number = 55
12/26/2021 23:59:07 - INFO - __main__ -   Batch number = 56
12/26/2021 23:59:07 - INFO - __main__ -   Batch number = 57
12/26/2021 23:59:07 - INFO - __main__ -   Batch number = 58
12/26/2021 23:59:08 - INFO - __main__ -   Batch number = 59
12/26/2021 23:59:08 - INFO - __main__ -   Batch number = 60
12/26/2021 23:59:08 - INFO - __main__ -   Batch number = 61
12/26/2021 23:59:08 - INFO - __main__ -   Batch number = 62
12/26/2021 23:59:08 - INFO - __main__ -   Batch number = 63
12/26/2021 23:59:08 - INFO - __main__ -   Batch number = 64
12/26/2021 23:59:09 - INFO - __main__ -   Batch number = 65
12/26/2021 23:59:09 - INFO - __main__ -   Batch number = 66
12/26/2021 23:59:09 - INFO - __main__ -   Batch number = 67
12/26/2021 23:59:09 - INFO - __main__ -   Batch number = 68
12/26/2021 23:59:09 - INFO - __main__ -   Batch number = 69
12/26/2021 23:59:10 - INFO - __main__ -   Batch number = 70
12/26/2021 23:59:10 - INFO - __main__ -   Batch number = 71
12/26/2021 23:59:10 - INFO - __main__ -   Batch number = 72
12/26/2021 23:59:10 - INFO - __main__ -   Batch number = 73
12/26/2021 23:59:11 - INFO - __main__ -   Batch number = 74
12/26/2021 23:59:11 - INFO - __main__ -   Batch number = 75
12/26/2021 23:59:11 - INFO - __main__ -   Batch number = 76
12/26/2021 23:59:11 - INFO - __main__ -   Batch number = 77
12/26/2021 23:59:11 - INFO - __main__ -   Batch number = 78
12/26/2021 23:59:11 - INFO - __main__ -   Batch number = 79
12/26/2021 23:59:11 - INFO - __main__ -   Batch number = 80
12/26/2021 23:59:12 - INFO - __main__ -   Batch number = 81
12/26/2021 23:59:12 - INFO - __main__ -   Batch number = 82
12/26/2021 23:59:12 - INFO - __main__ -   Batch number = 83
12/26/2021 23:59:12 - INFO - __main__ -   Batch number = 84
12/26/2021 23:59:12 - INFO - __main__ -   Batch number = 85
12/26/2021 23:59:12 - INFO - __main__ -   Batch number = 86
12/26/2021 23:59:13 - INFO - __main__ -   Batch number = 87
12/26/2021 23:59:13 - INFO - __main__ -   Batch number = 88
12/26/2021 23:59:13 - INFO - __main__ -   Batch number = 89
12/26/2021 23:59:13 - INFO - __main__ -   Batch number = 90
12/26/2021 23:59:13 - INFO - __main__ -   Batch number = 91
12/26/2021 23:59:13 - INFO - __main__ -   Batch number = 92
12/26/2021 23:59:13 - INFO - __main__ -   Batch number = 93
12/26/2021 23:59:14 - INFO - __main__ -   Batch number = 94
12/26/2021 23:59:14 - INFO - __main__ -   Batch number = 95
12/26/2021 23:59:14 - INFO - __main__ -   Batch number = 96
12/26/2021 23:59:14 - INFO - __main__ -   Batch number = 97
12/26/2021 23:59:14 - INFO - __main__ -   Batch number = 98
12/26/2021 23:59:14 - INFO - __main__ -   Batch number = 99
12/26/2021 23:59:15 - INFO - __main__ -   Batch number = 100
12/26/2021 23:59:15 - INFO - __main__ -   Batch number = 101
12/26/2021 23:59:15 - INFO - __main__ -   Batch number = 102
12/26/2021 23:59:15 - INFO - __main__ -   Batch number = 103
12/26/2021 23:59:16 - INFO - __main__ -   Batch number = 104
12/26/2021 23:59:16 - INFO - __main__ -   Batch number = 105
12/26/2021 23:59:16 - INFO - __main__ -   Batch number = 106
12/26/2021 23:59:16 - INFO - __main__ -   Batch number = 107
12/26/2021 23:59:16 - INFO - __main__ -   Batch number = 108
12/26/2021 23:59:16 - INFO - __main__ -   Batch number = 109
12/26/2021 23:59:16 - INFO - __main__ -   Batch number = 110
12/26/2021 23:59:17 - INFO - __main__ -   Batch number = 111
12/26/2021 23:59:17 - INFO - __main__ -   Batch number = 112
12/26/2021 23:59:17 - INFO - __main__ -   Batch number = 113
12/26/2021 23:59:17 - INFO - __main__ -   Batch number = 114
12/26/2021 23:59:17 - INFO - __main__ -   Batch number = 115
12/26/2021 23:59:17 - INFO - __main__ -   Batch number = 116
12/26/2021 23:59:18 - INFO - __main__ -   Batch number = 117
12/26/2021 23:59:18 - INFO - __main__ -   Batch number = 118
12/26/2021 23:59:18 - INFO - __main__ -   Batch number = 119
12/26/2021 23:59:18 - INFO - __main__ -   Batch number = 120
12/26/2021 23:59:18 - INFO - __main__ -   Batch number = 121
12/26/2021 23:59:18 - INFO - __main__ -   Batch number = 122
12/26/2021 23:59:18 - INFO - __main__ -   Batch number = 123
12/26/2021 23:59:19 - INFO - __main__ -   Batch number = 124
12/26/2021 23:59:19 - INFO - __main__ -   Batch number = 125
12/26/2021 23:59:19 - INFO - __main__ -   Batch number = 126
12/26/2021 23:59:19 - INFO - __main__ -   Batch number = 127
12/26/2021 23:59:19 - INFO - __main__ -   Batch number = 128
12/26/2021 23:59:19 - INFO - __main__ -   Batch number = 129
12/26/2021 23:59:19 - INFO - __main__ -   Batch number = 130
12/26/2021 23:59:20 - INFO - __main__ -   Batch number = 131
12/26/2021 23:59:20 - INFO - __main__ -   Batch number = 132
12/26/2021 23:59:20 - INFO - __main__ -   Batch number = 133
12/26/2021 23:59:20 - INFO - __main__ -   Batch number = 134
12/26/2021 23:59:20 - INFO - __main__ -   Batch number = 135
12/26/2021 23:59:21 - INFO - __main__ -   Batch number = 136
12/26/2021 23:59:21 - INFO - __main__ -   Batch number = 137
12/26/2021 23:59:21 - INFO - __main__ -   Batch number = 138
12/26/2021 23:59:21 - INFO - __main__ -   Batch number = 139
12/26/2021 23:59:21 - INFO - __main__ -   Batch number = 140
12/26/2021 23:59:22 - INFO - __main__ -   Batch number = 141
12/26/2021 23:59:22 - INFO - __main__ -   Batch number = 142
12/26/2021 23:59:22 - INFO - __main__ -   Batch number = 143
12/26/2021 23:59:22 - INFO - __main__ -   Batch number = 144
12/26/2021 23:59:22 - INFO - __main__ -   Batch number = 145
12/26/2021 23:59:22 - INFO - __main__ -   Batch number = 146
12/26/2021 23:59:22 - INFO - __main__ -   Batch number = 147
12/26/2021 23:59:23 - INFO - __main__ -   Batch number = 148
12/26/2021 23:59:23 - INFO - __main__ -   Batch number = 149
12/26/2021 23:59:23 - INFO - __main__ -   Batch number = 150
12/26/2021 23:59:23 - INFO - __main__ -   Batch number = 151
12/26/2021 23:59:23 - INFO - __main__ -   Batch number = 152
12/26/2021 23:59:23 - INFO - __main__ -   Batch number = 153
12/26/2021 23:59:24 - INFO - __main__ -   Batch number = 154
12/26/2021 23:59:24 - INFO - __main__ -   Batch number = 155
12/26/2021 23:59:24 - INFO - __main__ -   Batch number = 156
12/26/2021 23:59:24 - INFO - __main__ -   Batch number = 157
12/26/2021 23:59:24 - INFO - __main__ -   Batch number = 158
12/26/2021 23:59:24 - INFO - __main__ -   Batch number = 159
12/26/2021 23:59:25 - INFO - __main__ -   Batch number = 160
12/26/2021 23:59:25 - INFO - __main__ -   Batch number = 161
12/26/2021 23:59:25 - INFO - __main__ -   Batch number = 162
12/26/2021 23:59:25 - INFO - __main__ -   Batch number = 163
12/26/2021 23:59:25 - INFO - __main__ -   Batch number = 164
12/26/2021 23:59:25 - INFO - __main__ -   Batch number = 165
12/26/2021 23:59:26 - INFO - __main__ -   Batch number = 166
12/26/2021 23:59:26 - INFO - __main__ -   Batch number = 167
12/26/2021 23:59:26 - INFO - __main__ -   Batch number = 168
12/26/2021 23:59:26 - INFO - __main__ -   Batch number = 169
12/26/2021 23:59:26 - INFO - __main__ -   Batch number = 170
12/26/2021 23:59:26 - INFO - __main__ -   Batch number = 171
12/26/2021 23:59:27 - INFO - __main__ -   Batch number = 172
12/26/2021 23:59:27 - INFO - __main__ -   Batch number = 173
12/26/2021 23:59:27 - INFO - __main__ -   Batch number = 174
12/26/2021 23:59:27 - INFO - __main__ -   Batch number = 175
12/26/2021 23:59:27 - INFO - __main__ -   Batch number = 176
12/26/2021 23:59:27 - INFO - __main__ -   Batch number = 177
12/26/2021 23:59:27 - INFO - __main__ -   Batch number = 178
12/26/2021 23:59:28 - INFO - __main__ -   Batch number = 179
12/26/2021 23:59:28 - INFO - __main__ -   Batch number = 180
12/26/2021 23:59:28 - INFO - __main__ -   Batch number = 181
12/26/2021 23:59:28 - INFO - __main__ -   Batch number = 182
12/26/2021 23:59:28 - INFO - __main__ -   Batch number = 183
12/26/2021 23:59:28 - INFO - __main__ -   Batch number = 184
12/26/2021 23:59:28 - INFO - __main__ -   Batch number = 185
12/26/2021 23:59:29 - INFO - __main__ -   Batch number = 186
12/26/2021 23:59:29 - INFO - __main__ -   Batch number = 187
12/26/2021 23:59:29 - INFO - __main__ -   Batch number = 188
12/26/2021 23:59:29 - INFO - __main__ -   Batch number = 189
12/26/2021 23:59:29 - INFO - __main__ -   Batch number = 190
12/26/2021 23:59:29 - INFO - __main__ -   Batch number = 191
12/26/2021 23:59:29 - INFO - __main__ -   Batch number = 192
12/26/2021 23:59:30 - INFO - __main__ -   Batch number = 193
12/26/2021 23:59:30 - INFO - __main__ -   Batch number = 194
12/26/2021 23:59:30 - INFO - __main__ -   Batch number = 195
12/26/2021 23:59:30 - INFO - __main__ -   Batch number = 196
12/26/2021 23:59:30 - INFO - __main__ -   Batch number = 197
12/26/2021 23:59:31 - INFO - __main__ -   Batch number = 198
12/26/2021 23:59:31 - INFO - __main__ -   Batch number = 199
12/26/2021 23:59:31 - INFO - __main__ -   Batch number = 200
12/26/2021 23:59:31 - INFO - __main__ -   Batch number = 201
12/26/2021 23:59:31 - INFO - __main__ -   Batch number = 202
12/26/2021 23:59:31 - INFO - __main__ -   Batch number = 203
12/26/2021 23:59:32 - INFO - __main__ -   Batch number = 204
12/26/2021 23:59:32 - INFO - __main__ -   Batch number = 205
12/26/2021 23:59:32 - INFO - __main__ -   Batch number = 206
12/26/2021 23:59:32 - INFO - __main__ -   Batch number = 207
12/26/2021 23:59:32 - INFO - __main__ -   Batch number = 208
12/26/2021 23:59:32 - INFO - __main__ -   Batch number = 209
12/26/2021 23:59:32 - INFO - __main__ -   Batch number = 210
12/26/2021 23:59:33 - INFO - __main__ -   Batch number = 211
12/26/2021 23:59:33 - INFO - __main__ -   Batch number = 212
12/26/2021 23:59:33 - INFO - __main__ -   Batch number = 213
12/26/2021 23:59:33 - INFO - __main__ -   Batch number = 214
12/26/2021 23:59:33 - INFO - __main__ -   Batch number = 215
12/26/2021 23:59:33 - INFO - __main__ -   Batch number = 216
12/26/2021 23:59:34 - INFO - __main__ -   Batch number = 217
12/26/2021 23:59:34 - INFO - __main__ -   Batch number = 218
12/26/2021 23:59:34 - INFO - __main__ -   Batch number = 219
12/26/2021 23:59:34 - INFO - __main__ -   Batch number = 220
12/26/2021 23:59:34 - INFO - __main__ -   Batch number = 221
12/26/2021 23:59:34 - INFO - __main__ -   Batch number = 222
12/26/2021 23:59:34 - INFO - __main__ -   Batch number = 223
12/26/2021 23:59:35 - INFO - __main__ -   Batch number = 224
12/26/2021 23:59:35 - INFO - __main__ -   Batch number = 225
12/26/2021 23:59:35 - INFO - __main__ -   Batch number = 226
12/26/2021 23:59:35 - INFO - __main__ -   Batch number = 227
12/26/2021 23:59:35 - INFO - __main__ -   Batch number = 228
12/26/2021 23:59:36 - INFO - __main__ -   Batch number = 229
12/26/2021 23:59:36 - INFO - __main__ -   Batch number = 230
12/26/2021 23:59:36 - INFO - __main__ -   Batch number = 231
12/26/2021 23:59:36 - INFO - __main__ -   Batch number = 232
12/26/2021 23:59:36 - INFO - __main__ -   Batch number = 233
12/26/2021 23:59:36 - INFO - __main__ -   Batch number = 234
12/26/2021 23:59:37 - INFO - __main__ -   Batch number = 235
12/26/2021 23:59:37 - INFO - __main__ -   Batch number = 236
12/26/2021 23:59:37 - INFO - __main__ -   Batch number = 237
12/26/2021 23:59:37 - INFO - __main__ -   Batch number = 238
12/26/2021 23:59:37 - INFO - __main__ -   Batch number = 239
12/26/2021 23:59:37 - INFO - __main__ -   Batch number = 240
12/26/2021 23:59:37 - INFO - __main__ -   Batch number = 241
12/26/2021 23:59:38 - INFO - __main__ -   Batch number = 242
12/26/2021 23:59:38 - INFO - __main__ -   Batch number = 243
12/26/2021 23:59:38 - INFO - __main__ -   Batch number = 244
12/26/2021 23:59:38 - INFO - __main__ -   Batch number = 245
12/26/2021 23:59:38 - INFO - __main__ -   Batch number = 246
12/26/2021 23:59:38 - INFO - __main__ -   Batch number = 247
12/26/2021 23:59:38 - INFO - __main__ -   Batch number = 248
12/26/2021 23:59:39 - INFO - __main__ -   Batch number = 249
12/26/2021 23:59:39 - INFO - __main__ -   Batch number = 250
12/26/2021 23:59:39 - INFO - __main__ -   Batch number = 251
12/26/2021 23:59:39 - INFO - __main__ -   Batch number = 252
12/26/2021 23:59:39 - INFO - __main__ -   Batch number = 253
12/26/2021 23:59:39 - INFO - __main__ -   Batch number = 254
12/26/2021 23:59:40 - INFO - __main__ -   Batch number = 255
12/26/2021 23:59:40 - INFO - __main__ -   Batch number = 256
12/26/2021 23:59:40 - INFO - __main__ -   Batch number = 257
12/26/2021 23:59:40 - INFO - __main__ -   Batch number = 258
12/26/2021 23:59:40 - INFO - __main__ -   Batch number = 259
12/26/2021 23:59:41 - INFO - __main__ -   Batch number = 260
12/26/2021 23:59:41 - INFO - __main__ -   Batch number = 261
12/26/2021 23:59:41 - INFO - __main__ -   Batch number = 262
12/26/2021 23:59:41 - INFO - __main__ -   Batch number = 263
12/26/2021 23:59:41 - INFO - __main__ -   Batch number = 264
12/26/2021 23:59:41 - INFO - __main__ -   Batch number = 265
12/26/2021 23:59:42 - INFO - __main__ -   Batch number = 266
12/26/2021 23:59:42 - INFO - __main__ -   Batch number = 267
12/26/2021 23:59:42 - INFO - __main__ -   Batch number = 268
12/26/2021 23:59:42 - INFO - __main__ -   Batch number = 269
12/26/2021 23:59:42 - INFO - __main__ -   Batch number = 270
12/26/2021 23:59:42 - INFO - __main__ -   Batch number = 271
12/26/2021 23:59:42 - INFO - __main__ -   Batch number = 272
12/26/2021 23:59:43 - INFO - __main__ -   Batch number = 273
12/26/2021 23:59:43 - INFO - __main__ -   Batch number = 274
12/26/2021 23:59:43 - INFO - __main__ -   Batch number = 275
12/26/2021 23:59:43 - INFO - __main__ -   Batch number = 276
12/26/2021 23:59:43 - INFO - __main__ -   Batch number = 277
12/26/2021 23:59:43 - INFO - __main__ -   Batch number = 278
12/26/2021 23:59:44 - INFO - __main__ -   Batch number = 279
12/26/2021 23:59:44 - INFO - __main__ -   Batch number = 280
12/26/2021 23:59:44 - INFO - __main__ -   Batch number = 281
12/26/2021 23:59:44 - INFO - __main__ -   Batch number = 282
12/26/2021 23:59:44 - INFO - __main__ -   Batch number = 283
12/26/2021 23:59:44 - INFO - __main__ -   Batch number = 284
12/26/2021 23:59:44 - INFO - __main__ -   Batch number = 285
12/26/2021 23:59:45 - INFO - __main__ -   Batch number = 286
12/26/2021 23:59:45 - INFO - __main__ -   Batch number = 287
12/26/2021 23:59:45 - INFO - __main__ -   Batch number = 288
12/26/2021 23:59:45 - INFO - __main__ -   Batch number = 289
12/26/2021 23:59:45 - INFO - __main__ -   Batch number = 290
12/26/2021 23:59:46 - INFO - __main__ -   Batch number = 291
12/26/2021 23:59:46 - INFO - __main__ -   Batch number = 292
12/26/2021 23:59:46 - INFO - __main__ -   Batch number = 293
12/26/2021 23:59:46 - INFO - __main__ -   Batch number = 294
12/26/2021 23:59:46 - INFO - __main__ -   Batch number = 295
12/26/2021 23:59:46 - INFO - __main__ -   Batch number = 296
12/26/2021 23:59:46 - INFO - __main__ -   Batch number = 297
12/26/2021 23:59:47 - INFO - __main__ -   Batch number = 298
12/26/2021 23:59:47 - INFO - __main__ -   Batch number = 299
12/26/2021 23:59:47 - INFO - __main__ -   Batch number = 300
12/26/2021 23:59:47 - INFO - __main__ -   Batch number = 301
12/26/2021 23:59:47 - INFO - __main__ -   Batch number = 302
12/26/2021 23:59:47 - INFO - __main__ -   Batch number = 303
12/26/2021 23:59:48 - INFO - __main__ -   Batch number = 304
12/26/2021 23:59:48 - INFO - __main__ -   Batch number = 305
12/26/2021 23:59:48 - INFO - __main__ -   Batch number = 306
12/26/2021 23:59:48 - INFO - __main__ -   Batch number = 307
12/26/2021 23:59:48 - INFO - __main__ -   Batch number = 308
12/26/2021 23:59:48 - INFO - __main__ -   Batch number = 309
12/26/2021 23:59:48 - INFO - __main__ -   Batch number = 310
12/26/2021 23:59:49 - INFO - __main__ -   Batch number = 311
12/26/2021 23:59:49 - INFO - __main__ -   Batch number = 312
12/26/2021 23:59:49 - INFO - __main__ -   Batch number = 313
12/26/2021 23:59:49 - INFO - __main__ -   Batch number = 314
12/26/2021 23:59:49 - INFO - __main__ -   Batch number = 315
12/26/2021 23:59:49 - INFO - __main__ -   Batch number = 316
12/26/2021 23:59:50 - INFO - __main__ -   Batch number = 317
12/26/2021 23:59:50 - INFO - __main__ -   Batch number = 318
12/26/2021 23:59:50 - INFO - __main__ -   Batch number = 319
12/26/2021 23:59:50 - INFO - __main__ -   Batch number = 320
12/26/2021 23:59:50 - INFO - __main__ -   Batch number = 321
12/26/2021 23:59:51 - INFO - __main__ -   Batch number = 322
12/26/2021 23:59:51 - INFO - __main__ -   Batch number = 323
12/26/2021 23:59:51 - INFO - __main__ -   Batch number = 324
12/26/2021 23:59:51 - INFO - __main__ -   Batch number = 325
12/26/2021 23:59:51 - INFO - __main__ -   Batch number = 326
12/26/2021 23:59:51 - INFO - __main__ -   Batch number = 327
12/26/2021 23:59:51 - INFO - __main__ -   Batch number = 328
12/26/2021 23:59:52 - INFO - __main__ -   Batch number = 329
12/26/2021 23:59:52 - INFO - __main__ -   Batch number = 330
12/26/2021 23:59:52 - INFO - __main__ -   Batch number = 331
12/26/2021 23:59:52 - INFO - __main__ -   Batch number = 332
12/26/2021 23:59:55 - INFO - __main__ -   ***** Evaluation result  in ja *****
12/26/2021 23:59:55 - INFO - __main__ -     f1 = 0.18709206458261765
12/26/2021 23:59:55 - INFO - __main__ -     loss = 4.664307902376335
12/26/2021 23:59:55 - INFO - __main__ -     precision = 0.13380216810490433
12/26/2021 23:59:55 - INFO - __main__ -     recall = 0.3109255691143938
12/26/2021 23:59:56 - INFO - __main__ -   Language adapter for zh not found, using pt instead
12/26/2021 23:59:56 - INFO - __main__ -   Set active language adapter to pt
12/26/2021 23:59:56 - INFO - __main__ -   Args Adapter Weight = None
12/26/2021 23:59:56 - INFO - __main__ -   Adapter Languages = ['pt']
12/26/2021 23:59:56 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_zh_bert-base-multilingual-cased_128
12/26/2021 23:59:57 - INFO - __main__ -   ***** Running evaluation  in zh *****
12/26/2021 23:59:57 - INFO - __main__ -     Num examples = 10257
12/26/2021 23:59:57 - INFO - __main__ -     Batch size = 32
12/26/2021 23:59:57 - INFO - __main__ -   Batch number = 1
12/26/2021 23:59:57 - INFO - __main__ -   Batch number = 2
12/26/2021 23:59:57 - INFO - __main__ -   Batch number = 3
12/26/2021 23:59:57 - INFO - __main__ -   Batch number = 4
12/26/2021 23:59:57 - INFO - __main__ -   Batch number = 5
12/26/2021 23:59:58 - INFO - __main__ -   Batch number = 6
12/26/2021 23:59:58 - INFO - __main__ -   Batch number = 7
12/26/2021 23:59:58 - INFO - __main__ -   Batch number = 8
12/26/2021 23:59:58 - INFO - __main__ -   Batch number = 9
12/26/2021 23:59:58 - INFO - __main__ -   Batch number = 10
12/26/2021 23:59:58 - INFO - __main__ -   Batch number = 11
12/26/2021 23:59:58 - INFO - __main__ -   Batch number = 12
12/26/2021 23:59:59 - INFO - __main__ -   Batch number = 13
12/26/2021 23:59:59 - INFO - __main__ -   Batch number = 14
12/26/2021 23:59:59 - INFO - __main__ -   Batch number = 15
12/26/2021 23:59:59 - INFO - __main__ -   Batch number = 16
12/26/2021 23:59:59 - INFO - __main__ -   Batch number = 17
12/26/2021 23:59:59 - INFO - __main__ -   Batch number = 18
12/26/2021 23:59:59 - INFO - __main__ -   Batch number = 19
12/27/2021 00:00:00 - INFO - __main__ -   Batch number = 20
12/27/2021 00:00:00 - INFO - __main__ -   Batch number = 21
12/27/2021 00:00:00 - INFO - __main__ -   Batch number = 22
12/27/2021 00:00:00 - INFO - __main__ -   Batch number = 23
12/27/2021 00:00:00 - INFO - __main__ -   Batch number = 24
12/27/2021 00:00:00 - INFO - __main__ -   Batch number = 25
12/27/2021 00:00:01 - INFO - __main__ -   Batch number = 26
12/27/2021 00:00:01 - INFO - __main__ -   Batch number = 27
12/27/2021 00:00:01 - INFO - __main__ -   Batch number = 28
12/27/2021 00:00:01 - INFO - __main__ -   Batch number = 29
12/27/2021 00:00:01 - INFO - __main__ -   Batch number = 30
12/27/2021 00:00:01 - INFO - __main__ -   Batch number = 31
12/27/2021 00:00:01 - INFO - __main__ -   Batch number = 32
12/27/2021 00:00:02 - INFO - __main__ -   Batch number = 33
12/27/2021 00:00:02 - INFO - __main__ -   Batch number = 34
12/27/2021 00:00:02 - INFO - __main__ -   Batch number = 35
12/27/2021 00:00:02 - INFO - __main__ -   Batch number = 36
12/27/2021 00:00:02 - INFO - __main__ -   Batch number = 37
12/27/2021 00:00:02 - INFO - __main__ -   Batch number = 38
12/27/2021 00:00:03 - INFO - __main__ -   Batch number = 39
12/27/2021 00:00:03 - INFO - __main__ -   Batch number = 40
12/27/2021 00:00:03 - INFO - __main__ -   Batch number = 41
12/27/2021 00:00:03 - INFO - __main__ -   Batch number = 42
12/27/2021 00:00:03 - INFO - __main__ -   Batch number = 43
12/27/2021 00:00:03 - INFO - __main__ -   Batch number = 44
12/27/2021 00:00:03 - INFO - __main__ -   Batch number = 45
12/27/2021 00:00:04 - INFO - __main__ -   Batch number = 46
12/27/2021 00:00:04 - INFO - __main__ -   Batch number = 47
12/27/2021 00:00:04 - INFO - __main__ -   Batch number = 48
12/27/2021 00:00:04 - INFO - __main__ -   Batch number = 49
12/27/2021 00:00:04 - INFO - __main__ -   Batch number = 50
12/27/2021 00:00:04 - INFO - __main__ -   Batch number = 51
12/27/2021 00:00:05 - INFO - __main__ -   Batch number = 52
12/27/2021 00:00:05 - INFO - __main__ -   Batch number = 53
12/27/2021 00:00:05 - INFO - __main__ -   Batch number = 54
12/27/2021 00:00:05 - INFO - __main__ -   Batch number = 55
12/27/2021 00:00:05 - INFO - __main__ -   Batch number = 56
12/27/2021 00:00:05 - INFO - __main__ -   Batch number = 57
12/27/2021 00:00:06 - INFO - __main__ -   Batch number = 58
12/27/2021 00:00:06 - INFO - __main__ -   Batch number = 59
12/27/2021 00:00:06 - INFO - __main__ -   Batch number = 60
12/27/2021 00:00:06 - INFO - __main__ -   Batch number = 61
12/27/2021 00:00:06 - INFO - __main__ -   Batch number = 62
12/27/2021 00:00:06 - INFO - __main__ -   Batch number = 63
12/27/2021 00:00:06 - INFO - __main__ -   Batch number = 64
12/27/2021 00:00:07 - INFO - __main__ -   Batch number = 65
12/27/2021 00:00:07 - INFO - __main__ -   Batch number = 66
12/27/2021 00:00:07 - INFO - __main__ -   Batch number = 67
12/27/2021 00:00:07 - INFO - __main__ -   Batch number = 68
12/27/2021 00:00:07 - INFO - __main__ -   Batch number = 69
12/27/2021 00:00:07 - INFO - __main__ -   Batch number = 70
12/27/2021 00:00:07 - INFO - __main__ -   Batch number = 71
12/27/2021 00:00:08 - INFO - __main__ -   Batch number = 72
12/27/2021 00:00:08 - INFO - __main__ -   Batch number = 73
12/27/2021 00:00:08 - INFO - __main__ -   Batch number = 74
12/27/2021 00:00:08 - INFO - __main__ -   Batch number = 75
12/27/2021 00:00:08 - INFO - __main__ -   Batch number = 76
12/27/2021 00:00:08 - INFO - __main__ -   Batch number = 77
12/27/2021 00:00:09 - INFO - __main__ -   Batch number = 78
12/27/2021 00:00:09 - INFO - __main__ -   Batch number = 79
12/27/2021 00:00:09 - INFO - __main__ -   Batch number = 80
12/27/2021 00:00:09 - INFO - __main__ -   Batch number = 81
12/27/2021 00:00:09 - INFO - __main__ -   Batch number = 82
12/27/2021 00:00:09 - INFO - __main__ -   Batch number = 83
12/27/2021 00:00:09 - INFO - __main__ -   Batch number = 84
12/27/2021 00:00:10 - INFO - __main__ -   Batch number = 85
12/27/2021 00:00:10 - INFO - __main__ -   Batch number = 86
12/27/2021 00:00:10 - INFO - __main__ -   Batch number = 87
12/27/2021 00:00:10 - INFO - __main__ -   Batch number = 88
12/27/2021 00:00:10 - INFO - __main__ -   Batch number = 89
12/27/2021 00:00:10 - INFO - __main__ -   Batch number = 90
12/27/2021 00:00:11 - INFO - __main__ -   Batch number = 91
12/27/2021 00:00:11 - INFO - __main__ -   Batch number = 92
12/27/2021 00:00:11 - INFO - __main__ -   Batch number = 93
12/27/2021 00:00:11 - INFO - __main__ -   Batch number = 94
12/27/2021 00:00:11 - INFO - __main__ -   Batch number = 95
12/27/2021 00:00:11 - INFO - __main__ -   Batch number = 96
12/27/2021 00:00:11 - INFO - __main__ -   Batch number = 97
12/27/2021 00:00:12 - INFO - __main__ -   Batch number = 98
12/27/2021 00:00:12 - INFO - __main__ -   Batch number = 99
12/27/2021 00:00:12 - INFO - __main__ -   Batch number = 100
12/27/2021 00:00:12 - INFO - __main__ -   Batch number = 101
12/27/2021 00:00:12 - INFO - __main__ -   Batch number = 102
12/27/2021 00:00:12 - INFO - __main__ -   Batch number = 103
12/27/2021 00:00:13 - INFO - __main__ -   Batch number = 104
12/27/2021 00:00:13 - INFO - __main__ -   Batch number = 105
12/27/2021 00:00:13 - INFO - __main__ -   Batch number = 106
12/27/2021 00:00:13 - INFO - __main__ -   Batch number = 107
12/27/2021 00:00:13 - INFO - __main__ -   Batch number = 108
12/27/2021 00:00:13 - INFO - __main__ -   Batch number = 109
12/27/2021 00:00:13 - INFO - __main__ -   Batch number = 110
12/27/2021 00:00:14 - INFO - __main__ -   Batch number = 111
12/27/2021 00:00:14 - INFO - __main__ -   Batch number = 112
12/27/2021 00:00:14 - INFO - __main__ -   Batch number = 113
12/27/2021 00:00:14 - INFO - __main__ -   Batch number = 114
12/27/2021 00:00:14 - INFO - __main__ -   Batch number = 115
12/27/2021 00:00:14 - INFO - __main__ -   Batch number = 116
12/27/2021 00:00:15 - INFO - __main__ -   Batch number = 117
12/27/2021 00:00:15 - INFO - __main__ -   Batch number = 118
12/27/2021 00:00:15 - INFO - __main__ -   Batch number = 119
12/27/2021 00:00:15 - INFO - __main__ -   Batch number = 120
12/27/2021 00:00:15 - INFO - __main__ -   Batch number = 121
12/27/2021 00:00:15 - INFO - __main__ -   Batch number = 122
12/27/2021 00:00:15 - INFO - __main__ -   Batch number = 123
12/27/2021 00:00:16 - INFO - __main__ -   Batch number = 124
12/27/2021 00:00:16 - INFO - __main__ -   Batch number = 125
12/27/2021 00:00:16 - INFO - __main__ -   Batch number = 126
12/27/2021 00:00:16 - INFO - __main__ -   Batch number = 127
12/27/2021 00:00:16 - INFO - __main__ -   Batch number = 128
12/27/2021 00:00:16 - INFO - __main__ -   Batch number = 129
12/27/2021 00:00:17 - INFO - __main__ -   Batch number = 130
12/27/2021 00:00:17 - INFO - __main__ -   Batch number = 131
12/27/2021 00:00:17 - INFO - __main__ -   Batch number = 132
12/27/2021 00:00:17 - INFO - __main__ -   Batch number = 133
12/27/2021 00:00:17 - INFO - __main__ -   Batch number = 134
12/27/2021 00:00:17 - INFO - __main__ -   Batch number = 135
12/27/2021 00:00:17 - INFO - __main__ -   Batch number = 136
12/27/2021 00:00:18 - INFO - __main__ -   Batch number = 137
12/27/2021 00:00:18 - INFO - __main__ -   Batch number = 138
12/27/2021 00:00:18 - INFO - __main__ -   Batch number = 139
12/27/2021 00:00:18 - INFO - __main__ -   Batch number = 140
12/27/2021 00:00:18 - INFO - __main__ -   Batch number = 141
12/27/2021 00:00:18 - INFO - __main__ -   Batch number = 142
12/27/2021 00:00:19 - INFO - __main__ -   Batch number = 143
12/27/2021 00:00:19 - INFO - __main__ -   Batch number = 144
12/27/2021 00:00:19 - INFO - __main__ -   Batch number = 145
12/27/2021 00:00:19 - INFO - __main__ -   Batch number = 146
12/27/2021 00:00:19 - INFO - __main__ -   Batch number = 147
12/27/2021 00:00:19 - INFO - __main__ -   Batch number = 148
12/27/2021 00:00:19 - INFO - __main__ -   Batch number = 149
12/27/2021 00:00:20 - INFO - __main__ -   Batch number = 150
12/27/2021 00:00:20 - INFO - __main__ -   Batch number = 151
12/27/2021 00:00:20 - INFO - __main__ -   Batch number = 152
12/27/2021 00:00:20 - INFO - __main__ -   Batch number = 153
12/27/2021 00:00:20 - INFO - __main__ -   Batch number = 154
12/27/2021 00:00:20 - INFO - __main__ -   Batch number = 155
12/27/2021 00:00:21 - INFO - __main__ -   Batch number = 156
12/27/2021 00:00:21 - INFO - __main__ -   Batch number = 157
12/27/2021 00:00:21 - INFO - __main__ -   Batch number = 158
12/27/2021 00:00:21 - INFO - __main__ -   Batch number = 159
12/27/2021 00:00:21 - INFO - __main__ -   Batch number = 160
12/27/2021 00:00:21 - INFO - __main__ -   Batch number = 161
12/27/2021 00:00:22 - INFO - __main__ -   Batch number = 162
12/27/2021 00:00:22 - INFO - __main__ -   Batch number = 163
12/27/2021 00:00:22 - INFO - __main__ -   Batch number = 164
12/27/2021 00:00:22 - INFO - __main__ -   Batch number = 165
12/27/2021 00:00:22 - INFO - __main__ -   Batch number = 166
12/27/2021 00:00:22 - INFO - __main__ -   Batch number = 167
12/27/2021 00:00:22 - INFO - __main__ -   Batch number = 168
12/27/2021 00:00:23 - INFO - __main__ -   Batch number = 169
12/27/2021 00:00:23 - INFO - __main__ -   Batch number = 170
12/27/2021 00:00:23 - INFO - __main__ -   Batch number = 171
12/27/2021 00:00:23 - INFO - __main__ -   Batch number = 172
12/27/2021 00:00:23 - INFO - __main__ -   Batch number = 173
12/27/2021 00:00:23 - INFO - __main__ -   Batch number = 174
12/27/2021 00:00:24 - INFO - __main__ -   Batch number = 175
12/27/2021 00:00:24 - INFO - __main__ -   Batch number = 176
12/27/2021 00:00:24 - INFO - __main__ -   Batch number = 177
12/27/2021 00:00:24 - INFO - __main__ -   Batch number = 178
12/27/2021 00:00:24 - INFO - __main__ -   Batch number = 179
12/27/2021 00:00:24 - INFO - __main__ -   Batch number = 180
12/27/2021 00:00:24 - INFO - __main__ -   Batch number = 181
12/27/2021 00:00:25 - INFO - __main__ -   Batch number = 182
12/27/2021 00:00:25 - INFO - __main__ -   Batch number = 183
12/27/2021 00:00:25 - INFO - __main__ -   Batch number = 184
12/27/2021 00:00:25 - INFO - __main__ -   Batch number = 185
12/27/2021 00:00:25 - INFO - __main__ -   Batch number = 186
12/27/2021 00:00:25 - INFO - __main__ -   Batch number = 187
12/27/2021 00:00:26 - INFO - __main__ -   Batch number = 188
12/27/2021 00:00:26 - INFO - __main__ -   Batch number = 189
12/27/2021 00:00:26 - INFO - __main__ -   Batch number = 190
12/27/2021 00:00:26 - INFO - __main__ -   Batch number = 191
12/27/2021 00:00:26 - INFO - __main__ -   Batch number = 192
12/27/2021 00:00:26 - INFO - __main__ -   Batch number = 193
12/27/2021 00:00:27 - INFO - __main__ -   Batch number = 194
12/27/2021 00:00:27 - INFO - __main__ -   Batch number = 195
12/27/2021 00:00:27 - INFO - __main__ -   Batch number = 196
12/27/2021 00:00:27 - INFO - __main__ -   Batch number = 197
12/27/2021 00:00:27 - INFO - __main__ -   Batch number = 198
12/27/2021 00:00:27 - INFO - __main__ -   Batch number = 199
12/27/2021 00:00:27 - INFO - __main__ -   Batch number = 200
12/27/2021 00:00:28 - INFO - __main__ -   Batch number = 201
12/27/2021 00:00:28 - INFO - __main__ -   Batch number = 202
12/27/2021 00:00:28 - INFO - __main__ -   Batch number = 203
12/27/2021 00:00:28 - INFO - __main__ -   Batch number = 204
12/27/2021 00:00:28 - INFO - __main__ -   Batch number = 205
12/27/2021 00:00:28 - INFO - __main__ -   Batch number = 206
12/27/2021 00:00:29 - INFO - __main__ -   Batch number = 207
12/27/2021 00:00:29 - INFO - __main__ -   Batch number = 208
12/27/2021 00:00:29 - INFO - __main__ -   Batch number = 209
12/27/2021 00:00:29 - INFO - __main__ -   Batch number = 210
12/27/2021 00:00:29 - INFO - __main__ -   Batch number = 211
12/27/2021 00:00:29 - INFO - __main__ -   Batch number = 212
12/27/2021 00:00:30 - INFO - __main__ -   Batch number = 213
12/27/2021 00:00:30 - INFO - __main__ -   Batch number = 214
12/27/2021 00:00:30 - INFO - __main__ -   Batch number = 215
12/27/2021 00:00:30 - INFO - __main__ -   Batch number = 216
12/27/2021 00:00:30 - INFO - __main__ -   Batch number = 217
12/27/2021 00:00:30 - INFO - __main__ -   Batch number = 218
12/27/2021 00:00:30 - INFO - __main__ -   Batch number = 219
12/27/2021 00:00:31 - INFO - __main__ -   Batch number = 220
12/27/2021 00:00:31 - INFO - __main__ -   Batch number = 221
12/27/2021 00:00:31 - INFO - __main__ -   Batch number = 222
12/27/2021 00:00:31 - INFO - __main__ -   Batch number = 223
12/27/2021 00:00:31 - INFO - __main__ -   Batch number = 224
12/27/2021 00:00:31 - INFO - __main__ -   Batch number = 225
12/27/2021 00:00:32 - INFO - __main__ -   Batch number = 226
12/27/2021 00:00:32 - INFO - __main__ -   Batch number = 227
12/27/2021 00:00:32 - INFO - __main__ -   Batch number = 228
12/27/2021 00:00:32 - INFO - __main__ -   Batch number = 229
12/27/2021 00:00:32 - INFO - __main__ -   Batch number = 230
12/27/2021 00:00:32 - INFO - __main__ -   Batch number = 231
12/27/2021 00:00:33 - INFO - __main__ -   Batch number = 232
12/27/2021 00:00:33 - INFO - __main__ -   Batch number = 233
12/27/2021 00:00:33 - INFO - __main__ -   Batch number = 234
12/27/2021 00:00:33 - INFO - __main__ -   Batch number = 235
12/27/2021 00:00:33 - INFO - __main__ -   Batch number = 236
12/27/2021 00:00:33 - INFO - __main__ -   Batch number = 237
12/27/2021 00:00:33 - INFO - __main__ -   Batch number = 238
12/27/2021 00:00:34 - INFO - __main__ -   Batch number = 239
12/27/2021 00:00:34 - INFO - __main__ -   Batch number = 240
12/27/2021 00:00:34 - INFO - __main__ -   Batch number = 241
12/27/2021 00:00:34 - INFO - __main__ -   Batch number = 242
12/27/2021 00:00:34 - INFO - __main__ -   Batch number = 243
12/27/2021 00:00:34 - INFO - __main__ -   Batch number = 244
12/27/2021 00:00:35 - INFO - __main__ -   Batch number = 245
12/27/2021 00:00:35 - INFO - __main__ -   Batch number = 246
12/27/2021 00:00:35 - INFO - __main__ -   Batch number = 247
12/27/2021 00:00:35 - INFO - __main__ -   Batch number = 248
12/27/2021 00:00:35 - INFO - __main__ -   Batch number = 249
12/27/2021 00:00:35 - INFO - __main__ -   Batch number = 250
12/27/2021 00:00:35 - INFO - __main__ -   Batch number = 251
12/27/2021 00:00:36 - INFO - __main__ -   Batch number = 252
12/27/2021 00:00:36 - INFO - __main__ -   Batch number = 253
12/27/2021 00:00:36 - INFO - __main__ -   Batch number = 254
12/27/2021 00:00:36 - INFO - __main__ -   Batch number = 255
12/27/2021 00:00:36 - INFO - __main__ -   Batch number = 256
12/27/2021 00:00:36 - INFO - __main__ -   Batch number = 257
12/27/2021 00:00:36 - INFO - __main__ -   Batch number = 258
12/27/2021 00:00:37 - INFO - __main__ -   Batch number = 259
12/27/2021 00:00:37 - INFO - __main__ -   Batch number = 260
12/27/2021 00:00:37 - INFO - __main__ -   Batch number = 261
12/27/2021 00:00:37 - INFO - __main__ -   Batch number = 262
12/27/2021 00:00:37 - INFO - __main__ -   Batch number = 263
12/27/2021 00:00:37 - INFO - __main__ -   Batch number = 264
12/27/2021 00:00:38 - INFO - __main__ -   Batch number = 265
12/27/2021 00:00:38 - INFO - __main__ -   Batch number = 266
12/27/2021 00:00:38 - INFO - __main__ -   Batch number = 267
12/27/2021 00:00:38 - INFO - __main__ -   Batch number = 268
12/27/2021 00:00:38 - INFO - __main__ -   Batch number = 269
12/27/2021 00:00:39 - INFO - __main__ -   Batch number = 270
12/27/2021 00:00:39 - INFO - __main__ -   Batch number = 271
12/27/2021 00:00:39 - INFO - __main__ -   Batch number = 272
12/27/2021 00:00:39 - INFO - __main__ -   Batch number = 273
12/27/2021 00:00:39 - INFO - __main__ -   Batch number = 274
12/27/2021 00:00:39 - INFO - __main__ -   Batch number = 275
12/27/2021 00:00:40 - INFO - __main__ -   Batch number = 276
12/27/2021 00:00:40 - INFO - __main__ -   Batch number = 277
12/27/2021 00:00:40 - INFO - __main__ -   Batch number = 278
12/27/2021 00:00:40 - INFO - __main__ -   Batch number = 279
12/27/2021 00:00:40 - INFO - __main__ -   Batch number = 280
12/27/2021 00:00:40 - INFO - __main__ -   Batch number = 281
12/27/2021 00:00:41 - INFO - __main__ -   Batch number = 282
12/27/2021 00:00:41 - INFO - __main__ -   Batch number = 283
12/27/2021 00:00:41 - INFO - __main__ -   Batch number = 284
12/27/2021 00:00:41 - INFO - __main__ -   Batch number = 285
12/27/2021 00:00:41 - INFO - __main__ -   Batch number = 286
12/27/2021 00:00:41 - INFO - __main__ -   Batch number = 287
12/27/2021 00:00:42 - INFO - __main__ -   Batch number = 288
12/27/2021 00:00:42 - INFO - __main__ -   Batch number = 289
12/27/2021 00:00:42 - INFO - __main__ -   Batch number = 290
12/27/2021 00:00:42 - INFO - __main__ -   Batch number = 291
12/27/2021 00:00:42 - INFO - __main__ -   Batch number = 292
12/27/2021 00:00:42 - INFO - __main__ -   Batch number = 293
12/27/2021 00:00:43 - INFO - __main__ -   Batch number = 294
12/27/2021 00:00:43 - INFO - __main__ -   Batch number = 295
12/27/2021 00:00:43 - INFO - __main__ -   Batch number = 296
12/27/2021 00:00:43 - INFO - __main__ -   Batch number = 297
12/27/2021 00:00:43 - INFO - __main__ -   Batch number = 298
12/27/2021 00:00:43 - INFO - __main__ -   Batch number = 299
12/27/2021 00:00:43 - INFO - __main__ -   Batch number = 300
12/27/2021 00:00:44 - INFO - __main__ -   Batch number = 301
12/27/2021 00:00:44 - INFO - __main__ -   Batch number = 302
12/27/2021 00:00:44 - INFO - __main__ -   Batch number = 303
12/27/2021 00:00:44 - INFO - __main__ -   Batch number = 304
12/27/2021 00:00:44 - INFO - __main__ -   Batch number = 305
12/27/2021 00:00:44 - INFO - __main__ -   Batch number = 306
12/27/2021 00:00:45 - INFO - __main__ -   Batch number = 307
12/27/2021 00:00:45 - INFO - __main__ -   Batch number = 308
12/27/2021 00:00:45 - INFO - __main__ -   Batch number = 309
12/27/2021 00:00:45 - INFO - __main__ -   Batch number = 310
12/27/2021 00:00:45 - INFO - __main__ -   Batch number = 311
12/27/2021 00:00:45 - INFO - __main__ -   Batch number = 312
12/27/2021 00:00:46 - INFO - __main__ -   Batch number = 313
12/27/2021 00:00:46 - INFO - __main__ -   Batch number = 314
12/27/2021 00:00:46 - INFO - __main__ -   Batch number = 315
12/27/2021 00:00:46 - INFO - __main__ -   Batch number = 316
12/27/2021 00:00:46 - INFO - __main__ -   Batch number = 317
12/27/2021 00:00:46 - INFO - __main__ -   Batch number = 318
12/27/2021 00:00:47 - INFO - __main__ -   Batch number = 319
12/27/2021 00:00:47 - INFO - __main__ -   Batch number = 320
12/27/2021 00:00:47 - INFO - __main__ -   Batch number = 321
12/27/2021 00:00:49 - INFO - __main__ -   ***** Evaluation result  in zh *****
12/27/2021 00:00:49 - INFO - __main__ -     f1 = 0.3102488792703663
12/27/2021 00:00:49 - INFO - __main__ -     loss = 3.4764267462436282
12/27/2021 00:00:49 - INFO - __main__ -     precision = 0.22913574608973628
12/27/2021 00:00:49 - INFO - __main__ -     recall = 0.48025843503230436
12/27/2021 00:00:49 - INFO - __main__ -   Language adapter for ar not found, using pt instead
12/27/2021 00:00:49 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:00:49 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:00:49 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:00:49 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
12/27/2021 00:00:51 - INFO - __main__ -   ***** Running evaluation  in ar *****
12/27/2021 00:00:51 - INFO - __main__ -     Num examples = 10000
12/27/2021 00:00:51 - INFO - __main__ -     Batch size = 32
12/27/2021 00:00:51 - INFO - __main__ -   Batch number = 1
12/27/2021 00:00:51 - INFO - __main__ -   Batch number = 2
12/27/2021 00:00:51 - INFO - __main__ -   Batch number = 3
12/27/2021 00:00:51 - INFO - __main__ -   Batch number = 4
12/27/2021 00:00:51 - INFO - __main__ -   Batch number = 5
12/27/2021 00:00:51 - INFO - __main__ -   Batch number = 6
12/27/2021 00:00:51 - INFO - __main__ -   Batch number = 7
12/27/2021 00:00:52 - INFO - __main__ -   Batch number = 8
12/27/2021 00:00:52 - INFO - __main__ -   Batch number = 9
12/27/2021 00:00:52 - INFO - __main__ -   Batch number = 10
12/27/2021 00:00:52 - INFO - __main__ -   Batch number = 11
12/27/2021 00:00:52 - INFO - __main__ -   Batch number = 12
12/27/2021 00:00:52 - INFO - __main__ -   Batch number = 13
12/27/2021 00:00:53 - INFO - __main__ -   Batch number = 14
12/27/2021 00:00:53 - INFO - __main__ -   Batch number = 15
12/27/2021 00:00:53 - INFO - __main__ -   Batch number = 16
12/27/2021 00:00:53 - INFO - __main__ -   Batch number = 17
12/27/2021 00:00:53 - INFO - __main__ -   Batch number = 18
12/27/2021 00:00:53 - INFO - __main__ -   Batch number = 19
12/27/2021 00:00:53 - INFO - __main__ -   Batch number = 20
12/27/2021 00:00:54 - INFO - __main__ -   Batch number = 21
12/27/2021 00:00:54 - INFO - __main__ -   Batch number = 22
12/27/2021 00:00:54 - INFO - __main__ -   Batch number = 23
12/27/2021 00:00:54 - INFO - __main__ -   Batch number = 24
12/27/2021 00:00:54 - INFO - __main__ -   Batch number = 25
12/27/2021 00:00:54 - INFO - __main__ -   Batch number = 26
12/27/2021 00:00:54 - INFO - __main__ -   Batch number = 27
12/27/2021 00:00:55 - INFO - __main__ -   Batch number = 28
12/27/2021 00:00:55 - INFO - __main__ -   Batch number = 29
12/27/2021 00:00:55 - INFO - __main__ -   Batch number = 30
12/27/2021 00:00:55 - INFO - __main__ -   Batch number = 31
12/27/2021 00:00:55 - INFO - __main__ -   Batch number = 32
12/27/2021 00:00:55 - INFO - __main__ -   Batch number = 33
12/27/2021 00:00:56 - INFO - __main__ -   Batch number = 34
12/27/2021 00:00:56 - INFO - __main__ -   Batch number = 35
12/27/2021 00:00:56 - INFO - __main__ -   Batch number = 36
12/27/2021 00:00:56 - INFO - __main__ -   Batch number = 37
12/27/2021 00:00:56 - INFO - __main__ -   Batch number = 38
12/27/2021 00:00:56 - INFO - __main__ -   Batch number = 39
12/27/2021 00:00:56 - INFO - __main__ -   Batch number = 40
12/27/2021 00:00:57 - INFO - __main__ -   Batch number = 41
12/27/2021 00:00:57 - INFO - __main__ -   Batch number = 42
12/27/2021 00:00:57 - INFO - __main__ -   Batch number = 43
12/27/2021 00:00:57 - INFO - __main__ -   Batch number = 44
12/27/2021 00:00:57 - INFO - __main__ -   Batch number = 45
12/27/2021 00:00:57 - INFO - __main__ -   Batch number = 46
12/27/2021 00:00:58 - INFO - __main__ -   Batch number = 47
12/27/2021 00:00:58 - INFO - __main__ -   Batch number = 48
12/27/2021 00:00:58 - INFO - __main__ -   Batch number = 49
12/27/2021 00:00:58 - INFO - __main__ -   Batch number = 50
12/27/2021 00:00:58 - INFO - __main__ -   Batch number = 51
12/27/2021 00:00:58 - INFO - __main__ -   Batch number = 52
12/27/2021 00:00:59 - INFO - __main__ -   Batch number = 53
12/27/2021 00:00:59 - INFO - __main__ -   Batch number = 54
12/27/2021 00:00:59 - INFO - __main__ -   Batch number = 55
12/27/2021 00:00:59 - INFO - __main__ -   Batch number = 56
12/27/2021 00:00:59 - INFO - __main__ -   Batch number = 57
12/27/2021 00:00:59 - INFO - __main__ -   Batch number = 58
12/27/2021 00:00:59 - INFO - __main__ -   Batch number = 59
12/27/2021 00:01:00 - INFO - __main__ -   Batch number = 60
12/27/2021 00:01:00 - INFO - __main__ -   Batch number = 61
12/27/2021 00:01:00 - INFO - __main__ -   Batch number = 62
12/27/2021 00:01:00 - INFO - __main__ -   Batch number = 63
12/27/2021 00:01:00 - INFO - __main__ -   Batch number = 64
12/27/2021 00:01:01 - INFO - __main__ -   Batch number = 65
12/27/2021 00:01:01 - INFO - __main__ -   Batch number = 66
12/27/2021 00:01:01 - INFO - __main__ -   Batch number = 67
12/27/2021 00:01:01 - INFO - __main__ -   Batch number = 68
12/27/2021 00:01:01 - INFO - __main__ -   Batch number = 69
12/27/2021 00:01:01 - INFO - __main__ -   Batch number = 70
12/27/2021 00:01:02 - INFO - __main__ -   Batch number = 71
12/27/2021 00:01:02 - INFO - __main__ -   Batch number = 72
12/27/2021 00:01:02 - INFO - __main__ -   Batch number = 73
12/27/2021 00:01:02 - INFO - __main__ -   Batch number = 74
12/27/2021 00:01:02 - INFO - __main__ -   Batch number = 75
12/27/2021 00:01:02 - INFO - __main__ -   Batch number = 76
12/27/2021 00:01:02 - INFO - __main__ -   Batch number = 77
12/27/2021 00:01:03 - INFO - __main__ -   Batch number = 78
12/27/2021 00:01:03 - INFO - __main__ -   Batch number = 79
12/27/2021 00:01:03 - INFO - __main__ -   Batch number = 80
12/27/2021 00:01:03 - INFO - __main__ -   Batch number = 81
12/27/2021 00:01:03 - INFO - __main__ -   Batch number = 82
12/27/2021 00:01:03 - INFO - __main__ -   Batch number = 83
12/27/2021 00:01:04 - INFO - __main__ -   Batch number = 84
12/27/2021 00:01:04 - INFO - __main__ -   Batch number = 85
12/27/2021 00:01:04 - INFO - __main__ -   Batch number = 86
12/27/2021 00:01:04 - INFO - __main__ -   Batch number = 87
12/27/2021 00:01:04 - INFO - __main__ -   Batch number = 88
12/27/2021 00:01:04 - INFO - __main__ -   Batch number = 89
12/27/2021 00:01:04 - INFO - __main__ -   Batch number = 90
12/27/2021 00:01:05 - INFO - __main__ -   Batch number = 91
12/27/2021 00:01:05 - INFO - __main__ -   Batch number = 92
12/27/2021 00:01:05 - INFO - __main__ -   Batch number = 93
12/27/2021 00:01:05 - INFO - __main__ -   Batch number = 94
12/27/2021 00:01:05 - INFO - __main__ -   Batch number = 95
12/27/2021 00:01:06 - INFO - __main__ -   Batch number = 96
12/27/2021 00:01:06 - INFO - __main__ -   Batch number = 97
12/27/2021 00:01:06 - INFO - __main__ -   Batch number = 98
12/27/2021 00:01:06 - INFO - __main__ -   Batch number = 99
12/27/2021 00:01:06 - INFO - __main__ -   Batch number = 100
12/27/2021 00:01:06 - INFO - __main__ -   Batch number = 101
12/27/2021 00:01:07 - INFO - __main__ -   Batch number = 102
12/27/2021 00:01:07 - INFO - __main__ -   Batch number = 103
12/27/2021 00:01:07 - INFO - __main__ -   Batch number = 104
12/27/2021 00:01:07 - INFO - __main__ -   Batch number = 105
12/27/2021 00:01:07 - INFO - __main__ -   Batch number = 106
12/27/2021 00:01:07 - INFO - __main__ -   Batch number = 107
12/27/2021 00:01:07 - INFO - __main__ -   Batch number = 108
12/27/2021 00:01:08 - INFO - __main__ -   Batch number = 109
12/27/2021 00:01:08 - INFO - __main__ -   Batch number = 110
12/27/2021 00:01:08 - INFO - __main__ -   Batch number = 111
12/27/2021 00:01:08 - INFO - __main__ -   Batch number = 112
12/27/2021 00:01:08 - INFO - __main__ -   Batch number = 113
12/27/2021 00:01:08 - INFO - __main__ -   Batch number = 114
12/27/2021 00:01:08 - INFO - __main__ -   Batch number = 115
12/27/2021 00:01:09 - INFO - __main__ -   Batch number = 116
12/27/2021 00:01:09 - INFO - __main__ -   Batch number = 117
12/27/2021 00:01:09 - INFO - __main__ -   Batch number = 118
12/27/2021 00:01:09 - INFO - __main__ -   Batch number = 119
12/27/2021 00:01:09 - INFO - __main__ -   Batch number = 120
12/27/2021 00:01:09 - INFO - __main__ -   Batch number = 121
12/27/2021 00:01:10 - INFO - __main__ -   Batch number = 122
12/27/2021 00:01:10 - INFO - __main__ -   Batch number = 123
12/27/2021 00:01:10 - INFO - __main__ -   Batch number = 124
12/27/2021 00:01:10 - INFO - __main__ -   Batch number = 125
12/27/2021 00:01:10 - INFO - __main__ -   Batch number = 126
12/27/2021 00:01:10 - INFO - __main__ -   Batch number = 127
12/27/2021 00:01:11 - INFO - __main__ -   Batch number = 128
12/27/2021 00:01:11 - INFO - __main__ -   Batch number = 129
12/27/2021 00:01:11 - INFO - __main__ -   Batch number = 130
12/27/2021 00:01:11 - INFO - __main__ -   Batch number = 131
12/27/2021 00:01:11 - INFO - __main__ -   Batch number = 132
12/27/2021 00:01:11 - INFO - __main__ -   Batch number = 133
12/27/2021 00:01:11 - INFO - __main__ -   Batch number = 134
12/27/2021 00:01:12 - INFO - __main__ -   Batch number = 135
12/27/2021 00:01:12 - INFO - __main__ -   Batch number = 136
12/27/2021 00:01:12 - INFO - __main__ -   Batch number = 137
12/27/2021 00:01:12 - INFO - __main__ -   Batch number = 138
12/27/2021 00:01:12 - INFO - __main__ -   Batch number = 139
12/27/2021 00:01:12 - INFO - __main__ -   Batch number = 140
12/27/2021 00:01:13 - INFO - __main__ -   Batch number = 141
12/27/2021 00:01:13 - INFO - __main__ -   Batch number = 142
12/27/2021 00:01:13 - INFO - __main__ -   Batch number = 143
12/27/2021 00:01:13 - INFO - __main__ -   Batch number = 144
12/27/2021 00:01:13 - INFO - __main__ -   Batch number = 145
12/27/2021 00:01:13 - INFO - __main__ -   Batch number = 146
12/27/2021 00:01:13 - INFO - __main__ -   Batch number = 147
12/27/2021 00:01:14 - INFO - __main__ -   Batch number = 148
12/27/2021 00:01:14 - INFO - __main__ -   Batch number = 149
12/27/2021 00:01:14 - INFO - __main__ -   Batch number = 150
12/27/2021 00:01:14 - INFO - __main__ -   Batch number = 151
12/27/2021 00:01:14 - INFO - __main__ -   Batch number = 152
12/27/2021 00:01:14 - INFO - __main__ -   Batch number = 153
12/27/2021 00:01:15 - INFO - __main__ -   Batch number = 154
12/27/2021 00:01:15 - INFO - __main__ -   Batch number = 155
12/27/2021 00:01:15 - INFO - __main__ -   Batch number = 156
12/27/2021 00:01:15 - INFO - __main__ -   Batch number = 157
12/27/2021 00:01:15 - INFO - __main__ -   Batch number = 158
12/27/2021 00:01:15 - INFO - __main__ -   Batch number = 159
12/27/2021 00:01:16 - INFO - __main__ -   Batch number = 160
12/27/2021 00:01:16 - INFO - __main__ -   Batch number = 161
12/27/2021 00:01:16 - INFO - __main__ -   Batch number = 162
12/27/2021 00:01:16 - INFO - __main__ -   Batch number = 163
12/27/2021 00:01:16 - INFO - __main__ -   Batch number = 164
12/27/2021 00:01:16 - INFO - __main__ -   Batch number = 165
12/27/2021 00:01:17 - INFO - __main__ -   Batch number = 166
12/27/2021 00:01:17 - INFO - __main__ -   Batch number = 167
12/27/2021 00:01:17 - INFO - __main__ -   Batch number = 168
12/27/2021 00:01:17 - INFO - __main__ -   Batch number = 169
12/27/2021 00:01:17 - INFO - __main__ -   Batch number = 170
12/27/2021 00:01:17 - INFO - __main__ -   Batch number = 171
12/27/2021 00:01:17 - INFO - __main__ -   Batch number = 172
12/27/2021 00:01:18 - INFO - __main__ -   Batch number = 173
12/27/2021 00:01:18 - INFO - __main__ -   Batch number = 174
12/27/2021 00:01:18 - INFO - __main__ -   Batch number = 175
12/27/2021 00:01:18 - INFO - __main__ -   Batch number = 176
12/27/2021 00:01:18 - INFO - __main__ -   Batch number = 177
12/27/2021 00:01:18 - INFO - __main__ -   Batch number = 178
12/27/2021 00:01:19 - INFO - __main__ -   Batch number = 179
12/27/2021 00:01:19 - INFO - __main__ -   Batch number = 180
12/27/2021 00:01:19 - INFO - __main__ -   Batch number = 181
12/27/2021 00:01:19 - INFO - __main__ -   Batch number = 182
12/27/2021 00:01:19 - INFO - __main__ -   Batch number = 183
12/27/2021 00:01:19 - INFO - __main__ -   Batch number = 184
12/27/2021 00:01:20 - INFO - __main__ -   Batch number = 185
12/27/2021 00:01:20 - INFO - __main__ -   Batch number = 186
12/27/2021 00:01:20 - INFO - __main__ -   Batch number = 187
12/27/2021 00:01:20 - INFO - __main__ -   Batch number = 188
12/27/2021 00:01:20 - INFO - __main__ -   Batch number = 189
12/27/2021 00:01:20 - INFO - __main__ -   Batch number = 190
12/27/2021 00:01:21 - INFO - __main__ -   Batch number = 191
12/27/2021 00:01:21 - INFO - __main__ -   Batch number = 192
12/27/2021 00:01:21 - INFO - __main__ -   Batch number = 193
12/27/2021 00:01:21 - INFO - __main__ -   Batch number = 194
12/27/2021 00:01:21 - INFO - __main__ -   Batch number = 195
12/27/2021 00:01:21 - INFO - __main__ -   Batch number = 196
12/27/2021 00:01:22 - INFO - __main__ -   Batch number = 197
12/27/2021 00:01:22 - INFO - __main__ -   Batch number = 198
12/27/2021 00:01:22 - INFO - __main__ -   Batch number = 199
12/27/2021 00:01:22 - INFO - __main__ -   Batch number = 200
12/27/2021 00:01:22 - INFO - __main__ -   Batch number = 201
12/27/2021 00:01:22 - INFO - __main__ -   Batch number = 202
12/27/2021 00:01:23 - INFO - __main__ -   Batch number = 203
12/27/2021 00:01:23 - INFO - __main__ -   Batch number = 204
12/27/2021 00:01:23 - INFO - __main__ -   Batch number = 205
12/27/2021 00:01:23 - INFO - __main__ -   Batch number = 206
12/27/2021 00:01:23 - INFO - __main__ -   Batch number = 207
12/27/2021 00:01:23 - INFO - __main__ -   Batch number = 208
12/27/2021 00:01:24 - INFO - __main__ -   Batch number = 209
12/27/2021 00:01:24 - INFO - __main__ -   Batch number = 210
12/27/2021 00:01:24 - INFO - __main__ -   Batch number = 211
12/27/2021 00:01:24 - INFO - __main__ -   Batch number = 212
12/27/2021 00:01:24 - INFO - __main__ -   Batch number = 213
12/27/2021 00:01:24 - INFO - __main__ -   Batch number = 214
12/27/2021 00:01:24 - INFO - __main__ -   Batch number = 215
12/27/2021 00:01:25 - INFO - __main__ -   Batch number = 216
12/27/2021 00:01:25 - INFO - __main__ -   Batch number = 217
12/27/2021 00:01:25 - INFO - __main__ -   Batch number = 218
12/27/2021 00:01:25 - INFO - __main__ -   Batch number = 219
12/27/2021 00:01:25 - INFO - __main__ -   Batch number = 220
12/27/2021 00:01:26 - INFO - __main__ -   Batch number = 221
12/27/2021 00:01:26 - INFO - __main__ -   Batch number = 222
12/27/2021 00:01:26 - INFO - __main__ -   Batch number = 223
12/27/2021 00:01:26 - INFO - __main__ -   Batch number = 224
12/27/2021 00:01:26 - INFO - __main__ -   Batch number = 225
12/27/2021 00:01:26 - INFO - __main__ -   Batch number = 226
12/27/2021 00:01:27 - INFO - __main__ -   Batch number = 227
12/27/2021 00:01:27 - INFO - __main__ -   Batch number = 228
12/27/2021 00:01:27 - INFO - __main__ -   Batch number = 229
12/27/2021 00:01:27 - INFO - __main__ -   Batch number = 230
12/27/2021 00:01:27 - INFO - __main__ -   Batch number = 231
12/27/2021 00:01:27 - INFO - __main__ -   Batch number = 232
12/27/2021 00:01:28 - INFO - __main__ -   Batch number = 233
12/27/2021 00:01:28 - INFO - __main__ -   Batch number = 234
12/27/2021 00:01:28 - INFO - __main__ -   Batch number = 235
12/27/2021 00:01:28 - INFO - __main__ -   Batch number = 236
12/27/2021 00:01:28 - INFO - __main__ -   Batch number = 237
12/27/2021 00:01:28 - INFO - __main__ -   Batch number = 238
12/27/2021 00:01:28 - INFO - __main__ -   Batch number = 239
12/27/2021 00:01:29 - INFO - __main__ -   Batch number = 240
12/27/2021 00:01:29 - INFO - __main__ -   Batch number = 241
12/27/2021 00:01:29 - INFO - __main__ -   Batch number = 242
12/27/2021 00:01:29 - INFO - __main__ -   Batch number = 243
12/27/2021 00:01:29 - INFO - __main__ -   Batch number = 244
12/27/2021 00:01:29 - INFO - __main__ -   Batch number = 245
12/27/2021 00:01:30 - INFO - __main__ -   Batch number = 246
12/27/2021 00:01:30 - INFO - __main__ -   Batch number = 247
12/27/2021 00:01:30 - INFO - __main__ -   Batch number = 248
12/27/2021 00:01:30 - INFO - __main__ -   Batch number = 249
12/27/2021 00:01:30 - INFO - __main__ -   Batch number = 250
12/27/2021 00:01:30 - INFO - __main__ -   Batch number = 251
12/27/2021 00:01:31 - INFO - __main__ -   Batch number = 252
12/27/2021 00:01:31 - INFO - __main__ -   Batch number = 253
12/27/2021 00:01:31 - INFO - __main__ -   Batch number = 254
12/27/2021 00:01:31 - INFO - __main__ -   Batch number = 255
12/27/2021 00:01:31 - INFO - __main__ -   Batch number = 256
12/27/2021 00:01:32 - INFO - __main__ -   Batch number = 257
12/27/2021 00:01:32 - INFO - __main__ -   Batch number = 258
12/27/2021 00:01:32 - INFO - __main__ -   Batch number = 259
12/27/2021 00:01:32 - INFO - __main__ -   Batch number = 260
12/27/2021 00:01:32 - INFO - __main__ -   Batch number = 261
12/27/2021 00:01:32 - INFO - __main__ -   Batch number = 262
12/27/2021 00:01:32 - INFO - __main__ -   Batch number = 263
12/27/2021 00:01:33 - INFO - __main__ -   Batch number = 264
12/27/2021 00:01:33 - INFO - __main__ -   Batch number = 265
12/27/2021 00:01:33 - INFO - __main__ -   Batch number = 266
12/27/2021 00:01:33 - INFO - __main__ -   Batch number = 267
12/27/2021 00:01:33 - INFO - __main__ -   Batch number = 268
12/27/2021 00:01:33 - INFO - __main__ -   Batch number = 269
12/27/2021 00:01:34 - INFO - __main__ -   Batch number = 270
12/27/2021 00:01:34 - INFO - __main__ -   Batch number = 271
12/27/2021 00:01:34 - INFO - __main__ -   Batch number = 272
12/27/2021 00:01:34 - INFO - __main__ -   Batch number = 273
12/27/2021 00:01:34 - INFO - __main__ -   Batch number = 274
12/27/2021 00:01:34 - INFO - __main__ -   Batch number = 275
12/27/2021 00:01:35 - INFO - __main__ -   Batch number = 276
12/27/2021 00:01:35 - INFO - __main__ -   Batch number = 277
12/27/2021 00:01:35 - INFO - __main__ -   Batch number = 278
12/27/2021 00:01:35 - INFO - __main__ -   Batch number = 279
12/27/2021 00:01:35 - INFO - __main__ -   Batch number = 280
12/27/2021 00:01:35 - INFO - __main__ -   Batch number = 281
12/27/2021 00:01:36 - INFO - __main__ -   Batch number = 282
12/27/2021 00:01:36 - INFO - __main__ -   Batch number = 283
12/27/2021 00:01:36 - INFO - __main__ -   Batch number = 284
12/27/2021 00:01:36 - INFO - __main__ -   Batch number = 285
12/27/2021 00:01:36 - INFO - __main__ -   Batch number = 286
12/27/2021 00:01:36 - INFO - __main__ -   Batch number = 287
12/27/2021 00:01:37 - INFO - __main__ -   Batch number = 288
12/27/2021 00:01:37 - INFO - __main__ -   Batch number = 289
12/27/2021 00:01:37 - INFO - __main__ -   Batch number = 290
12/27/2021 00:01:37 - INFO - __main__ -   Batch number = 291
12/27/2021 00:01:37 - INFO - __main__ -   Batch number = 292
12/27/2021 00:01:37 - INFO - __main__ -   Batch number = 293
12/27/2021 00:01:38 - INFO - __main__ -   Batch number = 294
12/27/2021 00:01:38 - INFO - __main__ -   Batch number = 295
12/27/2021 00:01:38 - INFO - __main__ -   Batch number = 296
12/27/2021 00:01:38 - INFO - __main__ -   Batch number = 297
12/27/2021 00:01:38 - INFO - __main__ -   Batch number = 298
12/27/2021 00:01:38 - INFO - __main__ -   Batch number = 299
12/27/2021 00:01:39 - INFO - __main__ -   Batch number = 300
12/27/2021 00:01:39 - INFO - __main__ -   Batch number = 301
12/27/2021 00:01:39 - INFO - __main__ -   Batch number = 302
12/27/2021 00:01:39 - INFO - __main__ -   Batch number = 303
12/27/2021 00:01:39 - INFO - __main__ -   Batch number = 304
12/27/2021 00:01:39 - INFO - __main__ -   Batch number = 305
12/27/2021 00:01:39 - INFO - __main__ -   Batch number = 306
12/27/2021 00:01:40 - INFO - __main__ -   Batch number = 307
12/27/2021 00:01:40 - INFO - __main__ -   Batch number = 308
12/27/2021 00:01:40 - INFO - __main__ -   Batch number = 309
12/27/2021 00:01:40 - INFO - __main__ -   Batch number = 310
12/27/2021 00:01:40 - INFO - __main__ -   Batch number = 311
12/27/2021 00:01:40 - INFO - __main__ -   Batch number = 312
12/27/2021 00:01:41 - INFO - __main__ -   Batch number = 313
12/27/2021 00:01:42 - INFO - __main__ -   ***** Evaluation result  in ar *****
12/27/2021 00:01:42 - INFO - __main__ -     f1 = 0.3182097123920959
12/27/2021 00:01:42 - INFO - __main__ -     loss = 5.038072746020918
12/27/2021 00:01:42 - INFO - __main__ -     precision = 0.29497876213592233
12/27/2021 00:01:42 - INFO - __main__ -     recall = 0.34541255884181543
12/27/2021 00:01:42 - INFO - __main__ -   Language adapter for jv not found, using pt instead
12/27/2021 00:01:42 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:01:42 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:01:42 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:01:42 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_jv_bert-base-multilingual-cased_128
12/27/2021 00:01:42 - INFO - __main__ -   ***** Running evaluation  in jv *****
12/27/2021 00:01:42 - INFO - __main__ -     Num examples = 100
12/27/2021 00:01:42 - INFO - __main__ -     Batch size = 32
12/27/2021 00:01:42 - INFO - __main__ -   Batch number = 1
12/27/2021 00:01:42 - INFO - __main__ -   Batch number = 2
12/27/2021 00:01:43 - INFO - __main__ -   Batch number = 3
12/27/2021 00:01:43 - INFO - __main__ -   Batch number = 4
12/27/2021 00:01:43 - INFO - __main__ -   ***** Evaluation result  in jv *****
12/27/2021 00:01:43 - INFO - __main__ -     f1 = 0.5968992248062015
12/27/2021 00:01:43 - INFO - __main__ -     loss = 2.718653380870819
12/27/2021 00:01:43 - INFO - __main__ -     precision = 0.5460992907801419
12/27/2021 00:01:43 - INFO - __main__ -     recall = 0.6581196581196581
12/27/2021 00:01:43 - INFO - __main__ -   Language adapter for sw not found, using pt instead
12/27/2021 00:01:43 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:01:43 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:01:43 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:01:43 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_sw_bert-base-multilingual-cased_128
12/27/2021 00:01:43 - INFO - __main__ -   ***** Running evaluation  in sw *****
12/27/2021 00:01:43 - INFO - __main__ -     Num examples = 1000
12/27/2021 00:01:43 - INFO - __main__ -     Batch size = 32
12/27/2021 00:01:43 - INFO - __main__ -   Batch number = 1
12/27/2021 00:01:43 - INFO - __main__ -   Batch number = 2
12/27/2021 00:01:43 - INFO - __main__ -   Batch number = 3
12/27/2021 00:01:43 - INFO - __main__ -   Batch number = 4
12/27/2021 00:01:43 - INFO - __main__ -   Batch number = 5
12/27/2021 00:01:44 - INFO - __main__ -   Batch number = 6
12/27/2021 00:01:44 - INFO - __main__ -   Batch number = 7
12/27/2021 00:01:44 - INFO - __main__ -   Batch number = 8
12/27/2021 00:01:44 - INFO - __main__ -   Batch number = 9
12/27/2021 00:01:44 - INFO - __main__ -   Batch number = 10
12/27/2021 00:01:44 - INFO - __main__ -   Batch number = 11
12/27/2021 00:01:45 - INFO - __main__ -   Batch number = 12
12/27/2021 00:01:45 - INFO - __main__ -   Batch number = 13
12/27/2021 00:01:45 - INFO - __main__ -   Batch number = 14
12/27/2021 00:01:45 - INFO - __main__ -   Batch number = 15
12/27/2021 00:01:45 - INFO - __main__ -   Batch number = 16
12/27/2021 00:01:45 - INFO - __main__ -   Batch number = 17
12/27/2021 00:01:45 - INFO - __main__ -   Batch number = 18
12/27/2021 00:01:46 - INFO - __main__ -   Batch number = 19
12/27/2021 00:01:46 - INFO - __main__ -   Batch number = 20
12/27/2021 00:01:46 - INFO - __main__ -   Batch number = 21
12/27/2021 00:01:46 - INFO - __main__ -   Batch number = 22
12/27/2021 00:01:46 - INFO - __main__ -   Batch number = 23
12/27/2021 00:01:46 - INFO - __main__ -   Batch number = 24
12/27/2021 00:01:47 - INFO - __main__ -   Batch number = 25
12/27/2021 00:01:47 - INFO - __main__ -   Batch number = 26
12/27/2021 00:01:47 - INFO - __main__ -   Batch number = 27
12/27/2021 00:01:47 - INFO - __main__ -   Batch number = 28
12/27/2021 00:01:47 - INFO - __main__ -   Batch number = 29
12/27/2021 00:01:47 - INFO - __main__ -   Batch number = 30
12/27/2021 00:01:47 - INFO - __main__ -   Batch number = 31
12/27/2021 00:01:48 - INFO - __main__ -   Batch number = 32
12/27/2021 00:01:48 - INFO - __main__ -   ***** Evaluation result  in sw *****
12/27/2021 00:01:48 - INFO - __main__ -     f1 = 0.6053459119496856
12/27/2021 00:01:48 - INFO - __main__ -     loss = 2.375826144590974
12/27/2021 00:01:48 - INFO - __main__ -     precision = 0.5703703703703704
12/27/2021 00:01:48 - INFO - __main__ -     recall = 0.644891122278057
12/27/2021 00:01:48 - INFO - __main__ -   Language adapter for is not found, using pt instead
12/27/2021 00:01:48 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:01:48 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:01:48 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:01:48 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_is_bert-base-multilingual-cased_128
12/27/2021 00:01:48 - INFO - __main__ -   ***** Running evaluation  in is *****
12/27/2021 00:01:48 - INFO - __main__ -     Num examples = 1000
12/27/2021 00:01:48 - INFO - __main__ -     Batch size = 32
12/27/2021 00:01:48 - INFO - __main__ -   Batch number = 1
12/27/2021 00:01:48 - INFO - __main__ -   Batch number = 2
12/27/2021 00:01:48 - INFO - __main__ -   Batch number = 3
12/27/2021 00:01:48 - INFO - __main__ -   Batch number = 4
12/27/2021 00:01:48 - INFO - __main__ -   Batch number = 5
12/27/2021 00:01:49 - INFO - __main__ -   Batch number = 6
12/27/2021 00:01:49 - INFO - __main__ -   Batch number = 7
12/27/2021 00:01:49 - INFO - __main__ -   Batch number = 8
12/27/2021 00:01:49 - INFO - __main__ -   Batch number = 9
12/27/2021 00:01:49 - INFO - __main__ -   Batch number = 10
12/27/2021 00:01:49 - INFO - __main__ -   Batch number = 11
12/27/2021 00:01:50 - INFO - __main__ -   Batch number = 12
12/27/2021 00:01:50 - INFO - __main__ -   Batch number = 13
12/27/2021 00:01:50 - INFO - __main__ -   Batch number = 14
12/27/2021 00:01:50 - INFO - __main__ -   Batch number = 15
12/27/2021 00:01:50 - INFO - __main__ -   Batch number = 16
12/27/2021 00:01:50 - INFO - __main__ -   Batch number = 17
12/27/2021 00:01:50 - INFO - __main__ -   Batch number = 18
12/27/2021 00:01:51 - INFO - __main__ -   Batch number = 19
12/27/2021 00:01:51 - INFO - __main__ -   Batch number = 20
12/27/2021 00:01:51 - INFO - __main__ -   Batch number = 21
12/27/2021 00:01:51 - INFO - __main__ -   Batch number = 22
12/27/2021 00:01:51 - INFO - __main__ -   Batch number = 23
12/27/2021 00:01:51 - INFO - __main__ -   Batch number = 24
12/27/2021 00:01:52 - INFO - __main__ -   Batch number = 25
12/27/2021 00:01:52 - INFO - __main__ -   Batch number = 26
12/27/2021 00:01:52 - INFO - __main__ -   Batch number = 27
12/27/2021 00:01:52 - INFO - __main__ -   Batch number = 28
12/27/2021 00:01:52 - INFO - __main__ -   Batch number = 29
12/27/2021 00:01:52 - INFO - __main__ -   Batch number = 30
12/27/2021 00:01:52 - INFO - __main__ -   Batch number = 31
12/27/2021 00:01:53 - INFO - __main__ -   Batch number = 32
12/27/2021 00:01:53 - INFO - __main__ -   ***** Evaluation result  in is *****
12/27/2021 00:01:53 - INFO - __main__ -     f1 = 0.6592307692307692
12/27/2021 00:01:53 - INFO - __main__ -     loss = 1.2434670738875866
12/27/2021 00:01:53 - INFO - __main__ -     precision = 0.6232727272727273
12/27/2021 00:01:53 - INFO - __main__ -     recall = 0.6995918367346938
12/27/2021 00:01:53 - INFO - __main__ -   Language adapter for my not found, using pt instead
12/27/2021 00:01:53 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:01:53 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:01:53 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:01:53 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_my_bert-base-multilingual-cased_128
12/27/2021 00:01:53 - INFO - __main__ -   ***** Running evaluation  in my *****
12/27/2021 00:01:53 - INFO - __main__ -     Num examples = 110
12/27/2021 00:01:53 - INFO - __main__ -     Batch size = 32
12/27/2021 00:01:53 - INFO - __main__ -   Batch number = 1
12/27/2021 00:01:53 - INFO - __main__ -   Batch number = 2
12/27/2021 00:01:53 - INFO - __main__ -   Batch number = 3
12/27/2021 00:01:53 - INFO - __main__ -   Batch number = 4
12/27/2021 00:01:53 - INFO - __main__ -   ***** Evaluation result  in my *****
12/27/2021 00:01:53 - INFO - __main__ -     f1 = 0.4232081911262799
12/27/2021 00:01:53 - INFO - __main__ -     loss = 3.2835822105407715
12/27/2021 00:01:53 - INFO - __main__ -     precision = 0.3563218390804598
12/27/2021 00:01:53 - INFO - __main__ -     recall = 0.5210084033613446
12/27/2021 00:01:56 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en,ja,zh,ar,jv,sw,is,my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/27/2021 00:01:56 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/27/2021 00:01:56 - INFO - __main__ -   Seed = 3
12/27/2021 00:01:56 - INFO - root -   save model
12/27/2021 00:01:56 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en,ja,zh,ar,jv,sw,is,my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/27/2021 00:01:56 - INFO - __main__ -   Loading pretrained model and tokenizer
12/27/2021 00:02:00 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/27/2021 00:02:06 - INFO - __main__ -   Using lang2id = None
12/27/2021 00:02:06 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/27/2021 00:02:06 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s3/checkpoint-best/ner/
12/27/2021 00:02:06 - INFO - root -   Trying to decide if add adapter
12/27/2021 00:02:06 - INFO - root -   loading task adapter
12/27/2021 00:02:06 - INFO - root -   loading lang adpater pt/wiki@ukp
12/27/2021 00:02:06 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/27/2021 00:02:06 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/27/2021 00:02:06 - INFO - __main__ -   Language = pt
12/27/2021 00:02:06 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/27/2021 00:02:12 - INFO - __main__ -   Language adapter for en not found, using pt instead
12/27/2021 00:02:12 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:02:12 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:02:12 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:02:12 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
12/27/2021 00:02:14 - INFO - __main__ -   ***** Running evaluation  in en *****
12/27/2021 00:02:14 - INFO - __main__ -     Num examples = 10004
12/27/2021 00:02:14 - INFO - __main__ -     Batch size = 32
12/27/2021 00:02:14 - INFO - __main__ -   Batch number = 1
12/27/2021 00:02:14 - INFO - __main__ -   Batch number = 2
12/27/2021 00:02:14 - INFO - __main__ -   Batch number = 3
12/27/2021 00:02:14 - INFO - __main__ -   Batch number = 4
12/27/2021 00:02:14 - INFO - __main__ -   Batch number = 5
12/27/2021 00:02:14 - INFO - __main__ -   Batch number = 6
12/27/2021 00:02:15 - INFO - __main__ -   Batch number = 7
12/27/2021 00:02:15 - INFO - __main__ -   Batch number = 8
12/27/2021 00:02:15 - INFO - __main__ -   Batch number = 9
12/27/2021 00:02:15 - INFO - __main__ -   Batch number = 10
12/27/2021 00:02:15 - INFO - __main__ -   Batch number = 11
12/27/2021 00:02:15 - INFO - __main__ -   Batch number = 12
12/27/2021 00:02:15 - INFO - __main__ -   Batch number = 13
12/27/2021 00:02:16 - INFO - __main__ -   Batch number = 14
12/27/2021 00:02:16 - INFO - __main__ -   Batch number = 15
12/27/2021 00:02:16 - INFO - __main__ -   Batch number = 16
12/27/2021 00:02:16 - INFO - __main__ -   Batch number = 17
12/27/2021 00:02:16 - INFO - __main__ -   Batch number = 18
12/27/2021 00:02:16 - INFO - __main__ -   Batch number = 19
12/27/2021 00:02:17 - INFO - __main__ -   Batch number = 20
12/27/2021 00:02:17 - INFO - __main__ -   Batch number = 21
12/27/2021 00:02:17 - INFO - __main__ -   Batch number = 22
12/27/2021 00:02:17 - INFO - __main__ -   Batch number = 23
12/27/2021 00:02:17 - INFO - __main__ -   Batch number = 24
12/27/2021 00:02:17 - INFO - __main__ -   Batch number = 25
12/27/2021 00:02:17 - INFO - __main__ -   Batch number = 26
12/27/2021 00:02:17 - INFO - __main__ -   Batch number = 27
12/27/2021 00:02:18 - INFO - __main__ -   Batch number = 28
12/27/2021 00:02:18 - INFO - __main__ -   Batch number = 29
12/27/2021 00:02:18 - INFO - __main__ -   Batch number = 30
12/27/2021 00:02:18 - INFO - __main__ -   Batch number = 31
12/27/2021 00:02:18 - INFO - __main__ -   Batch number = 32
12/27/2021 00:02:18 - INFO - __main__ -   Batch number = 33
12/27/2021 00:02:18 - INFO - __main__ -   Batch number = 34
12/27/2021 00:02:19 - INFO - __main__ -   Batch number = 35
12/27/2021 00:02:19 - INFO - __main__ -   Batch number = 36
12/27/2021 00:02:19 - INFO - __main__ -   Batch number = 37
12/27/2021 00:02:19 - INFO - __main__ -   Batch number = 38
12/27/2021 00:02:19 - INFO - __main__ -   Batch number = 39
12/27/2021 00:02:19 - INFO - __main__ -   Batch number = 40
12/27/2021 00:02:19 - INFO - __main__ -   Batch number = 41
12/27/2021 00:02:20 - INFO - __main__ -   Batch number = 42
12/27/2021 00:02:20 - INFO - __main__ -   Batch number = 43
12/27/2021 00:02:20 - INFO - __main__ -   Batch number = 44
12/27/2021 00:02:20 - INFO - __main__ -   Batch number = 45
12/27/2021 00:02:20 - INFO - __main__ -   Batch number = 46
12/27/2021 00:02:20 - INFO - __main__ -   Batch number = 47
12/27/2021 00:02:21 - INFO - __main__ -   Batch number = 48
12/27/2021 00:02:21 - INFO - __main__ -   Batch number = 49
12/27/2021 00:02:21 - INFO - __main__ -   Batch number = 50
12/27/2021 00:02:21 - INFO - __main__ -   Batch number = 51
12/27/2021 00:02:21 - INFO - __main__ -   Batch number = 52
12/27/2021 00:02:21 - INFO - __main__ -   Batch number = 53
12/27/2021 00:02:21 - INFO - __main__ -   Batch number = 54
12/27/2021 00:02:22 - INFO - __main__ -   Batch number = 55
12/27/2021 00:02:22 - INFO - __main__ -   Batch number = 56
12/27/2021 00:02:22 - INFO - __main__ -   Batch number = 57
12/27/2021 00:02:22 - INFO - __main__ -   Batch number = 58
12/27/2021 00:02:22 - INFO - __main__ -   Batch number = 59
12/27/2021 00:02:22 - INFO - __main__ -   Batch number = 60
12/27/2021 00:02:22 - INFO - __main__ -   Batch number = 61
12/27/2021 00:02:23 - INFO - __main__ -   Batch number = 62
12/27/2021 00:02:23 - INFO - __main__ -   Batch number = 63
12/27/2021 00:02:23 - INFO - __main__ -   Batch number = 64
12/27/2021 00:02:23 - INFO - __main__ -   Batch number = 65
12/27/2021 00:02:23 - INFO - __main__ -   Batch number = 66
12/27/2021 00:02:23 - INFO - __main__ -   Batch number = 67
12/27/2021 00:02:23 - INFO - __main__ -   Batch number = 68
12/27/2021 00:02:24 - INFO - __main__ -   Batch number = 69
12/27/2021 00:02:24 - INFO - __main__ -   Batch number = 70
12/27/2021 00:02:24 - INFO - __main__ -   Batch number = 71
12/27/2021 00:02:24 - INFO - __main__ -   Batch number = 72
12/27/2021 00:02:24 - INFO - __main__ -   Batch number = 73
12/27/2021 00:02:24 - INFO - __main__ -   Batch number = 74
12/27/2021 00:02:24 - INFO - __main__ -   Batch number = 75
12/27/2021 00:02:25 - INFO - __main__ -   Batch number = 76
12/27/2021 00:02:25 - INFO - __main__ -   Batch number = 77
12/27/2021 00:02:25 - INFO - __main__ -   Batch number = 78
12/27/2021 00:02:25 - INFO - __main__ -   Batch number = 79
12/27/2021 00:02:25 - INFO - __main__ -   Batch number = 80
12/27/2021 00:02:25 - INFO - __main__ -   Batch number = 81
12/27/2021 00:02:26 - INFO - __main__ -   Batch number = 82
12/27/2021 00:02:26 - INFO - __main__ -   Batch number = 83
12/27/2021 00:02:26 - INFO - __main__ -   Batch number = 84
12/27/2021 00:02:26 - INFO - __main__ -   Batch number = 85
12/27/2021 00:02:26 - INFO - __main__ -   Batch number = 86
12/27/2021 00:02:26 - INFO - __main__ -   Batch number = 87
12/27/2021 00:02:27 - INFO - __main__ -   Batch number = 88
12/27/2021 00:02:27 - INFO - __main__ -   Batch number = 89
12/27/2021 00:02:27 - INFO - __main__ -   Batch number = 90
12/27/2021 00:02:27 - INFO - __main__ -   Batch number = 91
12/27/2021 00:02:27 - INFO - __main__ -   Batch number = 92
12/27/2021 00:02:27 - INFO - __main__ -   Batch number = 93
12/27/2021 00:02:27 - INFO - __main__ -   Batch number = 94
12/27/2021 00:02:28 - INFO - __main__ -   Batch number = 95
12/27/2021 00:02:28 - INFO - __main__ -   Batch number = 96
12/27/2021 00:02:28 - INFO - __main__ -   Batch number = 97
12/27/2021 00:02:28 - INFO - __main__ -   Batch number = 98
12/27/2021 00:02:28 - INFO - __main__ -   Batch number = 99
12/27/2021 00:02:28 - INFO - __main__ -   Batch number = 100
12/27/2021 00:02:28 - INFO - __main__ -   Batch number = 101
12/27/2021 00:02:29 - INFO - __main__ -   Batch number = 102
12/27/2021 00:02:29 - INFO - __main__ -   Batch number = 103
12/27/2021 00:02:29 - INFO - __main__ -   Batch number = 104
12/27/2021 00:02:29 - INFO - __main__ -   Batch number = 105
12/27/2021 00:02:29 - INFO - __main__ -   Batch number = 106
12/27/2021 00:02:29 - INFO - __main__ -   Batch number = 107
12/27/2021 00:02:29 - INFO - __main__ -   Batch number = 108
12/27/2021 00:02:30 - INFO - __main__ -   Batch number = 109
12/27/2021 00:02:30 - INFO - __main__ -   Batch number = 110
12/27/2021 00:02:30 - INFO - __main__ -   Batch number = 111
12/27/2021 00:02:30 - INFO - __main__ -   Batch number = 112
12/27/2021 00:02:30 - INFO - __main__ -   Batch number = 113
12/27/2021 00:02:30 - INFO - __main__ -   Batch number = 114
12/27/2021 00:02:30 - INFO - __main__ -   Batch number = 115
12/27/2021 00:02:31 - INFO - __main__ -   Batch number = 116
12/27/2021 00:02:31 - INFO - __main__ -   Batch number = 117
12/27/2021 00:02:31 - INFO - __main__ -   Batch number = 118
12/27/2021 00:02:31 - INFO - __main__ -   Batch number = 119
12/27/2021 00:02:31 - INFO - __main__ -   Batch number = 120
12/27/2021 00:02:31 - INFO - __main__ -   Batch number = 121
12/27/2021 00:02:32 - INFO - __main__ -   Batch number = 122
12/27/2021 00:02:32 - INFO - __main__ -   Batch number = 123
12/27/2021 00:02:32 - INFO - __main__ -   Batch number = 124
12/27/2021 00:02:32 - INFO - __main__ -   Batch number = 125
12/27/2021 00:02:32 - INFO - __main__ -   Batch number = 126
12/27/2021 00:02:32 - INFO - __main__ -   Batch number = 127
12/27/2021 00:02:33 - INFO - __main__ -   Batch number = 128
12/27/2021 00:02:33 - INFO - __main__ -   Batch number = 129
12/27/2021 00:02:33 - INFO - __main__ -   Batch number = 130
12/27/2021 00:02:33 - INFO - __main__ -   Batch number = 131
12/27/2021 00:02:33 - INFO - __main__ -   Batch number = 132
12/27/2021 00:02:33 - INFO - __main__ -   Batch number = 133
12/27/2021 00:02:33 - INFO - __main__ -   Batch number = 134
12/27/2021 00:02:34 - INFO - __main__ -   Batch number = 135
12/27/2021 00:02:34 - INFO - __main__ -   Batch number = 136
12/27/2021 00:02:34 - INFO - __main__ -   Batch number = 137
12/27/2021 00:02:34 - INFO - __main__ -   Batch number = 138
12/27/2021 00:02:34 - INFO - __main__ -   Batch number = 139
12/27/2021 00:02:34 - INFO - __main__ -   Batch number = 140
12/27/2021 00:02:35 - INFO - __main__ -   Batch number = 141
12/27/2021 00:02:35 - INFO - __main__ -   Batch number = 142
12/27/2021 00:02:35 - INFO - __main__ -   Batch number = 143
12/27/2021 00:02:35 - INFO - __main__ -   Batch number = 144
12/27/2021 00:02:35 - INFO - __main__ -   Batch number = 145
12/27/2021 00:02:35 - INFO - __main__ -   Batch number = 146
12/27/2021 00:02:36 - INFO - __main__ -   Batch number = 147
12/27/2021 00:02:36 - INFO - __main__ -   Batch number = 148
12/27/2021 00:02:36 - INFO - __main__ -   Batch number = 149
12/27/2021 00:02:36 - INFO - __main__ -   Batch number = 150
12/27/2021 00:02:36 - INFO - __main__ -   Batch number = 151
12/27/2021 00:02:36 - INFO - __main__ -   Batch number = 152
12/27/2021 00:02:36 - INFO - __main__ -   Batch number = 153
12/27/2021 00:02:37 - INFO - __main__ -   Batch number = 154
12/27/2021 00:02:37 - INFO - __main__ -   Batch number = 155
12/27/2021 00:02:37 - INFO - __main__ -   Batch number = 156
12/27/2021 00:02:37 - INFO - __main__ -   Batch number = 157
12/27/2021 00:02:37 - INFO - __main__ -   Batch number = 158
12/27/2021 00:02:37 - INFO - __main__ -   Batch number = 159
12/27/2021 00:02:38 - INFO - __main__ -   Batch number = 160
12/27/2021 00:02:38 - INFO - __main__ -   Batch number = 161
12/27/2021 00:02:38 - INFO - __main__ -   Batch number = 162
12/27/2021 00:02:38 - INFO - __main__ -   Batch number = 163
12/27/2021 00:02:38 - INFO - __main__ -   Batch number = 164
12/27/2021 00:02:38 - INFO - __main__ -   Batch number = 165
12/27/2021 00:02:39 - INFO - __main__ -   Batch number = 166
12/27/2021 00:02:39 - INFO - __main__ -   Batch number = 167
12/27/2021 00:02:39 - INFO - __main__ -   Batch number = 168
12/27/2021 00:02:39 - INFO - __main__ -   Batch number = 169
12/27/2021 00:02:39 - INFO - __main__ -   Batch number = 170
12/27/2021 00:02:39 - INFO - __main__ -   Batch number = 171
12/27/2021 00:02:39 - INFO - __main__ -   Batch number = 172
12/27/2021 00:02:40 - INFO - __main__ -   Batch number = 173
12/27/2021 00:02:40 - INFO - __main__ -   Batch number = 174
12/27/2021 00:02:40 - INFO - __main__ -   Batch number = 175
12/27/2021 00:02:40 - INFO - __main__ -   Batch number = 176
12/27/2021 00:02:40 - INFO - __main__ -   Batch number = 177
12/27/2021 00:02:40 - INFO - __main__ -   Batch number = 178
12/27/2021 00:02:41 - INFO - __main__ -   Batch number = 179
12/27/2021 00:02:41 - INFO - __main__ -   Batch number = 180
12/27/2021 00:02:41 - INFO - __main__ -   Batch number = 181
12/27/2021 00:02:41 - INFO - __main__ -   Batch number = 182
12/27/2021 00:02:41 - INFO - __main__ -   Batch number = 183
12/27/2021 00:02:41 - INFO - __main__ -   Batch number = 184
12/27/2021 00:02:42 - INFO - __main__ -   Batch number = 185
12/27/2021 00:02:42 - INFO - __main__ -   Batch number = 186
12/27/2021 00:02:42 - INFO - __main__ -   Batch number = 187
12/27/2021 00:02:42 - INFO - __main__ -   Batch number = 188
12/27/2021 00:02:42 - INFO - __main__ -   Batch number = 189
12/27/2021 00:02:42 - INFO - __main__ -   Batch number = 190
12/27/2021 00:02:42 - INFO - __main__ -   Batch number = 191
12/27/2021 00:02:43 - INFO - __main__ -   Batch number = 192
12/27/2021 00:02:43 - INFO - __main__ -   Batch number = 193
12/27/2021 00:02:43 - INFO - __main__ -   Batch number = 194
12/27/2021 00:02:43 - INFO - __main__ -   Batch number = 195
12/27/2021 00:02:43 - INFO - __main__ -   Batch number = 196
12/27/2021 00:02:43 - INFO - __main__ -   Batch number = 197
12/27/2021 00:02:44 - INFO - __main__ -   Batch number = 198
12/27/2021 00:02:44 - INFO - __main__ -   Batch number = 199
12/27/2021 00:02:44 - INFO - __main__ -   Batch number = 200
12/27/2021 00:02:44 - INFO - __main__ -   Batch number = 201
12/27/2021 00:02:44 - INFO - __main__ -   Batch number = 202
12/27/2021 00:02:44 - INFO - __main__ -   Batch number = 203
12/27/2021 00:02:44 - INFO - __main__ -   Batch number = 204
12/27/2021 00:02:45 - INFO - __main__ -   Batch number = 205
12/27/2021 00:02:45 - INFO - __main__ -   Batch number = 206
12/27/2021 00:02:45 - INFO - __main__ -   Batch number = 207
12/27/2021 00:02:45 - INFO - __main__ -   Batch number = 208
12/27/2021 00:02:45 - INFO - __main__ -   Batch number = 209
12/27/2021 00:02:45 - INFO - __main__ -   Batch number = 210
12/27/2021 00:02:46 - INFO - __main__ -   Batch number = 211
12/27/2021 00:02:46 - INFO - __main__ -   Batch number = 212
12/27/2021 00:02:46 - INFO - __main__ -   Batch number = 213
12/27/2021 00:02:46 - INFO - __main__ -   Batch number = 214
12/27/2021 00:02:46 - INFO - __main__ -   Batch number = 215
12/27/2021 00:02:46 - INFO - __main__ -   Batch number = 216
12/27/2021 00:02:47 - INFO - __main__ -   Batch number = 217
12/27/2021 00:02:47 - INFO - __main__ -   Batch number = 218
12/27/2021 00:02:47 - INFO - __main__ -   Batch number = 219
12/27/2021 00:02:47 - INFO - __main__ -   Batch number = 220
12/27/2021 00:02:47 - INFO - __main__ -   Batch number = 221
12/27/2021 00:02:47 - INFO - __main__ -   Batch number = 222
12/27/2021 00:02:47 - INFO - __main__ -   Batch number = 223
12/27/2021 00:02:48 - INFO - __main__ -   Batch number = 224
12/27/2021 00:02:48 - INFO - __main__ -   Batch number = 225
12/27/2021 00:02:48 - INFO - __main__ -   Batch number = 226
12/27/2021 00:02:48 - INFO - __main__ -   Batch number = 227
12/27/2021 00:02:48 - INFO - __main__ -   Batch number = 228
12/27/2021 00:02:48 - INFO - __main__ -   Batch number = 229
12/27/2021 00:02:49 - INFO - __main__ -   Batch number = 230
12/27/2021 00:02:49 - INFO - __main__ -   Batch number = 231
12/27/2021 00:02:49 - INFO - __main__ -   Batch number = 232
12/27/2021 00:02:49 - INFO - __main__ -   Batch number = 233
12/27/2021 00:02:49 - INFO - __main__ -   Batch number = 234
12/27/2021 00:02:49 - INFO - __main__ -   Batch number = 235
12/27/2021 00:02:50 - INFO - __main__ -   Batch number = 236
12/27/2021 00:02:50 - INFO - __main__ -   Batch number = 237
12/27/2021 00:02:50 - INFO - __main__ -   Batch number = 238
12/27/2021 00:02:50 - INFO - __main__ -   Batch number = 239
12/27/2021 00:02:50 - INFO - __main__ -   Batch number = 240
12/27/2021 00:02:50 - INFO - __main__ -   Batch number = 241
12/27/2021 00:02:51 - INFO - __main__ -   Batch number = 242
12/27/2021 00:02:51 - INFO - __main__ -   Batch number = 243
12/27/2021 00:02:51 - INFO - __main__ -   Batch number = 244
12/27/2021 00:02:51 - INFO - __main__ -   Batch number = 245
12/27/2021 00:02:51 - INFO - __main__ -   Batch number = 246
12/27/2021 00:02:51 - INFO - __main__ -   Batch number = 247
12/27/2021 00:02:52 - INFO - __main__ -   Batch number = 248
12/27/2021 00:02:52 - INFO - __main__ -   Batch number = 249
12/27/2021 00:02:52 - INFO - __main__ -   Batch number = 250
12/27/2021 00:02:52 - INFO - __main__ -   Batch number = 251
12/27/2021 00:02:52 - INFO - __main__ -   Batch number = 252
12/27/2021 00:02:52 - INFO - __main__ -   Batch number = 253
12/27/2021 00:02:52 - INFO - __main__ -   Batch number = 254
12/27/2021 00:02:53 - INFO - __main__ -   Batch number = 255
12/27/2021 00:02:53 - INFO - __main__ -   Batch number = 256
12/27/2021 00:02:53 - INFO - __main__ -   Batch number = 257
12/27/2021 00:02:53 - INFO - __main__ -   Batch number = 258
12/27/2021 00:02:53 - INFO - __main__ -   Batch number = 259
12/27/2021 00:02:53 - INFO - __main__ -   Batch number = 260
12/27/2021 00:02:54 - INFO - __main__ -   Batch number = 261
12/27/2021 00:02:54 - INFO - __main__ -   Batch number = 262
12/27/2021 00:02:54 - INFO - __main__ -   Batch number = 263
12/27/2021 00:02:54 - INFO - __main__ -   Batch number = 264
12/27/2021 00:02:54 - INFO - __main__ -   Batch number = 265
12/27/2021 00:02:54 - INFO - __main__ -   Batch number = 266
12/27/2021 00:02:55 - INFO - __main__ -   Batch number = 267
12/27/2021 00:02:55 - INFO - __main__ -   Batch number = 268
12/27/2021 00:02:55 - INFO - __main__ -   Batch number = 269
12/27/2021 00:02:55 - INFO - __main__ -   Batch number = 270
12/27/2021 00:02:55 - INFO - __main__ -   Batch number = 271
12/27/2021 00:02:55 - INFO - __main__ -   Batch number = 272
12/27/2021 00:02:56 - INFO - __main__ -   Batch number = 273
12/27/2021 00:02:56 - INFO - __main__ -   Batch number = 274
12/27/2021 00:02:56 - INFO - __main__ -   Batch number = 275
12/27/2021 00:02:56 - INFO - __main__ -   Batch number = 276
12/27/2021 00:02:56 - INFO - __main__ -   Batch number = 277
12/27/2021 00:02:57 - INFO - __main__ -   Batch number = 278
12/27/2021 00:02:57 - INFO - __main__ -   Batch number = 279
12/27/2021 00:02:57 - INFO - __main__ -   Batch number = 280
12/27/2021 00:02:57 - INFO - __main__ -   Batch number = 281
12/27/2021 00:02:57 - INFO - __main__ -   Batch number = 282
12/27/2021 00:02:57 - INFO - __main__ -   Batch number = 283
12/27/2021 00:02:58 - INFO - __main__ -   Batch number = 284
12/27/2021 00:02:58 - INFO - __main__ -   Batch number = 285
12/27/2021 00:02:58 - INFO - __main__ -   Batch number = 286
12/27/2021 00:02:58 - INFO - __main__ -   Batch number = 287
12/27/2021 00:02:58 - INFO - __main__ -   Batch number = 288
12/27/2021 00:02:58 - INFO - __main__ -   Batch number = 289
12/27/2021 00:02:59 - INFO - __main__ -   Batch number = 290
12/27/2021 00:02:59 - INFO - __main__ -   Batch number = 291
12/27/2021 00:02:59 - INFO - __main__ -   Batch number = 292
12/27/2021 00:02:59 - INFO - __main__ -   Batch number = 293
12/27/2021 00:02:59 - INFO - __main__ -   Batch number = 294
12/27/2021 00:02:59 - INFO - __main__ -   Batch number = 295
12/27/2021 00:03:00 - INFO - __main__ -   Batch number = 296
12/27/2021 00:03:00 - INFO - __main__ -   Batch number = 297
12/27/2021 00:03:00 - INFO - __main__ -   Batch number = 298
12/27/2021 00:03:00 - INFO - __main__ -   Batch number = 299
12/27/2021 00:03:00 - INFO - __main__ -   Batch number = 300
12/27/2021 00:03:00 - INFO - __main__ -   Batch number = 301
12/27/2021 00:03:01 - INFO - __main__ -   Batch number = 302
12/27/2021 00:03:01 - INFO - __main__ -   Batch number = 303
12/27/2021 00:03:01 - INFO - __main__ -   Batch number = 304
12/27/2021 00:03:01 - INFO - __main__ -   Batch number = 305
12/27/2021 00:03:01 - INFO - __main__ -   Batch number = 306
12/27/2021 00:03:02 - INFO - __main__ -   Batch number = 307
12/27/2021 00:03:02 - INFO - __main__ -   Batch number = 308
12/27/2021 00:03:02 - INFO - __main__ -   Batch number = 309
12/27/2021 00:03:02 - INFO - __main__ -   Batch number = 310
12/27/2021 00:03:02 - INFO - __main__ -   Batch number = 311
12/27/2021 00:03:02 - INFO - __main__ -   Batch number = 312
12/27/2021 00:03:02 - INFO - __main__ -   Batch number = 313
12/27/2021 00:03:04 - INFO - __main__ -   ***** Evaluation result  in en *****
12/27/2021 00:03:04 - INFO - __main__ -     f1 = 0.7917440515821565
12/27/2021 00:03:04 - INFO - __main__ -     loss = 0.9913181965402997
12/27/2021 00:03:04 - INFO - __main__ -     precision = 0.7749348333104679
12/27/2021 00:03:04 - INFO - __main__ -     recall = 0.8092986603624901
12/27/2021 00:03:04 - INFO - __main__ -   Language adapter for ja not found, using pt instead
12/27/2021 00:03:04 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:03:04 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:03:04 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:03:04 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ja_bert-base-multilingual-cased_128
12/27/2021 00:03:05 - INFO - __main__ -   ***** Running evaluation  in ja *****
12/27/2021 00:03:06 - INFO - __main__ -     Num examples = 10612
12/27/2021 00:03:06 - INFO - __main__ -     Batch size = 32
12/27/2021 00:03:06 - INFO - __main__ -   Batch number = 1
12/27/2021 00:03:06 - INFO - __main__ -   Batch number = 2
12/27/2021 00:03:06 - INFO - __main__ -   Batch number = 3
12/27/2021 00:03:06 - INFO - __main__ -   Batch number = 4
12/27/2021 00:03:06 - INFO - __main__ -   Batch number = 5
12/27/2021 00:03:06 - INFO - __main__ -   Batch number = 6
12/27/2021 00:03:06 - INFO - __main__ -   Batch number = 7
12/27/2021 00:03:07 - INFO - __main__ -   Batch number = 8
12/27/2021 00:03:07 - INFO - __main__ -   Batch number = 9
12/27/2021 00:03:07 - INFO - __main__ -   Batch number = 10
12/27/2021 00:03:07 - INFO - __main__ -   Batch number = 11
12/27/2021 00:03:07 - INFO - __main__ -   Batch number = 12
12/27/2021 00:03:07 - INFO - __main__ -   Batch number = 13
12/27/2021 00:03:08 - INFO - __main__ -   Batch number = 14
12/27/2021 00:03:08 - INFO - __main__ -   Batch number = 15
12/27/2021 00:03:08 - INFO - __main__ -   Batch number = 16
12/27/2021 00:03:08 - INFO - __main__ -   Batch number = 17
12/27/2021 00:03:08 - INFO - __main__ -   Batch number = 18
12/27/2021 00:03:08 - INFO - __main__ -   Batch number = 19
12/27/2021 00:03:08 - INFO - __main__ -   Batch number = 20
12/27/2021 00:03:09 - INFO - __main__ -   Batch number = 21
12/27/2021 00:03:09 - INFO - __main__ -   Batch number = 22
12/27/2021 00:03:09 - INFO - __main__ -   Batch number = 23
12/27/2021 00:03:09 - INFO - __main__ -   Batch number = 24
12/27/2021 00:03:09 - INFO - __main__ -   Batch number = 25
12/27/2021 00:03:09 - INFO - __main__ -   Batch number = 26
12/27/2021 00:03:10 - INFO - __main__ -   Batch number = 27
12/27/2021 00:03:10 - INFO - __main__ -   Batch number = 28
12/27/2021 00:03:10 - INFO - __main__ -   Batch number = 29
12/27/2021 00:03:10 - INFO - __main__ -   Batch number = 30
12/27/2021 00:03:10 - INFO - __main__ -   Batch number = 31
12/27/2021 00:03:10 - INFO - __main__ -   Batch number = 32
12/27/2021 00:03:11 - INFO - __main__ -   Batch number = 33
12/27/2021 00:03:11 - INFO - __main__ -   Batch number = 34
12/27/2021 00:03:11 - INFO - __main__ -   Batch number = 35
12/27/2021 00:03:11 - INFO - __main__ -   Batch number = 36
12/27/2021 00:03:11 - INFO - __main__ -   Batch number = 37
12/27/2021 00:03:12 - INFO - __main__ -   Batch number = 38
12/27/2021 00:03:12 - INFO - __main__ -   Batch number = 39
12/27/2021 00:03:12 - INFO - __main__ -   Batch number = 40
12/27/2021 00:03:12 - INFO - __main__ -   Batch number = 41
12/27/2021 00:03:12 - INFO - __main__ -   Batch number = 42
12/27/2021 00:03:12 - INFO - __main__ -   Batch number = 43
12/27/2021 00:03:12 - INFO - __main__ -   Batch number = 44
12/27/2021 00:03:13 - INFO - __main__ -   Batch number = 45
12/27/2021 00:03:13 - INFO - __main__ -   Batch number = 46
12/27/2021 00:03:13 - INFO - __main__ -   Batch number = 47
12/27/2021 00:03:13 - INFO - __main__ -   Batch number = 48
12/27/2021 00:03:13 - INFO - __main__ -   Batch number = 49
12/27/2021 00:03:13 - INFO - __main__ -   Batch number = 50
12/27/2021 00:03:14 - INFO - __main__ -   Batch number = 51
12/27/2021 00:03:14 - INFO - __main__ -   Batch number = 52
12/27/2021 00:03:14 - INFO - __main__ -   Batch number = 53
12/27/2021 00:03:14 - INFO - __main__ -   Batch number = 54
12/27/2021 00:03:14 - INFO - __main__ -   Batch number = 55
12/27/2021 00:03:14 - INFO - __main__ -   Batch number = 56
12/27/2021 00:03:14 - INFO - __main__ -   Batch number = 57
12/27/2021 00:03:15 - INFO - __main__ -   Batch number = 58
12/27/2021 00:03:15 - INFO - __main__ -   Batch number = 59
12/27/2021 00:03:15 - INFO - __main__ -   Batch number = 60
12/27/2021 00:03:15 - INFO - __main__ -   Batch number = 61
12/27/2021 00:03:15 - INFO - __main__ -   Batch number = 62
12/27/2021 00:03:15 - INFO - __main__ -   Batch number = 63
12/27/2021 00:03:16 - INFO - __main__ -   Batch number = 64
12/27/2021 00:03:16 - INFO - __main__ -   Batch number = 65
12/27/2021 00:03:16 - INFO - __main__ -   Batch number = 66
12/27/2021 00:03:16 - INFO - __main__ -   Batch number = 67
12/27/2021 00:03:16 - INFO - __main__ -   Batch number = 68
12/27/2021 00:03:17 - INFO - __main__ -   Batch number = 69
12/27/2021 00:03:17 - INFO - __main__ -   Batch number = 70
12/27/2021 00:03:17 - INFO - __main__ -   Batch number = 71
12/27/2021 00:03:17 - INFO - __main__ -   Batch number = 72
12/27/2021 00:03:17 - INFO - __main__ -   Batch number = 73
12/27/2021 00:03:17 - INFO - __main__ -   Batch number = 74
12/27/2021 00:03:18 - INFO - __main__ -   Batch number = 75
12/27/2021 00:03:18 - INFO - __main__ -   Batch number = 76
12/27/2021 00:03:18 - INFO - __main__ -   Batch number = 77
12/27/2021 00:03:18 - INFO - __main__ -   Batch number = 78
12/27/2021 00:03:18 - INFO - __main__ -   Batch number = 79
12/27/2021 00:03:18 - INFO - __main__ -   Batch number = 80
12/27/2021 00:03:18 - INFO - __main__ -   Batch number = 81
12/27/2021 00:03:19 - INFO - __main__ -   Batch number = 82
12/27/2021 00:03:19 - INFO - __main__ -   Batch number = 83
12/27/2021 00:03:19 - INFO - __main__ -   Batch number = 84
12/27/2021 00:03:19 - INFO - __main__ -   Batch number = 85
12/27/2021 00:03:19 - INFO - __main__ -   Batch number = 86
12/27/2021 00:03:19 - INFO - __main__ -   Batch number = 87
12/27/2021 00:03:20 - INFO - __main__ -   Batch number = 88
12/27/2021 00:03:20 - INFO - __main__ -   Batch number = 89
12/27/2021 00:03:20 - INFO - __main__ -   Batch number = 90
12/27/2021 00:03:20 - INFO - __main__ -   Batch number = 91
12/27/2021 00:03:20 - INFO - __main__ -   Batch number = 92
12/27/2021 00:03:20 - INFO - __main__ -   Batch number = 93
12/27/2021 00:03:21 - INFO - __main__ -   Batch number = 94
12/27/2021 00:03:21 - INFO - __main__ -   Batch number = 95
12/27/2021 00:03:21 - INFO - __main__ -   Batch number = 96
12/27/2021 00:03:21 - INFO - __main__ -   Batch number = 97
12/27/2021 00:03:21 - INFO - __main__ -   Batch number = 98
12/27/2021 00:03:22 - INFO - __main__ -   Batch number = 99
12/27/2021 00:03:22 - INFO - __main__ -   Batch number = 100
12/27/2021 00:03:22 - INFO - __main__ -   Batch number = 101
12/27/2021 00:03:22 - INFO - __main__ -   Batch number = 102
12/27/2021 00:03:22 - INFO - __main__ -   Batch number = 103
12/27/2021 00:03:22 - INFO - __main__ -   Batch number = 104
12/27/2021 00:03:22 - INFO - __main__ -   Batch number = 105
12/27/2021 00:03:23 - INFO - __main__ -   Batch number = 106
12/27/2021 00:03:23 - INFO - __main__ -   Batch number = 107
12/27/2021 00:03:23 - INFO - __main__ -   Batch number = 108
12/27/2021 00:03:23 - INFO - __main__ -   Batch number = 109
12/27/2021 00:03:23 - INFO - __main__ -   Batch number = 110
12/27/2021 00:03:23 - INFO - __main__ -   Batch number = 111
12/27/2021 00:03:24 - INFO - __main__ -   Batch number = 112
12/27/2021 00:03:24 - INFO - __main__ -   Batch number = 113
12/27/2021 00:03:24 - INFO - __main__ -   Batch number = 114
12/27/2021 00:03:24 - INFO - __main__ -   Batch number = 115
12/27/2021 00:03:24 - INFO - __main__ -   Batch number = 116
12/27/2021 00:03:24 - INFO - __main__ -   Batch number = 117
12/27/2021 00:03:25 - INFO - __main__ -   Batch number = 118
12/27/2021 00:03:25 - INFO - __main__ -   Batch number = 119
12/27/2021 00:03:25 - INFO - __main__ -   Batch number = 120
12/27/2021 00:03:25 - INFO - __main__ -   Batch number = 121
12/27/2021 00:03:25 - INFO - __main__ -   Batch number = 122
12/27/2021 00:03:25 - INFO - __main__ -   Batch number = 123
12/27/2021 00:03:26 - INFO - __main__ -   Batch number = 124
12/27/2021 00:03:26 - INFO - __main__ -   Batch number = 125
12/27/2021 00:03:26 - INFO - __main__ -   Batch number = 126
12/27/2021 00:03:26 - INFO - __main__ -   Batch number = 127
12/27/2021 00:03:26 - INFO - __main__ -   Batch number = 128
12/27/2021 00:03:27 - INFO - __main__ -   Batch number = 129
12/27/2021 00:03:27 - INFO - __main__ -   Batch number = 130
12/27/2021 00:03:27 - INFO - __main__ -   Batch number = 131
12/27/2021 00:03:27 - INFO - __main__ -   Batch number = 132
12/27/2021 00:03:27 - INFO - __main__ -   Batch number = 133
12/27/2021 00:03:27 - INFO - __main__ -   Batch number = 134
12/27/2021 00:03:28 - INFO - __main__ -   Batch number = 135
12/27/2021 00:03:28 - INFO - __main__ -   Batch number = 136
12/27/2021 00:03:28 - INFO - __main__ -   Batch number = 137
12/27/2021 00:03:28 - INFO - __main__ -   Batch number = 138
12/27/2021 00:03:28 - INFO - __main__ -   Batch number = 139
12/27/2021 00:03:28 - INFO - __main__ -   Batch number = 140
12/27/2021 00:03:28 - INFO - __main__ -   Batch number = 141
12/27/2021 00:03:29 - INFO - __main__ -   Batch number = 142
12/27/2021 00:03:29 - INFO - __main__ -   Batch number = 143
12/27/2021 00:03:29 - INFO - __main__ -   Batch number = 144
12/27/2021 00:03:29 - INFO - __main__ -   Batch number = 145
12/27/2021 00:03:29 - INFO - __main__ -   Batch number = 146
12/27/2021 00:03:29 - INFO - __main__ -   Batch number = 147
12/27/2021 00:03:30 - INFO - __main__ -   Batch number = 148
12/27/2021 00:03:30 - INFO - __main__ -   Batch number = 149
12/27/2021 00:03:30 - INFO - __main__ -   Batch number = 150
12/27/2021 00:03:30 - INFO - __main__ -   Batch number = 151
12/27/2021 00:03:30 - INFO - __main__ -   Batch number = 152
12/27/2021 00:03:30 - INFO - __main__ -   Batch number = 153
12/27/2021 00:03:31 - INFO - __main__ -   Batch number = 154
12/27/2021 00:03:31 - INFO - __main__ -   Batch number = 155
12/27/2021 00:03:31 - INFO - __main__ -   Batch number = 156
12/27/2021 00:03:31 - INFO - __main__ -   Batch number = 157
12/27/2021 00:03:31 - INFO - __main__ -   Batch number = 158
12/27/2021 00:03:32 - INFO - __main__ -   Batch number = 159
12/27/2021 00:03:32 - INFO - __main__ -   Batch number = 160
12/27/2021 00:03:32 - INFO - __main__ -   Batch number = 161
12/27/2021 00:03:32 - INFO - __main__ -   Batch number = 162
12/27/2021 00:03:32 - INFO - __main__ -   Batch number = 163
12/27/2021 00:03:32 - INFO - __main__ -   Batch number = 164
12/27/2021 00:03:32 - INFO - __main__ -   Batch number = 165
12/27/2021 00:03:33 - INFO - __main__ -   Batch number = 166
12/27/2021 00:03:33 - INFO - __main__ -   Batch number = 167
12/27/2021 00:03:33 - INFO - __main__ -   Batch number = 168
12/27/2021 00:03:33 - INFO - __main__ -   Batch number = 169
12/27/2021 00:03:33 - INFO - __main__ -   Batch number = 170
12/27/2021 00:03:33 - INFO - __main__ -   Batch number = 171
12/27/2021 00:03:34 - INFO - __main__ -   Batch number = 172
12/27/2021 00:03:34 - INFO - __main__ -   Batch number = 173
12/27/2021 00:03:34 - INFO - __main__ -   Batch number = 174
12/27/2021 00:03:34 - INFO - __main__ -   Batch number = 175
12/27/2021 00:03:34 - INFO - __main__ -   Batch number = 176
12/27/2021 00:03:34 - INFO - __main__ -   Batch number = 177
12/27/2021 00:03:35 - INFO - __main__ -   Batch number = 178
12/27/2021 00:03:35 - INFO - __main__ -   Batch number = 179
12/27/2021 00:03:35 - INFO - __main__ -   Batch number = 180
12/27/2021 00:03:35 - INFO - __main__ -   Batch number = 181
12/27/2021 00:03:35 - INFO - __main__ -   Batch number = 182
12/27/2021 00:03:35 - INFO - __main__ -   Batch number = 183
12/27/2021 00:03:35 - INFO - __main__ -   Batch number = 184
12/27/2021 00:03:36 - INFO - __main__ -   Batch number = 185
12/27/2021 00:03:36 - INFO - __main__ -   Batch number = 186
12/27/2021 00:03:36 - INFO - __main__ -   Batch number = 187
12/27/2021 00:03:36 - INFO - __main__ -   Batch number = 188
12/27/2021 00:03:36 - INFO - __main__ -   Batch number = 189
12/27/2021 00:03:37 - INFO - __main__ -   Batch number = 190
12/27/2021 00:03:37 - INFO - __main__ -   Batch number = 191
12/27/2021 00:03:37 - INFO - __main__ -   Batch number = 192
12/27/2021 00:03:37 - INFO - __main__ -   Batch number = 193
12/27/2021 00:03:37 - INFO - __main__ -   Batch number = 194
12/27/2021 00:03:37 - INFO - __main__ -   Batch number = 195
12/27/2021 00:03:37 - INFO - __main__ -   Batch number = 196
12/27/2021 00:03:38 - INFO - __main__ -   Batch number = 197
12/27/2021 00:03:38 - INFO - __main__ -   Batch number = 198
12/27/2021 00:03:38 - INFO - __main__ -   Batch number = 199
12/27/2021 00:03:38 - INFO - __main__ -   Batch number = 200
12/27/2021 00:03:38 - INFO - __main__ -   Batch number = 201
12/27/2021 00:03:38 - INFO - __main__ -   Batch number = 202
12/27/2021 00:03:39 - INFO - __main__ -   Batch number = 203
12/27/2021 00:03:39 - INFO - __main__ -   Batch number = 204
12/27/2021 00:03:39 - INFO - __main__ -   Batch number = 205
12/27/2021 00:03:39 - INFO - __main__ -   Batch number = 206
12/27/2021 00:03:39 - INFO - __main__ -   Batch number = 207
12/27/2021 00:03:39 - INFO - __main__ -   Batch number = 208
12/27/2021 00:03:40 - INFO - __main__ -   Batch number = 209
12/27/2021 00:03:40 - INFO - __main__ -   Batch number = 210
12/27/2021 00:03:40 - INFO - __main__ -   Batch number = 211
12/27/2021 00:03:40 - INFO - __main__ -   Batch number = 212
12/27/2021 00:03:40 - INFO - __main__ -   Batch number = 213
12/27/2021 00:03:40 - INFO - __main__ -   Batch number = 214
12/27/2021 00:03:41 - INFO - __main__ -   Batch number = 215
12/27/2021 00:03:41 - INFO - __main__ -   Batch number = 216
12/27/2021 00:03:41 - INFO - __main__ -   Batch number = 217
12/27/2021 00:03:41 - INFO - __main__ -   Batch number = 218
12/27/2021 00:03:41 - INFO - __main__ -   Batch number = 219
12/27/2021 00:03:41 - INFO - __main__ -   Batch number = 220
12/27/2021 00:03:41 - INFO - __main__ -   Batch number = 221
12/27/2021 00:03:42 - INFO - __main__ -   Batch number = 222
12/27/2021 00:03:42 - INFO - __main__ -   Batch number = 223
12/27/2021 00:03:42 - INFO - __main__ -   Batch number = 224
12/27/2021 00:03:42 - INFO - __main__ -   Batch number = 225
12/27/2021 00:03:42 - INFO - __main__ -   Batch number = 226
12/27/2021 00:03:42 - INFO - __main__ -   Batch number = 227
12/27/2021 00:03:43 - INFO - __main__ -   Batch number = 228
12/27/2021 00:03:43 - INFO - __main__ -   Batch number = 229
12/27/2021 00:03:43 - INFO - __main__ -   Batch number = 230
12/27/2021 00:03:43 - INFO - __main__ -   Batch number = 231
12/27/2021 00:03:43 - INFO - __main__ -   Batch number = 232
12/27/2021 00:03:43 - INFO - __main__ -   Batch number = 233
12/27/2021 00:03:43 - INFO - __main__ -   Batch number = 234
12/27/2021 00:03:44 - INFO - __main__ -   Batch number = 235
12/27/2021 00:03:44 - INFO - __main__ -   Batch number = 236
12/27/2021 00:03:44 - INFO - __main__ -   Batch number = 237
12/27/2021 00:03:44 - INFO - __main__ -   Batch number = 238
12/27/2021 00:03:44 - INFO - __main__ -   Batch number = 239
12/27/2021 00:03:44 - INFO - __main__ -   Batch number = 240
12/27/2021 00:03:45 - INFO - __main__ -   Batch number = 241
12/27/2021 00:03:45 - INFO - __main__ -   Batch number = 242
12/27/2021 00:03:45 - INFO - __main__ -   Batch number = 243
12/27/2021 00:03:45 - INFO - __main__ -   Batch number = 244
12/27/2021 00:03:45 - INFO - __main__ -   Batch number = 245
12/27/2021 00:03:45 - INFO - __main__ -   Batch number = 246
12/27/2021 00:03:46 - INFO - __main__ -   Batch number = 247
12/27/2021 00:03:46 - INFO - __main__ -   Batch number = 248
12/27/2021 00:03:46 - INFO - __main__ -   Batch number = 249
12/27/2021 00:03:46 - INFO - __main__ -   Batch number = 250
12/27/2021 00:03:46 - INFO - __main__ -   Batch number = 251
12/27/2021 00:03:46 - INFO - __main__ -   Batch number = 252
12/27/2021 00:03:46 - INFO - __main__ -   Batch number = 253
12/27/2021 00:03:47 - INFO - __main__ -   Batch number = 254
12/27/2021 00:03:47 - INFO - __main__ -   Batch number = 255
12/27/2021 00:03:47 - INFO - __main__ -   Batch number = 256
12/27/2021 00:03:47 - INFO - __main__ -   Batch number = 257
12/27/2021 00:03:47 - INFO - __main__ -   Batch number = 258
12/27/2021 00:03:47 - INFO - __main__ -   Batch number = 259
12/27/2021 00:03:48 - INFO - __main__ -   Batch number = 260
12/27/2021 00:03:48 - INFO - __main__ -   Batch number = 261
12/27/2021 00:03:48 - INFO - __main__ -   Batch number = 262
12/27/2021 00:03:48 - INFO - __main__ -   Batch number = 263
12/27/2021 00:03:48 - INFO - __main__ -   Batch number = 264
12/27/2021 00:03:48 - INFO - __main__ -   Batch number = 265
12/27/2021 00:03:49 - INFO - __main__ -   Batch number = 266
12/27/2021 00:03:49 - INFO - __main__ -   Batch number = 267
12/27/2021 00:03:49 - INFO - __main__ -   Batch number = 268
12/27/2021 00:03:49 - INFO - __main__ -   Batch number = 269
12/27/2021 00:03:49 - INFO - __main__ -   Batch number = 270
12/27/2021 00:03:49 - INFO - __main__ -   Batch number = 271
12/27/2021 00:03:50 - INFO - __main__ -   Batch number = 272
12/27/2021 00:03:50 - INFO - __main__ -   Batch number = 273
12/27/2021 00:03:50 - INFO - __main__ -   Batch number = 274
12/27/2021 00:03:50 - INFO - __main__ -   Batch number = 275
12/27/2021 00:03:50 - INFO - __main__ -   Batch number = 276
12/27/2021 00:03:51 - INFO - __main__ -   Batch number = 277
12/27/2021 00:03:51 - INFO - __main__ -   Batch number = 278
12/27/2021 00:03:51 - INFO - __main__ -   Batch number = 279
12/27/2021 00:03:51 - INFO - __main__ -   Batch number = 280
12/27/2021 00:03:51 - INFO - __main__ -   Batch number = 281
12/27/2021 00:03:51 - INFO - __main__ -   Batch number = 282
12/27/2021 00:03:52 - INFO - __main__ -   Batch number = 283
12/27/2021 00:03:52 - INFO - __main__ -   Batch number = 284
12/27/2021 00:03:52 - INFO - __main__ -   Batch number = 285
12/27/2021 00:03:52 - INFO - __main__ -   Batch number = 286
12/27/2021 00:03:52 - INFO - __main__ -   Batch number = 287
12/27/2021 00:03:52 - INFO - __main__ -   Batch number = 288
12/27/2021 00:03:53 - INFO - __main__ -   Batch number = 289
12/27/2021 00:03:53 - INFO - __main__ -   Batch number = 290
12/27/2021 00:03:53 - INFO - __main__ -   Batch number = 291
12/27/2021 00:03:53 - INFO - __main__ -   Batch number = 292
12/27/2021 00:03:53 - INFO - __main__ -   Batch number = 293
12/27/2021 00:03:53 - INFO - __main__ -   Batch number = 294
12/27/2021 00:03:53 - INFO - __main__ -   Batch number = 295
12/27/2021 00:03:54 - INFO - __main__ -   Batch number = 296
12/27/2021 00:03:54 - INFO - __main__ -   Batch number = 297
12/27/2021 00:03:54 - INFO - __main__ -   Batch number = 298
12/27/2021 00:03:54 - INFO - __main__ -   Batch number = 299
12/27/2021 00:03:54 - INFO - __main__ -   Batch number = 300
12/27/2021 00:03:54 - INFO - __main__ -   Batch number = 301
12/27/2021 00:03:55 - INFO - __main__ -   Batch number = 302
12/27/2021 00:03:55 - INFO - __main__ -   Batch number = 303
12/27/2021 00:03:55 - INFO - __main__ -   Batch number = 304
12/27/2021 00:03:55 - INFO - __main__ -   Batch number = 305
12/27/2021 00:03:55 - INFO - __main__ -   Batch number = 306
12/27/2021 00:03:55 - INFO - __main__ -   Batch number = 307
12/27/2021 00:03:56 - INFO - __main__ -   Batch number = 308
12/27/2021 00:03:56 - INFO - __main__ -   Batch number = 309
12/27/2021 00:03:56 - INFO - __main__ -   Batch number = 310
12/27/2021 00:03:56 - INFO - __main__ -   Batch number = 311
12/27/2021 00:03:56 - INFO - __main__ -   Batch number = 312
12/27/2021 00:03:56 - INFO - __main__ -   Batch number = 313
12/27/2021 00:03:57 - INFO - __main__ -   Batch number = 314
12/27/2021 00:03:57 - INFO - __main__ -   Batch number = 315
12/27/2021 00:03:57 - INFO - __main__ -   Batch number = 316
12/27/2021 00:03:57 - INFO - __main__ -   Batch number = 317
12/27/2021 00:03:57 - INFO - __main__ -   Batch number = 318
12/27/2021 00:03:57 - INFO - __main__ -   Batch number = 319
12/27/2021 00:03:58 - INFO - __main__ -   Batch number = 320
12/27/2021 00:03:58 - INFO - __main__ -   Batch number = 321
12/27/2021 00:03:58 - INFO - __main__ -   Batch number = 322
12/27/2021 00:03:58 - INFO - __main__ -   Batch number = 323
12/27/2021 00:03:58 - INFO - __main__ -   Batch number = 324
12/27/2021 00:03:58 - INFO - __main__ -   Batch number = 325
12/27/2021 00:03:59 - INFO - __main__ -   Batch number = 326
12/27/2021 00:03:59 - INFO - __main__ -   Batch number = 327
12/27/2021 00:03:59 - INFO - __main__ -   Batch number = 328
12/27/2021 00:03:59 - INFO - __main__ -   Batch number = 329
12/27/2021 00:03:59 - INFO - __main__ -   Batch number = 330
12/27/2021 00:04:00 - INFO - __main__ -   Batch number = 331
12/27/2021 00:04:00 - INFO - __main__ -   Batch number = 332
12/27/2021 00:04:03 - INFO - __main__ -   ***** Evaluation result  in ja *****
12/27/2021 00:04:03 - INFO - __main__ -     f1 = 0.202808729478473
12/27/2021 00:04:03 - INFO - __main__ -     loss = 4.118412348879389
12/27/2021 00:04:03 - INFO - __main__ -     precision = 0.14653201219512196
12/27/2021 00:04:03 - INFO - __main__ -     recall = 0.3292656818668379
12/27/2021 00:04:03 - INFO - __main__ -   Language adapter for zh not found, using pt instead
12/27/2021 00:04:03 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:04:03 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:04:03 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:04:03 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_zh_bert-base-multilingual-cased_128
12/27/2021 00:04:05 - INFO - __main__ -   ***** Running evaluation  in zh *****
12/27/2021 00:04:05 - INFO - __main__ -     Num examples = 10257
12/27/2021 00:04:05 - INFO - __main__ -     Batch size = 32
12/27/2021 00:04:05 - INFO - __main__ -   Batch number = 1
12/27/2021 00:04:05 - INFO - __main__ -   Batch number = 2
12/27/2021 00:04:05 - INFO - __main__ -   Batch number = 3
12/27/2021 00:04:05 - INFO - __main__ -   Batch number = 4
12/27/2021 00:04:05 - INFO - __main__ -   Batch number = 5
12/27/2021 00:04:05 - INFO - __main__ -   Batch number = 6
12/27/2021 00:04:05 - INFO - __main__ -   Batch number = 7
12/27/2021 00:04:06 - INFO - __main__ -   Batch number = 8
12/27/2021 00:04:06 - INFO - __main__ -   Batch number = 9
12/27/2021 00:04:06 - INFO - __main__ -   Batch number = 10
12/27/2021 00:04:06 - INFO - __main__ -   Batch number = 11
12/27/2021 00:04:06 - INFO - __main__ -   Batch number = 12
12/27/2021 00:04:06 - INFO - __main__ -   Batch number = 13
12/27/2021 00:04:07 - INFO - __main__ -   Batch number = 14
12/27/2021 00:04:07 - INFO - __main__ -   Batch number = 15
12/27/2021 00:04:07 - INFO - __main__ -   Batch number = 16
12/27/2021 00:04:07 - INFO - __main__ -   Batch number = 17
12/27/2021 00:04:07 - INFO - __main__ -   Batch number = 18
12/27/2021 00:04:07 - INFO - __main__ -   Batch number = 19
12/27/2021 00:04:07 - INFO - __main__ -   Batch number = 20
12/27/2021 00:04:08 - INFO - __main__ -   Batch number = 21
12/27/2021 00:04:08 - INFO - __main__ -   Batch number = 22
12/27/2021 00:04:08 - INFO - __main__ -   Batch number = 23
12/27/2021 00:04:08 - INFO - __main__ -   Batch number = 24
12/27/2021 00:04:08 - INFO - __main__ -   Batch number = 25
12/27/2021 00:04:08 - INFO - __main__ -   Batch number = 26
12/27/2021 00:04:09 - INFO - __main__ -   Batch number = 27
12/27/2021 00:04:09 - INFO - __main__ -   Batch number = 28
12/27/2021 00:04:09 - INFO - __main__ -   Batch number = 29
12/27/2021 00:04:09 - INFO - __main__ -   Batch number = 30
12/27/2021 00:04:09 - INFO - __main__ -   Batch number = 31
12/27/2021 00:04:09 - INFO - __main__ -   Batch number = 32
12/27/2021 00:04:09 - INFO - __main__ -   Batch number = 33
12/27/2021 00:04:10 - INFO - __main__ -   Batch number = 34
12/27/2021 00:04:10 - INFO - __main__ -   Batch number = 35
12/27/2021 00:04:10 - INFO - __main__ -   Batch number = 36
12/27/2021 00:04:10 - INFO - __main__ -   Batch number = 37
12/27/2021 00:04:10 - INFO - __main__ -   Batch number = 38
12/27/2021 00:04:10 - INFO - __main__ -   Batch number = 39
12/27/2021 00:04:11 - INFO - __main__ -   Batch number = 40
12/27/2021 00:04:11 - INFO - __main__ -   Batch number = 41
12/27/2021 00:04:11 - INFO - __main__ -   Batch number = 42
12/27/2021 00:04:11 - INFO - __main__ -   Batch number = 43
12/27/2021 00:04:11 - INFO - __main__ -   Batch number = 44
12/27/2021 00:04:11 - INFO - __main__ -   Batch number = 45
12/27/2021 00:04:11 - INFO - __main__ -   Batch number = 46
12/27/2021 00:04:12 - INFO - __main__ -   Batch number = 47
12/27/2021 00:04:12 - INFO - __main__ -   Batch number = 48
12/27/2021 00:04:12 - INFO - __main__ -   Batch number = 49
12/27/2021 00:04:12 - INFO - __main__ -   Batch number = 50
12/27/2021 00:04:12 - INFO - __main__ -   Batch number = 51
12/27/2021 00:04:12 - INFO - __main__ -   Batch number = 52
12/27/2021 00:04:13 - INFO - __main__ -   Batch number = 53
12/27/2021 00:04:13 - INFO - __main__ -   Batch number = 54
12/27/2021 00:04:13 - INFO - __main__ -   Batch number = 55
12/27/2021 00:04:13 - INFO - __main__ -   Batch number = 56
12/27/2021 00:04:13 - INFO - __main__ -   Batch number = 57
12/27/2021 00:04:13 - INFO - __main__ -   Batch number = 58
12/27/2021 00:04:13 - INFO - __main__ -   Batch number = 59
12/27/2021 00:04:14 - INFO - __main__ -   Batch number = 60
12/27/2021 00:04:14 - INFO - __main__ -   Batch number = 61
12/27/2021 00:04:14 - INFO - __main__ -   Batch number = 62
12/27/2021 00:04:14 - INFO - __main__ -   Batch number = 63
12/27/2021 00:04:14 - INFO - __main__ -   Batch number = 64
12/27/2021 00:04:14 - INFO - __main__ -   Batch number = 65
12/27/2021 00:04:15 - INFO - __main__ -   Batch number = 66
12/27/2021 00:04:15 - INFO - __main__ -   Batch number = 67
12/27/2021 00:04:15 - INFO - __main__ -   Batch number = 68
12/27/2021 00:04:15 - INFO - __main__ -   Batch number = 69
12/27/2021 00:04:15 - INFO - __main__ -   Batch number = 70
12/27/2021 00:04:15 - INFO - __main__ -   Batch number = 71
12/27/2021 00:04:16 - INFO - __main__ -   Batch number = 72
12/27/2021 00:04:16 - INFO - __main__ -   Batch number = 73
12/27/2021 00:04:16 - INFO - __main__ -   Batch number = 74
12/27/2021 00:04:16 - INFO - __main__ -   Batch number = 75
12/27/2021 00:04:16 - INFO - __main__ -   Batch number = 76
12/27/2021 00:04:16 - INFO - __main__ -   Batch number = 77
12/27/2021 00:04:17 - INFO - __main__ -   Batch number = 78
12/27/2021 00:04:17 - INFO - __main__ -   Batch number = 79
12/27/2021 00:04:17 - INFO - __main__ -   Batch number = 80
12/27/2021 00:04:17 - INFO - __main__ -   Batch number = 81
12/27/2021 00:04:17 - INFO - __main__ -   Batch number = 82
12/27/2021 00:04:17 - INFO - __main__ -   Batch number = 83
12/27/2021 00:04:18 - INFO - __main__ -   Batch number = 84
12/27/2021 00:04:18 - INFO - __main__ -   Batch number = 85
12/27/2021 00:04:18 - INFO - __main__ -   Batch number = 86
12/27/2021 00:04:18 - INFO - __main__ -   Batch number = 87
12/27/2021 00:04:18 - INFO - __main__ -   Batch number = 88
12/27/2021 00:04:18 - INFO - __main__ -   Batch number = 89
12/27/2021 00:04:18 - INFO - __main__ -   Batch number = 90
12/27/2021 00:04:19 - INFO - __main__ -   Batch number = 91
12/27/2021 00:04:19 - INFO - __main__ -   Batch number = 92
12/27/2021 00:04:19 - INFO - __main__ -   Batch number = 93
12/27/2021 00:04:19 - INFO - __main__ -   Batch number = 94
12/27/2021 00:04:19 - INFO - __main__ -   Batch number = 95
12/27/2021 00:04:19 - INFO - __main__ -   Batch number = 96
12/27/2021 00:04:20 - INFO - __main__ -   Batch number = 97
12/27/2021 00:04:20 - INFO - __main__ -   Batch number = 98
12/27/2021 00:04:20 - INFO - __main__ -   Batch number = 99
12/27/2021 00:04:20 - INFO - __main__ -   Batch number = 100
12/27/2021 00:04:20 - INFO - __main__ -   Batch number = 101
12/27/2021 00:04:20 - INFO - __main__ -   Batch number = 102
12/27/2021 00:04:20 - INFO - __main__ -   Batch number = 103
12/27/2021 00:04:21 - INFO - __main__ -   Batch number = 104
12/27/2021 00:04:21 - INFO - __main__ -   Batch number = 105
12/27/2021 00:04:21 - INFO - __main__ -   Batch number = 106
12/27/2021 00:04:21 - INFO - __main__ -   Batch number = 107
12/27/2021 00:04:21 - INFO - __main__ -   Batch number = 108
12/27/2021 00:04:21 - INFO - __main__ -   Batch number = 109
12/27/2021 00:04:22 - INFO - __main__ -   Batch number = 110
12/27/2021 00:04:22 - INFO - __main__ -   Batch number = 111
12/27/2021 00:04:22 - INFO - __main__ -   Batch number = 112
12/27/2021 00:04:22 - INFO - __main__ -   Batch number = 113
12/27/2021 00:04:22 - INFO - __main__ -   Batch number = 114
12/27/2021 00:04:22 - INFO - __main__ -   Batch number = 115
12/27/2021 00:04:23 - INFO - __main__ -   Batch number = 116
12/27/2021 00:04:23 - INFO - __main__ -   Batch number = 117
12/27/2021 00:04:23 - INFO - __main__ -   Batch number = 118
12/27/2021 00:04:23 - INFO - __main__ -   Batch number = 119
12/27/2021 00:04:23 - INFO - __main__ -   Batch number = 120
12/27/2021 00:04:23 - INFO - __main__ -   Batch number = 121
12/27/2021 00:04:23 - INFO - __main__ -   Batch number = 122
12/27/2021 00:04:24 - INFO - __main__ -   Batch number = 123
12/27/2021 00:04:24 - INFO - __main__ -   Batch number = 124
12/27/2021 00:04:24 - INFO - __main__ -   Batch number = 125
12/27/2021 00:04:24 - INFO - __main__ -   Batch number = 126
12/27/2021 00:04:24 - INFO - __main__ -   Batch number = 127
12/27/2021 00:04:24 - INFO - __main__ -   Batch number = 128
12/27/2021 00:04:25 - INFO - __main__ -   Batch number = 129
12/27/2021 00:04:25 - INFO - __main__ -   Batch number = 130
12/27/2021 00:04:25 - INFO - __main__ -   Batch number = 131
12/27/2021 00:04:25 - INFO - __main__ -   Batch number = 132
12/27/2021 00:04:25 - INFO - __main__ -   Batch number = 133
12/27/2021 00:04:25 - INFO - __main__ -   Batch number = 134
12/27/2021 00:04:25 - INFO - __main__ -   Batch number = 135
12/27/2021 00:04:26 - INFO - __main__ -   Batch number = 136
12/27/2021 00:04:26 - INFO - __main__ -   Batch number = 137
12/27/2021 00:04:26 - INFO - __main__ -   Batch number = 138
12/27/2021 00:04:26 - INFO - __main__ -   Batch number = 139
12/27/2021 00:04:26 - INFO - __main__ -   Batch number = 140
12/27/2021 00:04:27 - INFO - __main__ -   Batch number = 141
12/27/2021 00:04:27 - INFO - __main__ -   Batch number = 142
12/27/2021 00:04:27 - INFO - __main__ -   Batch number = 143
12/27/2021 00:04:27 - INFO - __main__ -   Batch number = 144
12/27/2021 00:04:27 - INFO - __main__ -   Batch number = 145
12/27/2021 00:04:27 - INFO - __main__ -   Batch number = 146
12/27/2021 00:04:28 - INFO - __main__ -   Batch number = 147
12/27/2021 00:04:28 - INFO - __main__ -   Batch number = 148
12/27/2021 00:04:28 - INFO - __main__ -   Batch number = 149
12/27/2021 00:04:28 - INFO - __main__ -   Batch number = 150
12/27/2021 00:04:28 - INFO - __main__ -   Batch number = 151
12/27/2021 00:04:28 - INFO - __main__ -   Batch number = 152
12/27/2021 00:04:29 - INFO - __main__ -   Batch number = 153
12/27/2021 00:04:29 - INFO - __main__ -   Batch number = 154
12/27/2021 00:04:29 - INFO - __main__ -   Batch number = 155
12/27/2021 00:04:29 - INFO - __main__ -   Batch number = 156
12/27/2021 00:04:29 - INFO - __main__ -   Batch number = 157
12/27/2021 00:04:29 - INFO - __main__ -   Batch number = 158
12/27/2021 00:04:29 - INFO - __main__ -   Batch number = 159
12/27/2021 00:04:30 - INFO - __main__ -   Batch number = 160
12/27/2021 00:04:30 - INFO - __main__ -   Batch number = 161
12/27/2021 00:04:30 - INFO - __main__ -   Batch number = 162
12/27/2021 00:04:30 - INFO - __main__ -   Batch number = 163
12/27/2021 00:04:30 - INFO - __main__ -   Batch number = 164
12/27/2021 00:04:30 - INFO - __main__ -   Batch number = 165
12/27/2021 00:04:31 - INFO - __main__ -   Batch number = 166
12/27/2021 00:04:31 - INFO - __main__ -   Batch number = 167
12/27/2021 00:04:31 - INFO - __main__ -   Batch number = 168
12/27/2021 00:04:31 - INFO - __main__ -   Batch number = 169
12/27/2021 00:04:31 - INFO - __main__ -   Batch number = 170
12/27/2021 00:04:32 - INFO - __main__ -   Batch number = 171
12/27/2021 00:04:32 - INFO - __main__ -   Batch number = 172
12/27/2021 00:04:32 - INFO - __main__ -   Batch number = 173
12/27/2021 00:04:32 - INFO - __main__ -   Batch number = 174
12/27/2021 00:04:32 - INFO - __main__ -   Batch number = 175
12/27/2021 00:04:32 - INFO - __main__ -   Batch number = 176
12/27/2021 00:04:33 - INFO - __main__ -   Batch number = 177
12/27/2021 00:04:33 - INFO - __main__ -   Batch number = 178
12/27/2021 00:04:33 - INFO - __main__ -   Batch number = 179
12/27/2021 00:04:33 - INFO - __main__ -   Batch number = 180
12/27/2021 00:04:33 - INFO - __main__ -   Batch number = 181
12/27/2021 00:04:33 - INFO - __main__ -   Batch number = 182
12/27/2021 00:04:33 - INFO - __main__ -   Batch number = 183
12/27/2021 00:04:34 - INFO - __main__ -   Batch number = 184
12/27/2021 00:04:34 - INFO - __main__ -   Batch number = 185
12/27/2021 00:04:34 - INFO - __main__ -   Batch number = 186
12/27/2021 00:04:34 - INFO - __main__ -   Batch number = 187
12/27/2021 00:04:34 - INFO - __main__ -   Batch number = 188
12/27/2021 00:04:34 - INFO - __main__ -   Batch number = 189
12/27/2021 00:04:35 - INFO - __main__ -   Batch number = 190
12/27/2021 00:04:35 - INFO - __main__ -   Batch number = 191
12/27/2021 00:04:35 - INFO - __main__ -   Batch number = 192
12/27/2021 00:04:35 - INFO - __main__ -   Batch number = 193
12/27/2021 00:04:35 - INFO - __main__ -   Batch number = 194
12/27/2021 00:04:35 - INFO - __main__ -   Batch number = 195
12/27/2021 00:04:35 - INFO - __main__ -   Batch number = 196
12/27/2021 00:04:36 - INFO - __main__ -   Batch number = 197
12/27/2021 00:04:36 - INFO - __main__ -   Batch number = 198
12/27/2021 00:04:36 - INFO - __main__ -   Batch number = 199
12/27/2021 00:04:36 - INFO - __main__ -   Batch number = 200
12/27/2021 00:04:37 - INFO - __main__ -   Batch number = 201
12/27/2021 00:04:37 - INFO - __main__ -   Batch number = 202
12/27/2021 00:04:37 - INFO - __main__ -   Batch number = 203
12/27/2021 00:04:37 - INFO - __main__ -   Batch number = 204
12/27/2021 00:04:37 - INFO - __main__ -   Batch number = 205
12/27/2021 00:04:37 - INFO - __main__ -   Batch number = 206
12/27/2021 00:04:37 - INFO - __main__ -   Batch number = 207
12/27/2021 00:04:38 - INFO - __main__ -   Batch number = 208
12/27/2021 00:04:38 - INFO - __main__ -   Batch number = 209
12/27/2021 00:04:38 - INFO - __main__ -   Batch number = 210
12/27/2021 00:04:38 - INFO - __main__ -   Batch number = 211
12/27/2021 00:04:38 - INFO - __main__ -   Batch number = 212
12/27/2021 00:04:38 - INFO - __main__ -   Batch number = 213
12/27/2021 00:04:39 - INFO - __main__ -   Batch number = 214
12/27/2021 00:04:39 - INFO - __main__ -   Batch number = 215
12/27/2021 00:04:39 - INFO - __main__ -   Batch number = 216
12/27/2021 00:04:39 - INFO - __main__ -   Batch number = 217
12/27/2021 00:04:39 - INFO - __main__ -   Batch number = 218
12/27/2021 00:04:39 - INFO - __main__ -   Batch number = 219
12/27/2021 00:04:40 - INFO - __main__ -   Batch number = 220
12/27/2021 00:04:40 - INFO - __main__ -   Batch number = 221
12/27/2021 00:04:40 - INFO - __main__ -   Batch number = 222
12/27/2021 00:04:40 - INFO - __main__ -   Batch number = 223
12/27/2021 00:04:40 - INFO - __main__ -   Batch number = 224
12/27/2021 00:04:40 - INFO - __main__ -   Batch number = 225
12/27/2021 00:04:40 - INFO - __main__ -   Batch number = 226
12/27/2021 00:04:41 - INFO - __main__ -   Batch number = 227
12/27/2021 00:04:41 - INFO - __main__ -   Batch number = 228
12/27/2021 00:04:41 - INFO - __main__ -   Batch number = 229
12/27/2021 00:04:41 - INFO - __main__ -   Batch number = 230
12/27/2021 00:04:41 - INFO - __main__ -   Batch number = 231
12/27/2021 00:04:41 - INFO - __main__ -   Batch number = 232
12/27/2021 00:04:42 - INFO - __main__ -   Batch number = 233
12/27/2021 00:04:42 - INFO - __main__ -   Batch number = 234
12/27/2021 00:04:42 - INFO - __main__ -   Batch number = 235
12/27/2021 00:04:42 - INFO - __main__ -   Batch number = 236
12/27/2021 00:04:42 - INFO - __main__ -   Batch number = 237
12/27/2021 00:04:42 - INFO - __main__ -   Batch number = 238
12/27/2021 00:04:43 - INFO - __main__ -   Batch number = 239
12/27/2021 00:04:43 - INFO - __main__ -   Batch number = 240
12/27/2021 00:04:43 - INFO - __main__ -   Batch number = 241
12/27/2021 00:04:43 - INFO - __main__ -   Batch number = 242
12/27/2021 00:04:43 - INFO - __main__ -   Batch number = 243
12/27/2021 00:04:43 - INFO - __main__ -   Batch number = 244
12/27/2021 00:04:43 - INFO - __main__ -   Batch number = 245
12/27/2021 00:04:44 - INFO - __main__ -   Batch number = 246
12/27/2021 00:04:44 - INFO - __main__ -   Batch number = 247
12/27/2021 00:04:44 - INFO - __main__ -   Batch number = 248
12/27/2021 00:04:44 - INFO - __main__ -   Batch number = 249
12/27/2021 00:04:44 - INFO - __main__ -   Batch number = 250
12/27/2021 00:04:44 - INFO - __main__ -   Batch number = 251
12/27/2021 00:04:45 - INFO - __main__ -   Batch number = 252
12/27/2021 00:04:45 - INFO - __main__ -   Batch number = 253
12/27/2021 00:04:45 - INFO - __main__ -   Batch number = 254
12/27/2021 00:04:45 - INFO - __main__ -   Batch number = 255
12/27/2021 00:04:45 - INFO - __main__ -   Batch number = 256
12/27/2021 00:04:45 - INFO - __main__ -   Batch number = 257
12/27/2021 00:04:46 - INFO - __main__ -   Batch number = 258
12/27/2021 00:04:46 - INFO - __main__ -   Batch number = 259
12/27/2021 00:04:46 - INFO - __main__ -   Batch number = 260
12/27/2021 00:04:46 - INFO - __main__ -   Batch number = 261
12/27/2021 00:04:46 - INFO - __main__ -   Batch number = 262
12/27/2021 00:04:46 - INFO - __main__ -   Batch number = 263
12/27/2021 00:04:47 - INFO - __main__ -   Batch number = 264
12/27/2021 00:04:47 - INFO - __main__ -   Batch number = 265
12/27/2021 00:04:47 - INFO - __main__ -   Batch number = 266
12/27/2021 00:04:47 - INFO - __main__ -   Batch number = 267
12/27/2021 00:04:47 - INFO - __main__ -   Batch number = 268
12/27/2021 00:04:47 - INFO - __main__ -   Batch number = 269
12/27/2021 00:04:47 - INFO - __main__ -   Batch number = 270
12/27/2021 00:04:48 - INFO - __main__ -   Batch number = 271
12/27/2021 00:04:48 - INFO - __main__ -   Batch number = 272
12/27/2021 00:04:48 - INFO - __main__ -   Batch number = 273
12/27/2021 00:04:48 - INFO - __main__ -   Batch number = 274
12/27/2021 00:04:48 - INFO - __main__ -   Batch number = 275
12/27/2021 00:04:48 - INFO - __main__ -   Batch number = 276
12/27/2021 00:04:49 - INFO - __main__ -   Batch number = 277
12/27/2021 00:04:49 - INFO - __main__ -   Batch number = 278
12/27/2021 00:04:49 - INFO - __main__ -   Batch number = 279
12/27/2021 00:04:49 - INFO - __main__ -   Batch number = 280
12/27/2021 00:04:49 - INFO - __main__ -   Batch number = 281
12/27/2021 00:04:49 - INFO - __main__ -   Batch number = 282
12/27/2021 00:04:50 - INFO - __main__ -   Batch number = 283
12/27/2021 00:04:50 - INFO - __main__ -   Batch number = 284
12/27/2021 00:04:50 - INFO - __main__ -   Batch number = 285
12/27/2021 00:04:50 - INFO - __main__ -   Batch number = 286
12/27/2021 00:04:50 - INFO - __main__ -   Batch number = 287
12/27/2021 00:04:50 - INFO - __main__ -   Batch number = 288
12/27/2021 00:04:50 - INFO - __main__ -   Batch number = 289
12/27/2021 00:04:51 - INFO - __main__ -   Batch number = 290
12/27/2021 00:04:51 - INFO - __main__ -   Batch number = 291
12/27/2021 00:04:51 - INFO - __main__ -   Batch number = 292
12/27/2021 00:04:51 - INFO - __main__ -   Batch number = 293
12/27/2021 00:04:51 - INFO - __main__ -   Batch number = 294
12/27/2021 00:04:51 - INFO - __main__ -   Batch number = 295
12/27/2021 00:04:52 - INFO - __main__ -   Batch number = 296
12/27/2021 00:04:52 - INFO - __main__ -   Batch number = 297
12/27/2021 00:04:52 - INFO - __main__ -   Batch number = 298
12/27/2021 00:04:52 - INFO - __main__ -   Batch number = 299
12/27/2021 00:04:52 - INFO - __main__ -   Batch number = 300
12/27/2021 00:04:52 - INFO - __main__ -   Batch number = 301
12/27/2021 00:04:53 - INFO - __main__ -   Batch number = 302
12/27/2021 00:04:53 - INFO - __main__ -   Batch number = 303
12/27/2021 00:04:53 - INFO - __main__ -   Batch number = 304
12/27/2021 00:04:53 - INFO - __main__ -   Batch number = 305
12/27/2021 00:04:53 - INFO - __main__ -   Batch number = 306
12/27/2021 00:04:53 - INFO - __main__ -   Batch number = 307
12/27/2021 00:04:54 - INFO - __main__ -   Batch number = 308
12/27/2021 00:04:54 - INFO - __main__ -   Batch number = 309
12/27/2021 00:04:54 - INFO - __main__ -   Batch number = 310
12/27/2021 00:04:54 - INFO - __main__ -   Batch number = 311
12/27/2021 00:04:54 - INFO - __main__ -   Batch number = 312
12/27/2021 00:04:54 - INFO - __main__ -   Batch number = 313
12/27/2021 00:04:55 - INFO - __main__ -   Batch number = 314
12/27/2021 00:04:55 - INFO - __main__ -   Batch number = 315
12/27/2021 00:04:55 - INFO - __main__ -   Batch number = 316
12/27/2021 00:04:55 - INFO - __main__ -   Batch number = 317
12/27/2021 00:04:55 - INFO - __main__ -   Batch number = 318
12/27/2021 00:04:55 - INFO - __main__ -   Batch number = 319
12/27/2021 00:04:56 - INFO - __main__ -   Batch number = 320
12/27/2021 00:04:56 - INFO - __main__ -   Batch number = 321
12/27/2021 00:04:58 - INFO - __main__ -   ***** Evaluation result  in zh *****
12/27/2021 00:04:58 - INFO - __main__ -     f1 = 0.32028541787910225
12/27/2021 00:04:58 - INFO - __main__ -     loss = 3.8251013213600324
12/27/2021 00:04:58 - INFO - __main__ -     precision = 0.2345463978654017
12/27/2021 00:04:58 - INFO - __main__ -     recall = 0.5048257158809922
12/27/2021 00:04:58 - INFO - __main__ -   Language adapter for ar not found, using pt instead
12/27/2021 00:04:58 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:04:58 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:04:58 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:04:58 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
12/27/2021 00:05:00 - INFO - __main__ -   ***** Running evaluation  in ar *****
12/27/2021 00:05:00 - INFO - __main__ -     Num examples = 10000
12/27/2021 00:05:00 - INFO - __main__ -     Batch size = 32
12/27/2021 00:05:00 - INFO - __main__ -   Batch number = 1
12/27/2021 00:05:00 - INFO - __main__ -   Batch number = 2
12/27/2021 00:05:00 - INFO - __main__ -   Batch number = 3
12/27/2021 00:05:00 - INFO - __main__ -   Batch number = 4
12/27/2021 00:05:00 - INFO - __main__ -   Batch number = 5
12/27/2021 00:05:00 - INFO - __main__ -   Batch number = 6
12/27/2021 00:05:01 - INFO - __main__ -   Batch number = 7
12/27/2021 00:05:01 - INFO - __main__ -   Batch number = 8
12/27/2021 00:05:01 - INFO - __main__ -   Batch number = 9
12/27/2021 00:05:01 - INFO - __main__ -   Batch number = 10
12/27/2021 00:05:01 - INFO - __main__ -   Batch number = 11
12/27/2021 00:05:02 - INFO - __main__ -   Batch number = 12
12/27/2021 00:05:02 - INFO - __main__ -   Batch number = 13
12/27/2021 00:05:02 - INFO - __main__ -   Batch number = 14
12/27/2021 00:05:02 - INFO - __main__ -   Batch number = 15
12/27/2021 00:05:02 - INFO - __main__ -   Batch number = 16
12/27/2021 00:05:02 - INFO - __main__ -   Batch number = 17
12/27/2021 00:05:02 - INFO - __main__ -   Batch number = 18
12/27/2021 00:05:03 - INFO - __main__ -   Batch number = 19
12/27/2021 00:05:03 - INFO - __main__ -   Batch number = 20
12/27/2021 00:05:03 - INFO - __main__ -   Batch number = 21
12/27/2021 00:05:03 - INFO - __main__ -   Batch number = 22
12/27/2021 00:05:03 - INFO - __main__ -   Batch number = 23
12/27/2021 00:05:03 - INFO - __main__ -   Batch number = 24
12/27/2021 00:05:04 - INFO - __main__ -   Batch number = 25
12/27/2021 00:05:04 - INFO - __main__ -   Batch number = 26
12/27/2021 00:05:04 - INFO - __main__ -   Batch number = 27
12/27/2021 00:05:04 - INFO - __main__ -   Batch number = 28
12/27/2021 00:05:04 - INFO - __main__ -   Batch number = 29
12/27/2021 00:05:04 - INFO - __main__ -   Batch number = 30
12/27/2021 00:05:04 - INFO - __main__ -   Batch number = 31
12/27/2021 00:05:05 - INFO - __main__ -   Batch number = 32
12/27/2021 00:05:05 - INFO - __main__ -   Batch number = 33
12/27/2021 00:05:05 - INFO - __main__ -   Batch number = 34
12/27/2021 00:05:05 - INFO - __main__ -   Batch number = 35
12/27/2021 00:05:05 - INFO - __main__ -   Batch number = 36
12/27/2021 00:05:05 - INFO - __main__ -   Batch number = 37
12/27/2021 00:05:06 - INFO - __main__ -   Batch number = 38
12/27/2021 00:05:06 - INFO - __main__ -   Batch number = 39
12/27/2021 00:05:06 - INFO - __main__ -   Batch number = 40
12/27/2021 00:05:06 - INFO - __main__ -   Batch number = 41
12/27/2021 00:05:06 - INFO - __main__ -   Batch number = 42
12/27/2021 00:05:06 - INFO - __main__ -   Batch number = 43
12/27/2021 00:05:06 - INFO - __main__ -   Batch number = 44
12/27/2021 00:05:07 - INFO - __main__ -   Batch number = 45
12/27/2021 00:05:07 - INFO - __main__ -   Batch number = 46
12/27/2021 00:05:07 - INFO - __main__ -   Batch number = 47
12/27/2021 00:05:07 - INFO - __main__ -   Batch number = 48
12/27/2021 00:05:07 - INFO - __main__ -   Batch number = 49
12/27/2021 00:05:07 - INFO - __main__ -   Batch number = 50
12/27/2021 00:05:08 - INFO - __main__ -   Batch number = 51
12/27/2021 00:05:08 - INFO - __main__ -   Batch number = 52
12/27/2021 00:05:08 - INFO - __main__ -   Batch number = 53
12/27/2021 00:05:08 - INFO - __main__ -   Batch number = 54
12/27/2021 00:05:08 - INFO - __main__ -   Batch number = 55
12/27/2021 00:05:08 - INFO - __main__ -   Batch number = 56
12/27/2021 00:05:08 - INFO - __main__ -   Batch number = 57
12/27/2021 00:05:09 - INFO - __main__ -   Batch number = 58
12/27/2021 00:05:09 - INFO - __main__ -   Batch number = 59
12/27/2021 00:05:09 - INFO - __main__ -   Batch number = 60
12/27/2021 00:05:09 - INFO - __main__ -   Batch number = 61
12/27/2021 00:05:09 - INFO - __main__ -   Batch number = 62
12/27/2021 00:05:09 - INFO - __main__ -   Batch number = 63
12/27/2021 00:05:10 - INFO - __main__ -   Batch number = 64
12/27/2021 00:05:10 - INFO - __main__ -   Batch number = 65
12/27/2021 00:05:10 - INFO - __main__ -   Batch number = 66
12/27/2021 00:05:10 - INFO - __main__ -   Batch number = 67
12/27/2021 00:05:10 - INFO - __main__ -   Batch number = 68
12/27/2021 00:05:10 - INFO - __main__ -   Batch number = 69
12/27/2021 00:05:10 - INFO - __main__ -   Batch number = 70
12/27/2021 00:05:11 - INFO - __main__ -   Batch number = 71
12/27/2021 00:05:11 - INFO - __main__ -   Batch number = 72
12/27/2021 00:05:11 - INFO - __main__ -   Batch number = 73
12/27/2021 00:05:11 - INFO - __main__ -   Batch number = 74
12/27/2021 00:05:11 - INFO - __main__ -   Batch number = 75
12/27/2021 00:05:11 - INFO - __main__ -   Batch number = 76
12/27/2021 00:05:12 - INFO - __main__ -   Batch number = 77
12/27/2021 00:05:12 - INFO - __main__ -   Batch number = 78
12/27/2021 00:05:12 - INFO - __main__ -   Batch number = 79
12/27/2021 00:05:12 - INFO - __main__ -   Batch number = 80
12/27/2021 00:05:12 - INFO - __main__ -   Batch number = 81
12/27/2021 00:05:12 - INFO - __main__ -   Batch number = 82
12/27/2021 00:05:12 - INFO - __main__ -   Batch number = 83
12/27/2021 00:05:13 - INFO - __main__ -   Batch number = 84
12/27/2021 00:05:13 - INFO - __main__ -   Batch number = 85
12/27/2021 00:05:13 - INFO - __main__ -   Batch number = 86
12/27/2021 00:05:13 - INFO - __main__ -   Batch number = 87
12/27/2021 00:05:13 - INFO - __main__ -   Batch number = 88
12/27/2021 00:05:13 - INFO - __main__ -   Batch number = 89
12/27/2021 00:05:14 - INFO - __main__ -   Batch number = 90
12/27/2021 00:05:14 - INFO - __main__ -   Batch number = 91
12/27/2021 00:05:14 - INFO - __main__ -   Batch number = 92
12/27/2021 00:05:14 - INFO - __main__ -   Batch number = 93
12/27/2021 00:05:14 - INFO - __main__ -   Batch number = 94
12/27/2021 00:05:14 - INFO - __main__ -   Batch number = 95
12/27/2021 00:05:14 - INFO - __main__ -   Batch number = 96
12/27/2021 00:05:15 - INFO - __main__ -   Batch number = 97
12/27/2021 00:05:15 - INFO - __main__ -   Batch number = 98
12/27/2021 00:05:15 - INFO - __main__ -   Batch number = 99
12/27/2021 00:05:15 - INFO - __main__ -   Batch number = 100
12/27/2021 00:05:15 - INFO - __main__ -   Batch number = 101
12/27/2021 00:05:15 - INFO - __main__ -   Batch number = 102
12/27/2021 00:05:16 - INFO - __main__ -   Batch number = 103
12/27/2021 00:05:16 - INFO - __main__ -   Batch number = 104
12/27/2021 00:05:16 - INFO - __main__ -   Batch number = 105
12/27/2021 00:05:16 - INFO - __main__ -   Batch number = 106
12/27/2021 00:05:16 - INFO - __main__ -   Batch number = 107
12/27/2021 00:05:16 - INFO - __main__ -   Batch number = 108
12/27/2021 00:05:17 - INFO - __main__ -   Batch number = 109
12/27/2021 00:05:17 - INFO - __main__ -   Batch number = 110
12/27/2021 00:05:17 - INFO - __main__ -   Batch number = 111
12/27/2021 00:05:17 - INFO - __main__ -   Batch number = 112
12/27/2021 00:05:17 - INFO - __main__ -   Batch number = 113
12/27/2021 00:05:17 - INFO - __main__ -   Batch number = 114
12/27/2021 00:05:18 - INFO - __main__ -   Batch number = 115
12/27/2021 00:05:18 - INFO - __main__ -   Batch number = 116
12/27/2021 00:05:18 - INFO - __main__ -   Batch number = 117
12/27/2021 00:05:18 - INFO - __main__ -   Batch number = 118
12/27/2021 00:05:18 - INFO - __main__ -   Batch number = 119
12/27/2021 00:05:18 - INFO - __main__ -   Batch number = 120
12/27/2021 00:05:19 - INFO - __main__ -   Batch number = 121
12/27/2021 00:05:19 - INFO - __main__ -   Batch number = 122
12/27/2021 00:05:19 - INFO - __main__ -   Batch number = 123
12/27/2021 00:05:19 - INFO - __main__ -   Batch number = 124
12/27/2021 00:05:19 - INFO - __main__ -   Batch number = 125
12/27/2021 00:05:19 - INFO - __main__ -   Batch number = 126
12/27/2021 00:05:19 - INFO - __main__ -   Batch number = 127
12/27/2021 00:05:20 - INFO - __main__ -   Batch number = 128
12/27/2021 00:05:20 - INFO - __main__ -   Batch number = 129
12/27/2021 00:05:20 - INFO - __main__ -   Batch number = 130
12/27/2021 00:05:20 - INFO - __main__ -   Batch number = 131
12/27/2021 00:05:20 - INFO - __main__ -   Batch number = 132
12/27/2021 00:05:20 - INFO - __main__ -   Batch number = 133
12/27/2021 00:05:21 - INFO - __main__ -   Batch number = 134
12/27/2021 00:05:21 - INFO - __main__ -   Batch number = 135
12/27/2021 00:05:21 - INFO - __main__ -   Batch number = 136
12/27/2021 00:05:21 - INFO - __main__ -   Batch number = 137
12/27/2021 00:05:21 - INFO - __main__ -   Batch number = 138
12/27/2021 00:05:21 - INFO - __main__ -   Batch number = 139
12/27/2021 00:05:21 - INFO - __main__ -   Batch number = 140
12/27/2021 00:05:22 - INFO - __main__ -   Batch number = 141
12/27/2021 00:05:22 - INFO - __main__ -   Batch number = 142
12/27/2021 00:05:22 - INFO - __main__ -   Batch number = 143
12/27/2021 00:05:22 - INFO - __main__ -   Batch number = 144
12/27/2021 00:05:22 - INFO - __main__ -   Batch number = 145
12/27/2021 00:05:22 - INFO - __main__ -   Batch number = 146
12/27/2021 00:05:23 - INFO - __main__ -   Batch number = 147
12/27/2021 00:05:23 - INFO - __main__ -   Batch number = 148
12/27/2021 00:05:23 - INFO - __main__ -   Batch number = 149
12/27/2021 00:05:23 - INFO - __main__ -   Batch number = 150
12/27/2021 00:05:23 - INFO - __main__ -   Batch number = 151
12/27/2021 00:05:23 - INFO - __main__ -   Batch number = 152
12/27/2021 00:05:24 - INFO - __main__ -   Batch number = 153
12/27/2021 00:05:24 - INFO - __main__ -   Batch number = 154
12/27/2021 00:05:24 - INFO - __main__ -   Batch number = 155
12/27/2021 00:05:24 - INFO - __main__ -   Batch number = 156
12/27/2021 00:05:24 - INFO - __main__ -   Batch number = 157
12/27/2021 00:05:24 - INFO - __main__ -   Batch number = 158
12/27/2021 00:05:24 - INFO - __main__ -   Batch number = 159
12/27/2021 00:05:25 - INFO - __main__ -   Batch number = 160
12/27/2021 00:05:25 - INFO - __main__ -   Batch number = 161
12/27/2021 00:05:25 - INFO - __main__ -   Batch number = 162
12/27/2021 00:05:25 - INFO - __main__ -   Batch number = 163
12/27/2021 00:05:25 - INFO - __main__ -   Batch number = 164
12/27/2021 00:05:25 - INFO - __main__ -   Batch number = 165
12/27/2021 00:05:26 - INFO - __main__ -   Batch number = 166
12/27/2021 00:05:26 - INFO - __main__ -   Batch number = 167
12/27/2021 00:05:26 - INFO - __main__ -   Batch number = 168
12/27/2021 00:05:26 - INFO - __main__ -   Batch number = 169
12/27/2021 00:05:26 - INFO - __main__ -   Batch number = 170
12/27/2021 00:05:26 - INFO - __main__ -   Batch number = 171
12/27/2021 00:05:27 - INFO - __main__ -   Batch number = 172
12/27/2021 00:05:27 - INFO - __main__ -   Batch number = 173
12/27/2021 00:05:27 - INFO - __main__ -   Batch number = 174
12/27/2021 00:05:27 - INFO - __main__ -   Batch number = 175
12/27/2021 00:05:27 - INFO - __main__ -   Batch number = 176
12/27/2021 00:05:27 - INFO - __main__ -   Batch number = 177
12/27/2021 00:05:28 - INFO - __main__ -   Batch number = 178
12/27/2021 00:05:28 - INFO - __main__ -   Batch number = 179
12/27/2021 00:05:28 - INFO - __main__ -   Batch number = 180
12/27/2021 00:05:28 - INFO - __main__ -   Batch number = 181
12/27/2021 00:05:28 - INFO - __main__ -   Batch number = 182
12/27/2021 00:05:28 - INFO - __main__ -   Batch number = 183
12/27/2021 00:05:28 - INFO - __main__ -   Batch number = 184
12/27/2021 00:05:29 - INFO - __main__ -   Batch number = 185
12/27/2021 00:05:29 - INFO - __main__ -   Batch number = 186
12/27/2021 00:05:29 - INFO - __main__ -   Batch number = 187
12/27/2021 00:05:29 - INFO - __main__ -   Batch number = 188
12/27/2021 00:05:29 - INFO - __main__ -   Batch number = 189
12/27/2021 00:05:29 - INFO - __main__ -   Batch number = 190
12/27/2021 00:05:30 - INFO - __main__ -   Batch number = 191
12/27/2021 00:05:30 - INFO - __main__ -   Batch number = 192
12/27/2021 00:05:30 - INFO - __main__ -   Batch number = 193
12/27/2021 00:05:30 - INFO - __main__ -   Batch number = 194
12/27/2021 00:05:30 - INFO - __main__ -   Batch number = 195
12/27/2021 00:05:30 - INFO - __main__ -   Batch number = 196
12/27/2021 00:05:31 - INFO - __main__ -   Batch number = 197
12/27/2021 00:05:31 - INFO - __main__ -   Batch number = 198
12/27/2021 00:05:31 - INFO - __main__ -   Batch number = 199
12/27/2021 00:05:31 - INFO - __main__ -   Batch number = 200
12/27/2021 00:05:31 - INFO - __main__ -   Batch number = 201
12/27/2021 00:05:31 - INFO - __main__ -   Batch number = 202
12/27/2021 00:05:31 - INFO - __main__ -   Batch number = 203
12/27/2021 00:05:32 - INFO - __main__ -   Batch number = 204
12/27/2021 00:05:32 - INFO - __main__ -   Batch number = 205
12/27/2021 00:05:32 - INFO - __main__ -   Batch number = 206
12/27/2021 00:05:32 - INFO - __main__ -   Batch number = 207
12/27/2021 00:05:32 - INFO - __main__ -   Batch number = 208
12/27/2021 00:05:32 - INFO - __main__ -   Batch number = 209
12/27/2021 00:05:33 - INFO - __main__ -   Batch number = 210
12/27/2021 00:05:33 - INFO - __main__ -   Batch number = 211
12/27/2021 00:05:33 - INFO - __main__ -   Batch number = 212
12/27/2021 00:05:33 - INFO - __main__ -   Batch number = 213
12/27/2021 00:05:33 - INFO - __main__ -   Batch number = 214
12/27/2021 00:05:33 - INFO - __main__ -   Batch number = 215
12/27/2021 00:05:34 - INFO - __main__ -   Batch number = 216
12/27/2021 00:05:34 - INFO - __main__ -   Batch number = 217
12/27/2021 00:05:34 - INFO - __main__ -   Batch number = 218
12/27/2021 00:05:34 - INFO - __main__ -   Batch number = 219
12/27/2021 00:05:34 - INFO - __main__ -   Batch number = 220
12/27/2021 00:05:34 - INFO - __main__ -   Batch number = 221
12/27/2021 00:05:34 - INFO - __main__ -   Batch number = 222
12/27/2021 00:05:35 - INFO - __main__ -   Batch number = 223
12/27/2021 00:05:35 - INFO - __main__ -   Batch number = 224
12/27/2021 00:05:35 - INFO - __main__ -   Batch number = 225
12/27/2021 00:05:35 - INFO - __main__ -   Batch number = 226
12/27/2021 00:05:35 - INFO - __main__ -   Batch number = 227
12/27/2021 00:05:35 - INFO - __main__ -   Batch number = 228
12/27/2021 00:05:36 - INFO - __main__ -   Batch number = 229
12/27/2021 00:05:36 - INFO - __main__ -   Batch number = 230
12/27/2021 00:05:36 - INFO - __main__ -   Batch number = 231
12/27/2021 00:05:36 - INFO - __main__ -   Batch number = 232
12/27/2021 00:05:37 - INFO - __main__ -   Batch number = 233
12/27/2021 00:05:37 - INFO - __main__ -   Batch number = 234
12/27/2021 00:05:37 - INFO - __main__ -   Batch number = 235
12/27/2021 00:05:37 - INFO - __main__ -   Batch number = 236
12/27/2021 00:05:37 - INFO - __main__ -   Batch number = 237
12/27/2021 00:05:37 - INFO - __main__ -   Batch number = 238
12/27/2021 00:05:37 - INFO - __main__ -   Batch number = 239
12/27/2021 00:05:38 - INFO - __main__ -   Batch number = 240
12/27/2021 00:05:38 - INFO - __main__ -   Batch number = 241
12/27/2021 00:05:38 - INFO - __main__ -   Batch number = 242
12/27/2021 00:05:38 - INFO - __main__ -   Batch number = 243
12/27/2021 00:05:38 - INFO - __main__ -   Batch number = 244
12/27/2021 00:05:38 - INFO - __main__ -   Batch number = 245
12/27/2021 00:05:39 - INFO - __main__ -   Batch number = 246
12/27/2021 00:05:39 - INFO - __main__ -   Batch number = 247
12/27/2021 00:05:39 - INFO - __main__ -   Batch number = 248
12/27/2021 00:05:39 - INFO - __main__ -   Batch number = 249
12/27/2021 00:05:39 - INFO - __main__ -   Batch number = 250
12/27/2021 00:05:39 - INFO - __main__ -   Batch number = 251
12/27/2021 00:05:40 - INFO - __main__ -   Batch number = 252
12/27/2021 00:05:40 - INFO - __main__ -   Batch number = 253
12/27/2021 00:05:40 - INFO - __main__ -   Batch number = 254
12/27/2021 00:05:40 - INFO - __main__ -   Batch number = 255
12/27/2021 00:05:40 - INFO - __main__ -   Batch number = 256
12/27/2021 00:05:40 - INFO - __main__ -   Batch number = 257
12/27/2021 00:05:40 - INFO - __main__ -   Batch number = 258
12/27/2021 00:05:41 - INFO - __main__ -   Batch number = 259
12/27/2021 00:05:41 - INFO - __main__ -   Batch number = 260
12/27/2021 00:05:41 - INFO - __main__ -   Batch number = 261
12/27/2021 00:05:41 - INFO - __main__ -   Batch number = 262
12/27/2021 00:05:41 - INFO - __main__ -   Batch number = 263
12/27/2021 00:05:42 - INFO - __main__ -   Batch number = 264
12/27/2021 00:05:42 - INFO - __main__ -   Batch number = 265
12/27/2021 00:05:42 - INFO - __main__ -   Batch number = 266
12/27/2021 00:05:42 - INFO - __main__ -   Batch number = 267
12/27/2021 00:05:42 - INFO - __main__ -   Batch number = 268
12/27/2021 00:05:42 - INFO - __main__ -   Batch number = 269
12/27/2021 00:05:43 - INFO - __main__ -   Batch number = 270
12/27/2021 00:05:43 - INFO - __main__ -   Batch number = 271
12/27/2021 00:05:43 - INFO - __main__ -   Batch number = 272
12/27/2021 00:05:43 - INFO - __main__ -   Batch number = 273
12/27/2021 00:05:43 - INFO - __main__ -   Batch number = 274
12/27/2021 00:05:43 - INFO - __main__ -   Batch number = 275
12/27/2021 00:05:44 - INFO - __main__ -   Batch number = 276
12/27/2021 00:05:44 - INFO - __main__ -   Batch number = 277
12/27/2021 00:05:44 - INFO - __main__ -   Batch number = 278
12/27/2021 00:05:44 - INFO - __main__ -   Batch number = 279
12/27/2021 00:05:44 - INFO - __main__ -   Batch number = 280
12/27/2021 00:05:44 - INFO - __main__ -   Batch number = 281
12/27/2021 00:05:44 - INFO - __main__ -   Batch number = 282
12/27/2021 00:05:45 - INFO - __main__ -   Batch number = 283
12/27/2021 00:05:45 - INFO - __main__ -   Batch number = 284
12/27/2021 00:05:45 - INFO - __main__ -   Batch number = 285
12/27/2021 00:05:45 - INFO - __main__ -   Batch number = 286
12/27/2021 00:05:45 - INFO - __main__ -   Batch number = 287
12/27/2021 00:05:45 - INFO - __main__ -   Batch number = 288
12/27/2021 00:05:46 - INFO - __main__ -   Batch number = 289
12/27/2021 00:05:46 - INFO - __main__ -   Batch number = 290
12/27/2021 00:05:46 - INFO - __main__ -   Batch number = 291
12/27/2021 00:05:46 - INFO - __main__ -   Batch number = 292
12/27/2021 00:05:46 - INFO - __main__ -   Batch number = 293
12/27/2021 00:05:47 - INFO - __main__ -   Batch number = 294
12/27/2021 00:05:47 - INFO - __main__ -   Batch number = 295
12/27/2021 00:05:47 - INFO - __main__ -   Batch number = 296
12/27/2021 00:05:47 - INFO - __main__ -   Batch number = 297
12/27/2021 00:05:47 - INFO - __main__ -   Batch number = 298
12/27/2021 00:05:47 - INFO - __main__ -   Batch number = 299
12/27/2021 00:05:48 - INFO - __main__ -   Batch number = 300
12/27/2021 00:05:48 - INFO - __main__ -   Batch number = 301
12/27/2021 00:05:48 - INFO - __main__ -   Batch number = 302
12/27/2021 00:05:48 - INFO - __main__ -   Batch number = 303
12/27/2021 00:05:48 - INFO - __main__ -   Batch number = 304
12/27/2021 00:05:48 - INFO - __main__ -   Batch number = 305
12/27/2021 00:05:48 - INFO - __main__ -   Batch number = 306
12/27/2021 00:05:49 - INFO - __main__ -   Batch number = 307
12/27/2021 00:05:49 - INFO - __main__ -   Batch number = 308
12/27/2021 00:05:49 - INFO - __main__ -   Batch number = 309
12/27/2021 00:05:49 - INFO - __main__ -   Batch number = 310
12/27/2021 00:05:49 - INFO - __main__ -   Batch number = 311
12/27/2021 00:05:49 - INFO - __main__ -   Batch number = 312
12/27/2021 00:05:50 - INFO - __main__ -   Batch number = 313
12/27/2021 00:05:51 - INFO - __main__ -   ***** Evaluation result  in ar *****
12/27/2021 00:05:51 - INFO - __main__ -     f1 = 0.32978591246014327
12/27/2021 00:05:51 - INFO - __main__ -     loss = 5.636599961180275
12/27/2021 00:05:51 - INFO - __main__ -     precision = 0.30892164468580297
12/27/2021 00:05:51 - INFO - __main__ -     recall = 0.3536726174615863
12/27/2021 00:05:51 - INFO - __main__ -   Language adapter for jv not found, using pt instead
12/27/2021 00:05:51 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:05:51 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:05:51 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:05:51 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_jv_bert-base-multilingual-cased_128
12/27/2021 00:05:51 - INFO - __main__ -   ***** Running evaluation  in jv *****
12/27/2021 00:05:51 - INFO - __main__ -     Num examples = 100
12/27/2021 00:05:51 - INFO - __main__ -     Batch size = 32
12/27/2021 00:05:51 - INFO - __main__ -   Batch number = 1
12/27/2021 00:05:51 - INFO - __main__ -   Batch number = 2
12/27/2021 00:05:51 - INFO - __main__ -   Batch number = 3
12/27/2021 00:05:51 - INFO - __main__ -   Batch number = 4
12/27/2021 00:05:51 - INFO - __main__ -   ***** Evaluation result  in jv *****
12/27/2021 00:05:51 - INFO - __main__ -     f1 = 0.570342205323194
12/27/2021 00:05:51 - INFO - __main__ -     loss = 3.5524738430976868
12/27/2021 00:05:51 - INFO - __main__ -     precision = 0.5136986301369864
12/27/2021 00:05:51 - INFO - __main__ -     recall = 0.6410256410256411
12/27/2021 00:05:51 - INFO - __main__ -   Language adapter for sw not found, using pt instead
12/27/2021 00:05:51 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:05:51 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:05:51 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:05:51 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_sw_bert-base-multilingual-cased_128
12/27/2021 00:05:51 - INFO - __main__ -   ***** Running evaluation  in sw *****
12/27/2021 00:05:51 - INFO - __main__ -     Num examples = 1000
12/27/2021 00:05:51 - INFO - __main__ -     Batch size = 32
12/27/2021 00:05:51 - INFO - __main__ -   Batch number = 1
12/27/2021 00:05:52 - INFO - __main__ -   Batch number = 2
12/27/2021 00:05:52 - INFO - __main__ -   Batch number = 3
12/27/2021 00:05:52 - INFO - __main__ -   Batch number = 4
12/27/2021 00:05:52 - INFO - __main__ -   Batch number = 5
12/27/2021 00:05:52 - INFO - __main__ -   Batch number = 6
12/27/2021 00:05:52 - INFO - __main__ -   Batch number = 7
12/27/2021 00:05:53 - INFO - __main__ -   Batch number = 8
12/27/2021 00:05:53 - INFO - __main__ -   Batch number = 9
12/27/2021 00:05:53 - INFO - __main__ -   Batch number = 10
12/27/2021 00:05:53 - INFO - __main__ -   Batch number = 11
12/27/2021 00:05:53 - INFO - __main__ -   Batch number = 12
12/27/2021 00:05:53 - INFO - __main__ -   Batch number = 13
12/27/2021 00:05:53 - INFO - __main__ -   Batch number = 14
12/27/2021 00:05:54 - INFO - __main__ -   Batch number = 15
12/27/2021 00:05:54 - INFO - __main__ -   Batch number = 16
12/27/2021 00:05:54 - INFO - __main__ -   Batch number = 17
12/27/2021 00:05:54 - INFO - __main__ -   Batch number = 18
12/27/2021 00:05:54 - INFO - __main__ -   Batch number = 19
12/27/2021 00:05:54 - INFO - __main__ -   Batch number = 20
12/27/2021 00:05:54 - INFO - __main__ -   Batch number = 21
12/27/2021 00:05:55 - INFO - __main__ -   Batch number = 22
12/27/2021 00:05:55 - INFO - __main__ -   Batch number = 23
12/27/2021 00:05:55 - INFO - __main__ -   Batch number = 24
12/27/2021 00:05:55 - INFO - __main__ -   Batch number = 25
12/27/2021 00:05:55 - INFO - __main__ -   Batch number = 26
12/27/2021 00:05:55 - INFO - __main__ -   Batch number = 27
12/27/2021 00:05:56 - INFO - __main__ -   Batch number = 28
12/27/2021 00:05:56 - INFO - __main__ -   Batch number = 29
12/27/2021 00:05:56 - INFO - __main__ -   Batch number = 30
12/27/2021 00:05:56 - INFO - __main__ -   Batch number = 31
12/27/2021 00:05:56 - INFO - __main__ -   Batch number = 32
12/27/2021 00:05:56 - INFO - __main__ -   ***** Evaluation result  in sw *****
12/27/2021 00:05:56 - INFO - __main__ -     f1 = 0.5854632587859425
12/27/2021 00:05:56 - INFO - __main__ -     loss = 3.0700526870787144
12/27/2021 00:05:56 - INFO - __main__ -     precision = 0.5595419847328245
12/27/2021 00:05:56 - INFO - __main__ -     recall = 0.6139028475711893
12/27/2021 00:05:56 - INFO - __main__ -   Language adapter for is not found, using pt instead
12/27/2021 00:05:56 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:05:56 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:05:56 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:05:56 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_is_bert-base-multilingual-cased_128
12/27/2021 00:05:56 - INFO - __main__ -   ***** Running evaluation  in is *****
12/27/2021 00:05:56 - INFO - __main__ -     Num examples = 1000
12/27/2021 00:05:56 - INFO - __main__ -     Batch size = 32
12/27/2021 00:05:56 - INFO - __main__ -   Batch number = 1
12/27/2021 00:05:57 - INFO - __main__ -   Batch number = 2
12/27/2021 00:05:57 - INFO - __main__ -   Batch number = 3
12/27/2021 00:05:57 - INFO - __main__ -   Batch number = 4
12/27/2021 00:05:57 - INFO - __main__ -   Batch number = 5
12/27/2021 00:05:57 - INFO - __main__ -   Batch number = 6
12/27/2021 00:05:57 - INFO - __main__ -   Batch number = 7
12/27/2021 00:05:58 - INFO - __main__ -   Batch number = 8
12/27/2021 00:05:58 - INFO - __main__ -   Batch number = 9
12/27/2021 00:05:58 - INFO - __main__ -   Batch number = 10
12/27/2021 00:05:58 - INFO - __main__ -   Batch number = 11
12/27/2021 00:05:58 - INFO - __main__ -   Batch number = 12
12/27/2021 00:05:58 - INFO - __main__ -   Batch number = 13
12/27/2021 00:05:58 - INFO - __main__ -   Batch number = 14
12/27/2021 00:05:59 - INFO - __main__ -   Batch number = 15
12/27/2021 00:05:59 - INFO - __main__ -   Batch number = 16
12/27/2021 00:05:59 - INFO - __main__ -   Batch number = 17
12/27/2021 00:05:59 - INFO - __main__ -   Batch number = 18
12/27/2021 00:05:59 - INFO - __main__ -   Batch number = 19
12/27/2021 00:05:59 - INFO - __main__ -   Batch number = 20
12/27/2021 00:06:00 - INFO - __main__ -   Batch number = 21
12/27/2021 00:06:00 - INFO - __main__ -   Batch number = 22
12/27/2021 00:06:00 - INFO - __main__ -   Batch number = 23
12/27/2021 00:06:00 - INFO - __main__ -   Batch number = 24
12/27/2021 00:06:00 - INFO - __main__ -   Batch number = 25
12/27/2021 00:06:00 - INFO - __main__ -   Batch number = 26
12/27/2021 00:06:00 - INFO - __main__ -   Batch number = 27
12/27/2021 00:06:01 - INFO - __main__ -   Batch number = 28
12/27/2021 00:06:01 - INFO - __main__ -   Batch number = 29
12/27/2021 00:06:01 - INFO - __main__ -   Batch number = 30
12/27/2021 00:06:01 - INFO - __main__ -   Batch number = 31
12/27/2021 00:06:01 - INFO - __main__ -   Batch number = 32
12/27/2021 00:06:01 - INFO - __main__ -   ***** Evaluation result  in is *****
12/27/2021 00:06:01 - INFO - __main__ -     f1 = 0.6337448559670782
12/27/2021 00:06:01 - INFO - __main__ -     loss = 1.481986502185464
12/27/2021 00:06:01 - INFO - __main__ -     precision = 0.5849447513812155
12/27/2021 00:06:01 - INFO - __main__ -     recall = 0.6914285714285714
12/27/2021 00:06:01 - INFO - __main__ -   Language adapter for my not found, using pt instead
12/27/2021 00:06:01 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 00:06:01 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 00:06:01 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 00:06:01 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_my_bert-base-multilingual-cased_128
12/27/2021 00:06:01 - INFO - __main__ -   ***** Running evaluation  in my *****
12/27/2021 00:06:01 - INFO - __main__ -     Num examples = 110
12/27/2021 00:06:01 - INFO - __main__ -     Batch size = 32
12/27/2021 00:06:01 - INFO - __main__ -   Batch number = 1
12/27/2021 00:06:02 - INFO - __main__ -   Batch number = 2
12/27/2021 00:06:02 - INFO - __main__ -   Batch number = 3
12/27/2021 00:06:02 - INFO - __main__ -   Batch number = 4
12/27/2021 00:06:02 - INFO - __main__ -   ***** Evaluation result  in my *****
12/27/2021 00:06:02 - INFO - __main__ -     f1 = 0.4280936454849498
12/27/2021 00:06:02 - INFO - __main__ -     loss = 3.363052010536194
12/27/2021 00:06:02 - INFO - __main__ -     precision = 0.35555555555555557
12/27/2021 00:06:02 - INFO - __main__ -     recall = 0.5378151260504201
12/27/2021 13:22:30 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en,ja,zh,ar,jv,sw,is,my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/27/2021 13:22:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
12/27/2021 13:22:30 - INFO - __main__ -   Seed = 1
12/27/2021 13:22:30 - INFO - root -   save model
12/27/2021 13:22:30 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=100.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en,ja,zh,ar,jv,sw,is,my', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//panx/my-bert-base-multilingual-cased-MaxLen128_ner_pt//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='ner', predict_task_adapter='output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
12/27/2021 13:22:30 - INFO - __main__ -   Loading pretrained model and tokenizer
12/27/2021 13:22:34 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
12/27/2021 13:22:40 - INFO - __main__ -   Using lang2id = None
12/27/2021 13:22:40 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
12/27/2021 13:22:40 - INFO - __main__ -   Task Adapter will be loaded from this path output/panx/my-bert-base-multilingual-cased-LR1e-4-epoch100-MaxLen128-TrainLangen_en_s1/checkpoint-best/ner/
12/27/2021 13:22:40 - INFO - root -   Trying to decide if add adapter
12/27/2021 13:22:40 - INFO - root -   loading task adapter
12/27/2021 13:22:40 - INFO - root -   loading lang adpater pt/wiki@ukp
12/27/2021 13:22:40 - INFO - __main__ -   Adapter Languages : ['pt'], Length : 1
12/27/2021 13:22:40 - INFO - __main__ -   Adapter Names ['pt/wiki@ukp'], Length : 1
12/27/2021 13:22:40 - INFO - __main__ -   Language = pt
12/27/2021 13:22:40 - INFO - __main__ -   Adapter Name = pt/wiki@ukp
12/27/2021 13:22:49 - INFO - __main__ -   Language adapter for en not found, using pt instead
12/27/2021 13:22:49 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 13:22:49 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 13:22:49 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 13:22:49 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
12/27/2021 13:22:51 - INFO - __main__ -   ***** Running evaluation  in en *****
12/27/2021 13:22:51 - INFO - __main__ -     Num examples = 10004
12/27/2021 13:22:51 - INFO - __main__ -     Batch size = 32
12/27/2021 13:22:51 - INFO - __main__ -   Batch number = 1
12/27/2021 13:22:51 - INFO - __main__ -   Batch number = 2
12/27/2021 13:22:51 - INFO - __main__ -   Batch number = 3
12/27/2021 13:22:52 - INFO - __main__ -   Batch number = 4
12/27/2021 13:22:52 - INFO - __main__ -   Batch number = 5
12/27/2021 13:22:52 - INFO - __main__ -   Batch number = 6
12/27/2021 13:22:53 - INFO - __main__ -   Batch number = 7
12/27/2021 13:22:53 - INFO - __main__ -   Batch number = 8
12/27/2021 13:22:53 - INFO - __main__ -   Batch number = 9
12/27/2021 13:22:53 - INFO - __main__ -   Batch number = 10
12/27/2021 13:22:53 - INFO - __main__ -   Batch number = 11
12/27/2021 13:22:54 - INFO - __main__ -   Batch number = 12
12/27/2021 13:22:54 - INFO - __main__ -   Batch number = 13
12/27/2021 13:22:54 - INFO - __main__ -   Batch number = 14
12/27/2021 13:22:54 - INFO - __main__ -   Batch number = 15
12/27/2021 13:22:55 - INFO - __main__ -   Batch number = 16
12/27/2021 13:22:55 - INFO - __main__ -   Batch number = 17
12/27/2021 13:22:55 - INFO - __main__ -   Batch number = 18
12/27/2021 13:22:56 - INFO - __main__ -   Batch number = 19
12/27/2021 13:22:56 - INFO - __main__ -   Batch number = 20
12/27/2021 13:22:57 - INFO - __main__ -   Batch number = 21
12/27/2021 13:22:57 - INFO - __main__ -   Batch number = 22
12/27/2021 13:22:57 - INFO - __main__ -   Batch number = 23
12/27/2021 13:22:57 - INFO - __main__ -   Batch number = 24
12/27/2021 13:22:58 - INFO - __main__ -   Batch number = 25
12/27/2021 13:22:58 - INFO - __main__ -   Batch number = 26
12/27/2021 13:22:58 - INFO - __main__ -   Batch number = 27
12/27/2021 13:22:58 - INFO - __main__ -   Batch number = 28
12/27/2021 13:22:59 - INFO - __main__ -   Batch number = 29
12/27/2021 13:22:59 - INFO - __main__ -   Batch number = 30
12/27/2021 13:22:59 - INFO - __main__ -   Batch number = 31
12/27/2021 13:23:00 - INFO - __main__ -   Batch number = 32
12/27/2021 13:23:00 - INFO - __main__ -   Batch number = 33
12/27/2021 13:23:00 - INFO - __main__ -   Batch number = 34
12/27/2021 13:23:00 - INFO - __main__ -   Batch number = 35
12/27/2021 13:23:01 - INFO - __main__ -   Batch number = 36
12/27/2021 13:23:01 - INFO - __main__ -   Batch number = 37
12/27/2021 13:23:01 - INFO - __main__ -   Batch number = 38
12/27/2021 13:23:02 - INFO - __main__ -   Batch number = 39
12/27/2021 13:23:02 - INFO - __main__ -   Batch number = 40
12/27/2021 13:23:02 - INFO - __main__ -   Batch number = 41
12/27/2021 13:23:03 - INFO - __main__ -   Batch number = 42
12/27/2021 13:23:03 - INFO - __main__ -   Batch number = 43
12/27/2021 13:23:03 - INFO - __main__ -   Batch number = 44
12/27/2021 13:23:04 - INFO - __main__ -   Batch number = 45
12/27/2021 13:23:04 - INFO - __main__ -   Batch number = 46
12/27/2021 13:23:04 - INFO - __main__ -   Batch number = 47
12/27/2021 13:23:04 - INFO - __main__ -   Batch number = 48
12/27/2021 13:23:05 - INFO - __main__ -   Batch number = 49
12/27/2021 13:23:05 - INFO - __main__ -   Batch number = 50
12/27/2021 13:23:05 - INFO - __main__ -   Batch number = 51
12/27/2021 13:23:05 - INFO - __main__ -   Batch number = 52
12/27/2021 13:23:06 - INFO - __main__ -   Batch number = 53
12/27/2021 13:23:06 - INFO - __main__ -   Batch number = 54
12/27/2021 13:23:06 - INFO - __main__ -   Batch number = 55
12/27/2021 13:23:07 - INFO - __main__ -   Batch number = 56
12/27/2021 13:23:07 - INFO - __main__ -   Batch number = 57
12/27/2021 13:23:07 - INFO - __main__ -   Batch number = 58
12/27/2021 13:23:08 - INFO - __main__ -   Batch number = 59
12/27/2021 13:23:08 - INFO - __main__ -   Batch number = 60
12/27/2021 13:23:08 - INFO - __main__ -   Batch number = 61
12/27/2021 13:23:09 - INFO - __main__ -   Batch number = 62
12/27/2021 13:23:09 - INFO - __main__ -   Batch number = 63
12/27/2021 13:23:09 - INFO - __main__ -   Batch number = 64
12/27/2021 13:23:10 - INFO - __main__ -   Batch number = 65
12/27/2021 13:23:10 - INFO - __main__ -   Batch number = 66
12/27/2021 13:23:10 - INFO - __main__ -   Batch number = 67
12/27/2021 13:23:10 - INFO - __main__ -   Batch number = 68
12/27/2021 13:23:10 - INFO - __main__ -   Batch number = 69
12/27/2021 13:23:11 - INFO - __main__ -   Batch number = 70
12/27/2021 13:23:11 - INFO - __main__ -   Batch number = 71
12/27/2021 13:23:11 - INFO - __main__ -   Batch number = 72
12/27/2021 13:23:12 - INFO - __main__ -   Batch number = 73
12/27/2021 13:23:12 - INFO - __main__ -   Batch number = 74
12/27/2021 13:23:12 - INFO - __main__ -   Batch number = 75
12/27/2021 13:23:13 - INFO - __main__ -   Batch number = 76
12/27/2021 13:23:13 - INFO - __main__ -   Batch number = 77
12/27/2021 13:23:13 - INFO - __main__ -   Batch number = 78
12/27/2021 13:23:14 - INFO - __main__ -   Batch number = 79
12/27/2021 13:23:14 - INFO - __main__ -   Batch number = 80
12/27/2021 13:23:14 - INFO - __main__ -   Batch number = 81
12/27/2021 13:23:15 - INFO - __main__ -   Batch number = 82
12/27/2021 13:23:15 - INFO - __main__ -   Batch number = 83
12/27/2021 13:23:15 - INFO - __main__ -   Batch number = 84
12/27/2021 13:23:15 - INFO - __main__ -   Batch number = 85
12/27/2021 13:23:16 - INFO - __main__ -   Batch number = 86
12/27/2021 13:23:16 - INFO - __main__ -   Batch number = 87
12/27/2021 13:23:16 - INFO - __main__ -   Batch number = 88
12/27/2021 13:23:16 - INFO - __main__ -   Batch number = 89
12/27/2021 13:23:17 - INFO - __main__ -   Batch number = 90
12/27/2021 13:23:17 - INFO - __main__ -   Batch number = 91
12/27/2021 13:23:17 - INFO - __main__ -   Batch number = 92
12/27/2021 13:23:18 - INFO - __main__ -   Batch number = 93
12/27/2021 13:23:18 - INFO - __main__ -   Batch number = 94
12/27/2021 13:23:18 - INFO - __main__ -   Batch number = 95
12/27/2021 13:23:19 - INFO - __main__ -   Batch number = 96
12/27/2021 13:23:19 - INFO - __main__ -   Batch number = 97
12/27/2021 13:23:19 - INFO - __main__ -   Batch number = 98
12/27/2021 13:23:20 - INFO - __main__ -   Batch number = 99
12/27/2021 13:23:20 - INFO - __main__ -   Batch number = 100
12/27/2021 13:23:20 - INFO - __main__ -   Batch number = 101
12/27/2021 13:23:21 - INFO - __main__ -   Batch number = 102
12/27/2021 13:23:21 - INFO - __main__ -   Batch number = 103
12/27/2021 13:23:21 - INFO - __main__ -   Batch number = 104
12/27/2021 13:23:21 - INFO - __main__ -   Batch number = 105
12/27/2021 13:23:21 - INFO - __main__ -   Batch number = 106
12/27/2021 13:23:22 - INFO - __main__ -   Batch number = 107
12/27/2021 13:23:22 - INFO - __main__ -   Batch number = 108
12/27/2021 13:23:22 - INFO - __main__ -   Batch number = 109
12/27/2021 13:23:23 - INFO - __main__ -   Batch number = 110
12/27/2021 13:23:23 - INFO - __main__ -   Batch number = 111
12/27/2021 13:23:23 - INFO - __main__ -   Batch number = 112
12/27/2021 13:23:24 - INFO - __main__ -   Batch number = 113
12/27/2021 13:23:24 - INFO - __main__ -   Batch number = 114
12/27/2021 13:23:24 - INFO - __main__ -   Batch number = 115
12/27/2021 13:23:25 - INFO - __main__ -   Batch number = 116
12/27/2021 13:23:25 - INFO - __main__ -   Batch number = 117
12/27/2021 13:23:25 - INFO - __main__ -   Batch number = 118
12/27/2021 13:23:26 - INFO - __main__ -   Batch number = 119
12/27/2021 13:23:26 - INFO - __main__ -   Batch number = 120
12/27/2021 13:23:26 - INFO - __main__ -   Batch number = 121
12/27/2021 13:23:26 - INFO - __main__ -   Batch number = 122
12/27/2021 13:23:27 - INFO - __main__ -   Batch number = 123
12/27/2021 13:23:27 - INFO - __main__ -   Batch number = 124
12/27/2021 13:23:27 - INFO - __main__ -   Batch number = 125
12/27/2021 13:23:27 - INFO - __main__ -   Batch number = 126
12/27/2021 13:23:28 - INFO - __main__ -   Batch number = 127
12/27/2021 13:23:28 - INFO - __main__ -   Batch number = 128
12/27/2021 13:23:28 - INFO - __main__ -   Batch number = 129
12/27/2021 13:23:29 - INFO - __main__ -   Batch number = 130
12/27/2021 13:23:29 - INFO - __main__ -   Batch number = 131
12/27/2021 13:23:29 - INFO - __main__ -   Batch number = 132
12/27/2021 13:23:29 - INFO - __main__ -   Batch number = 133
12/27/2021 13:23:30 - INFO - __main__ -   Batch number = 134
12/27/2021 13:23:30 - INFO - __main__ -   Batch number = 135
12/27/2021 13:23:30 - INFO - __main__ -   Batch number = 136
12/27/2021 13:23:31 - INFO - __main__ -   Batch number = 137
12/27/2021 13:23:31 - INFO - __main__ -   Batch number = 138
12/27/2021 13:23:32 - INFO - __main__ -   Batch number = 139
12/27/2021 13:23:32 - INFO - __main__ -   Batch number = 140
12/27/2021 13:23:32 - INFO - __main__ -   Batch number = 141
12/27/2021 13:23:32 - INFO - __main__ -   Batch number = 142
12/27/2021 13:23:33 - INFO - __main__ -   Batch number = 143
12/27/2021 13:23:33 - INFO - __main__ -   Batch number = 144
12/27/2021 13:23:33 - INFO - __main__ -   Batch number = 145
12/27/2021 13:23:34 - INFO - __main__ -   Batch number = 146
12/27/2021 13:23:34 - INFO - __main__ -   Batch number = 147
12/27/2021 13:23:34 - INFO - __main__ -   Batch number = 148
12/27/2021 13:23:35 - INFO - __main__ -   Batch number = 149
12/27/2021 13:23:35 - INFO - __main__ -   Batch number = 150
12/27/2021 13:23:35 - INFO - __main__ -   Batch number = 151
12/27/2021 13:23:35 - INFO - __main__ -   Batch number = 152
12/27/2021 13:23:36 - INFO - __main__ -   Batch number = 153
12/27/2021 13:23:36 - INFO - __main__ -   Batch number = 154
12/27/2021 13:23:36 - INFO - __main__ -   Batch number = 155
12/27/2021 13:23:37 - INFO - __main__ -   Batch number = 156
12/27/2021 13:23:37 - INFO - __main__ -   Batch number = 157
12/27/2021 13:23:37 - INFO - __main__ -   Batch number = 158
12/27/2021 13:23:38 - INFO - __main__ -   Batch number = 159
12/27/2021 13:23:38 - INFO - __main__ -   Batch number = 160
12/27/2021 13:23:38 - INFO - __main__ -   Batch number = 161
12/27/2021 13:23:38 - INFO - __main__ -   Batch number = 162
12/27/2021 13:23:39 - INFO - __main__ -   Batch number = 163
12/27/2021 13:23:39 - INFO - __main__ -   Batch number = 164
12/27/2021 13:23:39 - INFO - __main__ -   Batch number = 165
12/27/2021 13:23:40 - INFO - __main__ -   Batch number = 166
12/27/2021 13:23:40 - INFO - __main__ -   Batch number = 167
12/27/2021 13:23:40 - INFO - __main__ -   Batch number = 168
12/27/2021 13:23:40 - INFO - __main__ -   Batch number = 169
12/27/2021 13:23:41 - INFO - __main__ -   Batch number = 170
12/27/2021 13:23:41 - INFO - __main__ -   Batch number = 171
12/27/2021 13:23:41 - INFO - __main__ -   Batch number = 172
12/27/2021 13:23:42 - INFO - __main__ -   Batch number = 173
12/27/2021 13:23:42 - INFO - __main__ -   Batch number = 174
12/27/2021 13:23:42 - INFO - __main__ -   Batch number = 175
12/27/2021 13:23:43 - INFO - __main__ -   Batch number = 176
12/27/2021 13:23:43 - INFO - __main__ -   Batch number = 177
12/27/2021 13:23:43 - INFO - __main__ -   Batch number = 178
12/27/2021 13:23:43 - INFO - __main__ -   Batch number = 179
12/27/2021 13:23:44 - INFO - __main__ -   Batch number = 180
12/27/2021 13:23:44 - INFO - __main__ -   Batch number = 181
12/27/2021 13:23:44 - INFO - __main__ -   Batch number = 182
12/27/2021 13:23:45 - INFO - __main__ -   Batch number = 183
12/27/2021 13:23:45 - INFO - __main__ -   Batch number = 184
12/27/2021 13:23:45 - INFO - __main__ -   Batch number = 185
12/27/2021 13:23:45 - INFO - __main__ -   Batch number = 186
12/27/2021 13:23:46 - INFO - __main__ -   Batch number = 187
12/27/2021 13:23:46 - INFO - __main__ -   Batch number = 188
12/27/2021 13:23:46 - INFO - __main__ -   Batch number = 189
12/27/2021 13:23:47 - INFO - __main__ -   Batch number = 190
12/27/2021 13:23:47 - INFO - __main__ -   Batch number = 191
12/27/2021 13:23:47 - INFO - __main__ -   Batch number = 192
12/27/2021 13:23:48 - INFO - __main__ -   Batch number = 193
12/27/2021 13:23:48 - INFO - __main__ -   Batch number = 194
12/27/2021 13:23:48 - INFO - __main__ -   Batch number = 195
12/27/2021 13:23:49 - INFO - __main__ -   Batch number = 196
12/27/2021 13:23:49 - INFO - __main__ -   Batch number = 197
12/27/2021 13:23:49 - INFO - __main__ -   Batch number = 198
12/27/2021 13:23:49 - INFO - __main__ -   Batch number = 199
12/27/2021 13:23:50 - INFO - __main__ -   Batch number = 200
12/27/2021 13:23:50 - INFO - __main__ -   Batch number = 201
12/27/2021 13:23:50 - INFO - __main__ -   Batch number = 202
12/27/2021 13:23:50 - INFO - __main__ -   Batch number = 203
12/27/2021 13:23:51 - INFO - __main__ -   Batch number = 204
12/27/2021 13:23:51 - INFO - __main__ -   Batch number = 205
12/27/2021 13:23:51 - INFO - __main__ -   Batch number = 206
12/27/2021 13:23:52 - INFO - __main__ -   Batch number = 207
12/27/2021 13:23:52 - INFO - __main__ -   Batch number = 208
12/27/2021 13:23:52 - INFO - __main__ -   Batch number = 209
12/27/2021 13:23:53 - INFO - __main__ -   Batch number = 210
12/27/2021 13:23:53 - INFO - __main__ -   Batch number = 211
12/27/2021 13:23:53 - INFO - __main__ -   Batch number = 212
12/27/2021 13:23:54 - INFO - __main__ -   Batch number = 213
12/27/2021 13:23:54 - INFO - __main__ -   Batch number = 214
12/27/2021 13:23:54 - INFO - __main__ -   Batch number = 215
12/27/2021 13:23:54 - INFO - __main__ -   Batch number = 216
12/27/2021 13:23:55 - INFO - __main__ -   Batch number = 217
12/27/2021 13:23:55 - INFO - __main__ -   Batch number = 218
12/27/2021 13:23:55 - INFO - __main__ -   Batch number = 219
12/27/2021 13:23:55 - INFO - __main__ -   Batch number = 220
12/27/2021 13:23:56 - INFO - __main__ -   Batch number = 221
12/27/2021 13:23:56 - INFO - __main__ -   Batch number = 222
12/27/2021 13:23:56 - INFO - __main__ -   Batch number = 223
12/27/2021 13:23:57 - INFO - __main__ -   Batch number = 224
12/27/2021 13:23:57 - INFO - __main__ -   Batch number = 225
12/27/2021 13:23:57 - INFO - __main__ -   Batch number = 226
12/27/2021 13:23:58 - INFO - __main__ -   Batch number = 227
12/27/2021 13:23:58 - INFO - __main__ -   Batch number = 228
12/27/2021 13:23:58 - INFO - __main__ -   Batch number = 229
12/27/2021 13:23:59 - INFO - __main__ -   Batch number = 230
12/27/2021 13:23:59 - INFO - __main__ -   Batch number = 231
12/27/2021 13:24:00 - INFO - __main__ -   Batch number = 232
12/27/2021 13:24:00 - INFO - __main__ -   Batch number = 233
12/27/2021 13:24:00 - INFO - __main__ -   Batch number = 234
12/27/2021 13:24:00 - INFO - __main__ -   Batch number = 235
12/27/2021 13:24:00 - INFO - __main__ -   Batch number = 236
12/27/2021 13:24:01 - INFO - __main__ -   Batch number = 237
12/27/2021 13:24:01 - INFO - __main__ -   Batch number = 238
12/27/2021 13:24:01 - INFO - __main__ -   Batch number = 239
12/27/2021 13:24:02 - INFO - __main__ -   Batch number = 240
12/27/2021 13:24:02 - INFO - __main__ -   Batch number = 241
12/27/2021 13:24:02 - INFO - __main__ -   Batch number = 242
12/27/2021 13:24:03 - INFO - __main__ -   Batch number = 243
12/27/2021 13:24:03 - INFO - __main__ -   Batch number = 244
12/27/2021 13:24:03 - INFO - __main__ -   Batch number = 245
12/27/2021 13:24:04 - INFO - __main__ -   Batch number = 246
12/27/2021 13:24:04 - INFO - __main__ -   Batch number = 247
12/27/2021 13:24:04 - INFO - __main__ -   Batch number = 248
12/27/2021 13:24:05 - INFO - __main__ -   Batch number = 249
12/27/2021 13:24:05 - INFO - __main__ -   Batch number = 250
12/27/2021 13:24:05 - INFO - __main__ -   Batch number = 251
12/27/2021 13:24:05 - INFO - __main__ -   Batch number = 252
12/27/2021 13:24:06 - INFO - __main__ -   Batch number = 253
12/27/2021 13:24:06 - INFO - __main__ -   Batch number = 254
12/27/2021 13:24:06 - INFO - __main__ -   Batch number = 255
12/27/2021 13:24:06 - INFO - __main__ -   Batch number = 256
12/27/2021 13:24:07 - INFO - __main__ -   Batch number = 257
12/27/2021 13:24:07 - INFO - __main__ -   Batch number = 258
12/27/2021 13:24:07 - INFO - __main__ -   Batch number = 259
12/27/2021 13:24:08 - INFO - __main__ -   Batch number = 260
12/27/2021 13:24:08 - INFO - __main__ -   Batch number = 261
12/27/2021 13:24:08 - INFO - __main__ -   Batch number = 262
12/27/2021 13:24:09 - INFO - __main__ -   Batch number = 263
12/27/2021 13:24:09 - INFO - __main__ -   Batch number = 264
12/27/2021 13:24:09 - INFO - __main__ -   Batch number = 265
12/27/2021 13:24:10 - INFO - __main__ -   Batch number = 266
12/27/2021 13:24:10 - INFO - __main__ -   Batch number = 267
12/27/2021 13:24:10 - INFO - __main__ -   Batch number = 268
12/27/2021 13:24:11 - INFO - __main__ -   Batch number = 269
12/27/2021 13:24:11 - INFO - __main__ -   Batch number = 270
12/27/2021 13:24:11 - INFO - __main__ -   Batch number = 271
12/27/2021 13:24:11 - INFO - __main__ -   Batch number = 272
12/27/2021 13:24:12 - INFO - __main__ -   Batch number = 273
12/27/2021 13:24:12 - INFO - __main__ -   Batch number = 274
12/27/2021 13:24:12 - INFO - __main__ -   Batch number = 275
12/27/2021 13:24:12 - INFO - __main__ -   Batch number = 276
12/27/2021 13:24:13 - INFO - __main__ -   Batch number = 277
12/27/2021 13:24:13 - INFO - __main__ -   Batch number = 278
12/27/2021 13:24:13 - INFO - __main__ -   Batch number = 279
12/27/2021 13:24:14 - INFO - __main__ -   Batch number = 280
12/27/2021 13:24:14 - INFO - __main__ -   Batch number = 281
12/27/2021 13:24:14 - INFO - __main__ -   Batch number = 282
12/27/2021 13:24:15 - INFO - __main__ -   Batch number = 283
12/27/2021 13:24:15 - INFO - __main__ -   Batch number = 284
12/27/2021 13:24:15 - INFO - __main__ -   Batch number = 285
12/27/2021 13:24:16 - INFO - __main__ -   Batch number = 286
12/27/2021 13:24:16 - INFO - __main__ -   Batch number = 287
12/27/2021 13:24:16 - INFO - __main__ -   Batch number = 288
12/27/2021 13:24:16 - INFO - __main__ -   Batch number = 289
12/27/2021 13:24:17 - INFO - __main__ -   Batch number = 290
12/27/2021 13:24:17 - INFO - __main__ -   Batch number = 291
12/27/2021 13:24:17 - INFO - __main__ -   Batch number = 292
12/27/2021 13:24:17 - INFO - __main__ -   Batch number = 293
12/27/2021 13:24:18 - INFO - __main__ -   Batch number = 294
12/27/2021 13:24:18 - INFO - __main__ -   Batch number = 295
12/27/2021 13:24:18 - INFO - __main__ -   Batch number = 296
12/27/2021 13:24:19 - INFO - __main__ -   Batch number = 297
12/27/2021 13:24:19 - INFO - __main__ -   Batch number = 298
12/27/2021 13:24:19 - INFO - __main__ -   Batch number = 299
12/27/2021 13:24:20 - INFO - __main__ -   Batch number = 300
12/27/2021 13:24:20 - INFO - __main__ -   Batch number = 301
12/27/2021 13:24:20 - INFO - __main__ -   Batch number = 302
12/27/2021 13:24:21 - INFO - __main__ -   Batch number = 303
12/27/2021 13:24:21 - INFO - __main__ -   Batch number = 304
12/27/2021 13:24:21 - INFO - __main__ -   Batch number = 305
12/27/2021 13:24:22 - INFO - __main__ -   Batch number = 306
12/27/2021 13:24:22 - INFO - __main__ -   Batch number = 307
12/27/2021 13:24:22 - INFO - __main__ -   Batch number = 308
12/27/2021 13:24:22 - INFO - __main__ -   Batch number = 309
12/27/2021 13:24:23 - INFO - __main__ -   Batch number = 310
12/27/2021 13:24:23 - INFO - __main__ -   Batch number = 311
12/27/2021 13:24:23 - INFO - __main__ -   Batch number = 312
12/27/2021 13:24:23 - INFO - __main__ -   Batch number = 313
12/27/2021 13:24:25 - INFO - __main__ -   ***** Evaluation result  in en *****
12/27/2021 13:24:25 - INFO - __main__ -     f1 = 0.7826420088461672
12/27/2021 13:24:25 - INFO - __main__ -     loss = 1.0368526690422346
12/27/2021 13:24:25 - INFO - __main__ -     precision = 0.7615561881523655
12/27/2021 13:24:25 - INFO - __main__ -     recall = 0.8049287198223368
12/27/2021 13:24:25 - INFO - __main__ -   Language adapter for ja not found, using pt instead
12/27/2021 13:24:25 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 13:24:25 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 13:24:25 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 13:24:25 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ja_bert-base-multilingual-cased_128
12/27/2021 13:24:26 - INFO - __main__ -   ***** Running evaluation  in ja *****
12/27/2021 13:24:26 - INFO - __main__ -     Num examples = 10612
12/27/2021 13:24:26 - INFO - __main__ -     Batch size = 32
12/27/2021 13:24:26 - INFO - __main__ -   Batch number = 1
12/27/2021 13:24:27 - INFO - __main__ -   Batch number = 2
12/27/2021 13:24:27 - INFO - __main__ -   Batch number = 3
12/27/2021 13:24:27 - INFO - __main__ -   Batch number = 4
12/27/2021 13:24:28 - INFO - __main__ -   Batch number = 5
12/27/2021 13:24:28 - INFO - __main__ -   Batch number = 6
12/27/2021 13:24:28 - INFO - __main__ -   Batch number = 7
12/27/2021 13:24:28 - INFO - __main__ -   Batch number = 8
12/27/2021 13:24:29 - INFO - __main__ -   Batch number = 9
12/27/2021 13:24:29 - INFO - __main__ -   Batch number = 10
12/27/2021 13:24:29 - INFO - __main__ -   Batch number = 11
12/27/2021 13:24:30 - INFO - __main__ -   Batch number = 12
12/27/2021 13:24:30 - INFO - __main__ -   Batch number = 13
12/27/2021 13:24:30 - INFO - __main__ -   Batch number = 14
12/27/2021 13:24:30 - INFO - __main__ -   Batch number = 15
12/27/2021 13:24:31 - INFO - __main__ -   Batch number = 16
12/27/2021 13:24:31 - INFO - __main__ -   Batch number = 17
12/27/2021 13:24:31 - INFO - __main__ -   Batch number = 18
12/27/2021 13:24:31 - INFO - __main__ -   Batch number = 19
12/27/2021 13:24:32 - INFO - __main__ -   Batch number = 20
12/27/2021 13:24:32 - INFO - __main__ -   Batch number = 21
12/27/2021 13:24:32 - INFO - __main__ -   Batch number = 22
12/27/2021 13:24:33 - INFO - __main__ -   Batch number = 23
12/27/2021 13:24:33 - INFO - __main__ -   Batch number = 24
12/27/2021 13:24:33 - INFO - __main__ -   Batch number = 25
12/27/2021 13:24:34 - INFO - __main__ -   Batch number = 26
12/27/2021 13:24:34 - INFO - __main__ -   Batch number = 27
12/27/2021 13:24:34 - INFO - __main__ -   Batch number = 28
12/27/2021 13:24:35 - INFO - __main__ -   Batch number = 29
12/27/2021 13:24:35 - INFO - __main__ -   Batch number = 30
12/27/2021 13:24:35 - INFO - __main__ -   Batch number = 31
12/27/2021 13:24:35 - INFO - __main__ -   Batch number = 32
12/27/2021 13:24:36 - INFO - __main__ -   Batch number = 33
12/27/2021 13:24:36 - INFO - __main__ -   Batch number = 34
12/27/2021 13:24:36 - INFO - __main__ -   Batch number = 35
12/27/2021 13:24:36 - INFO - __main__ -   Batch number = 36
12/27/2021 13:24:37 - INFO - __main__ -   Batch number = 37
12/27/2021 13:24:37 - INFO - __main__ -   Batch number = 38
12/27/2021 13:24:37 - INFO - __main__ -   Batch number = 39
12/27/2021 13:24:37 - INFO - __main__ -   Batch number = 40
12/27/2021 13:24:38 - INFO - __main__ -   Batch number = 41
12/27/2021 13:24:38 - INFO - __main__ -   Batch number = 42
12/27/2021 13:24:38 - INFO - __main__ -   Batch number = 43
12/27/2021 13:24:39 - INFO - __main__ -   Batch number = 44
12/27/2021 13:24:39 - INFO - __main__ -   Batch number = 45
12/27/2021 13:24:39 - INFO - __main__ -   Batch number = 46
12/27/2021 13:24:40 - INFO - __main__ -   Batch number = 47
12/27/2021 13:24:40 - INFO - __main__ -   Batch number = 48
12/27/2021 13:24:40 - INFO - __main__ -   Batch number = 49
12/27/2021 13:24:41 - INFO - __main__ -   Batch number = 50
12/27/2021 13:24:41 - INFO - __main__ -   Batch number = 51
12/27/2021 13:24:41 - INFO - __main__ -   Batch number = 52
12/27/2021 13:24:41 - INFO - __main__ -   Batch number = 53
12/27/2021 13:24:42 - INFO - __main__ -   Batch number = 54
12/27/2021 13:24:42 - INFO - __main__ -   Batch number = 55
12/27/2021 13:24:42 - INFO - __main__ -   Batch number = 56
12/27/2021 13:24:43 - INFO - __main__ -   Batch number = 57
12/27/2021 13:24:43 - INFO - __main__ -   Batch number = 58
12/27/2021 13:24:43 - INFO - __main__ -   Batch number = 59
12/27/2021 13:24:43 - INFO - __main__ -   Batch number = 60
12/27/2021 13:24:44 - INFO - __main__ -   Batch number = 61
12/27/2021 13:24:44 - INFO - __main__ -   Batch number = 62
12/27/2021 13:24:44 - INFO - __main__ -   Batch number = 63
12/27/2021 13:24:45 - INFO - __main__ -   Batch number = 64
12/27/2021 13:24:45 - INFO - __main__ -   Batch number = 65
12/27/2021 13:24:45 - INFO - __main__ -   Batch number = 66
12/27/2021 13:24:46 - INFO - __main__ -   Batch number = 67
12/27/2021 13:24:46 - INFO - __main__ -   Batch number = 68
12/27/2021 13:24:46 - INFO - __main__ -   Batch number = 69
12/27/2021 13:24:47 - INFO - __main__ -   Batch number = 70
12/27/2021 13:24:47 - INFO - __main__ -   Batch number = 71
12/27/2021 13:24:47 - INFO - __main__ -   Batch number = 72
12/27/2021 13:24:47 - INFO - __main__ -   Batch number = 73
12/27/2021 13:24:48 - INFO - __main__ -   Batch number = 74
12/27/2021 13:24:48 - INFO - __main__ -   Batch number = 75
12/27/2021 13:24:48 - INFO - __main__ -   Batch number = 76
12/27/2021 13:24:48 - INFO - __main__ -   Batch number = 77
12/27/2021 13:24:49 - INFO - __main__ -   Batch number = 78
12/27/2021 13:24:49 - INFO - __main__ -   Batch number = 79
12/27/2021 13:24:49 - INFO - __main__ -   Batch number = 80
12/27/2021 13:24:50 - INFO - __main__ -   Batch number = 81
12/27/2021 13:24:50 - INFO - __main__ -   Batch number = 82
12/27/2021 13:24:50 - INFO - __main__ -   Batch number = 83
12/27/2021 13:24:51 - INFO - __main__ -   Batch number = 84
12/27/2021 13:24:51 - INFO - __main__ -   Batch number = 85
12/27/2021 13:24:51 - INFO - __main__ -   Batch number = 86
12/27/2021 13:24:52 - INFO - __main__ -   Batch number = 87
12/27/2021 13:24:52 - INFO - __main__ -   Batch number = 88
12/27/2021 13:24:52 - INFO - __main__ -   Batch number = 89
12/27/2021 13:24:52 - INFO - __main__ -   Batch number = 90
12/27/2021 13:24:53 - INFO - __main__ -   Batch number = 91
12/27/2021 13:24:53 - INFO - __main__ -   Batch number = 92
12/27/2021 13:24:53 - INFO - __main__ -   Batch number = 93
12/27/2021 13:24:53 - INFO - __main__ -   Batch number = 94
12/27/2021 13:24:54 - INFO - __main__ -   Batch number = 95
12/27/2021 13:24:54 - INFO - __main__ -   Batch number = 96
12/27/2021 13:24:54 - INFO - __main__ -   Batch number = 97
12/27/2021 13:24:55 - INFO - __main__ -   Batch number = 98
12/27/2021 13:24:55 - INFO - __main__ -   Batch number = 99
12/27/2021 13:24:55 - INFO - __main__ -   Batch number = 100
12/27/2021 13:24:55 - INFO - __main__ -   Batch number = 101
12/27/2021 13:24:56 - INFO - __main__ -   Batch number = 102
12/27/2021 13:24:56 - INFO - __main__ -   Batch number = 103
12/27/2021 13:24:56 - INFO - __main__ -   Batch number = 104
12/27/2021 13:24:57 - INFO - __main__ -   Batch number = 105
12/27/2021 13:24:57 - INFO - __main__ -   Batch number = 106
12/27/2021 13:24:57 - INFO - __main__ -   Batch number = 107
12/27/2021 13:24:58 - INFO - __main__ -   Batch number = 108
12/27/2021 13:24:58 - INFO - __main__ -   Batch number = 109
12/27/2021 13:24:58 - INFO - __main__ -   Batch number = 110
12/27/2021 13:24:59 - INFO - __main__ -   Batch number = 111
12/27/2021 13:24:59 - INFO - __main__ -   Batch number = 112
12/27/2021 13:24:59 - INFO - __main__ -   Batch number = 113
12/27/2021 13:24:59 - INFO - __main__ -   Batch number = 114
12/27/2021 13:25:00 - INFO - __main__ -   Batch number = 115
12/27/2021 13:25:00 - INFO - __main__ -   Batch number = 116
12/27/2021 13:25:00 - INFO - __main__ -   Batch number = 117
12/27/2021 13:25:00 - INFO - __main__ -   Batch number = 118
12/27/2021 13:25:01 - INFO - __main__ -   Batch number = 119
12/27/2021 13:25:01 - INFO - __main__ -   Batch number = 120
12/27/2021 13:25:01 - INFO - __main__ -   Batch number = 121
12/27/2021 13:25:02 - INFO - __main__ -   Batch number = 122
12/27/2021 13:25:02 - INFO - __main__ -   Batch number = 123
12/27/2021 13:25:02 - INFO - __main__ -   Batch number = 124
12/27/2021 13:25:03 - INFO - __main__ -   Batch number = 125
12/27/2021 13:25:03 - INFO - __main__ -   Batch number = 126
12/27/2021 13:25:03 - INFO - __main__ -   Batch number = 127
12/27/2021 13:25:04 - INFO - __main__ -   Batch number = 128
12/27/2021 13:25:04 - INFO - __main__ -   Batch number = 129
12/27/2021 13:25:04 - INFO - __main__ -   Batch number = 130
12/27/2021 13:25:04 - INFO - __main__ -   Batch number = 131
12/27/2021 13:25:05 - INFO - __main__ -   Batch number = 132
12/27/2021 13:25:05 - INFO - __main__ -   Batch number = 133
12/27/2021 13:25:05 - INFO - __main__ -   Batch number = 134
12/27/2021 13:25:05 - INFO - __main__ -   Batch number = 135
12/27/2021 13:25:06 - INFO - __main__ -   Batch number = 136
12/27/2021 13:25:06 - INFO - __main__ -   Batch number = 137
12/27/2021 13:25:06 - INFO - __main__ -   Batch number = 138
12/27/2021 13:25:07 - INFO - __main__ -   Batch number = 139
12/27/2021 13:25:07 - INFO - __main__ -   Batch number = 140
12/27/2021 13:25:07 - INFO - __main__ -   Batch number = 141
12/27/2021 13:25:08 - INFO - __main__ -   Batch number = 142
12/27/2021 13:25:08 - INFO - __main__ -   Batch number = 143
12/27/2021 13:25:08 - INFO - __main__ -   Batch number = 144
12/27/2021 13:25:09 - INFO - __main__ -   Batch number = 145
12/27/2021 13:25:09 - INFO - __main__ -   Batch number = 146
12/27/2021 13:25:09 - INFO - __main__ -   Batch number = 147
12/27/2021 13:25:09 - INFO - __main__ -   Batch number = 148
12/27/2021 13:25:10 - INFO - __main__ -   Batch number = 149
12/27/2021 13:25:10 - INFO - __main__ -   Batch number = 150
12/27/2021 13:25:10 - INFO - __main__ -   Batch number = 151
12/27/2021 13:25:10 - INFO - __main__ -   Batch number = 152
12/27/2021 13:25:11 - INFO - __main__ -   Batch number = 153
12/27/2021 13:25:11 - INFO - __main__ -   Batch number = 154
12/27/2021 13:25:11 - INFO - __main__ -   Batch number = 155
12/27/2021 13:25:12 - INFO - __main__ -   Batch number = 156
12/27/2021 13:25:12 - INFO - __main__ -   Batch number = 157
12/27/2021 13:25:12 - INFO - __main__ -   Batch number = 158
12/27/2021 13:25:13 - INFO - __main__ -   Batch number = 159
12/27/2021 13:25:13 - INFO - __main__ -   Batch number = 160
12/27/2021 13:25:13 - INFO - __main__ -   Batch number = 161
12/27/2021 13:25:14 - INFO - __main__ -   Batch number = 162
12/27/2021 13:25:14 - INFO - __main__ -   Batch number = 163
12/27/2021 13:25:14 - INFO - __main__ -   Batch number = 164
12/27/2021 13:25:15 - INFO - __main__ -   Batch number = 165
12/27/2021 13:25:15 - INFO - __main__ -   Batch number = 166
12/27/2021 13:25:15 - INFO - __main__ -   Batch number = 167
12/27/2021 13:25:15 - INFO - __main__ -   Batch number = 168
12/27/2021 13:25:16 - INFO - __main__ -   Batch number = 169
12/27/2021 13:25:16 - INFO - __main__ -   Batch number = 170
12/27/2021 13:25:16 - INFO - __main__ -   Batch number = 171
12/27/2021 13:25:16 - INFO - __main__ -   Batch number = 172
12/27/2021 13:25:17 - INFO - __main__ -   Batch number = 173
12/27/2021 13:25:17 - INFO - __main__ -   Batch number = 174
12/27/2021 13:25:17 - INFO - __main__ -   Batch number = 175
12/27/2021 13:25:18 - INFO - __main__ -   Batch number = 176
12/27/2021 13:25:18 - INFO - __main__ -   Batch number = 177
12/27/2021 13:25:18 - INFO - __main__ -   Batch number = 178
12/27/2021 13:25:19 - INFO - __main__ -   Batch number = 179
12/27/2021 13:25:19 - INFO - __main__ -   Batch number = 180
12/27/2021 13:25:19 - INFO - __main__ -   Batch number = 181
12/27/2021 13:25:20 - INFO - __main__ -   Batch number = 182
12/27/2021 13:25:20 - INFO - __main__ -   Batch number = 183
12/27/2021 13:25:20 - INFO - __main__ -   Batch number = 184
12/27/2021 13:25:21 - INFO - __main__ -   Batch number = 185
12/27/2021 13:25:21 - INFO - __main__ -   Batch number = 186
12/27/2021 13:25:21 - INFO - __main__ -   Batch number = 187
12/27/2021 13:25:21 - INFO - __main__ -   Batch number = 188
12/27/2021 13:25:21 - INFO - __main__ -   Batch number = 189
12/27/2021 13:25:22 - INFO - __main__ -   Batch number = 190
12/27/2021 13:25:22 - INFO - __main__ -   Batch number = 191
12/27/2021 13:25:22 - INFO - __main__ -   Batch number = 192
12/27/2021 13:25:23 - INFO - __main__ -   Batch number = 193
12/27/2021 13:25:23 - INFO - __main__ -   Batch number = 194
12/27/2021 13:25:23 - INFO - __main__ -   Batch number = 195
12/27/2021 13:25:24 - INFO - __main__ -   Batch number = 196
12/27/2021 13:25:24 - INFO - __main__ -   Batch number = 197
12/27/2021 13:25:24 - INFO - __main__ -   Batch number = 198
12/27/2021 13:25:25 - INFO - __main__ -   Batch number = 199
12/27/2021 13:25:25 - INFO - __main__ -   Batch number = 200
12/27/2021 13:25:25 - INFO - __main__ -   Batch number = 201
12/27/2021 13:25:26 - INFO - __main__ -   Batch number = 202
12/27/2021 13:25:26 - INFO - __main__ -   Batch number = 203
12/27/2021 13:25:26 - INFO - __main__ -   Batch number = 204
12/27/2021 13:25:26 - INFO - __main__ -   Batch number = 205
12/27/2021 13:25:27 - INFO - __main__ -   Batch number = 206
12/27/2021 13:25:27 - INFO - __main__ -   Batch number = 207
12/27/2021 13:25:27 - INFO - __main__ -   Batch number = 208
12/27/2021 13:25:27 - INFO - __main__ -   Batch number = 209
12/27/2021 13:25:28 - INFO - __main__ -   Batch number = 210
12/27/2021 13:25:28 - INFO - __main__ -   Batch number = 211
12/27/2021 13:25:28 - INFO - __main__ -   Batch number = 212
12/27/2021 13:25:29 - INFO - __main__ -   Batch number = 213
12/27/2021 13:25:29 - INFO - __main__ -   Batch number = 214
12/27/2021 13:25:29 - INFO - __main__ -   Batch number = 215
12/27/2021 13:25:30 - INFO - __main__ -   Batch number = 216
12/27/2021 13:25:30 - INFO - __main__ -   Batch number = 217
12/27/2021 13:25:30 - INFO - __main__ -   Batch number = 218
12/27/2021 13:25:31 - INFO - __main__ -   Batch number = 219
12/27/2021 13:25:31 - INFO - __main__ -   Batch number = 220
12/27/2021 13:25:31 - INFO - __main__ -   Batch number = 221
12/27/2021 13:25:32 - INFO - __main__ -   Batch number = 222
12/27/2021 13:25:32 - INFO - __main__ -   Batch number = 223
12/27/2021 13:25:32 - INFO - __main__ -   Batch number = 224
12/27/2021 13:25:32 - INFO - __main__ -   Batch number = 225
12/27/2021 13:25:32 - INFO - __main__ -   Batch number = 226
12/27/2021 13:25:33 - INFO - __main__ -   Batch number = 227
12/27/2021 13:25:33 - INFO - __main__ -   Batch number = 228
12/27/2021 13:25:33 - INFO - __main__ -   Batch number = 229
12/27/2021 13:25:34 - INFO - __main__ -   Batch number = 230
12/27/2021 13:25:34 - INFO - __main__ -   Batch number = 231
12/27/2021 13:25:34 - INFO - __main__ -   Batch number = 232
12/27/2021 13:25:35 - INFO - __main__ -   Batch number = 233
12/27/2021 13:25:35 - INFO - __main__ -   Batch number = 234
12/27/2021 13:25:35 - INFO - __main__ -   Batch number = 235
12/27/2021 13:25:36 - INFO - __main__ -   Batch number = 236
12/27/2021 13:25:36 - INFO - __main__ -   Batch number = 237
12/27/2021 13:25:36 - INFO - __main__ -   Batch number = 238
12/27/2021 13:25:37 - INFO - __main__ -   Batch number = 239
12/27/2021 13:25:37 - INFO - __main__ -   Batch number = 240
12/27/2021 13:25:37 - INFO - __main__ -   Batch number = 241
12/27/2021 13:25:37 - INFO - __main__ -   Batch number = 242
12/27/2021 13:25:38 - INFO - __main__ -   Batch number = 243
12/27/2021 13:25:38 - INFO - __main__ -   Batch number = 244
12/27/2021 13:25:38 - INFO - __main__ -   Batch number = 245
12/27/2021 13:25:38 - INFO - __main__ -   Batch number = 246
12/27/2021 13:25:39 - INFO - __main__ -   Batch number = 247
12/27/2021 13:25:39 - INFO - __main__ -   Batch number = 248
12/27/2021 13:25:39 - INFO - __main__ -   Batch number = 249
12/27/2021 13:25:40 - INFO - __main__ -   Batch number = 250
12/27/2021 13:25:40 - INFO - __main__ -   Batch number = 251
12/27/2021 13:25:40 - INFO - __main__ -   Batch number = 252
12/27/2021 13:25:41 - INFO - __main__ -   Batch number = 253
12/27/2021 13:25:41 - INFO - __main__ -   Batch number = 254
12/27/2021 13:25:41 - INFO - __main__ -   Batch number = 255
12/27/2021 13:25:42 - INFO - __main__ -   Batch number = 256
12/27/2021 13:25:42 - INFO - __main__ -   Batch number = 257
12/27/2021 13:25:42 - INFO - __main__ -   Batch number = 258
12/27/2021 13:25:43 - INFO - __main__ -   Batch number = 259
12/27/2021 13:25:43 - INFO - __main__ -   Batch number = 260
12/27/2021 13:25:43 - INFO - __main__ -   Batch number = 261
12/27/2021 13:25:43 - INFO - __main__ -   Batch number = 262
12/27/2021 13:25:44 - INFO - __main__ -   Batch number = 263
12/27/2021 13:25:44 - INFO - __main__ -   Batch number = 264
12/27/2021 13:25:44 - INFO - __main__ -   Batch number = 265
12/27/2021 13:25:44 - INFO - __main__ -   Batch number = 266
12/27/2021 13:25:45 - INFO - __main__ -   Batch number = 267
12/27/2021 13:25:45 - INFO - __main__ -   Batch number = 268
12/27/2021 13:25:45 - INFO - __main__ -   Batch number = 269
12/27/2021 13:25:46 - INFO - __main__ -   Batch number = 270
12/27/2021 13:25:46 - INFO - __main__ -   Batch number = 271
12/27/2021 13:25:46 - INFO - __main__ -   Batch number = 272
12/27/2021 13:25:47 - INFO - __main__ -   Batch number = 273
12/27/2021 13:25:47 - INFO - __main__ -   Batch number = 274
12/27/2021 13:25:47 - INFO - __main__ -   Batch number = 275
12/27/2021 13:25:48 - INFO - __main__ -   Batch number = 276
12/27/2021 13:25:48 - INFO - __main__ -   Batch number = 277
12/27/2021 13:25:48 - INFO - __main__ -   Batch number = 278
12/27/2021 13:25:48 - INFO - __main__ -   Batch number = 279
12/27/2021 13:25:49 - INFO - __main__ -   Batch number = 280
12/27/2021 13:25:49 - INFO - __main__ -   Batch number = 281
12/27/2021 13:25:49 - INFO - __main__ -   Batch number = 282
12/27/2021 13:25:49 - INFO - __main__ -   Batch number = 283
12/27/2021 13:25:50 - INFO - __main__ -   Batch number = 284
12/27/2021 13:25:50 - INFO - __main__ -   Batch number = 285
12/27/2021 13:25:50 - INFO - __main__ -   Batch number = 286
12/27/2021 13:25:51 - INFO - __main__ -   Batch number = 287
12/27/2021 13:25:51 - INFO - __main__ -   Batch number = 288
12/27/2021 13:25:51 - INFO - __main__ -   Batch number = 289
12/27/2021 13:25:52 - INFO - __main__ -   Batch number = 290
12/27/2021 13:25:52 - INFO - __main__ -   Batch number = 291
12/27/2021 13:25:52 - INFO - __main__ -   Batch number = 292
12/27/2021 13:25:53 - INFO - __main__ -   Batch number = 293
12/27/2021 13:25:53 - INFO - __main__ -   Batch number = 294
12/27/2021 13:25:53 - INFO - __main__ -   Batch number = 295
12/27/2021 13:25:54 - INFO - __main__ -   Batch number = 296
12/27/2021 13:25:54 - INFO - __main__ -   Batch number = 297
12/27/2021 13:25:54 - INFO - __main__ -   Batch number = 298
12/27/2021 13:25:54 - INFO - __main__ -   Batch number = 299
12/27/2021 13:25:55 - INFO - __main__ -   Batch number = 300
12/27/2021 13:25:55 - INFO - __main__ -   Batch number = 301
12/27/2021 13:25:55 - INFO - __main__ -   Batch number = 302
12/27/2021 13:25:55 - INFO - __main__ -   Batch number = 303
12/27/2021 13:25:56 - INFO - __main__ -   Batch number = 304
12/27/2021 13:25:56 - INFO - __main__ -   Batch number = 305
12/27/2021 13:25:56 - INFO - __main__ -   Batch number = 306
12/27/2021 13:25:56 - INFO - __main__ -   Batch number = 307
12/27/2021 13:25:57 - INFO - __main__ -   Batch number = 308
12/27/2021 13:25:57 - INFO - __main__ -   Batch number = 309
12/27/2021 13:25:57 - INFO - __main__ -   Batch number = 310
12/27/2021 13:25:58 - INFO - __main__ -   Batch number = 311
12/27/2021 13:25:58 - INFO - __main__ -   Batch number = 312
12/27/2021 13:25:58 - INFO - __main__ -   Batch number = 313
12/27/2021 13:25:59 - INFO - __main__ -   Batch number = 314
12/27/2021 13:25:59 - INFO - __main__ -   Batch number = 315
12/27/2021 13:25:59 - INFO - __main__ -   Batch number = 316
12/27/2021 13:26:00 - INFO - __main__ -   Batch number = 317
12/27/2021 13:26:00 - INFO - __main__ -   Batch number = 318
12/27/2021 13:26:00 - INFO - __main__ -   Batch number = 319
12/27/2021 13:26:00 - INFO - __main__ -   Batch number = 320
12/27/2021 13:26:01 - INFO - __main__ -   Batch number = 321
12/27/2021 13:26:01 - INFO - __main__ -   Batch number = 322
12/27/2021 13:26:01 - INFO - __main__ -   Batch number = 323
12/27/2021 13:26:02 - INFO - __main__ -   Batch number = 324
12/27/2021 13:26:02 - INFO - __main__ -   Batch number = 325
12/27/2021 13:26:02 - INFO - __main__ -   Batch number = 326
12/27/2021 13:26:02 - INFO - __main__ -   Batch number = 327
12/27/2021 13:26:03 - INFO - __main__ -   Batch number = 328
12/27/2021 13:26:03 - INFO - __main__ -   Batch number = 329
12/27/2021 13:26:03 - INFO - __main__ -   Batch number = 330
12/27/2021 13:26:04 - INFO - __main__ -   Batch number = 331
12/27/2021 13:26:04 - INFO - __main__ -   Batch number = 332
12/27/2021 13:26:08 - INFO - __main__ -   ***** Evaluation result  in ja *****
12/27/2021 13:26:08 - INFO - __main__ -     f1 = 0.19523086129908393
12/27/2021 13:26:08 - INFO - __main__ -     loss = 3.8253803504518715
12/27/2021 13:26:08 - INFO - __main__ -     precision = 0.14408996704379437
12/27/2021 13:26:08 - INFO - __main__ -     recall = 0.3026475415685435
12/27/2021 13:26:08 - INFO - __main__ -   Language adapter for zh not found, using pt instead
12/27/2021 13:26:08 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 13:26:08 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 13:26:08 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 13:26:08 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_zh_bert-base-multilingual-cased_128
12/27/2021 13:26:09 - INFO - __main__ -   ***** Running evaluation  in zh *****
12/27/2021 13:26:09 - INFO - __main__ -     Num examples = 10257
12/27/2021 13:26:09 - INFO - __main__ -     Batch size = 32
12/27/2021 13:26:09 - INFO - __main__ -   Batch number = 1
12/27/2021 13:26:10 - INFO - __main__ -   Batch number = 2
12/27/2021 13:26:10 - INFO - __main__ -   Batch number = 3
12/27/2021 13:26:10 - INFO - __main__ -   Batch number = 4
12/27/2021 13:26:10 - INFO - __main__ -   Batch number = 5
12/27/2021 13:26:11 - INFO - __main__ -   Batch number = 6
12/27/2021 13:26:11 - INFO - __main__ -   Batch number = 7
12/27/2021 13:26:11 - INFO - __main__ -   Batch number = 8
12/27/2021 13:26:11 - INFO - __main__ -   Batch number = 9
12/27/2021 13:26:12 - INFO - __main__ -   Batch number = 10
12/27/2021 13:26:12 - INFO - __main__ -   Batch number = 11
12/27/2021 13:26:12 - INFO - __main__ -   Batch number = 12
12/27/2021 13:26:13 - INFO - __main__ -   Batch number = 13
12/27/2021 13:26:13 - INFO - __main__ -   Batch number = 14
12/27/2021 13:26:13 - INFO - __main__ -   Batch number = 15
12/27/2021 13:26:14 - INFO - __main__ -   Batch number = 16
12/27/2021 13:26:14 - INFO - __main__ -   Batch number = 17
12/27/2021 13:26:14 - INFO - __main__ -   Batch number = 18
12/27/2021 13:26:15 - INFO - __main__ -   Batch number = 19
12/27/2021 13:26:15 - INFO - __main__ -   Batch number = 20
12/27/2021 13:26:15 - INFO - __main__ -   Batch number = 21
12/27/2021 13:26:16 - INFO - __main__ -   Batch number = 22
12/27/2021 13:26:16 - INFO - __main__ -   Batch number = 23
12/27/2021 13:26:16 - INFO - __main__ -   Batch number = 24
12/27/2021 13:26:16 - INFO - __main__ -   Batch number = 25
12/27/2021 13:26:16 - INFO - __main__ -   Batch number = 26
12/27/2021 13:26:17 - INFO - __main__ -   Batch number = 27
12/27/2021 13:26:17 - INFO - __main__ -   Batch number = 28
12/27/2021 13:26:17 - INFO - __main__ -   Batch number = 29
12/27/2021 13:26:18 - INFO - __main__ -   Batch number = 30
12/27/2021 13:26:18 - INFO - __main__ -   Batch number = 31
12/27/2021 13:26:18 - INFO - __main__ -   Batch number = 32
12/27/2021 13:26:18 - INFO - __main__ -   Batch number = 33
12/27/2021 13:26:19 - INFO - __main__ -   Batch number = 34
12/27/2021 13:26:19 - INFO - __main__ -   Batch number = 35
12/27/2021 13:26:19 - INFO - __main__ -   Batch number = 36
12/27/2021 13:26:20 - INFO - __main__ -   Batch number = 37
12/27/2021 13:26:20 - INFO - __main__ -   Batch number = 38
12/27/2021 13:26:20 - INFO - __main__ -   Batch number = 39
12/27/2021 13:26:21 - INFO - __main__ -   Batch number = 40
12/27/2021 13:26:21 - INFO - __main__ -   Batch number = 41
12/27/2021 13:26:21 - INFO - __main__ -   Batch number = 42
12/27/2021 13:26:22 - INFO - __main__ -   Batch number = 43
12/27/2021 13:26:22 - INFO - __main__ -   Batch number = 44
12/27/2021 13:26:22 - INFO - __main__ -   Batch number = 45
12/27/2021 13:26:22 - INFO - __main__ -   Batch number = 46
12/27/2021 13:26:23 - INFO - __main__ -   Batch number = 47
12/27/2021 13:26:23 - INFO - __main__ -   Batch number = 48
12/27/2021 13:26:23 - INFO - __main__ -   Batch number = 49
12/27/2021 13:26:23 - INFO - __main__ -   Batch number = 50
12/27/2021 13:26:24 - INFO - __main__ -   Batch number = 51
12/27/2021 13:26:24 - INFO - __main__ -   Batch number = 52
12/27/2021 13:26:24 - INFO - __main__ -   Batch number = 53
12/27/2021 13:26:25 - INFO - __main__ -   Batch number = 54
12/27/2021 13:26:25 - INFO - __main__ -   Batch number = 55
12/27/2021 13:26:25 - INFO - __main__ -   Batch number = 56
12/27/2021 13:26:26 - INFO - __main__ -   Batch number = 57
12/27/2021 13:26:26 - INFO - __main__ -   Batch number = 58
12/27/2021 13:26:26 - INFO - __main__ -   Batch number = 59
12/27/2021 13:26:27 - INFO - __main__ -   Batch number = 60
12/27/2021 13:26:27 - INFO - __main__ -   Batch number = 61
12/27/2021 13:26:27 - INFO - __main__ -   Batch number = 62
12/27/2021 13:26:27 - INFO - __main__ -   Batch number = 63
12/27/2021 13:26:28 - INFO - __main__ -   Batch number = 64
12/27/2021 13:26:28 - INFO - __main__ -   Batch number = 65
12/27/2021 13:26:28 - INFO - __main__ -   Batch number = 66
12/27/2021 13:26:28 - INFO - __main__ -   Batch number = 67
12/27/2021 13:26:29 - INFO - __main__ -   Batch number = 68
12/27/2021 13:26:29 - INFO - __main__ -   Batch number = 69
12/27/2021 13:26:29 - INFO - __main__ -   Batch number = 70
12/27/2021 13:26:30 - INFO - __main__ -   Batch number = 71
12/27/2021 13:26:30 - INFO - __main__ -   Batch number = 72
12/27/2021 13:26:30 - INFO - __main__ -   Batch number = 73
12/27/2021 13:26:31 - INFO - __main__ -   Batch number = 74
12/27/2021 13:26:31 - INFO - __main__ -   Batch number = 75
12/27/2021 13:26:31 - INFO - __main__ -   Batch number = 76
12/27/2021 13:26:32 - INFO - __main__ -   Batch number = 77
12/27/2021 13:26:32 - INFO - __main__ -   Batch number = 78
12/27/2021 13:26:32 - INFO - __main__ -   Batch number = 79
12/27/2021 13:26:33 - INFO - __main__ -   Batch number = 80
12/27/2021 13:26:33 - INFO - __main__ -   Batch number = 81
12/27/2021 13:26:33 - INFO - __main__ -   Batch number = 82
12/27/2021 13:26:33 - INFO - __main__ -   Batch number = 83
12/27/2021 13:26:34 - INFO - __main__ -   Batch number = 84
12/27/2021 13:26:34 - INFO - __main__ -   Batch number = 85
12/27/2021 13:26:34 - INFO - __main__ -   Batch number = 86
12/27/2021 13:26:34 - INFO - __main__ -   Batch number = 87
12/27/2021 13:26:35 - INFO - __main__ -   Batch number = 88
12/27/2021 13:26:35 - INFO - __main__ -   Batch number = 89
12/27/2021 13:26:35 - INFO - __main__ -   Batch number = 90
12/27/2021 13:26:36 - INFO - __main__ -   Batch number = 91
12/27/2021 13:26:36 - INFO - __main__ -   Batch number = 92
12/27/2021 13:26:36 - INFO - __main__ -   Batch number = 93
12/27/2021 13:26:37 - INFO - __main__ -   Batch number = 94
12/27/2021 13:26:37 - INFO - __main__ -   Batch number = 95
12/27/2021 13:26:37 - INFO - __main__ -   Batch number = 96
12/27/2021 13:26:38 - INFO - __main__ -   Batch number = 97
12/27/2021 13:26:38 - INFO - __main__ -   Batch number = 98
12/27/2021 13:26:38 - INFO - __main__ -   Batch number = 99
12/27/2021 13:26:38 - INFO - __main__ -   Batch number = 100
12/27/2021 13:26:39 - INFO - __main__ -   Batch number = 101
12/27/2021 13:26:39 - INFO - __main__ -   Batch number = 102
12/27/2021 13:26:39 - INFO - __main__ -   Batch number = 103
12/27/2021 13:26:39 - INFO - __main__ -   Batch number = 104
12/27/2021 13:26:40 - INFO - __main__ -   Batch number = 105
12/27/2021 13:26:40 - INFO - __main__ -   Batch number = 106
12/27/2021 13:26:40 - INFO - __main__ -   Batch number = 107
12/27/2021 13:26:41 - INFO - __main__ -   Batch number = 108
12/27/2021 13:26:41 - INFO - __main__ -   Batch number = 109
12/27/2021 13:26:41 - INFO - __main__ -   Batch number = 110
12/27/2021 13:26:42 - INFO - __main__ -   Batch number = 111
12/27/2021 13:26:42 - INFO - __main__ -   Batch number = 112
12/27/2021 13:26:42 - INFO - __main__ -   Batch number = 113
12/27/2021 13:26:43 - INFO - __main__ -   Batch number = 114
12/27/2021 13:26:43 - INFO - __main__ -   Batch number = 115
12/27/2021 13:26:43 - INFO - __main__ -   Batch number = 116
12/27/2021 13:26:44 - INFO - __main__ -   Batch number = 117
12/27/2021 13:26:44 - INFO - __main__ -   Batch number = 118
12/27/2021 13:26:44 - INFO - __main__ -   Batch number = 119
12/27/2021 13:26:44 - INFO - __main__ -   Batch number = 120
12/27/2021 13:26:45 - INFO - __main__ -   Batch number = 121
12/27/2021 13:26:45 - INFO - __main__ -   Batch number = 122
12/27/2021 13:26:45 - INFO - __main__ -   Batch number = 123
12/27/2021 13:26:45 - INFO - __main__ -   Batch number = 124
12/27/2021 13:26:46 - INFO - __main__ -   Batch number = 125
12/27/2021 13:26:46 - INFO - __main__ -   Batch number = 126
12/27/2021 13:26:46 - INFO - __main__ -   Batch number = 127
12/27/2021 13:26:47 - INFO - __main__ -   Batch number = 128
12/27/2021 13:26:47 - INFO - __main__ -   Batch number = 129
12/27/2021 13:26:47 - INFO - __main__ -   Batch number = 130
12/27/2021 13:26:48 - INFO - __main__ -   Batch number = 131
12/27/2021 13:26:48 - INFO - __main__ -   Batch number = 132
12/27/2021 13:26:48 - INFO - __main__ -   Batch number = 133
12/27/2021 13:26:49 - INFO - __main__ -   Batch number = 134
12/27/2021 13:26:49 - INFO - __main__ -   Batch number = 135
12/27/2021 13:26:49 - INFO - __main__ -   Batch number = 136
12/27/2021 13:26:49 - INFO - __main__ -   Batch number = 137
12/27/2021 13:26:50 - INFO - __main__ -   Batch number = 138
12/27/2021 13:26:50 - INFO - __main__ -   Batch number = 139
12/27/2021 13:26:50 - INFO - __main__ -   Batch number = 140
12/27/2021 13:26:51 - INFO - __main__ -   Batch number = 141
12/27/2021 13:26:51 - INFO - __main__ -   Batch number = 142
12/27/2021 13:26:51 - INFO - __main__ -   Batch number = 143
12/27/2021 13:26:51 - INFO - __main__ -   Batch number = 144
12/27/2021 13:26:52 - INFO - __main__ -   Batch number = 145
12/27/2021 13:26:52 - INFO - __main__ -   Batch number = 146
12/27/2021 13:26:52 - INFO - __main__ -   Batch number = 147
12/27/2021 13:26:53 - INFO - __main__ -   Batch number = 148
12/27/2021 13:26:53 - INFO - __main__ -   Batch number = 149
12/27/2021 13:26:53 - INFO - __main__ -   Batch number = 150
12/27/2021 13:26:54 - INFO - __main__ -   Batch number = 151
12/27/2021 13:26:54 - INFO - __main__ -   Batch number = 152
12/27/2021 13:26:54 - INFO - __main__ -   Batch number = 153
12/27/2021 13:26:55 - INFO - __main__ -   Batch number = 154
12/27/2021 13:26:55 - INFO - __main__ -   Batch number = 155
12/27/2021 13:26:55 - INFO - __main__ -   Batch number = 156
12/27/2021 13:26:55 - INFO - __main__ -   Batch number = 157
12/27/2021 13:26:56 - INFO - __main__ -   Batch number = 158
12/27/2021 13:26:56 - INFO - __main__ -   Batch number = 159
12/27/2021 13:26:56 - INFO - __main__ -   Batch number = 160
12/27/2021 13:26:56 - INFO - __main__ -   Batch number = 161
12/27/2021 13:26:57 - INFO - __main__ -   Batch number = 162
12/27/2021 13:26:57 - INFO - __main__ -   Batch number = 163
12/27/2021 13:26:57 - INFO - __main__ -   Batch number = 164
12/27/2021 13:26:58 - INFO - __main__ -   Batch number = 165
12/27/2021 13:26:58 - INFO - __main__ -   Batch number = 166
12/27/2021 13:26:58 - INFO - __main__ -   Batch number = 167
12/27/2021 13:26:59 - INFO - __main__ -   Batch number = 168
12/27/2021 13:26:59 - INFO - __main__ -   Batch number = 169
12/27/2021 13:26:59 - INFO - __main__ -   Batch number = 170
12/27/2021 13:27:00 - INFO - __main__ -   Batch number = 171
12/27/2021 13:27:00 - INFO - __main__ -   Batch number = 172
12/27/2021 13:27:00 - INFO - __main__ -   Batch number = 173
12/27/2021 13:27:01 - INFO - __main__ -   Batch number = 174
12/27/2021 13:27:01 - INFO - __main__ -   Batch number = 175
12/27/2021 13:27:01 - INFO - __main__ -   Batch number = 176
12/27/2021 13:27:01 - INFO - __main__ -   Batch number = 177
12/27/2021 13:27:01 - INFO - __main__ -   Batch number = 178
12/27/2021 13:27:02 - INFO - __main__ -   Batch number = 179
12/27/2021 13:27:02 - INFO - __main__ -   Batch number = 180
12/27/2021 13:27:02 - INFO - __main__ -   Batch number = 181
12/27/2021 13:27:02 - INFO - __main__ -   Batch number = 182
12/27/2021 13:27:03 - INFO - __main__ -   Batch number = 183
12/27/2021 13:27:03 - INFO - __main__ -   Batch number = 184
12/27/2021 13:27:03 - INFO - __main__ -   Batch number = 185
12/27/2021 13:27:04 - INFO - __main__ -   Batch number = 186
12/27/2021 13:27:04 - INFO - __main__ -   Batch number = 187
12/27/2021 13:27:04 - INFO - __main__ -   Batch number = 188
12/27/2021 13:27:05 - INFO - __main__ -   Batch number = 189
12/27/2021 13:27:05 - INFO - __main__ -   Batch number = 190
12/27/2021 13:27:05 - INFO - __main__ -   Batch number = 191
12/27/2021 13:27:06 - INFO - __main__ -   Batch number = 192
12/27/2021 13:27:06 - INFO - __main__ -   Batch number = 193
12/27/2021 13:27:06 - INFO - __main__ -   Batch number = 194
12/27/2021 13:27:06 - INFO - __main__ -   Batch number = 195
12/27/2021 13:27:07 - INFO - __main__ -   Batch number = 196
12/27/2021 13:27:07 - INFO - __main__ -   Batch number = 197
12/27/2021 13:27:07 - INFO - __main__ -   Batch number = 198
12/27/2021 13:27:08 - INFO - __main__ -   Batch number = 199
12/27/2021 13:27:08 - INFO - __main__ -   Batch number = 200
12/27/2021 13:27:08 - INFO - __main__ -   Batch number = 201
12/27/2021 13:27:08 - INFO - __main__ -   Batch number = 202
12/27/2021 13:27:09 - INFO - __main__ -   Batch number = 203
12/27/2021 13:27:09 - INFO - __main__ -   Batch number = 204
12/27/2021 13:27:09 - INFO - __main__ -   Batch number = 205
12/27/2021 13:27:10 - INFO - __main__ -   Batch number = 206
12/27/2021 13:27:10 - INFO - __main__ -   Batch number = 207
12/27/2021 13:27:10 - INFO - __main__ -   Batch number = 208
12/27/2021 13:27:11 - INFO - __main__ -   Batch number = 209
12/27/2021 13:27:11 - INFO - __main__ -   Batch number = 210
12/27/2021 13:27:11 - INFO - __main__ -   Batch number = 211
12/27/2021 13:27:12 - INFO - __main__ -   Batch number = 212
12/27/2021 13:27:12 - INFO - __main__ -   Batch number = 213
12/27/2021 13:27:12 - INFO - __main__ -   Batch number = 214
12/27/2021 13:27:12 - INFO - __main__ -   Batch number = 215
12/27/2021 13:27:13 - INFO - __main__ -   Batch number = 216
12/27/2021 13:27:13 - INFO - __main__ -   Batch number = 217
12/27/2021 13:27:13 - INFO - __main__ -   Batch number = 218
12/27/2021 13:27:13 - INFO - __main__ -   Batch number = 219
12/27/2021 13:27:14 - INFO - __main__ -   Batch number = 220
12/27/2021 13:27:14 - INFO - __main__ -   Batch number = 221
12/27/2021 13:27:14 - INFO - __main__ -   Batch number = 222
12/27/2021 13:27:15 - INFO - __main__ -   Batch number = 223
12/27/2021 13:27:15 - INFO - __main__ -   Batch number = 224
12/27/2021 13:27:15 - INFO - __main__ -   Batch number = 225
12/27/2021 13:27:16 - INFO - __main__ -   Batch number = 226
12/27/2021 13:27:16 - INFO - __main__ -   Batch number = 227
12/27/2021 13:27:16 - INFO - __main__ -   Batch number = 228
12/27/2021 13:27:16 - INFO - __main__ -   Batch number = 229
12/27/2021 13:27:17 - INFO - __main__ -   Batch number = 230
12/27/2021 13:27:17 - INFO - __main__ -   Batch number = 231
12/27/2021 13:27:17 - INFO - __main__ -   Batch number = 232
12/27/2021 13:27:18 - INFO - __main__ -   Batch number = 233
12/27/2021 13:27:18 - INFO - __main__ -   Batch number = 234
12/27/2021 13:27:18 - INFO - __main__ -   Batch number = 235
12/27/2021 13:27:18 - INFO - __main__ -   Batch number = 236
12/27/2021 13:27:19 - INFO - __main__ -   Batch number = 237
12/27/2021 13:27:19 - INFO - __main__ -   Batch number = 238
12/27/2021 13:27:19 - INFO - __main__ -   Batch number = 239
12/27/2021 13:27:20 - INFO - __main__ -   Batch number = 240
12/27/2021 13:27:20 - INFO - __main__ -   Batch number = 241
12/27/2021 13:27:20 - INFO - __main__ -   Batch number = 242
12/27/2021 13:27:20 - INFO - __main__ -   Batch number = 243
12/27/2021 13:27:21 - INFO - __main__ -   Batch number = 244
12/27/2021 13:27:21 - INFO - __main__ -   Batch number = 245
12/27/2021 13:27:21 - INFO - __main__ -   Batch number = 246
12/27/2021 13:27:22 - INFO - __main__ -   Batch number = 247
12/27/2021 13:27:22 - INFO - __main__ -   Batch number = 248
12/27/2021 13:27:22 - INFO - __main__ -   Batch number = 249
12/27/2021 13:27:23 - INFO - __main__ -   Batch number = 250
12/27/2021 13:27:23 - INFO - __main__ -   Batch number = 251
12/27/2021 13:27:23 - INFO - __main__ -   Batch number = 252
12/27/2021 13:27:23 - INFO - __main__ -   Batch number = 253
12/27/2021 13:27:24 - INFO - __main__ -   Batch number = 254
12/27/2021 13:27:24 - INFO - __main__ -   Batch number = 255
12/27/2021 13:27:24 - INFO - __main__ -   Batch number = 256
12/27/2021 13:27:25 - INFO - __main__ -   Batch number = 257
12/27/2021 13:27:25 - INFO - __main__ -   Batch number = 258
12/27/2021 13:27:25 - INFO - __main__ -   Batch number = 259
12/27/2021 13:27:25 - INFO - __main__ -   Batch number = 260
12/27/2021 13:27:26 - INFO - __main__ -   Batch number = 261
12/27/2021 13:27:26 - INFO - __main__ -   Batch number = 262
12/27/2021 13:27:26 - INFO - __main__ -   Batch number = 263
12/27/2021 13:27:27 - INFO - __main__ -   Batch number = 264
12/27/2021 13:27:27 - INFO - __main__ -   Batch number = 265
12/27/2021 13:27:27 - INFO - __main__ -   Batch number = 266
12/27/2021 13:27:28 - INFO - __main__ -   Batch number = 267
12/27/2021 13:27:28 - INFO - __main__ -   Batch number = 268
12/27/2021 13:27:28 - INFO - __main__ -   Batch number = 269
12/27/2021 13:27:29 - INFO - __main__ -   Batch number = 270
12/27/2021 13:27:29 - INFO - __main__ -   Batch number = 271
12/27/2021 13:27:29 - INFO - __main__ -   Batch number = 272
12/27/2021 13:27:29 - INFO - __main__ -   Batch number = 273
12/27/2021 13:27:30 - INFO - __main__ -   Batch number = 274
12/27/2021 13:27:30 - INFO - __main__ -   Batch number = 275
12/27/2021 13:27:30 - INFO - __main__ -   Batch number = 276
12/27/2021 13:27:30 - INFO - __main__ -   Batch number = 277
12/27/2021 13:27:31 - INFO - __main__ -   Batch number = 278
12/27/2021 13:27:31 - INFO - __main__ -   Batch number = 279
12/27/2021 13:27:31 - INFO - __main__ -   Batch number = 280
12/27/2021 13:27:32 - INFO - __main__ -   Batch number = 281
12/27/2021 13:27:32 - INFO - __main__ -   Batch number = 282
12/27/2021 13:27:32 - INFO - __main__ -   Batch number = 283
12/27/2021 13:27:33 - INFO - __main__ -   Batch number = 284
12/27/2021 13:27:33 - INFO - __main__ -   Batch number = 285
12/27/2021 13:27:33 - INFO - __main__ -   Batch number = 286
12/27/2021 13:27:34 - INFO - __main__ -   Batch number = 287
12/27/2021 13:27:34 - INFO - __main__ -   Batch number = 288
12/27/2021 13:27:34 - INFO - __main__ -   Batch number = 289
12/27/2021 13:27:35 - INFO - __main__ -   Batch number = 290
12/27/2021 13:27:35 - INFO - __main__ -   Batch number = 291
12/27/2021 13:27:35 - INFO - __main__ -   Batch number = 292
12/27/2021 13:27:35 - INFO - __main__ -   Batch number = 293
12/27/2021 13:27:36 - INFO - __main__ -   Batch number = 294
12/27/2021 13:27:36 - INFO - __main__ -   Batch number = 295
12/27/2021 13:27:36 - INFO - __main__ -   Batch number = 296
12/27/2021 13:27:36 - INFO - __main__ -   Batch number = 297
12/27/2021 13:27:37 - INFO - __main__ -   Batch number = 298
12/27/2021 13:27:37 - INFO - __main__ -   Batch number = 299
12/27/2021 13:27:37 - INFO - __main__ -   Batch number = 300
12/27/2021 13:27:38 - INFO - __main__ -   Batch number = 301
12/27/2021 13:27:38 - INFO - __main__ -   Batch number = 302
12/27/2021 13:27:38 - INFO - __main__ -   Batch number = 303
12/27/2021 13:27:39 - INFO - __main__ -   Batch number = 304
12/27/2021 13:27:39 - INFO - __main__ -   Batch number = 305
12/27/2021 13:27:39 - INFO - __main__ -   Batch number = 306
12/27/2021 13:27:40 - INFO - __main__ -   Batch number = 307
12/27/2021 13:27:40 - INFO - __main__ -   Batch number = 308
12/27/2021 13:27:40 - INFO - __main__ -   Batch number = 309
12/27/2021 13:27:40 - INFO - __main__ -   Batch number = 310
12/27/2021 13:27:41 - INFO - __main__ -   Batch number = 311
12/27/2021 13:27:41 - INFO - __main__ -   Batch number = 312
12/27/2021 13:27:41 - INFO - __main__ -   Batch number = 313
12/27/2021 13:27:41 - INFO - __main__ -   Batch number = 314
12/27/2021 13:27:42 - INFO - __main__ -   Batch number = 315
12/27/2021 13:27:42 - INFO - __main__ -   Batch number = 316
12/27/2021 13:27:42 - INFO - __main__ -   Batch number = 317
12/27/2021 13:27:43 - INFO - __main__ -   Batch number = 318
12/27/2021 13:27:43 - INFO - __main__ -   Batch number = 319
12/27/2021 13:27:43 - INFO - __main__ -   Batch number = 320
12/27/2021 13:27:44 - INFO - __main__ -   Batch number = 321
12/27/2021 13:27:46 - INFO - __main__ -   ***** Evaluation result  in zh *****
12/27/2021 13:27:46 - INFO - __main__ -     f1 = 0.29588548302480705
12/27/2021 13:27:46 - INFO - __main__ -     loss = 3.4630675943469704
12/27/2021 13:27:46 - INFO - __main__ -     precision = 0.2154081187254474
12/27/2021 13:27:46 - INFO - __main__ -     recall = 0.4723618090452261
12/27/2021 13:27:46 - INFO - __main__ -   Language adapter for ar not found, using pt instead
12/27/2021 13:27:46 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 13:27:46 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 13:27:46 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 13:27:46 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_ar_bert-base-multilingual-cased_128
12/27/2021 13:27:48 - INFO - __main__ -   ***** Running evaluation  in ar *****
12/27/2021 13:27:48 - INFO - __main__ -     Num examples = 10000
12/27/2021 13:27:48 - INFO - __main__ -     Batch size = 32
12/27/2021 13:27:48 - INFO - __main__ -   Batch number = 1
12/27/2021 13:27:48 - INFO - __main__ -   Batch number = 2
12/27/2021 13:27:48 - INFO - __main__ -   Batch number = 3
12/27/2021 13:27:48 - INFO - __main__ -   Batch number = 4
12/27/2021 13:27:49 - INFO - __main__ -   Batch number = 5
12/27/2021 13:27:49 - INFO - __main__ -   Batch number = 6
12/27/2021 13:27:49 - INFO - __main__ -   Batch number = 7
12/27/2021 13:27:50 - INFO - __main__ -   Batch number = 8
12/27/2021 13:27:50 - INFO - __main__ -   Batch number = 9
12/27/2021 13:27:50 - INFO - __main__ -   Batch number = 10
12/27/2021 13:27:50 - INFO - __main__ -   Batch number = 11
12/27/2021 13:27:51 - INFO - __main__ -   Batch number = 12
12/27/2021 13:27:51 - INFO - __main__ -   Batch number = 13
12/27/2021 13:27:51 - INFO - __main__ -   Batch number = 14
12/27/2021 13:27:52 - INFO - __main__ -   Batch number = 15
12/27/2021 13:27:52 - INFO - __main__ -   Batch number = 16
12/27/2021 13:27:52 - INFO - __main__ -   Batch number = 17
12/27/2021 13:27:53 - INFO - __main__ -   Batch number = 18
12/27/2021 13:27:53 - INFO - __main__ -   Batch number = 19
12/27/2021 13:27:53 - INFO - __main__ -   Batch number = 20
12/27/2021 13:27:53 - INFO - __main__ -   Batch number = 21
12/27/2021 13:27:53 - INFO - __main__ -   Batch number = 22
12/27/2021 13:27:54 - INFO - __main__ -   Batch number = 23
12/27/2021 13:27:54 - INFO - __main__ -   Batch number = 24
12/27/2021 13:27:54 - INFO - __main__ -   Batch number = 25
12/27/2021 13:27:55 - INFO - __main__ -   Batch number = 26
12/27/2021 13:27:55 - INFO - __main__ -   Batch number = 27
12/27/2021 13:27:55 - INFO - __main__ -   Batch number = 28
12/27/2021 13:27:56 - INFO - __main__ -   Batch number = 29
12/27/2021 13:27:56 - INFO - __main__ -   Batch number = 30
12/27/2021 13:27:56 - INFO - __main__ -   Batch number = 31
12/27/2021 13:27:57 - INFO - __main__ -   Batch number = 32
12/27/2021 13:27:57 - INFO - __main__ -   Batch number = 33
12/27/2021 13:27:57 - INFO - __main__ -   Batch number = 34
12/27/2021 13:27:58 - INFO - __main__ -   Batch number = 35
12/27/2021 13:27:58 - INFO - __main__ -   Batch number = 36
12/27/2021 13:27:58 - INFO - __main__ -   Batch number = 37
12/27/2021 13:27:58 - INFO - __main__ -   Batch number = 38
12/27/2021 13:27:59 - INFO - __main__ -   Batch number = 39
12/27/2021 13:27:59 - INFO - __main__ -   Batch number = 40
12/27/2021 13:27:59 - INFO - __main__ -   Batch number = 41
12/27/2021 13:27:59 - INFO - __main__ -   Batch number = 42
12/27/2021 13:27:59 - INFO - __main__ -   Batch number = 43
12/27/2021 13:28:00 - INFO - __main__ -   Batch number = 44
12/27/2021 13:28:00 - INFO - __main__ -   Batch number = 45
12/27/2021 13:28:00 - INFO - __main__ -   Batch number = 46
12/27/2021 13:28:01 - INFO - __main__ -   Batch number = 47
12/27/2021 13:28:01 - INFO - __main__ -   Batch number = 48
12/27/2021 13:28:01 - INFO - __main__ -   Batch number = 49
12/27/2021 13:28:02 - INFO - __main__ -   Batch number = 50
12/27/2021 13:28:02 - INFO - __main__ -   Batch number = 51
12/27/2021 13:28:02 - INFO - __main__ -   Batch number = 52
12/27/2021 13:28:03 - INFO - __main__ -   Batch number = 53
12/27/2021 13:28:03 - INFO - __main__ -   Batch number = 54
12/27/2021 13:28:03 - INFO - __main__ -   Batch number = 55
12/27/2021 13:28:04 - INFO - __main__ -   Batch number = 56
12/27/2021 13:28:04 - INFO - __main__ -   Batch number = 57
12/27/2021 13:28:04 - INFO - __main__ -   Batch number = 58
12/27/2021 13:28:04 - INFO - __main__ -   Batch number = 59
12/27/2021 13:28:05 - INFO - __main__ -   Batch number = 60
12/27/2021 13:28:05 - INFO - __main__ -   Batch number = 61
12/27/2021 13:28:05 - INFO - __main__ -   Batch number = 62
12/27/2021 13:28:05 - INFO - __main__ -   Batch number = 63
12/27/2021 13:28:06 - INFO - __main__ -   Batch number = 64
12/27/2021 13:28:06 - INFO - __main__ -   Batch number = 65
12/27/2021 13:28:06 - INFO - __main__ -   Batch number = 66
12/27/2021 13:28:07 - INFO - __main__ -   Batch number = 67
12/27/2021 13:28:07 - INFO - __main__ -   Batch number = 68
12/27/2021 13:28:07 - INFO - __main__ -   Batch number = 69
12/27/2021 13:28:08 - INFO - __main__ -   Batch number = 70
12/27/2021 13:28:08 - INFO - __main__ -   Batch number = 71
12/27/2021 13:28:08 - INFO - __main__ -   Batch number = 72
12/27/2021 13:28:09 - INFO - __main__ -   Batch number = 73
12/27/2021 13:28:09 - INFO - __main__ -   Batch number = 74
12/27/2021 13:28:09 - INFO - __main__ -   Batch number = 75
12/27/2021 13:28:10 - INFO - __main__ -   Batch number = 76
12/27/2021 13:28:10 - INFO - __main__ -   Batch number = 77
12/27/2021 13:28:10 - INFO - __main__ -   Batch number = 78
12/27/2021 13:28:10 - INFO - __main__ -   Batch number = 79
12/27/2021 13:28:11 - INFO - __main__ -   Batch number = 80
12/27/2021 13:28:11 - INFO - __main__ -   Batch number = 81
12/27/2021 13:28:11 - INFO - __main__ -   Batch number = 82
12/27/2021 13:28:11 - INFO - __main__ -   Batch number = 83
12/27/2021 13:28:12 - INFO - __main__ -   Batch number = 84
12/27/2021 13:28:12 - INFO - __main__ -   Batch number = 85
12/27/2021 13:28:12 - INFO - __main__ -   Batch number = 86
12/27/2021 13:28:13 - INFO - __main__ -   Batch number = 87
12/27/2021 13:28:13 - INFO - __main__ -   Batch number = 88
12/27/2021 13:28:13 - INFO - __main__ -   Batch number = 89
12/27/2021 13:28:14 - INFO - __main__ -   Batch number = 90
12/27/2021 13:28:14 - INFO - __main__ -   Batch number = 91
12/27/2021 13:28:14 - INFO - __main__ -   Batch number = 92
12/27/2021 13:28:15 - INFO - __main__ -   Batch number = 93
12/27/2021 13:28:15 - INFO - __main__ -   Batch number = 94
12/27/2021 13:28:15 - INFO - __main__ -   Batch number = 95
12/27/2021 13:28:15 - INFO - __main__ -   Batch number = 96
12/27/2021 13:28:16 - INFO - __main__ -   Batch number = 97
12/27/2021 13:28:16 - INFO - __main__ -   Batch number = 98
12/27/2021 13:28:16 - INFO - __main__ -   Batch number = 99
12/27/2021 13:28:16 - INFO - __main__ -   Batch number = 100
12/27/2021 13:28:17 - INFO - __main__ -   Batch number = 101
12/27/2021 13:28:17 - INFO - __main__ -   Batch number = 102
12/27/2021 13:28:17 - INFO - __main__ -   Batch number = 103
12/27/2021 13:28:17 - INFO - __main__ -   Batch number = 104
12/27/2021 13:28:18 - INFO - __main__ -   Batch number = 105
12/27/2021 13:28:18 - INFO - __main__ -   Batch number = 106
12/27/2021 13:28:18 - INFO - __main__ -   Batch number = 107
12/27/2021 13:28:19 - INFO - __main__ -   Batch number = 108
12/27/2021 13:28:19 - INFO - __main__ -   Batch number = 109
12/27/2021 13:28:19 - INFO - __main__ -   Batch number = 110
12/27/2021 13:28:20 - INFO - __main__ -   Batch number = 111
12/27/2021 13:28:20 - INFO - __main__ -   Batch number = 112
12/27/2021 13:28:20 - INFO - __main__ -   Batch number = 113
12/27/2021 13:28:21 - INFO - __main__ -   Batch number = 114
12/27/2021 13:28:21 - INFO - __main__ -   Batch number = 115
12/27/2021 13:28:21 - INFO - __main__ -   Batch number = 116
12/27/2021 13:28:21 - INFO - __main__ -   Batch number = 117
12/27/2021 13:28:22 - INFO - __main__ -   Batch number = 118
12/27/2021 13:28:22 - INFO - __main__ -   Batch number = 119
12/27/2021 13:28:22 - INFO - __main__ -   Batch number = 120
12/27/2021 13:28:22 - INFO - __main__ -   Batch number = 121
12/27/2021 13:28:23 - INFO - __main__ -   Batch number = 122
12/27/2021 13:28:23 - INFO - __main__ -   Batch number = 123
12/27/2021 13:28:23 - INFO - __main__ -   Batch number = 124
12/27/2021 13:28:24 - INFO - __main__ -   Batch number = 125
12/27/2021 13:28:24 - INFO - __main__ -   Batch number = 126
12/27/2021 13:28:24 - INFO - __main__ -   Batch number = 127
12/27/2021 13:28:25 - INFO - __main__ -   Batch number = 128
12/27/2021 13:28:25 - INFO - __main__ -   Batch number = 129
12/27/2021 13:28:25 - INFO - __main__ -   Batch number = 130
12/27/2021 13:28:26 - INFO - __main__ -   Batch number = 131
12/27/2021 13:28:26 - INFO - __main__ -   Batch number = 132
12/27/2021 13:28:26 - INFO - __main__ -   Batch number = 133
12/27/2021 13:28:27 - INFO - __main__ -   Batch number = 134
12/27/2021 13:28:27 - INFO - __main__ -   Batch number = 135
12/27/2021 13:28:27 - INFO - __main__ -   Batch number = 136
12/27/2021 13:28:27 - INFO - __main__ -   Batch number = 137
12/27/2021 13:28:28 - INFO - __main__ -   Batch number = 138
12/27/2021 13:28:28 - INFO - __main__ -   Batch number = 139
12/27/2021 13:28:28 - INFO - __main__ -   Batch number = 140
12/27/2021 13:28:28 - INFO - __main__ -   Batch number = 141
12/27/2021 13:28:29 - INFO - __main__ -   Batch number = 142
12/27/2021 13:28:29 - INFO - __main__ -   Batch number = 143
12/27/2021 13:28:29 - INFO - __main__ -   Batch number = 144
12/27/2021 13:28:30 - INFO - __main__ -   Batch number = 145
12/27/2021 13:28:30 - INFO - __main__ -   Batch number = 146
12/27/2021 13:28:30 - INFO - __main__ -   Batch number = 147
12/27/2021 13:28:31 - INFO - __main__ -   Batch number = 148
12/27/2021 13:28:31 - INFO - __main__ -   Batch number = 149
12/27/2021 13:28:31 - INFO - __main__ -   Batch number = 150
12/27/2021 13:28:32 - INFO - __main__ -   Batch number = 151
12/27/2021 13:28:32 - INFO - __main__ -   Batch number = 152
12/27/2021 13:28:32 - INFO - __main__ -   Batch number = 153
12/27/2021 13:28:32 - INFO - __main__ -   Batch number = 154
12/27/2021 13:28:33 - INFO - __main__ -   Batch number = 155
12/27/2021 13:28:33 - INFO - __main__ -   Batch number = 156
12/27/2021 13:28:33 - INFO - __main__ -   Batch number = 157
12/27/2021 13:28:33 - INFO - __main__ -   Batch number = 158
12/27/2021 13:28:34 - INFO - __main__ -   Batch number = 159
12/27/2021 13:28:34 - INFO - __main__ -   Batch number = 160
12/27/2021 13:28:34 - INFO - __main__ -   Batch number = 161
12/27/2021 13:28:35 - INFO - __main__ -   Batch number = 162
12/27/2021 13:28:35 - INFO - __main__ -   Batch number = 163
12/27/2021 13:28:35 - INFO - __main__ -   Batch number = 164
12/27/2021 13:28:36 - INFO - __main__ -   Batch number = 165
12/27/2021 13:28:36 - INFO - __main__ -   Batch number = 166
12/27/2021 13:28:36 - INFO - __main__ -   Batch number = 167
12/27/2021 13:28:37 - INFO - __main__ -   Batch number = 168
12/27/2021 13:28:37 - INFO - __main__ -   Batch number = 169
12/27/2021 13:28:37 - INFO - __main__ -   Batch number = 170
12/27/2021 13:28:38 - INFO - __main__ -   Batch number = 171
12/27/2021 13:28:38 - INFO - __main__ -   Batch number = 172
12/27/2021 13:28:38 - INFO - __main__ -   Batch number = 173
12/27/2021 13:28:38 - INFO - __main__ -   Batch number = 174
12/27/2021 13:28:39 - INFO - __main__ -   Batch number = 175
12/27/2021 13:28:39 - INFO - __main__ -   Batch number = 176
12/27/2021 13:28:39 - INFO - __main__ -   Batch number = 177
12/27/2021 13:28:39 - INFO - __main__ -   Batch number = 178
12/27/2021 13:28:40 - INFO - __main__ -   Batch number = 179
12/27/2021 13:28:40 - INFO - __main__ -   Batch number = 180
12/27/2021 13:28:40 - INFO - __main__ -   Batch number = 181
12/27/2021 13:28:41 - INFO - __main__ -   Batch number = 182
12/27/2021 13:28:41 - INFO - __main__ -   Batch number = 183
12/27/2021 13:28:41 - INFO - __main__ -   Batch number = 184
12/27/2021 13:28:41 - INFO - __main__ -   Batch number = 185
12/27/2021 13:28:42 - INFO - __main__ -   Batch number = 186
12/27/2021 13:28:42 - INFO - __main__ -   Batch number = 187
12/27/2021 13:28:42 - INFO - __main__ -   Batch number = 188
12/27/2021 13:28:43 - INFO - __main__ -   Batch number = 189
12/27/2021 13:28:43 - INFO - __main__ -   Batch number = 190
12/27/2021 13:28:43 - INFO - __main__ -   Batch number = 191
12/27/2021 13:28:44 - INFO - __main__ -   Batch number = 192
12/27/2021 13:28:44 - INFO - __main__ -   Batch number = 193
12/27/2021 13:28:44 - INFO - __main__ -   Batch number = 194
12/27/2021 13:28:44 - INFO - __main__ -   Batch number = 195
12/27/2021 13:28:45 - INFO - __main__ -   Batch number = 196
12/27/2021 13:28:45 - INFO - __main__ -   Batch number = 197
12/27/2021 13:28:45 - INFO - __main__ -   Batch number = 198
12/27/2021 13:28:46 - INFO - __main__ -   Batch number = 199
12/27/2021 13:28:46 - INFO - __main__ -   Batch number = 200
12/27/2021 13:28:46 - INFO - __main__ -   Batch number = 201
12/27/2021 13:28:46 - INFO - __main__ -   Batch number = 202
12/27/2021 13:28:47 - INFO - __main__ -   Batch number = 203
12/27/2021 13:28:47 - INFO - __main__ -   Batch number = 204
12/27/2021 13:28:47 - INFO - __main__ -   Batch number = 205
12/27/2021 13:28:48 - INFO - __main__ -   Batch number = 206
12/27/2021 13:28:48 - INFO - __main__ -   Batch number = 207
12/27/2021 13:28:48 - INFO - __main__ -   Batch number = 208
12/27/2021 13:28:49 - INFO - __main__ -   Batch number = 209
12/27/2021 13:28:49 - INFO - __main__ -   Batch number = 210
12/27/2021 13:28:49 - INFO - __main__ -   Batch number = 211
12/27/2021 13:28:49 - INFO - __main__ -   Batch number = 212
12/27/2021 13:28:50 - INFO - __main__ -   Batch number = 213
12/27/2021 13:28:50 - INFO - __main__ -   Batch number = 214
12/27/2021 13:28:50 - INFO - __main__ -   Batch number = 215
12/27/2021 13:28:51 - INFO - __main__ -   Batch number = 216
12/27/2021 13:28:51 - INFO - __main__ -   Batch number = 217
12/27/2021 13:28:51 - INFO - __main__ -   Batch number = 218
12/27/2021 13:28:51 - INFO - __main__ -   Batch number = 219
12/27/2021 13:28:52 - INFO - __main__ -   Batch number = 220
12/27/2021 13:28:52 - INFO - __main__ -   Batch number = 221
12/27/2021 13:28:52 - INFO - __main__ -   Batch number = 222
12/27/2021 13:28:53 - INFO - __main__ -   Batch number = 223
12/27/2021 13:28:53 - INFO - __main__ -   Batch number = 224
12/27/2021 13:28:53 - INFO - __main__ -   Batch number = 225
12/27/2021 13:28:54 - INFO - __main__ -   Batch number = 226
12/27/2021 13:28:54 - INFO - __main__ -   Batch number = 227
12/27/2021 13:28:54 - INFO - __main__ -   Batch number = 228
12/27/2021 13:28:55 - INFO - __main__ -   Batch number = 229
12/27/2021 13:28:55 - INFO - __main__ -   Batch number = 230
12/27/2021 13:28:55 - INFO - __main__ -   Batch number = 231
12/27/2021 13:28:55 - INFO - __main__ -   Batch number = 232
12/27/2021 13:28:56 - INFO - __main__ -   Batch number = 233
12/27/2021 13:28:56 - INFO - __main__ -   Batch number = 234
12/27/2021 13:28:56 - INFO - __main__ -   Batch number = 235
12/27/2021 13:28:57 - INFO - __main__ -   Batch number = 236
12/27/2021 13:28:57 - INFO - __main__ -   Batch number = 237
12/27/2021 13:28:57 - INFO - __main__ -   Batch number = 238
12/27/2021 13:28:58 - INFO - __main__ -   Batch number = 239
12/27/2021 13:28:58 - INFO - __main__ -   Batch number = 240
12/27/2021 13:28:58 - INFO - __main__ -   Batch number = 241
12/27/2021 13:28:59 - INFO - __main__ -   Batch number = 242
12/27/2021 13:28:59 - INFO - __main__ -   Batch number = 243
12/27/2021 13:28:59 - INFO - __main__ -   Batch number = 244
12/27/2021 13:29:00 - INFO - __main__ -   Batch number = 245
12/27/2021 13:29:00 - INFO - __main__ -   Batch number = 246
12/27/2021 13:29:00 - INFO - __main__ -   Batch number = 247
12/27/2021 13:29:00 - INFO - __main__ -   Batch number = 248
12/27/2021 13:29:01 - INFO - __main__ -   Batch number = 249
12/27/2021 13:29:01 - INFO - __main__ -   Batch number = 250
12/27/2021 13:29:01 - INFO - __main__ -   Batch number = 251
12/27/2021 13:29:01 - INFO - __main__ -   Batch number = 252
12/27/2021 13:29:02 - INFO - __main__ -   Batch number = 253
12/27/2021 13:29:02 - INFO - __main__ -   Batch number = 254
12/27/2021 13:29:02 - INFO - __main__ -   Batch number = 255
12/27/2021 13:29:02 - INFO - __main__ -   Batch number = 256
12/27/2021 13:29:03 - INFO - __main__ -   Batch number = 257
12/27/2021 13:29:03 - INFO - __main__ -   Batch number = 258
12/27/2021 13:29:03 - INFO - __main__ -   Batch number = 259
12/27/2021 13:29:04 - INFO - __main__ -   Batch number = 260
12/27/2021 13:29:04 - INFO - __main__ -   Batch number = 261
12/27/2021 13:29:04 - INFO - __main__ -   Batch number = 262
12/27/2021 13:29:05 - INFO - __main__ -   Batch number = 263
12/27/2021 13:29:05 - INFO - __main__ -   Batch number = 264
12/27/2021 13:29:05 - INFO - __main__ -   Batch number = 265
12/27/2021 13:29:06 - INFO - __main__ -   Batch number = 266
12/27/2021 13:29:06 - INFO - __main__ -   Batch number = 267
12/27/2021 13:29:06 - INFO - __main__ -   Batch number = 268
12/27/2021 13:29:06 - INFO - __main__ -   Batch number = 269
12/27/2021 13:29:07 - INFO - __main__ -   Batch number = 270
12/27/2021 13:29:07 - INFO - __main__ -   Batch number = 271
12/27/2021 13:29:07 - INFO - __main__ -   Batch number = 272
12/27/2021 13:29:08 - INFO - __main__ -   Batch number = 273
12/27/2021 13:29:08 - INFO - __main__ -   Batch number = 274
12/27/2021 13:29:08 - INFO - __main__ -   Batch number = 275
12/27/2021 13:29:09 - INFO - __main__ -   Batch number = 276
12/27/2021 13:29:09 - INFO - __main__ -   Batch number = 277
12/27/2021 13:29:09 - INFO - __main__ -   Batch number = 278
12/27/2021 13:29:10 - INFO - __main__ -   Batch number = 279
12/27/2021 13:29:10 - INFO - __main__ -   Batch number = 280
12/27/2021 13:29:10 - INFO - __main__ -   Batch number = 281
12/27/2021 13:29:11 - INFO - __main__ -   Batch number = 282
12/27/2021 13:29:11 - INFO - __main__ -   Batch number = 283
12/27/2021 13:29:11 - INFO - __main__ -   Batch number = 284
12/27/2021 13:29:11 - INFO - __main__ -   Batch number = 285
12/27/2021 13:29:12 - INFO - __main__ -   Batch number = 286
12/27/2021 13:29:12 - INFO - __main__ -   Batch number = 287
12/27/2021 13:29:12 - INFO - __main__ -   Batch number = 288
12/27/2021 13:29:12 - INFO - __main__ -   Batch number = 289
12/27/2021 13:29:13 - INFO - __main__ -   Batch number = 290
12/27/2021 13:29:13 - INFO - __main__ -   Batch number = 291
12/27/2021 13:29:13 - INFO - __main__ -   Batch number = 292
12/27/2021 13:29:14 - INFO - __main__ -   Batch number = 293
12/27/2021 13:29:14 - INFO - __main__ -   Batch number = 294
12/27/2021 13:29:14 - INFO - __main__ -   Batch number = 295
12/27/2021 13:29:15 - INFO - __main__ -   Batch number = 296
12/27/2021 13:29:15 - INFO - __main__ -   Batch number = 297
12/27/2021 13:29:15 - INFO - __main__ -   Batch number = 298
12/27/2021 13:29:16 - INFO - __main__ -   Batch number = 299
12/27/2021 13:29:16 - INFO - __main__ -   Batch number = 300
12/27/2021 13:29:16 - INFO - __main__ -   Batch number = 301
12/27/2021 13:29:17 - INFO - __main__ -   Batch number = 302
12/27/2021 13:29:17 - INFO - __main__ -   Batch number = 303
12/27/2021 13:29:17 - INFO - __main__ -   Batch number = 304
12/27/2021 13:29:17 - INFO - __main__ -   Batch number = 305
12/27/2021 13:29:18 - INFO - __main__ -   Batch number = 306
12/27/2021 13:29:18 - INFO - __main__ -   Batch number = 307
12/27/2021 13:29:18 - INFO - __main__ -   Batch number = 308
12/27/2021 13:29:18 - INFO - __main__ -   Batch number = 309
12/27/2021 13:29:19 - INFO - __main__ -   Batch number = 310
12/27/2021 13:29:19 - INFO - __main__ -   Batch number = 311
12/27/2021 13:29:19 - INFO - __main__ -   Batch number = 312
12/27/2021 13:29:19 - INFO - __main__ -   Batch number = 313
12/27/2021 13:29:21 - INFO - __main__ -   ***** Evaluation result  in ar *****
12/27/2021 13:29:21 - INFO - __main__ -     f1 = 0.33872048233126784
12/27/2021 13:29:21 - INFO - __main__ -     loss = 5.488271574623669
12/27/2021 13:29:21 - INFO - __main__ -     precision = 0.3203960396039604
12/27/2021 13:29:21 - INFO - __main__ -     recall = 0.35926814104272137
12/27/2021 13:29:21 - INFO - __main__ -   Language adapter for jv not found, using pt instead
12/27/2021 13:29:21 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 13:29:21 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 13:29:21 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 13:29:21 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_jv_bert-base-multilingual-cased_128
12/27/2021 13:29:21 - INFO - __main__ -   ***** Running evaluation  in jv *****
12/27/2021 13:29:21 - INFO - __main__ -     Num examples = 100
12/27/2021 13:29:21 - INFO - __main__ -     Batch size = 32
12/27/2021 13:29:21 - INFO - __main__ -   Batch number = 1
12/27/2021 13:29:21 - INFO - __main__ -   Batch number = 2
12/27/2021 13:29:21 - INFO - __main__ -   Batch number = 3
12/27/2021 13:29:22 - INFO - __main__ -   Batch number = 4
12/27/2021 13:29:22 - INFO - __main__ -   ***** Evaluation result  in jv *****
12/27/2021 13:29:22 - INFO - __main__ -     f1 = 0.5860805860805861
12/27/2021 13:29:22 - INFO - __main__ -     loss = 3.148055523633957
12/27/2021 13:29:22 - INFO - __main__ -     precision = 0.5128205128205128
12/27/2021 13:29:22 - INFO - __main__ -     recall = 0.6837606837606838
12/27/2021 13:29:22 - INFO - __main__ -   Language adapter for sw not found, using pt instead
12/27/2021 13:29:22 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 13:29:22 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 13:29:22 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 13:29:22 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_sw_bert-base-multilingual-cased_128
12/27/2021 13:29:22 - INFO - __main__ -   ***** Running evaluation  in sw *****
12/27/2021 13:29:22 - INFO - __main__ -     Num examples = 1000
12/27/2021 13:29:22 - INFO - __main__ -     Batch size = 32
12/27/2021 13:29:22 - INFO - __main__ -   Batch number = 1
12/27/2021 13:29:22 - INFO - __main__ -   Batch number = 2
12/27/2021 13:29:22 - INFO - __main__ -   Batch number = 3
12/27/2021 13:29:23 - INFO - __main__ -   Batch number = 4
12/27/2021 13:29:23 - INFO - __main__ -   Batch number = 5
12/27/2021 13:29:23 - INFO - __main__ -   Batch number = 6
12/27/2021 13:29:24 - INFO - __main__ -   Batch number = 7
12/27/2021 13:29:24 - INFO - __main__ -   Batch number = 8
12/27/2021 13:29:24 - INFO - __main__ -   Batch number = 9
12/27/2021 13:29:25 - INFO - __main__ -   Batch number = 10
12/27/2021 13:29:25 - INFO - __main__ -   Batch number = 11
12/27/2021 13:29:25 - INFO - __main__ -   Batch number = 12
12/27/2021 13:29:26 - INFO - __main__ -   Batch number = 13
12/27/2021 13:29:26 - INFO - __main__ -   Batch number = 14
12/27/2021 13:29:26 - INFO - __main__ -   Batch number = 15
12/27/2021 13:29:26 - INFO - __main__ -   Batch number = 16
12/27/2021 13:29:27 - INFO - __main__ -   Batch number = 17
12/27/2021 13:29:27 - INFO - __main__ -   Batch number = 18
12/27/2021 13:29:27 - INFO - __main__ -   Batch number = 19
12/27/2021 13:29:27 - INFO - __main__ -   Batch number = 20
12/27/2021 13:29:28 - INFO - __main__ -   Batch number = 21
12/27/2021 13:29:28 - INFO - __main__ -   Batch number = 22
12/27/2021 13:29:28 - INFO - __main__ -   Batch number = 23
12/27/2021 13:29:28 - INFO - __main__ -   Batch number = 24
12/27/2021 13:29:29 - INFO - __main__ -   Batch number = 25
12/27/2021 13:29:29 - INFO - __main__ -   Batch number = 26
12/27/2021 13:29:29 - INFO - __main__ -   Batch number = 27
12/27/2021 13:29:30 - INFO - __main__ -   Batch number = 28
12/27/2021 13:29:30 - INFO - __main__ -   Batch number = 29
12/27/2021 13:29:30 - INFO - __main__ -   Batch number = 30
12/27/2021 13:29:31 - INFO - __main__ -   Batch number = 31
12/27/2021 13:29:31 - INFO - __main__ -   Batch number = 32
12/27/2021 13:29:31 - INFO - __main__ -   ***** Evaluation result  in sw *****
12/27/2021 13:29:31 - INFO - __main__ -     f1 = 0.5541978715017737
12/27/2021 13:29:31 - INFO - __main__ -     loss = 3.399906139820814
12/27/2021 13:29:31 - INFO - __main__ -     precision = 0.5234549516008935
12/27/2021 13:29:31 - INFO - __main__ -     recall = 0.5887772194304858
12/27/2021 13:29:31 - INFO - __main__ -   Language adapter for is not found, using pt instead
12/27/2021 13:29:31 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 13:29:31 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 13:29:31 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 13:29:31 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_is_bert-base-multilingual-cased_128
12/27/2021 13:29:31 - INFO - __main__ -   ***** Running evaluation  in is *****
12/27/2021 13:29:31 - INFO - __main__ -     Num examples = 1000
12/27/2021 13:29:31 - INFO - __main__ -     Batch size = 32
12/27/2021 13:29:31 - INFO - __main__ -   Batch number = 1
12/27/2021 13:29:32 - INFO - __main__ -   Batch number = 2
12/27/2021 13:29:32 - INFO - __main__ -   Batch number = 3
12/27/2021 13:29:32 - INFO - __main__ -   Batch number = 4
12/27/2021 13:29:32 - INFO - __main__ -   Batch number = 5
12/27/2021 13:29:33 - INFO - __main__ -   Batch number = 6
12/27/2021 13:29:33 - INFO - __main__ -   Batch number = 7
12/27/2021 13:29:33 - INFO - __main__ -   Batch number = 8
12/27/2021 13:29:33 - INFO - __main__ -   Batch number = 9
12/27/2021 13:29:34 - INFO - __main__ -   Batch number = 10
12/27/2021 13:29:34 - INFO - __main__ -   Batch number = 11
12/27/2021 13:29:34 - INFO - __main__ -   Batch number = 12
12/27/2021 13:29:35 - INFO - __main__ -   Batch number = 13
12/27/2021 13:29:35 - INFO - __main__ -   Batch number = 14
12/27/2021 13:29:35 - INFO - __main__ -   Batch number = 15
12/27/2021 13:29:36 - INFO - __main__ -   Batch number = 16
12/27/2021 13:29:36 - INFO - __main__ -   Batch number = 17
12/27/2021 13:29:36 - INFO - __main__ -   Batch number = 18
12/27/2021 13:29:37 - INFO - __main__ -   Batch number = 19
12/27/2021 13:29:37 - INFO - __main__ -   Batch number = 20
12/27/2021 13:29:37 - INFO - __main__ -   Batch number = 21
12/27/2021 13:29:37 - INFO - __main__ -   Batch number = 22
12/27/2021 13:29:38 - INFO - __main__ -   Batch number = 23
12/27/2021 13:29:38 - INFO - __main__ -   Batch number = 24
12/27/2021 13:29:38 - INFO - __main__ -   Batch number = 25
12/27/2021 13:29:38 - INFO - __main__ -   Batch number = 26
12/27/2021 13:29:39 - INFO - __main__ -   Batch number = 27
12/27/2021 13:29:39 - INFO - __main__ -   Batch number = 28
12/27/2021 13:29:39 - INFO - __main__ -   Batch number = 29
12/27/2021 13:29:40 - INFO - __main__ -   Batch number = 30
12/27/2021 13:29:40 - INFO - __main__ -   Batch number = 31
12/27/2021 13:29:40 - INFO - __main__ -   Batch number = 32
12/27/2021 13:29:40 - INFO - __main__ -   ***** Evaluation result  in is *****
12/27/2021 13:29:40 - INFO - __main__ -     f1 = 0.6418188594856504
12/27/2021 13:29:40 - INFO - __main__ -     loss = 1.2655135300010443
12/27/2021 13:29:40 - INFO - __main__ -     precision = 0.5905349794238683
12/27/2021 13:29:40 - INFO - __main__ -     recall = 0.7028571428571428
12/27/2021 13:29:40 - INFO - __main__ -   Language adapter for my not found, using pt instead
12/27/2021 13:29:40 - INFO - __main__ -   Set active language adapter to pt
12/27/2021 13:29:40 - INFO - __main__ -   Args Adapter Weight = None
12/27/2021 13:29:40 - INFO - __main__ -   Adapter Languages = ['pt']
12/27/2021 13:29:40 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//panx/panx_processed_maxlen128/cached_test_my_bert-base-multilingual-cased_128
12/27/2021 13:29:41 - INFO - __main__ -   ***** Running evaluation  in my *****
12/27/2021 13:29:41 - INFO - __main__ -     Num examples = 110
12/27/2021 13:29:41 - INFO - __main__ -     Batch size = 32
12/27/2021 13:29:41 - INFO - __main__ -   Batch number = 1
12/27/2021 13:29:41 - INFO - __main__ -   Batch number = 2
12/27/2021 13:29:41 - INFO - __main__ -   Batch number = 3
12/27/2021 13:29:41 - INFO - __main__ -   Batch number = 4
12/27/2021 13:29:42 - INFO - __main__ -   ***** Evaluation result  in my *****
12/27/2021 13:29:42 - INFO - __main__ -     f1 = 0.3310810810810811
12/27/2021 13:29:42 - INFO - __main__ -     loss = 3.5024573802948
12/27/2021 13:29:42 - INFO - __main__ -     precision = 0.2768361581920904
12/27/2021 13:29:42 - INFO - __main__ -     recall = 0.4117647058823529
