01/15/2022 20:23:12 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='aii,he,mt', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 20:23:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 20:23:12 - INFO - __main__ -   Seed = 1
01/15/2022 20:23:12 - INFO - root -   save model
01/15/2022 20:23:12 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='aii,he,mt', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 20:23:12 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 20:23:15 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 20:23:21 - INFO - __main__ -   Using lang2id = None
01/15/2022 20:23:21 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 20:23:21 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/15/2022 20:23:21 - INFO - root -   Trying to decide if add adapter
01/15/2022 20:23:21 - INFO - root -   loading task adapter
01/15/2022 20:23:21 - INFO - root -   loading lang adpater en/wiki@ukp
01/15/2022 20:23:21 - INFO - __main__ -   Adapter Languages : ['en'], Length : 1
01/15/2022 20:23:21 - INFO - __main__ -   Adapter Names ['en/wiki@ukp'], Length : 1
01/15/2022 20:23:21 - INFO - __main__ -   Language = en
01/15/2022 20:23:21 - INFO - __main__ -   Adapter Name = en/wiki@ukp
01/15/2022 20:23:26 - INFO - __main__ -   Language adapter for aii not found, using en instead
01/15/2022 20:23:26 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:23:26 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:23:26 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:23:26 - INFO - __main__ -   all languages = aii
01/15/2022 20:23:26 - INFO - __main__ -   Creating features from dataset file at /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/aii/test.bert-base-multilingual-cased in language aii
01/15/2022 20:23:26 - INFO - utils_tag -   lang_id=0, lang=aii, lang2id=None
01/15/2022 20:23:26 - INFO - utils_tag -   Writing example 0 of 57
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: aii-1
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] [UNK] [UNK] [UNK] [UNK] [UNK] ، [UNK] [UNK] [UNK] [UNK] [UNK] . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 100 100 100 100 100 752 100 100 100 100 100 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 6 6 1 4 16 13 3 11 1 4 16 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: aii-2
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] ? [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 100 100 100 100 100 100 100 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 8 1 4 5 1 5 1 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: aii-3
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] [UNK] [UNK] [UNK] [UNK] . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 100 100 100 100 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 6 8 11 4 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: aii-4
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] [UNK] [UNK] [UNK] [UNK] . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 100 100 100 100 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 8 10 4 8 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: aii-5
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] [UNK] [UNK] [UNK] . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 100 100 100 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 8 1 4 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - __main__ -   Saving features into cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_aii_bert-base-multilingual-cased_128, len(features)=57
01/15/2022 20:23:26 - INFO - __main__ -   ***** Running evaluation  in aii *****
01/15/2022 20:23:26 - INFO - __main__ -     Num examples = 57
01/15/2022 20:23:26 - INFO - __main__ -     Batch size = 32
01/15/2022 20:23:26 - INFO - __main__ -   Batch number = 1
01/15/2022 20:23:26 - INFO - __main__ -   Batch number = 2
01/15/2022 20:23:26 - INFO - __main__ -   ***** Evaluation result  in aii *****
01/15/2022 20:23:26 - INFO - __main__ -     f1 = 0.0
01/15/2022 20:23:26 - INFO - __main__ -     loss = 8.341755390167236
01/15/2022 20:23:26 - INFO - __main__ -     precision = 0.0
01/15/2022 20:23:26 - INFO - __main__ -     recall = 0.0
01/15/2022 20:23:26 - INFO - __main__ -   Language adapter for he not found, using en instead
01/15/2022 20:23:26 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:23:26 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:23:26 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:23:26 - INFO - __main__ -   all languages = he
01/15/2022 20:23:26 - INFO - __main__ -   Creating features from dataset file at /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/he/test.bert-base-multilingual-cased in language he
01/15/2022 20:23:26 - INFO - utils_tag -   lang_id=0, lang=he, lang2id=None
01/15/2022 20:23:26 - INFO - utils_tag -   Writing example 0 of 492
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: he-1
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] ה ##ול ##קו ##מ ##ב לא ה ##זכיר את יכולת ##ו , ק ##רט ##ר ו ##ס ##מית שהיו אמו ##רים ל ##ע ##זור בר ##יב ##או ##נד , נ ##ת ##קל ##ו ב ##ק ##מ ##בל ובו ##רמו ##ר ש ##קט ##פו את מרבית ה ##כ ##דור ##ים ה ##חו ##זרים עובד ##ה ש ##אי ##פשר ##ה ל ##גל ##יל ל ##צאת לה ##ת ##ק ##פות מת ##פר ##צות בו ##רמו ##ר הוביל , ג ##ורד ##ון ו ##מט ##לון ס ##יי ##מו ב ##מר ##בית ה ##מקרים ב ##סל . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 727 17345 25941 34694 12094 12340 727 80227 10507 89408 10481 117 746 50139 11209 728 11828 20653 50959 104818 16160 735 13202 43793 54120 23449 23554 22622 117 739 10501 49325 10481 724 12510 34694 23917 81396 98822 11209 748 68642 19747 10507 85692 727 36051 34194 10438 727 37436 92468 97729 10416 748 16495 60276 10416 735 22359 20797 735 59553 25704 10501 12510 17085 70981 32512 30444 16790 98822 11209 104978 117 725 98845 11893 728 84583 72487 740 53631 16249 724 20597 34333 727 67608 724 61303 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 12 -100 -100 -100 -100 3 16 -100 2 8 -100 13 12 -100 -100 12 -100 -100 4 4 -100 16 -100 -100 8 -100 -100 -100 13 16 -100 -100 -100 12 -100 -100 -100 12 -100 -100 16 -100 -100 2 6 8 -100 -100 -100 1 -100 -100 8 -100 16 -100 -100 -100 8 -100 -100 16 -100 8 -100 -100 -100 16 -100 -100 12 -100 -100 16 13 12 -100 -100 12 -100 -100 16 -100 -100 2 -100 -100 8 -100 8 -100 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: he-2
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] ב ##דק ##ה ה - 37 היה י ##תר ##ון ה ##גל ##יל 91 81 . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 724 109780 10416 727 118 11204 12168 732 37454 11893 727 22359 20797 12519 12324 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 8 -100 -100 6 13 9 4 8 -100 -100 8 -100 -100 9 9 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: he-3
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] י ##צי ##את ##ו של לי ##ף ג ##רר ##ה בתוך ד ##קה את צ ##י ##מ ##צו ##ם ה ##תו ##צאה ל - 91 88 . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 732 38486 43448 10481 10318 63205 12530 725 102889 10416 38656 726 15912 10507 745 10534 34694 43066 10932 727 20375 63858 735 118 12519 12074 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 8 -100 -100 -100 2 12 -100 16 -100 -100 2 8 -100 2 8 -100 -100 -100 -100 8 -100 -100 2 13 9 9 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: he-4
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] אולם ק ##מ ##בל וג ##ורד ##ון די ##יקו ב ##קל ##יע ##ות ##יהם ו ##ה ##ב ##טיח ##ו את ה ##ני ##צחון ( 99 91 ) . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 25036 746 34694 23917 84661 98845 11893 91560 78555 724 49325 58166 10577 35585 728 10416 12094 106247 10481 10507 727 12706 48793 113 12187 12519 114 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 5 12 -100 -100 12 -100 -100 16 -100 8 -100 -100 -100 -100 16 -100 -100 -100 -100 2 8 -100 -100 13 9 9 13 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:26 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:26 - INFO - utils_tag -   guid: he-5
01/15/2022 20:23:26 - INFO - utils_tag -   tokens: [CLS] מ ##לכת ##חיל ##ה היה בר ##ור ש ##תו ##צאת המשחק תל ##וי ##יה אך ורק בה ##פועל ח ##ולו ##ן . [SEP]
01/15/2022 20:23:26 - INFO - utils_tag -   input_ids: 101 737 91292 49132 10416 12168 54120 14340 748 20375 59553 49708 25246 23264 12330 14016 103086 20074 106725 730 80267 11002 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:26 - INFO - utils_tag -   label_ids: -100 3 -100 -100 -100 4 16 -100 8 -100 -100 8 16 -100 -100 3 3 8 -100 12 -100 -100 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:26 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:27 - INFO - __main__ -   Saving features into cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_he_bert-base-multilingual-cased_128, len(features)=492
01/15/2022 20:23:27 - INFO - __main__ -   ***** Running evaluation  in he *****
01/15/2022 20:23:27 - INFO - __main__ -     Num examples = 492
01/15/2022 20:23:27 - INFO - __main__ -     Batch size = 32
01/15/2022 20:23:27 - INFO - __main__ -   Batch number = 1
01/15/2022 20:23:27 - INFO - __main__ -   Batch number = 2
01/15/2022 20:23:27 - INFO - __main__ -   Batch number = 3
01/15/2022 20:23:27 - INFO - __main__ -   Batch number = 4
01/15/2022 20:23:27 - INFO - __main__ -   Batch number = 5
01/15/2022 20:23:28 - INFO - __main__ -   Batch number = 6
01/15/2022 20:23:28 - INFO - __main__ -   Batch number = 7
01/15/2022 20:23:28 - INFO - __main__ -   Batch number = 8
01/15/2022 20:23:28 - INFO - __main__ -   Batch number = 9
01/15/2022 20:23:28 - INFO - __main__ -   Batch number = 10
01/15/2022 20:23:28 - INFO - __main__ -   Batch number = 11
01/15/2022 20:23:28 - INFO - __main__ -   Batch number = 12
01/15/2022 20:23:29 - INFO - __main__ -   Batch number = 13
01/15/2022 20:23:29 - INFO - __main__ -   Batch number = 14
01/15/2022 20:23:29 - INFO - __main__ -   Batch number = 15
01/15/2022 20:23:29 - INFO - __main__ -   Batch number = 16
01/15/2022 20:23:29 - INFO - __main__ -   ***** Evaluation result  in he *****
01/15/2022 20:23:29 - INFO - __main__ -     f1 = 0.5541763641065426
01/15/2022 20:23:29 - INFO - __main__ -     loss = 2.1113880202174187
01/15/2022 20:23:29 - INFO - __main__ -     precision = 0.5358839709927482
01/15/2022 20:23:29 - INFO - __main__ -     recall = 0.5737617135207497
01/15/2022 20:23:29 - INFO - __main__ -   Language adapter for mt not found, using en instead
01/15/2022 20:23:29 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:23:29 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:23:29 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:23:29 - INFO - __main__ -   all languages = mt
01/15/2022 20:23:29 - INFO - __main__ -   Creating features from dataset file at /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/mt/test.bert-base-multilingual-cased in language mt
01/15/2022 20:23:29 - INFO - utils_tag -   lang_id=0, lang=mt, lang2id=None
01/15/2022 20:23:29 - INFO - utils_tag -   Writing example 0 of 525
01/15/2022 20:23:29 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:29 - INFO - utils_tag -   guid: mt-1
01/15/2022 20:23:29 - INFO - utils_tag -   tokens: [CLS] Philip Sc ##hem ##bri , [UNK] - Chairman tal - Bord ta ' In ##kje ##sta dwa ##r l - alle ##gat ri ##mi illegal ##i ta ' kimi ##ka im ##se ##j ##ħ ##a mer ##cap ##tan mill - En ##ema ##lta , q ##al li l - Bord ta ' In ##kje ##sta tala ##b id - dokument ##i li q ##al li kell ##u f ' ide ##j ##h id - De ##putat Lab ##uris ##ta Joe Mi ##zzi war ##a li hu b ' mod pub ##blik ##u q ##al li kell ##u dokument ##i li ki ##en les ##t j ##g ##ħ ##ad ##di ##hom li ##l Bord ta ' In ##kje ##sta . [SEP]
01/15/2022 20:23:29 - INFO - utils_tag -   input_ids: 101 13324 55260 25947 32066 117 100 118 28635 13675 118 68475 11057 112 10167 85650 10972 20056 10129 180 118 10968 27107 29956 10500 39806 10116 11057 112 17007 10371 10211 10341 10418 110944 10113 13697 93103 12059 43980 118 10243 18089 15468 117 185 10415 11614 180 118 68475 11057 112 10167 85650 10972 100707 10457 12604 118 62348 10116 11614 185 10415 11614 24830 10138 174 112 38938 10418 10237 12604 118 10190 57408 48790 84926 10213 13062 19803 22125 10338 10113 11614 26506 170 112 15608 67742 85459 10138 185 10415 11614 24830 10138 62348 10116 11614 10879 10136 10152 10123 178 10240 110944 11488 10703 71784 11614 10161 68475 11057 112 10167 85650 10972 119 102 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   label_ids: -100 12 12 -100 -100 13 6 -100 8 2 -100 8 2 -100 8 -100 -100 2 -100 6 -100 16 -100 8 -100 1 -100 2 -100 8 -100 16 -100 -100 -100 -100 12 -100 -100 2 -100 12 -100 -100 13 16 -100 14 6 -100 8 2 -100 8 -100 -100 16 -100 6 -100 8 -100 14 16 -100 14 16 -100 2 -100 8 -100 -100 6 -100 8 -100 1 -100 -100 12 12 -100 2 -100 14 11 2 -100 8 1 -100 -100 16 -100 14 16 -100 8 -100 14 4 -100 1 -100 16 -100 -100 -100 -100 -100 2 -100 8 2 -100 8 -100 -100 13 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:29 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:29 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:29 - INFO - utils_tag -   guid: mt-2
01/15/2022 20:23:29 - INFO - utils_tag -   tokens: [CLS] [UNK] - Chairman q ##al li l - Bord q ##al li ##l Joe Mi ##zzi li hu ##ma ki ##enu les ##ti ji ##rri ##sp ##etta ##w is - sor ##s li kell ##u im ##ma Joe Mi ##zzi q ##al li hu ki ##en g ##ħ ##ad ##da d - dokument ##i lu ##ra li ##l min tag ##ħ ##hom ##lu . [SEP]
01/15/2022 20:23:29 - INFO - utils_tag -   input_ids: 101 100 118 28635 185 10415 11614 180 118 68475 185 10415 11614 10161 13062 19803 22125 11614 26506 10369 10879 55484 10152 10325 18028 24874 54609 19521 10874 10124 118 56011 10107 11614 24830 10138 10211 10369 13062 19803 22125 185 10415 11614 26506 10879 10136 175 110944 11488 10229 172 118 62348 10116 14657 10288 11614 10161 13484 37836 110944 71784 11435 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   label_ids: -100 6 -100 8 16 -100 14 6 -100 8 16 -100 2 -100 12 12 -100 14 11 -100 4 -100 1 -100 16 -100 -100 -100 -100 6 -100 8 -100 14 16 -100 5 -100 12 12 -100 16 -100 14 11 4 -100 16 -100 -100 -100 6 -100 8 -100 3 -100 2 -100 11 16 -100 -100 -100 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:29 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:29 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:29 - INFO - utils_tag -   guid: mt-3
01/15/2022 20:23:29 - INFO - utils_tag -   tokens: [CLS] Dan ħ ##are ##ġ meta l - Ku ##mita ##t Parlament ##ari dwa ##r il - Ko ##nti ##jie ##t [UNK] bed ##a ji ##ddi ##sku ##ti r - Rapport tal - Ko ##rp ##ora ##zz ##joni En ##ema ##lta ta ' [UNK] 2011 dwa ##r l - in ##kje ##sta fu ##q l - alle ##gat ri ##mi illegal ##i ta ' kimi ##ka im ##se ##j ##ħ ##a mer ##cap ##tan . [SEP]
01/15/2022 20:23:29 - INFO - utils_tag -   input_ids: 101 14261 314 11591 110940 39063 180 118 49869 63496 10123 29889 12476 20056 10129 10154 118 30186 12752 93246 10123 100 30113 10113 18028 37226 14836 10325 186 118 100882 13675 118 30186 33394 14945 46671 90353 10243 18089 15468 11057 112 100 10158 20056 10129 180 118 10106 85650 10972 11005 11703 180 118 10968 27107 29956 10500 39806 10116 11057 112 17007 10371 10211 10341 10418 110944 10113 13697 93103 12059 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   label_ids: -100 11 16 -100 -100 14 6 -100 8 -100 -100 1 -100 2 -100 6 -100 8 -100 -100 -100 1 16 -100 16 -100 -100 -100 6 -100 8 2 -100 8 -100 -100 -100 -100 12 -100 -100 2 -100 12 9 2 -100 6 -100 8 -100 -100 2 -100 6 -100 16 -100 8 -100 1 -100 2 -100 8 -100 16 -100 -100 -100 -100 12 -100 -100 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:29 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:29 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:29 - INFO - utils_tag -   guid: mt-4
01/15/2022 20:23:29 - INFO - utils_tag -   tokens: [CLS] Ir - rapport ki ##en t ##po ##ġ ##ġ ##a fu ##q il - Me ##jda tal - Ka ##m ##ra tar - Rap ##pre ##że ##ntan ##ti fit - 30 ta ' April li g ##ħ ##ad ##da . [SEP]
01/15/2022 20:23:29 - INFO - utils_tag -   input_ids: 101 61562 118 17508 10879 10136 188 13520 110940 110940 10113 11005 11703 10154 118 11589 95693 13675 118 25444 10147 10288 24948 118 47957 30619 21978 109368 10325 21635 118 10244 11057 112 10780 11614 175 110944 11488 10229 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   label_ids: -100 6 -100 8 4 -100 16 -100 -100 -100 -100 2 -100 6 -100 8 -100 2 -100 8 -100 -100 2 -100 8 -100 -100 -100 -100 2 -100 9 2 -100 12 14 16 -100 -100 -100 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:29 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:29 - INFO - utils_tag -   *** Example ***
01/15/2022 20:23:29 - INFO - utils_tag -   guid: mt-5
01/15/2022 20:23:29 - INFO - utils_tag -   tokens: [CLS] Fi ##l - bid ##u tal - la ##q ##g ##ħ ##a , li t ##me ##x ##xie ##t mid - De ##putat Lab ##uris ##ta Charles Man ##gion b ##ħ ##ala [UNK] - Chairman , sa ##ret disk ##uss ##joni dwa ##r il - lista tax - x ##hie ##da li g ##ħ ##and ##ha ti ##sse ##j ##ja ##ħ qu ##ddi ##em il - Ku ##mita ##t u l - [UNK] li se tin ##tu ##ża . [SEP]
01/15/2022 20:23:29 - INFO - utils_tag -   input_ids: 101 36448 10161 118 50385 10138 13675 118 10109 11703 10240 110944 10113 117 11614 188 10627 10686 50536 10123 15607 118 10190 57408 48790 84926 10213 10925 11343 69197 170 110944 13322 100 118 28635 117 10148 12785 50169 66148 90353 20056 10129 10154 118 15843 25468 118 192 72287 10229 11614 175 110944 14752 10921 14382 12818 10418 10320 110944 10608 37226 10451 10154 118 49869 63496 10123 189 180 118 100 11614 10126 21629 10991 19025 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/15/2022 20:23:29 - INFO - utils_tag -   label_ids: -100 2 -100 -100 8 -100 2 -100 8 -100 -100 -100 -100 13 14 16 -100 -100 -100 -100 2 -100 8 -100 1 -100 -100 12 12 -100 2 -100 -100 6 -100 8 13 16 -100 8 -100 -100 2 -100 6 -100 8 2 -100 8 -100 -100 14 16 -100 -100 -100 16 -100 -100 -100 -100 2 -100 -100 6 -100 8 -100 -100 5 6 -100 8 14 4 16 -100 -100 13 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
01/15/2022 20:23:29 - INFO - utils_tag -   langs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
01/15/2022 20:23:30 - INFO - __main__ -   Saving features into cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mt_bert-base-multilingual-cased_128, len(features)=525
01/15/2022 20:23:30 - INFO - __main__ -   ***** Running evaluation  in mt *****
01/15/2022 20:23:30 - INFO - __main__ -     Num examples = 525
01/15/2022 20:23:30 - INFO - __main__ -     Batch size = 32
01/15/2022 20:23:30 - INFO - __main__ -   Batch number = 1
01/15/2022 20:23:30 - INFO - __main__ -   Batch number = 2
01/15/2022 20:23:30 - INFO - __main__ -   Batch number = 3
01/15/2022 20:23:30 - INFO - __main__ -   Batch number = 4
01/15/2022 20:23:30 - INFO - __main__ -   Batch number = 5
01/15/2022 20:23:31 - INFO - __main__ -   Batch number = 6
01/15/2022 20:23:31 - INFO - __main__ -   Batch number = 7
01/15/2022 20:23:31 - INFO - __main__ -   Batch number = 8
01/15/2022 20:23:31 - INFO - __main__ -   Batch number = 9
01/15/2022 20:23:31 - INFO - __main__ -   Batch number = 10
01/15/2022 20:23:31 - INFO - __main__ -   Batch number = 11
01/15/2022 20:23:31 - INFO - __main__ -   Batch number = 12
01/15/2022 20:23:32 - INFO - __main__ -   Batch number = 13
01/15/2022 20:23:32 - INFO - __main__ -   Batch number = 14
01/15/2022 20:23:32 - INFO - __main__ -   Batch number = 15
01/15/2022 20:23:32 - INFO - __main__ -   Batch number = 16
01/15/2022 20:23:32 - INFO - __main__ -   Batch number = 17
01/15/2022 20:23:32 - INFO - __main__ -   ***** Evaluation result  in mt *****
01/15/2022 20:23:32 - INFO - __main__ -     f1 = 0.2104139751727237
01/15/2022 20:23:32 - INFO - __main__ -     loss = 3.7368571758270264
01/15/2022 20:23:32 - INFO - __main__ -     precision = 0.25482993197278914
01/15/2022 20:23:32 - INFO - __main__ -     recall = 0.17918300966229792
01/15/2022 20:23:35 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='aii,he,mt', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 20:23:35 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 20:23:35 - INFO - __main__ -   Seed = 2
01/15/2022 20:23:35 - INFO - root -   save model
01/15/2022 20:23:35 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='aii,he,mt', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 20:23:35 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 20:23:37 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 20:23:43 - INFO - __main__ -   Using lang2id = None
01/15/2022 20:23:43 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 20:23:43 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/15/2022 20:23:43 - INFO - root -   Trying to decide if add adapter
01/15/2022 20:23:43 - INFO - root -   loading task adapter
01/15/2022 20:23:43 - INFO - root -   loading lang adpater en/wiki@ukp
01/15/2022 20:23:43 - INFO - __main__ -   Adapter Languages : ['en'], Length : 1
01/15/2022 20:23:43 - INFO - __main__ -   Adapter Names ['en/wiki@ukp'], Length : 1
01/15/2022 20:23:43 - INFO - __main__ -   Language = en
01/15/2022 20:23:43 - INFO - __main__ -   Adapter Name = en/wiki@ukp
01/15/2022 20:23:47 - INFO - __main__ -   Language adapter for aii not found, using en instead
01/15/2022 20:23:47 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:23:47 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:23:47 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:23:47 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_aii_bert-base-multilingual-cased_128
01/15/2022 20:23:47 - INFO - __main__ -   ***** Running evaluation  in aii *****
01/15/2022 20:23:47 - INFO - __main__ -     Num examples = 57
01/15/2022 20:23:47 - INFO - __main__ -     Batch size = 32
01/15/2022 20:23:47 - INFO - __main__ -   Batch number = 1
01/15/2022 20:23:47 - INFO - __main__ -   Batch number = 2
01/15/2022 20:23:48 - INFO - __main__ -   ***** Evaluation result  in aii *****
01/15/2022 20:23:48 - INFO - __main__ -     f1 = 0.0
01/15/2022 20:23:48 - INFO - __main__ -     loss = 8.22346019744873
01/15/2022 20:23:48 - INFO - __main__ -     precision = 0.0
01/15/2022 20:23:48 - INFO - __main__ -     recall = 0.0
01/15/2022 20:23:48 - INFO - __main__ -   Language adapter for he not found, using en instead
01/15/2022 20:23:48 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:23:48 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:23:48 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:23:48 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_he_bert-base-multilingual-cased_128
01/15/2022 20:23:48 - INFO - __main__ -   ***** Running evaluation  in he *****
01/15/2022 20:23:48 - INFO - __main__ -     Num examples = 492
01/15/2022 20:23:48 - INFO - __main__ -     Batch size = 32
01/15/2022 20:23:48 - INFO - __main__ -   Batch number = 1
01/15/2022 20:23:48 - INFO - __main__ -   Batch number = 2
01/15/2022 20:23:48 - INFO - __main__ -   Batch number = 3
01/15/2022 20:23:48 - INFO - __main__ -   Batch number = 4
01/15/2022 20:23:48 - INFO - __main__ -   Batch number = 5
01/15/2022 20:23:48 - INFO - __main__ -   Batch number = 6
01/15/2022 20:23:48 - INFO - __main__ -   Batch number = 7
01/15/2022 20:23:49 - INFO - __main__ -   Batch number = 8
01/15/2022 20:23:49 - INFO - __main__ -   Batch number = 9
01/15/2022 20:23:49 - INFO - __main__ -   Batch number = 10
01/15/2022 20:23:49 - INFO - __main__ -   Batch number = 11
01/15/2022 20:23:49 - INFO - __main__ -   Batch number = 12
01/15/2022 20:23:49 - INFO - __main__ -   Batch number = 13
01/15/2022 20:23:49 - INFO - __main__ -   Batch number = 14
01/15/2022 20:23:50 - INFO - __main__ -   Batch number = 15
01/15/2022 20:23:50 - INFO - __main__ -   Batch number = 16
01/15/2022 20:23:50 - INFO - __main__ -   ***** Evaluation result  in he *****
01/15/2022 20:23:50 - INFO - __main__ -     f1 = 0.5286166979240768
01/15/2022 20:23:50 - INFO - __main__ -     loss = 2.388287380337715
01/15/2022 20:23:50 - INFO - __main__ -     precision = 0.5113224071062179
01/15/2022 20:23:50 - INFO - __main__ -     recall = 0.5471218206157965
01/15/2022 20:23:50 - INFO - __main__ -   Language adapter for mt not found, using en instead
01/15/2022 20:23:50 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:23:50 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:23:50 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:23:50 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mt_bert-base-multilingual-cased_128
01/15/2022 20:23:50 - INFO - __main__ -   ***** Running evaluation  in mt *****
01/15/2022 20:23:50 - INFO - __main__ -     Num examples = 525
01/15/2022 20:23:50 - INFO - __main__ -     Batch size = 32
01/15/2022 20:23:50 - INFO - __main__ -   Batch number = 1
01/15/2022 20:23:50 - INFO - __main__ -   Batch number = 2
01/15/2022 20:23:50 - INFO - __main__ -   Batch number = 3
01/15/2022 20:23:50 - INFO - __main__ -   Batch number = 4
01/15/2022 20:23:51 - INFO - __main__ -   Batch number = 5
01/15/2022 20:23:51 - INFO - __main__ -   Batch number = 6
01/15/2022 20:23:51 - INFO - __main__ -   Batch number = 7
01/15/2022 20:23:51 - INFO - __main__ -   Batch number = 8
01/15/2022 20:23:51 - INFO - __main__ -   Batch number = 9
01/15/2022 20:23:51 - INFO - __main__ -   Batch number = 10
01/15/2022 20:23:51 - INFO - __main__ -   Batch number = 11
01/15/2022 20:23:52 - INFO - __main__ -   Batch number = 12
01/15/2022 20:23:52 - INFO - __main__ -   Batch number = 13
01/15/2022 20:23:52 - INFO - __main__ -   Batch number = 14
01/15/2022 20:23:52 - INFO - __main__ -   Batch number = 15
01/15/2022 20:23:52 - INFO - __main__ -   Batch number = 16
01/15/2022 20:23:52 - INFO - __main__ -   Batch number = 17
01/15/2022 20:23:52 - INFO - __main__ -   ***** Evaluation result  in mt *****
01/15/2022 20:23:52 - INFO - __main__ -     f1 = 0.19312343564747728
01/15/2022 20:23:52 - INFO - __main__ -     loss = 4.913796172422521
01/15/2022 20:23:52 - INFO - __main__ -     precision = 0.3100021146119687
01/15/2022 20:23:52 - INFO - __main__ -     recall = 0.14024681909499664
01/15/2022 20:23:55 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='aii,he,mt', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 20:23:55 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 20:23:55 - INFO - __main__ -   Seed = 3
01/15/2022 20:23:55 - INFO - root -   save model
01/15/2022 20:23:55 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='aii,he,mt', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/cloud-bert-base-multilingual-cased-MaxLen128_udpos_en//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 20:23:55 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 20:23:57 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 20:24:03 - INFO - __main__ -   Using lang2id = None
01/15/2022 20:24:03 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 20:24:03 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/15/2022 20:24:03 - INFO - root -   Trying to decide if add adapter
01/15/2022 20:24:03 - INFO - root -   loading task adapter
01/15/2022 20:24:03 - INFO - root -   loading lang adpater en/wiki@ukp
01/15/2022 20:24:03 - INFO - __main__ -   Adapter Languages : ['en'], Length : 1
01/15/2022 20:24:03 - INFO - __main__ -   Adapter Names ['en/wiki@ukp'], Length : 1
01/15/2022 20:24:03 - INFO - __main__ -   Language = en
01/15/2022 20:24:03 - INFO - __main__ -   Adapter Name = en/wiki@ukp
01/15/2022 20:24:08 - INFO - __main__ -   Language adapter for aii not found, using en instead
01/15/2022 20:24:08 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:24:08 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:24:08 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:24:08 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_aii_bert-base-multilingual-cased_128
01/15/2022 20:24:08 - INFO - __main__ -   ***** Running evaluation  in aii *****
01/15/2022 20:24:08 - INFO - __main__ -     Num examples = 57
01/15/2022 20:24:08 - INFO - __main__ -     Batch size = 32
01/15/2022 20:24:08 - INFO - __main__ -   Batch number = 1
01/15/2022 20:24:08 - INFO - __main__ -   Batch number = 2
01/15/2022 20:24:08 - INFO - __main__ -   ***** Evaluation result  in aii *****
01/15/2022 20:24:08 - INFO - __main__ -     f1 = 0.0
01/15/2022 20:24:08 - INFO - __main__ -     loss = 9.42789888381958
01/15/2022 20:24:08 - INFO - __main__ -     precision = 0.0
01/15/2022 20:24:08 - INFO - __main__ -     recall = 0.0
01/15/2022 20:24:08 - INFO - __main__ -   Language adapter for he not found, using en instead
01/15/2022 20:24:08 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:24:08 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:24:08 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:24:08 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_he_bert-base-multilingual-cased_128
01/15/2022 20:24:08 - INFO - __main__ -   ***** Running evaluation  in he *****
01/15/2022 20:24:08 - INFO - __main__ -     Num examples = 492
01/15/2022 20:24:08 - INFO - __main__ -     Batch size = 32
01/15/2022 20:24:08 - INFO - __main__ -   Batch number = 1
01/15/2022 20:24:08 - INFO - __main__ -   Batch number = 2
01/15/2022 20:24:08 - INFO - __main__ -   Batch number = 3
01/15/2022 20:24:08 - INFO - __main__ -   Batch number = 4
01/15/2022 20:24:09 - INFO - __main__ -   Batch number = 5
01/15/2022 20:24:09 - INFO - __main__ -   Batch number = 6
01/15/2022 20:24:09 - INFO - __main__ -   Batch number = 7
01/15/2022 20:24:09 - INFO - __main__ -   Batch number = 8
01/15/2022 20:24:09 - INFO - __main__ -   Batch number = 9
01/15/2022 20:24:09 - INFO - __main__ -   Batch number = 10
01/15/2022 20:24:09 - INFO - __main__ -   Batch number = 11
01/15/2022 20:24:10 - INFO - __main__ -   Batch number = 12
01/15/2022 20:24:10 - INFO - __main__ -   Batch number = 13
01/15/2022 20:24:10 - INFO - __main__ -   Batch number = 14
01/15/2022 20:24:10 - INFO - __main__ -   Batch number = 15
01/15/2022 20:24:10 - INFO - __main__ -   Batch number = 16
01/15/2022 20:24:10 - INFO - __main__ -   ***** Evaluation result  in he *****
01/15/2022 20:24:10 - INFO - __main__ -     f1 = 0.5472823971980801
01/15/2022 20:24:10 - INFO - __main__ -     loss = 2.2514891251921654
01/15/2022 20:24:10 - INFO - __main__ -     precision = 0.5308253648716659
01/15/2022 20:24:10 - INFO - __main__ -     recall = 0.5647925033467203
01/15/2022 20:24:10 - INFO - __main__ -   Language adapter for mt not found, using en instead
01/15/2022 20:24:10 - INFO - __main__ -   Set active language adapter to en
01/15/2022 20:24:10 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 20:24:10 - INFO - __main__ -   Adapter Languages = ['en']
01/15/2022 20:24:10 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mt_bert-base-multilingual-cased_128
01/15/2022 20:24:10 - INFO - __main__ -   ***** Running evaluation  in mt *****
01/15/2022 20:24:10 - INFO - __main__ -     Num examples = 525
01/15/2022 20:24:10 - INFO - __main__ -     Batch size = 32
01/15/2022 20:24:10 - INFO - __main__ -   Batch number = 1
01/15/2022 20:24:11 - INFO - __main__ -   Batch number = 2
01/15/2022 20:24:11 - INFO - __main__ -   Batch number = 3
01/15/2022 20:24:11 - INFO - __main__ -   Batch number = 4
01/15/2022 20:24:11 - INFO - __main__ -   Batch number = 5
01/15/2022 20:24:11 - INFO - __main__ -   Batch number = 6
01/15/2022 20:24:11 - INFO - __main__ -   Batch number = 7
01/15/2022 20:24:11 - INFO - __main__ -   Batch number = 8
01/15/2022 20:24:12 - INFO - __main__ -   Batch number = 9
01/15/2022 20:24:12 - INFO - __main__ -   Batch number = 10
01/15/2022 20:24:12 - INFO - __main__ -   Batch number = 11
01/15/2022 20:24:12 - INFO - __main__ -   Batch number = 12
01/15/2022 20:24:12 - INFO - __main__ -   Batch number = 13
01/15/2022 20:24:12 - INFO - __main__ -   Batch number = 14
01/15/2022 20:24:12 - INFO - __main__ -   Batch number = 15
01/15/2022 20:24:13 - INFO - __main__ -   Batch number = 16
01/15/2022 20:24:13 - INFO - __main__ -   Batch number = 17
01/15/2022 20:24:13 - INFO - __main__ -   ***** Evaluation result  in mt *****
01/15/2022 20:24:13 - INFO - __main__ -     f1 = 0.22487562189054724
01/15/2022 20:24:13 - INFO - __main__ -     loss = 3.5075927341685578
01/15/2022 20:24:13 - INFO - __main__ -     precision = 0.26633494827811965
01/15/2022 20:24:13 - INFO - __main__ -     recall = 0.1945852865206161
