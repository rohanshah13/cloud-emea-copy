PyTorch version 1.9.0+cu102 available.
11/20/2021 22:23:49 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:23:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:23:49 - INFO - __main__ -   Seed = 1
11/20/2021 22:23:49 - INFO - root -   save model
11/20/2021 22:23:49 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:23:49 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/20/2021 22:23:51 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/20/2021 22:23:57 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:23:57 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:23:57 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
11/20/2021 22:23:57 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:23:57 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_model_head.bin
11/20/2021 22:23:57 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:23:57 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:23:57 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:23:57 - INFO - __main__ -   Language = hi
11/20/2021 22:23:57 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/20/2021 22:24:01 - INFO - __main__ -   Language adapter for mr not found, using hi instead
11/20/2021 22:24:01 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:24:01 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:24:01 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:24:01 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
11/20/2021 22:24:01 - INFO - __main__ -   ***** Running evaluation  in mr *****
11/20/2021 22:24:01 - INFO - __main__ -     Num examples = 47
11/20/2021 22:24:01 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]11/20/2021 22:24:01 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  6.78it/s]11/20/2021 22:24:01 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  9.16it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/20/2021 22:24:02 - INFO - __main__ -   ***** Evaluation result  in mr *****
11/20/2021 22:24:02 - INFO - __main__ -     f1 = 0.5079365079365079
11/20/2021 22:24:02 - INFO - __main__ -     loss = 1.4944716095924377
11/20/2021 22:24:02 - INFO - __main__ -     precision = 0.5387205387205387
11/20/2021 22:24:02 - INFO - __main__ -     recall = 0.4804804804804805
14.96user 9.80system 0:14.75elapsed 167%CPU (0avgtext+0avgdata 3868192maxresident)k
152inputs+64outputs (0major+1188890minor)pagefaults 0swaps
PyTorch version 1.9.0+cu102 available.
11/20/2021 22:24:03 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:24:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:24:03 - INFO - __main__ -   Seed = 2
11/20/2021 22:24:03 - INFO - root -   save model
11/20/2021 22:24:03 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:24:03 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/20/2021 22:24:06 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/20/2021 22:24:12 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:24:12 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:24:12 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
11/20/2021 22:24:12 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:24:12 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_model_head.bin
11/20/2021 22:24:12 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:24:12 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:24:12 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:24:12 - INFO - __main__ -   Language = hi
11/20/2021 22:24:12 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/20/2021 22:24:15 - INFO - __main__ -   Language adapter for mr not found, using hi instead
11/20/2021 22:24:15 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:24:15 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:24:15 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:24:15 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
11/20/2021 22:24:15 - INFO - __main__ -   ***** Running evaluation  in mr *****
11/20/2021 22:24:15 - INFO - __main__ -     Num examples = 47
11/20/2021 22:24:15 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]11/20/2021 22:24:15 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  7.32it/s]11/20/2021 22:24:16 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  9.68it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/20/2021 22:24:16 - INFO - __main__ -   ***** Evaluation result  in mr *****
11/20/2021 22:24:16 - INFO - __main__ -     f1 = 0.5297805642633229
11/20/2021 22:24:16 - INFO - __main__ -     loss = 1.4993798732757568
11/20/2021 22:24:16 - INFO - __main__ -     precision = 0.5540983606557377
11/20/2021 22:24:16 - INFO - __main__ -     recall = 0.5075075075075075
13.91user 8.27system 0:14.12elapsed 157%CPU (0avgtext+0avgdata 3874052maxresident)k
0inputs+48outputs (0major+1042911minor)pagefaults 0swaps
PyTorch version 1.9.0+cu102 available.
11/20/2021 22:24:18 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:24:18 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:24:18 - INFO - __main__ -   Seed = 3
11/20/2021 22:24:18 - INFO - root -   save model
11/20/2021 22:24:18 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:24:18 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/20/2021 22:24:20 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/20/2021 22:24:26 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:24:26 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:24:26 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
11/20/2021 22:24:26 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:24:26 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_model_head.bin
11/20/2021 22:24:26 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:24:26 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:24:26 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:24:26 - INFO - __main__ -   Language = hi
11/20/2021 22:24:26 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/20/2021 22:24:30 - INFO - __main__ -   Language adapter for mr not found, using hi instead
11/20/2021 22:24:30 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:24:30 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:24:30 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:24:30 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
11/20/2021 22:24:30 - INFO - __main__ -   ***** Running evaluation  in mr *****
11/20/2021 22:24:30 - INFO - __main__ -     Num examples = 47
11/20/2021 22:24:30 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]11/20/2021 22:24:30 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  7.30it/s]11/20/2021 22:24:30 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  9.47it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/20/2021 22:24:30 - INFO - __main__ -   ***** Evaluation result  in mr *****
11/20/2021 22:24:30 - INFO - __main__ -     f1 = 0.5795275590551181
11/20/2021 22:24:30 - INFO - __main__ -     loss = 1.4103431105613708
11/20/2021 22:24:30 - INFO - __main__ -     precision = 0.609271523178808
11/20/2021 22:24:30 - INFO - __main__ -     recall = 0.5525525525525525
15.02user 8.68system 0:14.25elapsed 166%CPU (0avgtext+0avgdata 3869432maxresident)k
0inputs+72outputs (0major+1176898minor)pagefaults 0swaps
PyTorch version 1.9.0+cu102 available.
11/20/2021 22:48:46 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:48:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:48:46 - INFO - __main__ -   Seed = 1
11/20/2021 22:48:46 - INFO - root -   save model
11/20/2021 22:48:46 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:48:46 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/20/2021 22:48:49 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/20/2021 22:48:54 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:48:54 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:48:54 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
11/20/2021 22:48:54 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:48:54 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_model_head.bin
11/20/2021 22:48:55 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:48:55 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:48:55 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:48:55 - INFO - __main__ -   Language = hi
11/20/2021 22:48:55 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/20/2021 22:48:59 - INFO - __main__ -   Language adapter for en not found, using hi instead
11/20/2021 22:48:59 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:48:59 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:48:59 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:48:59 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
11/20/2021 22:48:59 - INFO - __main__ -   ***** Running evaluation  in en *****
11/20/2021 22:48:59 - INFO - __main__ -     Num examples = 5441
11/20/2021 22:48:59 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/171 [00:00<?, ?it/s]11/20/2021 22:48:59 - INFO - __main__ -   Batch number = 1
Evaluating:   1%|          | 1/171 [00:00<00:26,  6.48it/s]11/20/2021 22:48:59 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/171 [00:00<00:24,  6.77it/s]11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 3
Evaluating:   2%|▏         | 3/171 [00:00<00:24,  6.97it/s]11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 4
Evaluating:   2%|▏         | 4/171 [00:00<00:23,  7.09it/s]11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 5
Evaluating:   3%|▎         | 5/171 [00:00<00:23,  7.15it/s]11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 6
Evaluating:   4%|▎         | 6/171 [00:00<00:22,  7.19it/s]11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 7
Evaluating:   4%|▍         | 7/171 [00:00<00:22,  7.21it/s]11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 8
Evaluating:   5%|▍         | 8/171 [00:01<00:22,  7.22it/s]11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 9
Evaluating:   5%|▌         | 9/171 [00:01<00:22,  7.21it/s]11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 10
Evaluating:   6%|▌         | 10/171 [00:01<00:22,  7.21it/s]11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 11
Evaluating:   6%|▋         | 11/171 [00:01<00:22,  7.23it/s]11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 12
Evaluating:   7%|▋         | 12/171 [00:01<00:21,  7.23it/s]11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 13
Evaluating:   8%|▊         | 13/171 [00:01<00:21,  7.23it/s]11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 14
Evaluating:   8%|▊         | 14/171 [00:01<00:21,  7.21it/s]11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 15
Evaluating:   9%|▉         | 15/171 [00:02<00:23,  6.76it/s]11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 16
Evaluating:   9%|▉         | 16/171 [00:02<00:22,  6.90it/s]11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 17
Evaluating:  10%|▉         | 17/171 [00:02<00:22,  6.96it/s]11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 18
Evaluating:  11%|█         | 18/171 [00:02<00:21,  7.04it/s]11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 19
Evaluating:  11%|█         | 19/171 [00:02<00:21,  7.09it/s]11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 20
Evaluating:  12%|█▏        | 20/171 [00:02<00:21,  7.12it/s]11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 21
Evaluating:  12%|█▏        | 21/171 [00:02<00:21,  7.14it/s]11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 22
Evaluating:  13%|█▎        | 22/171 [00:03<00:20,  7.15it/s]11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 23
Evaluating:  13%|█▎        | 23/171 [00:03<00:20,  7.15it/s]11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 24
Evaluating:  14%|█▍        | 24/171 [00:03<00:20,  7.16it/s]11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 25
Evaluating:  15%|█▍        | 25/171 [00:03<00:20,  7.17it/s]11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 26
Evaluating:  15%|█▌        | 26/171 [00:03<00:20,  7.18it/s]11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 27
Evaluating:  16%|█▌        | 27/171 [00:03<00:20,  7.14it/s]11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 28
Evaluating:  16%|█▋        | 28/171 [00:03<00:19,  7.16it/s]11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 29
Evaluating:  17%|█▋        | 29/171 [00:04<00:19,  7.18it/s]11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 30
Evaluating:  18%|█▊        | 30/171 [00:04<00:19,  7.17it/s]11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 31
Evaluating:  18%|█▊        | 31/171 [00:04<00:19,  7.17it/s]11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 32
Evaluating:  19%|█▊        | 32/171 [00:04<00:19,  7.18it/s]11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 33
Evaluating:  19%|█▉        | 33/171 [00:04<00:19,  7.18it/s]11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 34
Evaluating:  20%|█▉        | 34/171 [00:04<00:19,  7.17it/s]11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 35
Evaluating:  20%|██        | 35/171 [00:04<00:18,  7.17it/s]11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 36
Evaluating:  21%|██        | 36/171 [00:05<00:18,  7.16it/s]11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 37
Evaluating:  22%|██▏       | 37/171 [00:05<00:18,  7.14it/s]11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 38
Evaluating:  22%|██▏       | 38/171 [00:05<00:18,  7.13it/s]11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 39
Evaluating:  23%|██▎       | 39/171 [00:05<00:18,  7.13it/s]11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 40
Evaluating:  23%|██▎       | 40/171 [00:05<00:18,  7.13it/s]11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 41
Evaluating:  24%|██▍       | 41/171 [00:05<00:18,  7.13it/s]11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 42
Evaluating:  25%|██▍       | 42/171 [00:05<00:18,  7.14it/s]11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 43
Evaluating:  25%|██▌       | 43/171 [00:06<00:17,  7.13it/s]11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 44
Evaluating:  26%|██▌       | 44/171 [00:06<00:17,  7.09it/s]11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 45
Evaluating:  26%|██▋       | 45/171 [00:06<00:17,  7.07it/s]11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 46
Evaluating:  27%|██▋       | 46/171 [00:06<00:17,  7.09it/s]11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 47
Evaluating:  27%|██▋       | 47/171 [00:06<00:17,  7.10it/s]11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 48
Evaluating:  28%|██▊       | 48/171 [00:06<00:17,  7.10it/s]11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 49
Evaluating:  29%|██▊       | 49/171 [00:06<00:17,  7.10it/s]11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 50
Evaluating:  29%|██▉       | 50/171 [00:07<00:17,  7.09it/s]11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 51
Evaluating:  30%|██▉       | 51/171 [00:07<00:17,  7.06it/s]11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 52
Evaluating:  30%|███       | 52/171 [00:07<00:16,  7.00it/s]11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 53
Evaluating:  31%|███       | 53/171 [00:07<00:16,  7.02it/s]11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 54
Evaluating:  32%|███▏      | 54/171 [00:07<00:16,  7.02it/s]11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 55
Evaluating:  32%|███▏      | 55/171 [00:07<00:16,  7.02it/s]11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 56
Evaluating:  33%|███▎      | 56/171 [00:07<00:16,  7.03it/s]11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 57
Evaluating:  33%|███▎      | 57/171 [00:08<00:16,  7.03it/s]11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 58
Evaluating:  34%|███▍      | 58/171 [00:08<00:16,  7.04it/s]11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 59
Evaluating:  35%|███▍      | 59/171 [00:08<00:15,  7.04it/s]11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 60
Evaluating:  35%|███▌      | 60/171 [00:08<00:15,  7.04it/s]11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 61
Evaluating:  36%|███▌      | 61/171 [00:08<00:15,  7.04it/s]11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 62
Evaluating:  36%|███▋      | 62/171 [00:08<00:15,  7.04it/s]11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 63
Evaluating:  37%|███▋      | 63/171 [00:08<00:15,  7.02it/s]11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 64
Evaluating:  37%|███▋      | 64/171 [00:09<00:15,  6.98it/s]11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 65
Evaluating:  38%|███▊      | 65/171 [00:09<00:15,  6.99it/s]11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 66
Evaluating:  39%|███▊      | 66/171 [00:09<00:15,  6.99it/s]11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 67
Evaluating:  39%|███▉      | 67/171 [00:09<00:14,  6.99it/s]11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 68
Evaluating:  40%|███▉      | 68/171 [00:09<00:14,  7.00it/s]11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 69
Evaluating:  40%|████      | 69/171 [00:09<00:14,  6.97it/s]11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 70
Evaluating:  41%|████      | 70/171 [00:09<00:14,  6.98it/s]11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 71
Evaluating:  42%|████▏     | 71/171 [00:10<00:14,  6.93it/s]11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 72
Evaluating:  42%|████▏     | 72/171 [00:10<00:14,  6.94it/s]11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 73
Evaluating:  43%|████▎     | 73/171 [00:10<00:14,  6.95it/s]11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 74
Evaluating:  43%|████▎     | 74/171 [00:10<00:13,  6.96it/s]11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 75
Evaluating:  44%|████▍     | 75/171 [00:10<00:13,  6.95it/s]11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 76
Evaluating:  44%|████▍     | 76/171 [00:10<00:13,  6.95it/s]11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 77
Evaluating:  45%|████▌     | 77/171 [00:10<00:13,  6.96it/s]11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 78
Evaluating:  46%|████▌     | 78/171 [00:11<00:13,  6.94it/s]11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 79
Evaluating:  46%|████▌     | 79/171 [00:11<00:13,  6.95it/s]11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 80
Evaluating:  47%|████▋     | 80/171 [00:11<00:13,  6.96it/s]11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 81
Evaluating:  47%|████▋     | 81/171 [00:11<00:12,  6.95it/s]11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 82
Evaluating:  48%|████▊     | 82/171 [00:11<00:12,  6.94it/s]11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 83
Evaluating:  49%|████▊     | 83/171 [00:11<00:12,  6.93it/s]11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 84
Evaluating:  49%|████▉     | 84/171 [00:11<00:12,  6.92it/s]11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 85
Evaluating:  50%|████▉     | 85/171 [00:12<00:12,  6.92it/s]11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 86
Evaluating:  50%|█████     | 86/171 [00:12<00:12,  6.92it/s]11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 87
Evaluating:  51%|█████     | 87/171 [00:12<00:12,  6.91it/s]11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 88
Evaluating:  51%|█████▏    | 88/171 [00:12<00:12,  6.91it/s]11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 89
Evaluating:  52%|█████▏    | 89/171 [00:12<00:11,  6.90it/s]11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 90
Evaluating:  53%|█████▎    | 90/171 [00:12<00:11,  6.90it/s]11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 91
Evaluating:  53%|█████▎    | 91/171 [00:12<00:11,  6.91it/s]11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 92
Evaluating:  54%|█████▍    | 92/171 [00:13<00:11,  6.93it/s]11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 93
Evaluating:  54%|█████▍    | 93/171 [00:13<00:11,  6.93it/s]11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 94
Evaluating:  55%|█████▍    | 94/171 [00:13<00:11,  6.95it/s]11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 95
Evaluating:  56%|█████▌    | 95/171 [00:13<00:10,  6.95it/s]11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 96
Evaluating:  56%|█████▌    | 96/171 [00:13<00:10,  6.82it/s]11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 97
Evaluating:  57%|█████▋    | 97/171 [00:13<00:10,  6.76it/s]11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 98
Evaluating:  57%|█████▋    | 98/171 [00:13<00:10,  6.73it/s]11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 99
Evaluating:  58%|█████▊    | 99/171 [00:14<00:10,  6.72it/s]11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 100
Evaluating:  58%|█████▊    | 100/171 [00:14<00:10,  6.70it/s]11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 101
Evaluating:  59%|█████▉    | 101/171 [00:14<00:10,  6.70it/s]11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 102
Evaluating:  60%|█████▉    | 102/171 [00:14<00:10,  6.70it/s]11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 103
Evaluating:  60%|██████    | 103/171 [00:14<00:10,  6.67it/s]11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 104
Evaluating:  61%|██████    | 104/171 [00:14<00:10,  6.67it/s]11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 105
Evaluating:  61%|██████▏   | 105/171 [00:14<00:09,  6.66it/s]11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 106
Evaluating:  62%|██████▏   | 106/171 [00:15<00:09,  6.65it/s]11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 107
Evaluating:  63%|██████▎   | 107/171 [00:15<00:09,  6.65it/s]11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 108
Evaluating:  63%|██████▎   | 108/171 [00:15<00:09,  6.55it/s]11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 109
Evaluating:  64%|██████▎   | 109/171 [00:15<00:09,  6.54it/s]11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 110
Evaluating:  64%|██████▍   | 110/171 [00:15<00:09,  6.55it/s]11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 111
Evaluating:  65%|██████▍   | 111/171 [00:15<00:09,  6.56it/s]11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 112
Evaluating:  65%|██████▌   | 112/171 [00:16<00:09,  6.49it/s]11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 113
Evaluating:  66%|██████▌   | 113/171 [00:16<00:09,  6.41it/s]11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 114
Evaluating:  67%|██████▋   | 114/171 [00:16<00:08,  6.41it/s]11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 115
Evaluating:  67%|██████▋   | 115/171 [00:16<00:08,  6.42it/s]11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 116
Evaluating:  68%|██████▊   | 116/171 [00:16<00:08,  6.36it/s]11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 117
Evaluating:  68%|██████▊   | 117/171 [00:16<00:08,  6.38it/s]11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 118
Evaluating:  69%|██████▉   | 118/171 [00:17<00:08,  6.43it/s]11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 119
Evaluating:  70%|██████▉   | 119/171 [00:17<00:08,  6.48it/s]11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 120
Evaluating:  70%|███████   | 120/171 [00:17<00:07,  6.49it/s]11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 121
Evaluating:  71%|███████   | 121/171 [00:17<00:07,  6.51it/s]11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 122
Evaluating:  71%|███████▏  | 122/171 [00:17<00:07,  6.53it/s]11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 123
Evaluating:  72%|███████▏  | 123/171 [00:17<00:07,  6.54it/s]11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 124
Evaluating:  73%|███████▎  | 124/171 [00:17<00:07,  6.54it/s]11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 125
Evaluating:  73%|███████▎  | 125/171 [00:18<00:07,  6.52it/s]11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 126
Evaluating:  74%|███████▎  | 126/171 [00:18<00:06,  6.51it/s]11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 127
Evaluating:  74%|███████▍  | 127/171 [00:18<00:06,  6.51it/s]11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 128
Evaluating:  75%|███████▍  | 128/171 [00:18<00:06,  6.51it/s]11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 129
Evaluating:  75%|███████▌  | 129/171 [00:18<00:06,  6.53it/s]11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 130
Evaluating:  76%|███████▌  | 130/171 [00:18<00:06,  6.54it/s]11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 131
Evaluating:  77%|███████▋  | 131/171 [00:18<00:06,  6.53it/s]11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 132
Evaluating:  77%|███████▋  | 132/171 [00:19<00:05,  6.52it/s]11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 133
Evaluating:  78%|███████▊  | 133/171 [00:19<00:05,  6.51it/s]11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 134
Evaluating:  78%|███████▊  | 134/171 [00:19<00:05,  6.51it/s]11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 135
Evaluating:  79%|███████▉  | 135/171 [00:19<00:05,  6.50it/s]11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 136
Evaluating:  80%|███████▉  | 136/171 [00:19<00:05,  6.48it/s]11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 137
Evaluating:  80%|████████  | 137/171 [00:19<00:05,  6.48it/s]11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 138
Evaluating:  81%|████████  | 138/171 [00:20<00:05,  6.48it/s]11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 139
Evaluating:  81%|████████▏ | 139/171 [00:20<00:04,  6.47it/s]11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 140
Evaluating:  82%|████████▏ | 140/171 [00:20<00:04,  6.47it/s]11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 141
Evaluating:  82%|████████▏ | 141/171 [00:20<00:04,  6.44it/s]11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 142
Evaluating:  83%|████████▎ | 142/171 [00:20<00:04,  6.45it/s]11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 143
Evaluating:  84%|████████▎ | 143/171 [00:20<00:04,  6.44it/s]11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 144
Evaluating:  84%|████████▍ | 144/171 [00:21<00:04,  6.45it/s]11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 145
Evaluating:  85%|████████▍ | 145/171 [00:21<00:04,  6.44it/s]11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 146
Evaluating:  85%|████████▌ | 146/171 [00:21<00:03,  6.44it/s]11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 147
Evaluating:  86%|████████▌ | 147/171 [00:21<00:03,  6.42it/s]11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 148
Evaluating:  87%|████████▋ | 148/171 [00:21<00:03,  6.42it/s]11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 149
Evaluating:  87%|████████▋ | 149/171 [00:21<00:03,  6.40it/s]11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 150
Evaluating:  88%|████████▊ | 150/171 [00:21<00:03,  6.40it/s]11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 151
Evaluating:  88%|████████▊ | 151/171 [00:22<00:03,  5.70it/s]11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 152
Evaluating:  89%|████████▉ | 152/171 [00:22<00:03,  5.89it/s]11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 153
Evaluating:  89%|████████▉ | 153/171 [00:22<00:02,  6.01it/s]11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 154
Evaluating:  90%|█████████ | 154/171 [00:22<00:02,  5.99it/s]11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 155
Evaluating:  91%|█████████ | 155/171 [00:22<00:02,  5.93it/s]11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 156
Evaluating:  91%|█████████ | 156/171 [00:22<00:02,  5.93it/s]11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 157
Evaluating:  92%|█████████▏| 157/171 [00:23<00:02,  5.99it/s]11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 158
Evaluating:  92%|█████████▏| 158/171 [00:23<00:02,  6.05it/s]11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 159
Evaluating:  93%|█████████▎| 159/171 [00:23<00:01,  6.13it/s]11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 160
Evaluating:  94%|█████████▎| 160/171 [00:23<00:01,  6.22it/s]11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 161
Evaluating:  94%|█████████▍| 161/171 [00:23<00:01,  6.26it/s]11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 162
Evaluating:  95%|█████████▍| 162/171 [00:23<00:01,  6.29it/s]11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 163
Evaluating:  95%|█████████▌| 163/171 [00:24<00:01,  6.30it/s]11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 164
Evaluating:  96%|█████████▌| 164/171 [00:24<00:01,  6.30it/s]11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 165
Evaluating:  96%|█████████▋| 165/171 [00:24<00:00,  6.30it/s]11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 166
Evaluating:  97%|█████████▋| 166/171 [00:24<00:00,  6.31it/s]11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 167
Evaluating:  98%|█████████▊| 167/171 [00:24<00:00,  6.32it/s]11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 168
Evaluating:  98%|█████████▊| 168/171 [00:24<00:00,  6.31it/s]11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 169
Evaluating:  99%|█████████▉| 169/171 [00:25<00:00,  6.33it/s]11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 170
Evaluating:  99%|█████████▉| 170/171 [00:25<00:00,  6.31it/s]11/20/2021 22:49:25 - INFO - __main__ -   Batch number = 171
Evaluating: 100%|██████████| 171/171 [00:25<00:00,  6.77it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/20/2021 22:49:26 - INFO - __main__ -   ***** Evaluation result  in en *****
11/20/2021 22:49:26 - INFO - __main__ -     f1 = 0.9412752207306991
11/20/2021 22:49:26 - INFO - __main__ -     loss = 0.15675296131739316
11/20/2021 22:49:26 - INFO - __main__ -     precision = 0.9402367833772521
11/20/2021 22:49:26 - INFO - __main__ -     recall = 0.9423159544087544
35.64user 14.05system 0:41.65elapsed 119%CPU (0avgtext+0avgdata 3872988maxresident)k
0inputs+960outputs (0major+1340892minor)pagefaults 0swaps
PyTorch version 1.9.0+cu102 available.
11/20/2021 22:49:28 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:49:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:49:28 - INFO - __main__ -   Seed = 2
11/20/2021 22:49:28 - INFO - root -   save model
11/20/2021 22:49:28 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:49:28 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/20/2021 22:49:31 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/20/2021 22:49:36 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:49:36 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:49:36 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
11/20/2021 22:49:36 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:49:36 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_model_head.bin
11/20/2021 22:49:36 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:49:36 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:49:36 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:49:36 - INFO - __main__ -   Language = hi
11/20/2021 22:49:36 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/20/2021 22:49:40 - INFO - __main__ -   Language adapter for en not found, using hi instead
11/20/2021 22:49:40 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:49:40 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:49:40 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:49:40 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
11/20/2021 22:49:40 - INFO - __main__ -   ***** Running evaluation  in en *****
11/20/2021 22:49:40 - INFO - __main__ -     Num examples = 5441
11/20/2021 22:49:40 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/171 [00:00<?, ?it/s]11/20/2021 22:49:40 - INFO - __main__ -   Batch number = 1
Evaluating:   1%|          | 1/171 [00:00<00:26,  6.45it/s]11/20/2021 22:49:40 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/171 [00:00<00:24,  6.82it/s]11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 3
Evaluating:   2%|▏         | 3/171 [00:00<00:23,  7.03it/s]11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 4
Evaluating:   2%|▏         | 4/171 [00:00<00:23,  7.14it/s]11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 5
Evaluating:   3%|▎         | 5/171 [00:00<00:23,  7.20it/s]11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 6
Evaluating:   4%|▎         | 6/171 [00:00<00:22,  7.23it/s]11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 7
Evaluating:   4%|▍         | 7/171 [00:00<00:22,  7.24it/s]11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 8
Evaluating:   5%|▍         | 8/171 [00:01<00:22,  7.27it/s]11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 9
Evaluating:   5%|▌         | 9/171 [00:01<00:22,  7.27it/s]11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 10
Evaluating:   6%|▌         | 10/171 [00:01<00:22,  7.27it/s]11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 11
Evaluating:   6%|▋         | 11/171 [00:01<00:21,  7.27it/s]11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 12
Evaluating:   7%|▋         | 12/171 [00:01<00:21,  7.28it/s]11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 13
Evaluating:   8%|▊         | 13/171 [00:01<00:21,  7.28it/s]11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 14
Evaluating:   8%|▊         | 14/171 [00:01<00:21,  7.28it/s]11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 15
Evaluating:   9%|▉         | 15/171 [00:02<00:21,  7.28it/s]11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 16
Evaluating:   9%|▉         | 16/171 [00:02<00:21,  7.27it/s]11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 17
Evaluating:  10%|▉         | 17/171 [00:02<00:21,  7.26it/s]11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 18
Evaluating:  11%|█         | 18/171 [00:02<00:21,  7.25it/s]11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 19
Evaluating:  11%|█         | 19/171 [00:02<00:20,  7.25it/s]11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 20
Evaluating:  12%|█▏        | 20/171 [00:02<00:20,  7.24it/s]11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 21
Evaluating:  12%|█▏        | 21/171 [00:02<00:20,  7.20it/s]11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 22
Evaluating:  13%|█▎        | 22/171 [00:03<00:20,  7.18it/s]11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 23
Evaluating:  13%|█▎        | 23/171 [00:03<00:20,  7.19it/s]11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 24
Evaluating:  14%|█▍        | 24/171 [00:03<00:20,  7.20it/s]11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 25
Evaluating:  15%|█▍        | 25/171 [00:03<00:20,  7.21it/s]11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 26
Evaluating:  15%|█▌        | 26/171 [00:03<00:20,  7.20it/s]11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 27
Evaluating:  16%|█▌        | 27/171 [00:03<00:19,  7.21it/s]11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 28
Evaluating:  16%|█▋        | 28/171 [00:03<00:19,  7.21it/s]11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 29
Evaluating:  17%|█▋        | 29/171 [00:04<00:19,  7.21it/s]11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 30
Evaluating:  18%|█▊        | 30/171 [00:04<00:19,  7.22it/s]11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 31
Evaluating:  18%|█▊        | 31/171 [00:04<00:19,  7.22it/s]11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 32
Evaluating:  19%|█▊        | 32/171 [00:04<00:19,  7.22it/s]11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 33
Evaluating:  19%|█▉        | 33/171 [00:04<00:19,  7.20it/s]11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 34
Evaluating:  20%|█▉        | 34/171 [00:04<00:19,  7.20it/s]11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 35
Evaluating:  20%|██        | 35/171 [00:04<00:18,  7.19it/s]11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 36
Evaluating:  21%|██        | 36/171 [00:04<00:18,  7.19it/s]11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 37
Evaluating:  22%|██▏       | 37/171 [00:05<00:18,  7.17it/s]11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 38
Evaluating:  22%|██▏       | 38/171 [00:05<00:18,  7.17it/s]11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 39
Evaluating:  23%|██▎       | 39/171 [00:05<00:18,  7.16it/s]11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 40
Evaluating:  23%|██▎       | 40/171 [00:05<00:18,  7.17it/s]11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 41
Evaluating:  24%|██▍       | 41/171 [00:05<00:18,  7.17it/s]11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 42
Evaluating:  25%|██▍       | 42/171 [00:05<00:17,  7.17it/s]11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 43
Evaluating:  25%|██▌       | 43/171 [00:05<00:17,  7.16it/s]11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 44
Evaluating:  26%|██▌       | 44/171 [00:06<00:17,  7.10it/s]11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 45
Evaluating:  26%|██▋       | 45/171 [00:06<00:18,  6.88it/s]11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 46
Evaluating:  27%|██▋       | 46/171 [00:06<00:17,  6.95it/s]11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 47
Evaluating:  27%|██▋       | 47/171 [00:06<00:17,  7.00it/s]11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 48
Evaluating:  28%|██▊       | 48/171 [00:06<00:17,  7.03it/s]11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 49
Evaluating:  29%|██▊       | 49/171 [00:06<00:17,  7.05it/s]11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 50
Evaluating:  29%|██▉       | 50/171 [00:06<00:17,  7.07it/s]11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 51
Evaluating:  30%|██▉       | 51/171 [00:07<00:16,  7.07it/s]11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 52
Evaluating:  30%|███       | 52/171 [00:07<00:16,  7.08it/s]11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 53
Evaluating:  31%|███       | 53/171 [00:07<00:16,  7.10it/s]11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 54
Evaluating:  32%|███▏      | 54/171 [00:07<00:16,  7.09it/s]11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 55
Evaluating:  32%|███▏      | 55/171 [00:07<00:16,  7.09it/s]11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 56
Evaluating:  33%|███▎      | 56/171 [00:07<00:16,  7.09it/s]11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 57
Evaluating:  33%|███▎      | 57/171 [00:07<00:16,  7.08it/s]11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 58
Evaluating:  34%|███▍      | 58/171 [00:08<00:15,  7.07it/s]11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 59
Evaluating:  35%|███▍      | 59/171 [00:08<00:15,  7.08it/s]11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 60
Evaluating:  35%|███▌      | 60/171 [00:08<00:15,  7.07it/s]11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 61
Evaluating:  36%|███▌      | 61/171 [00:08<00:15,  7.06it/s]11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 62
Evaluating:  36%|███▋      | 62/171 [00:08<00:15,  7.07it/s]11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 63
Evaluating:  37%|███▋      | 63/171 [00:08<00:15,  7.05it/s]11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 64
Evaluating:  37%|███▋      | 64/171 [00:08<00:15,  7.06it/s]11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 65
Evaluating:  38%|███▊      | 65/171 [00:09<00:15,  7.05it/s]11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 66
Evaluating:  39%|███▊      | 66/171 [00:09<00:14,  7.05it/s]11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 67
Evaluating:  39%|███▉      | 67/171 [00:09<00:14,  7.04it/s]11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 68
Evaluating:  40%|███▉      | 68/171 [00:09<00:14,  7.05it/s]11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 69
Evaluating:  40%|████      | 69/171 [00:09<00:14,  7.01it/s]11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 70
Evaluating:  41%|████      | 70/171 [00:09<00:14,  6.97it/s]11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 71
Evaluating:  42%|████▏     | 71/171 [00:09<00:14,  6.97it/s]11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 72
Evaluating:  42%|████▏     | 72/171 [00:10<00:14,  6.91it/s]11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 73
Evaluating:  43%|████▎     | 73/171 [00:10<00:14,  6.88it/s]11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 74
Evaluating:  43%|████▎     | 74/171 [00:10<00:14,  6.89it/s]11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 75
Evaluating:  44%|████▍     | 75/171 [00:10<00:13,  6.90it/s]11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 76
Evaluating:  44%|████▍     | 76/171 [00:10<00:13,  6.92it/s]11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 77
Evaluating:  45%|████▌     | 77/171 [00:10<00:13,  6.95it/s]11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 78
Evaluating:  46%|████▌     | 78/171 [00:10<00:13,  6.95it/s]11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 79
Evaluating:  46%|████▌     | 79/171 [00:11<00:13,  6.92it/s]11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 80
Evaluating:  47%|████▋     | 80/171 [00:11<00:13,  6.91it/s]11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 81
Evaluating:  47%|████▋     | 81/171 [00:11<00:13,  6.84it/s]11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 82
Evaluating:  48%|████▊     | 82/171 [00:11<00:13,  6.82it/s]11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 83
Evaluating:  49%|████▊     | 83/171 [00:11<00:12,  6.82it/s]11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 84
Evaluating:  49%|████▉     | 84/171 [00:11<00:12,  6.85it/s]11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 85
Evaluating:  50%|████▉     | 85/171 [00:11<00:12,  6.77it/s]11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 86
Evaluating:  50%|█████     | 86/171 [00:12<00:12,  6.84it/s]11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 87
Evaluating:  51%|█████     | 87/171 [00:12<00:12,  6.87it/s]11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 88
Evaluating:  51%|█████▏    | 88/171 [00:12<00:12,  6.88it/s]11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 89
Evaluating:  52%|█████▏    | 89/171 [00:12<00:11,  6.89it/s]11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 90
Evaluating:  53%|█████▎    | 90/171 [00:12<00:11,  6.91it/s]11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 91
Evaluating:  53%|█████▎    | 91/171 [00:12<00:11,  6.92it/s]11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 92
Evaluating:  54%|█████▍    | 92/171 [00:13<00:11,  6.86it/s]11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 93
Evaluating:  54%|█████▍    | 93/171 [00:13<00:11,  6.86it/s]11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 94
Evaluating:  55%|█████▍    | 94/171 [00:13<00:11,  6.87it/s]11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 95
Evaluating:  56%|█████▌    | 95/171 [00:13<00:11,  6.89it/s]11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 96
Evaluating:  56%|█████▌    | 96/171 [00:13<00:10,  6.89it/s]11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 97
Evaluating:  57%|█████▋    | 97/171 [00:13<00:10,  6.86it/s]11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 98
Evaluating:  57%|█████▋    | 98/171 [00:13<00:10,  6.88it/s]11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 99
Evaluating:  58%|█████▊    | 99/171 [00:14<00:10,  6.90it/s]11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 100
Evaluating:  58%|█████▊    | 100/171 [00:14<00:10,  6.89it/s]11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 101
Evaluating:  59%|█████▉    | 101/171 [00:14<00:10,  6.87it/s]11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 102
Evaluating:  60%|█████▉    | 102/171 [00:14<00:10,  6.86it/s]11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 103
Evaluating:  60%|██████    | 103/171 [00:14<00:10,  6.80it/s]11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 104
Evaluating:  61%|██████    | 104/171 [00:14<00:09,  6.73it/s]11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 105
Evaluating:  61%|██████▏   | 105/171 [00:14<00:09,  6.75it/s]11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 106
Evaluating:  62%|██████▏   | 106/171 [00:15<00:09,  6.74it/s]11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 107
Evaluating:  63%|██████▎   | 107/171 [00:15<00:09,  6.71it/s]11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 108
Evaluating:  63%|██████▎   | 108/171 [00:15<00:09,  6.52it/s]11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 109
Evaluating:  64%|██████▎   | 109/171 [00:15<00:09,  6.51it/s]11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 110
Evaluating:  64%|██████▍   | 110/171 [00:15<00:09,  6.56it/s]11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 111
Evaluating:  65%|██████▍   | 111/171 [00:15<00:09,  6.64it/s]11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 112
Evaluating:  65%|██████▌   | 112/171 [00:15<00:08,  6.67it/s]11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 113
Evaluating:  66%|██████▌   | 113/171 [00:16<00:08,  6.69it/s]11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 114
Evaluating:  67%|██████▋   | 114/171 [00:16<00:08,  6.59it/s]11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 115
Evaluating:  67%|██████▋   | 115/171 [00:16<00:08,  6.65it/s]11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 116
Evaluating:  68%|██████▊   | 116/171 [00:16<00:08,  6.69it/s]11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 117
Evaluating:  68%|██████▊   | 117/171 [00:16<00:07,  6.75it/s]11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 118
Evaluating:  69%|██████▉   | 118/171 [00:16<00:07,  6.76it/s]11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 119
Evaluating:  70%|██████▉   | 119/171 [00:17<00:07,  6.74it/s]11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 120
Evaluating:  70%|███████   | 120/171 [00:17<00:07,  6.77it/s]11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 121
Evaluating:  71%|███████   | 121/171 [00:17<00:07,  6.81it/s]11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 122
Evaluating:  71%|███████▏  | 122/171 [00:17<00:07,  6.81it/s]11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 123
Evaluating:  72%|███████▏  | 123/171 [00:17<00:07,  6.84it/s]11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 124
Evaluating:  73%|███████▎  | 124/171 [00:17<00:06,  6.85it/s]11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 125
Evaluating:  73%|███████▎  | 125/171 [00:17<00:06,  6.84it/s]11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 126
Evaluating:  74%|███████▎  | 126/171 [00:18<00:06,  6.85it/s]11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 127
Evaluating:  74%|███████▍  | 127/171 [00:18<00:06,  6.83it/s]11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 128
Evaluating:  75%|███████▍  | 128/171 [00:18<00:06,  6.83it/s]11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 129
Evaluating:  75%|███████▌  | 129/171 [00:18<00:06,  6.84it/s]11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 130
Evaluating:  76%|███████▌  | 130/171 [00:18<00:05,  6.85it/s]11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 131
Evaluating:  77%|███████▋  | 131/171 [00:18<00:05,  6.81it/s]11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 132
Evaluating:  77%|███████▋  | 132/171 [00:18<00:05,  6.76it/s]11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 133
Evaluating:  78%|███████▊  | 133/171 [00:19<00:05,  6.72it/s]11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 134
Evaluating:  78%|███████▊  | 134/171 [00:19<00:05,  6.72it/s]11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 135
Evaluating:  79%|███████▉  | 135/171 [00:19<00:05,  6.74it/s]11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 136
Evaluating:  80%|███████▉  | 136/171 [00:19<00:05,  6.63it/s]11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 137
Evaluating:  80%|████████  | 137/171 [00:19<00:05,  6.56it/s]11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 138
Evaluating:  81%|████████  | 138/171 [00:19<00:05,  6.59it/s]11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 139
Evaluating:  81%|████████▏ | 139/171 [00:19<00:04,  6.64it/s]11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 140
Evaluating:  82%|████████▏ | 140/171 [00:20<00:04,  6.64it/s]11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 141
Evaluating:  82%|████████▏ | 141/171 [00:20<00:04,  6.51it/s]11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 142
Evaluating:  83%|████████▎ | 142/171 [00:20<00:04,  6.59it/s]11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 143
Evaluating:  84%|████████▎ | 143/171 [00:20<00:04,  6.65it/s]11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 144
Evaluating:  84%|████████▍ | 144/171 [00:20<00:04,  6.56it/s]11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 145
Evaluating:  85%|████████▍ | 145/171 [00:20<00:03,  6.59it/s]11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 146
Evaluating:  85%|████████▌ | 146/171 [00:21<00:03,  6.66it/s]11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 147
Evaluating:  86%|████████▌ | 147/171 [00:21<00:05,  4.56it/s]11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 148
Evaluating:  87%|████████▋ | 148/171 [00:21<00:04,  4.96it/s]11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 149
Evaluating:  87%|████████▋ | 149/171 [00:21<00:04,  5.30it/s]11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 150
Evaluating:  88%|████████▊ | 150/171 [00:21<00:03,  5.53it/s]11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 151
Evaluating:  88%|████████▊ | 151/171 [00:22<00:03,  5.75it/s]11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 152
Evaluating:  89%|████████▉ | 152/171 [00:22<00:03,  5.89it/s]11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 153
Evaluating:  89%|████████▉ | 153/171 [00:22<00:03,  5.91it/s]11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 154
Evaluating:  90%|█████████ | 154/171 [00:22<00:02,  5.89it/s]11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 155
Evaluating:  91%|█████████ | 155/171 [00:22<00:02,  5.94it/s]11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 156
Evaluating:  91%|█████████ | 156/171 [00:22<00:02,  6.00it/s]11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 157
Evaluating:  92%|█████████▏| 157/171 [00:23<00:02,  6.18it/s]11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 158
Evaluating:  92%|█████████▏| 158/171 [00:23<00:02,  6.34it/s]11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 159
Evaluating:  93%|█████████▎| 159/171 [00:23<00:01,  6.36it/s]11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 160
Evaluating:  94%|█████████▎| 160/171 [00:23<00:01,  6.47it/s]11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 161
Evaluating:  94%|█████████▍| 161/171 [00:23<00:01,  6.48it/s]11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 162
Evaluating:  95%|█████████▍| 162/171 [00:23<00:01,  6.37it/s]11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 163
Evaluating:  95%|█████████▌| 163/171 [00:23<00:01,  6.42it/s]11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 164
Evaluating:  96%|█████████▌| 164/171 [00:24<00:01,  6.49it/s]11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 165
Evaluating:  96%|█████████▋| 165/171 [00:24<00:00,  6.45it/s]11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 166
Evaluating:  97%|█████████▋| 166/171 [00:24<00:00,  6.53it/s]11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 167
Evaluating:  98%|█████████▊| 167/171 [00:24<00:00,  6.57it/s]11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 168
Evaluating:  98%|█████████▊| 168/171 [00:24<00:00,  6.48it/s]11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 169
Evaluating:  99%|█████████▉| 169/171 [00:24<00:00,  6.41it/s]11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 170
Evaluating:  99%|█████████▉| 170/171 [00:25<00:00,  6.38it/s]11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 171
Evaluating: 100%|██████████| 171/171 [00:25<00:00,  6.82it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/20/2021 22:50:07 - INFO - __main__ -   ***** Evaluation result  in en *****
11/20/2021 22:50:07 - INFO - __main__ -     f1 = 0.9426692085295492
11/20/2021 22:50:07 - INFO - __main__ -     loss = 0.16115038460583497
11/20/2021 22:50:07 - INFO - __main__ -     precision = 0.941848731015692
11/20/2021 22:50:07 - INFO - __main__ -     recall = 0.9434911167833405
35.73user 14.64system 0:40.86elapsed 123%CPU (0avgtext+0avgdata 3869844maxresident)k
0inputs+952outputs (0major+1206474minor)pagefaults 0swaps
PyTorch version 1.9.0+cu102 available.
11/20/2021 22:50:09 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:50:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:50:09 - INFO - __main__ -   Seed = 3
11/20/2021 22:50:09 - INFO - root -   save model
11/20/2021 22:50:09 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:50:09 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/20/2021 22:50:12 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/20/2021 22:50:17 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:50:17 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:50:17 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
11/20/2021 22:50:17 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:50:17 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_model_head.bin
11/20/2021 22:50:17 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:50:17 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:50:17 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:50:17 - INFO - __main__ -   Language = hi
11/20/2021 22:50:17 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/20/2021 22:50:21 - INFO - __main__ -   Language adapter for en not found, using hi instead
11/20/2021 22:50:21 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:50:21 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:50:21 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:50:21 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
11/20/2021 22:50:22 - INFO - __main__ -   ***** Running evaluation  in en *****
11/20/2021 22:50:22 - INFO - __main__ -     Num examples = 5441
11/20/2021 22:50:22 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/171 [00:00<?, ?it/s]11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 1
Evaluating:   1%|          | 1/171 [00:00<00:26,  6.50it/s]11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 2
Evaluating:   1%|          | 2/171 [00:00<00:24,  6.78it/s]11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 3
Evaluating:   2%|▏         | 3/171 [00:00<00:24,  6.98it/s]11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 4
Evaluating:   2%|▏         | 4/171 [00:00<00:23,  7.10it/s]11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 5
Evaluating:   3%|▎         | 5/171 [00:00<00:23,  7.17it/s]11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 6
Evaluating:   4%|▎         | 6/171 [00:00<00:22,  7.21it/s]11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 7
Evaluating:   4%|▍         | 7/171 [00:00<00:22,  7.24it/s]11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 8
Evaluating:   5%|▍         | 8/171 [00:01<00:22,  7.26it/s]11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 9
Evaluating:   5%|▌         | 9/171 [00:01<00:22,  7.26it/s]11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 10
Evaluating:   6%|▌         | 10/171 [00:01<00:22,  7.25it/s]11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 11
Evaluating:   6%|▋         | 11/171 [00:01<00:22,  7.26it/s]11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 12
Evaluating:   7%|▋         | 12/171 [00:01<00:21,  7.26it/s]11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 13
Evaluating:   8%|▊         | 13/171 [00:01<00:21,  7.25it/s]11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 14
Evaluating:   8%|▊         | 14/171 [00:01<00:21,  7.24it/s]11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 15
Evaluating:   9%|▉         | 15/171 [00:02<00:21,  7.25it/s]11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 16
Evaluating:   9%|▉         | 16/171 [00:02<00:21,  7.26it/s]11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 17
Evaluating:  10%|▉         | 17/171 [00:02<00:21,  7.24it/s]11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 18
Evaluating:  11%|█         | 18/171 [00:02<00:21,  7.24it/s]11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 19
Evaluating:  11%|█         | 19/171 [00:02<00:21,  7.23it/s]11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 20
Evaluating:  12%|█▏        | 20/171 [00:02<00:20,  7.22it/s]11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 21
Evaluating:  12%|█▏        | 21/171 [00:02<00:20,  7.23it/s]11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 22
Evaluating:  13%|█▎        | 22/171 [00:03<00:20,  7.23it/s]11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 23
Evaluating:  13%|█▎        | 23/171 [00:03<00:20,  7.23it/s]11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 24
Evaluating:  14%|█▍        | 24/171 [00:03<00:20,  7.24it/s]11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 25
Evaluating:  15%|█▍        | 25/171 [00:03<00:20,  7.23it/s]11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 26
Evaluating:  15%|█▌        | 26/171 [00:03<00:20,  7.22it/s]11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 27
Evaluating:  16%|█▌        | 27/171 [00:03<00:19,  7.22it/s]11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 28
Evaluating:  16%|█▋        | 28/171 [00:03<00:19,  7.22it/s]11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 29
Evaluating:  17%|█▋        | 29/171 [00:04<00:19,  7.22it/s]11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 30
Evaluating:  18%|█▊        | 30/171 [00:04<00:19,  7.22it/s]11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 31
Evaluating:  18%|█▊        | 31/171 [00:04<00:19,  7.21it/s]11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 32
Evaluating:  19%|█▊        | 32/171 [00:04<00:19,  7.21it/s]11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 33
Evaluating:  19%|█▉        | 33/171 [00:04<00:19,  7.20it/s]11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 34
Evaluating:  20%|█▉        | 34/171 [00:04<00:19,  7.20it/s]11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 35
Evaluating:  20%|██        | 35/171 [00:04<00:18,  7.19it/s]11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 36
Evaluating:  21%|██        | 36/171 [00:05<00:19,  6.80it/s]11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 37
Evaluating:  22%|██▏       | 37/171 [00:05<00:19,  6.90it/s]11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 38
Evaluating:  22%|██▏       | 38/171 [00:05<00:19,  6.97it/s]11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 39
Evaluating:  23%|██▎       | 39/171 [00:05<00:18,  7.01it/s]11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 40
Evaluating:  23%|██▎       | 40/171 [00:05<00:18,  7.06it/s]11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 41
Evaluating:  24%|██▍       | 41/171 [00:05<00:18,  7.04it/s]11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 42
Evaluating:  25%|██▍       | 42/171 [00:05<00:18,  7.03it/s]11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 43
Evaluating:  25%|██▌       | 43/171 [00:06<00:18,  7.06it/s]11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 44
Evaluating:  26%|██▌       | 44/171 [00:06<00:17,  7.08it/s]11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 45
Evaluating:  26%|██▋       | 45/171 [00:06<00:17,  7.08it/s]11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 46
Evaluating:  27%|██▋       | 46/171 [00:06<00:17,  7.10it/s]11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 47
Evaluating:  27%|██▋       | 47/171 [00:06<00:17,  7.11it/s]11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 48
Evaluating:  28%|██▊       | 48/171 [00:06<00:17,  7.11it/s]11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 49
Evaluating:  29%|██▊       | 49/171 [00:06<00:17,  7.11it/s]11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 50
Evaluating:  29%|██▉       | 50/171 [00:06<00:16,  7.12it/s]11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 51
Evaluating:  30%|██▉       | 51/171 [00:07<00:16,  7.10it/s]11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 52
Evaluating:  30%|███       | 52/171 [00:07<00:16,  7.10it/s]11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 53
Evaluating:  31%|███       | 53/171 [00:07<00:16,  7.10it/s]11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 54
Evaluating:  32%|███▏      | 54/171 [00:07<00:16,  7.08it/s]11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 55
Evaluating:  32%|███▏      | 55/171 [00:07<00:16,  7.06it/s]11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 56
Evaluating:  33%|███▎      | 56/171 [00:07<00:16,  7.07it/s]11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 57
Evaluating:  33%|███▎      | 57/171 [00:07<00:16,  7.07it/s]11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 58
Evaluating:  34%|███▍      | 58/171 [00:08<00:15,  7.07it/s]11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 59
Evaluating:  35%|███▍      | 59/171 [00:08<00:15,  7.08it/s]11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 60
Evaluating:  35%|███▌      | 60/171 [00:08<00:15,  7.06it/s]11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 61
Evaluating:  36%|███▌      | 61/171 [00:08<00:15,  7.05it/s]11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 62
Evaluating:  36%|███▋      | 62/171 [00:08<00:15,  7.06it/s]11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 63
Evaluating:  37%|███▋      | 63/171 [00:08<00:15,  7.05it/s]11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 64
Evaluating:  37%|███▋      | 64/171 [00:08<00:15,  6.88it/s]11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 65
Evaluating:  38%|███▊      | 65/171 [00:09<00:15,  6.85it/s]11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 66
Evaluating:  39%|███▊      | 66/171 [00:09<00:15,  6.91it/s]11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 67
Evaluating:  39%|███▉      | 67/171 [00:09<00:15,  6.85it/s]11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 68
Evaluating:  40%|███▉      | 68/171 [00:09<00:15,  6.77it/s]11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 69
Evaluating:  40%|████      | 69/171 [00:09<00:15,  6.75it/s]11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 70
Evaluating:  41%|████      | 70/171 [00:09<00:14,  6.76it/s]11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 71
Evaluating:  42%|████▏     | 71/171 [00:10<00:15,  6.46it/s]11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 72
Evaluating:  42%|████▏     | 72/171 [00:10<00:14,  6.60it/s]11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 73
Evaluating:  43%|████▎     | 73/171 [00:10<00:14,  6.71it/s]11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 74
Evaluating:  43%|████▎     | 74/171 [00:10<00:14,  6.78it/s]11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 75
Evaluating:  44%|████▍     | 75/171 [00:10<00:14,  6.84it/s]11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 76
Evaluating:  44%|████▍     | 76/171 [00:10<00:13,  6.89it/s]11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 77
Evaluating:  45%|████▌     | 77/171 [00:10<00:13,  6.92it/s]11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 78
Evaluating:  46%|████▌     | 78/171 [00:11<00:13,  6.93it/s]11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 79
Evaluating:  46%|████▌     | 79/171 [00:11<00:13,  6.95it/s]11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 80
Evaluating:  47%|████▋     | 80/171 [00:11<00:13,  6.97it/s]11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 81
Evaluating:  47%|████▋     | 81/171 [00:11<00:12,  6.95it/s]11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 82
Evaluating:  48%|████▊     | 82/171 [00:11<00:12,  6.92it/s]11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 83
Evaluating:  49%|████▊     | 83/171 [00:11<00:12,  6.91it/s]11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 84
Evaluating:  49%|████▉     | 84/171 [00:11<00:12,  6.90it/s]11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 85
Evaluating:  50%|████▉     | 85/171 [00:12<00:12,  6.82it/s]11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 86
Evaluating:  50%|█████     | 86/171 [00:12<00:12,  6.86it/s]11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 87
Evaluating:  51%|█████     | 87/171 [00:12<00:12,  6.88it/s]11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 88
Evaluating:  51%|█████▏    | 88/171 [00:12<00:12,  6.88it/s]11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 89
Evaluating:  52%|█████▏    | 89/171 [00:12<00:11,  6.86it/s]11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 90
Evaluating:  53%|█████▎    | 90/171 [00:12<00:11,  6.90it/s]11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 91
Evaluating:  53%|█████▎    | 91/171 [00:12<00:11,  6.91it/s]11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 92
Evaluating:  54%|█████▍    | 92/171 [00:13<00:11,  6.92it/s]11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 93
Evaluating:  54%|█████▍    | 93/171 [00:13<00:11,  6.92it/s]11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 94
Evaluating:  55%|█████▍    | 94/171 [00:13<00:11,  6.93it/s]11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 95
Evaluating:  56%|█████▌    | 95/171 [00:13<00:10,  6.95it/s]11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 96
Evaluating:  56%|█████▌    | 96/171 [00:13<00:10,  6.95it/s]11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 97
Evaluating:  57%|█████▋    | 97/171 [00:13<00:10,  6.93it/s]11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 98
Evaluating:  57%|█████▋    | 98/171 [00:13<00:10,  6.89it/s]11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 99
Evaluating:  58%|█████▊    | 99/171 [00:14<00:10,  6.88it/s]11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 100
Evaluating:  58%|█████▊    | 100/171 [00:14<00:10,  6.90it/s]11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 101
Evaluating:  59%|█████▉    | 101/171 [00:14<00:10,  6.89it/s]11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 102
Evaluating:  60%|█████▉    | 102/171 [00:14<00:09,  6.92it/s]11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 103
Evaluating:  60%|██████    | 103/171 [00:14<00:09,  6.92it/s]11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 104
Evaluating:  61%|██████    | 104/171 [00:14<00:09,  6.90it/s]11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 105
Evaluating:  61%|██████▏   | 105/171 [00:14<00:09,  6.89it/s]11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 106
Evaluating:  62%|██████▏   | 106/171 [00:15<00:09,  6.89it/s]11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 107
Evaluating:  63%|██████▎   | 107/171 [00:15<00:09,  6.90it/s]11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 108
Evaluating:  63%|██████▎   | 108/171 [00:15<00:09,  6.91it/s]11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 109
Evaluating:  64%|██████▎   | 109/171 [00:15<00:08,  6.91it/s]11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 110
Evaluating:  64%|██████▍   | 110/171 [00:15<00:08,  6.90it/s]11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 111
Evaluating:  65%|██████▍   | 111/171 [00:15<00:08,  6.92it/s]11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 112
Evaluating:  65%|██████▌   | 112/171 [00:15<00:08,  6.91it/s]11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 113
Evaluating:  66%|██████▌   | 113/171 [00:16<00:08,  6.89it/s]11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 114
Evaluating:  67%|██████▋   | 114/171 [00:16<00:08,  6.88it/s]11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 115
Evaluating:  67%|██████▋   | 115/171 [00:16<00:08,  6.85it/s]11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 116
Evaluating:  68%|██████▊   | 116/171 [00:16<00:08,  6.81it/s]11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 117
Evaluating:  68%|██████▊   | 117/171 [00:16<00:07,  6.84it/s]11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 118
Evaluating:  69%|██████▉   | 118/171 [00:16<00:07,  6.85it/s]11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 119
Evaluating:  70%|██████▉   | 119/171 [00:16<00:07,  6.83it/s]11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 120
Evaluating:  70%|███████   | 120/171 [00:17<00:07,  6.83it/s]11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 121
Evaluating:  71%|███████   | 121/171 [00:17<00:07,  6.83it/s]11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 122
Evaluating:  71%|███████▏  | 122/171 [00:17<00:07,  6.81it/s]11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 123
Evaluating:  72%|███████▏  | 123/171 [00:17<00:07,  6.82it/s]11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 124
Evaluating:  73%|███████▎  | 124/171 [00:17<00:06,  6.81it/s]11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 125
Evaluating:  73%|███████▎  | 125/171 [00:17<00:06,  6.81it/s]11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 126
Evaluating:  74%|███████▎  | 126/171 [00:18<00:06,  6.81it/s]11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 127
Evaluating:  74%|███████▍  | 127/171 [00:18<00:06,  6.80it/s]11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 128
Evaluating:  75%|███████▍  | 128/171 [00:18<00:06,  6.79it/s]11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 129
Evaluating:  75%|███████▌  | 129/171 [00:18<00:06,  6.81it/s]11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 130
Evaluating:  76%|███████▌  | 130/171 [00:18<00:06,  6.81it/s]11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 131
Evaluating:  77%|███████▋  | 131/171 [00:18<00:05,  6.81it/s]11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 132
Evaluating:  77%|███████▋  | 132/171 [00:18<00:05,  6.80it/s]11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 133
Evaluating:  78%|███████▊  | 133/171 [00:19<00:05,  6.77it/s]11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 134
Evaluating:  78%|███████▊  | 134/171 [00:19<00:05,  6.76it/s]11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 135
Evaluating:  79%|███████▉  | 135/171 [00:19<00:05,  6.78it/s]11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 136
Evaluating:  80%|███████▉  | 136/171 [00:19<00:05,  6.77it/s]11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 137
Evaluating:  80%|████████  | 137/171 [00:19<00:05,  6.79it/s]11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 138
Evaluating:  81%|████████  | 138/171 [00:19<00:04,  6.79it/s]11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 139
Evaluating:  81%|████████▏ | 139/171 [00:19<00:04,  6.68it/s]11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 140
Evaluating:  82%|████████▏ | 140/171 [00:20<00:04,  6.65it/s]11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 141
Evaluating:  82%|████████▏ | 141/171 [00:20<00:04,  6.61it/s]11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 142
Evaluating:  83%|████████▎ | 142/171 [00:20<00:04,  6.51it/s]11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 143
Evaluating:  84%|████████▎ | 143/171 [00:20<00:04,  6.57it/s]11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 144
Evaluating:  84%|████████▍ | 144/171 [00:20<00:04,  6.64it/s]11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 145
Evaluating:  85%|████████▍ | 145/171 [00:20<00:03,  6.58it/s]11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 146
Evaluating:  85%|████████▌ | 146/171 [00:21<00:03,  6.64it/s]11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 147
Evaluating:  86%|████████▌ | 147/171 [00:21<00:03,  6.68it/s]11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 148
Evaluating:  87%|████████▋ | 148/171 [00:21<00:03,  6.60it/s]11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 149
Evaluating:  87%|████████▋ | 149/171 [00:21<00:03,  6.66it/s]11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 150
Evaluating:  88%|████████▊ | 150/171 [00:21<00:03,  6.68it/s]11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 151
Evaluating:  88%|████████▊ | 151/171 [00:21<00:03,  6.60it/s]11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 152
Evaluating:  89%|████████▉ | 152/171 [00:21<00:02,  6.65it/s]11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 153
Evaluating:  89%|████████▉ | 153/171 [00:22<00:02,  6.68it/s]11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 154
Evaluating:  90%|█████████ | 154/171 [00:22<00:02,  6.57it/s]11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 155
Evaluating:  91%|█████████ | 155/171 [00:22<00:02,  6.59it/s]11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 156
Evaluating:  91%|█████████ | 156/171 [00:22<00:02,  6.61it/s]11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 157
Evaluating:  92%|█████████▏| 157/171 [00:22<00:02,  6.53it/s]11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 158
Evaluating:  92%|█████████▏| 158/171 [00:22<00:01,  6.58it/s]11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 159
Evaluating:  93%|█████████▎| 159/171 [00:22<00:01,  6.49it/s]11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 160
Evaluating:  94%|█████████▎| 160/171 [00:23<00:01,  6.32it/s]11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 161
Evaluating:  94%|█████████▍| 161/171 [00:23<00:01,  6.36it/s]11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 162
Evaluating:  95%|█████████▍| 162/171 [00:23<00:01,  6.41it/s]11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 163
Evaluating:  95%|█████████▌| 163/171 [00:23<00:01,  6.36it/s]11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 164
Evaluating:  96%|█████████▌| 164/171 [00:23<00:01,  6.45it/s]11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 165
Evaluating:  96%|█████████▋| 165/171 [00:23<00:00,  6.52it/s]11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 166
Evaluating:  97%|█████████▋| 166/171 [00:24<00:00,  6.47it/s]11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 167
Evaluating:  98%|█████████▊| 167/171 [00:24<00:00,  6.53it/s]11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 168
Evaluating:  98%|█████████▊| 168/171 [00:24<00:00,  6.55it/s]11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 169
Evaluating:  99%|█████████▉| 169/171 [00:24<00:00,  6.43it/s]11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 170
Evaluating:  99%|█████████▉| 170/171 [00:24<00:00,  6.49it/s]11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 171
Evaluating: 100%|██████████| 171/171 [00:24<00:00,  6.92it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/20/2021 22:50:48 - INFO - __main__ -   ***** Evaluation result  in en *****
11/20/2021 22:50:48 - INFO - __main__ -     f1 = 0.9433838342374659
11/20/2021 22:50:48 - INFO - __main__ -     loss = 0.1522504466487781
11/20/2021 22:50:48 - INFO - __main__ -     precision = 0.942961027156005
11/20/2021 22:50:48 - INFO - __main__ -     recall = 0.9438070206474766
36.50user 15.89system 0:40.80elapsed 128%CPU (0avgtext+0avgdata 3870492maxresident)k
0inputs+944outputs (0major+1164506minor)pagefaults 0swaps
Fatal Python error: initsite: Failed to import the site module
Traceback (most recent call last):
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 857, in get_code
  File "<frozen importlib._bootstrap_external>", line 525, in _compile_bytecode
KeyboardInterrupt
Command exited with non-zero status 1
0.01user 0.00system 0:00.01elapsed 100%CPU (0avgtext+0avgdata 8296maxresident)k
0inputs+8outputs (0major+728minor)pagefaults 0swaps
Fatal Python error: initsite: Failed to import the site module
Traceback (most recent call last):
  File "/home/abhijeet/rohan/venvs/emea/lib/python3.7/site.py", line 66, in <module>
    import os
  File "/home/abhijeet/rohan/venvs/emea/lib/python3.7/os.py", line 1002, in <module>
    class _wrap_close:
KeyboardInterrupt
Command exited with non-zero status 1
0.01user 0.01system 0:00.02elapsed 100%CPU (0avgtext+0avgdata 8732maxresident)k
0inputs+0outputs (0major+842minor)pagefaults 0swaps
Fatal Python error: initsite: Failed to import the site module
Traceback (most recent call last):
  File "/home/abhijeet/rohan/venvs/emea/lib/python3.7/site.py", line 791, in <module>
    main()
  File "/home/abhijeet/rohan/venvs/emea/lib/python3.7/site.py", line 768, in main
    paths_in_sys = addsitepackages(paths_in_sys)
  File "/home/abhijeet/rohan/venvs/emea/lib/python3.7/site.py", line 280, in addsitepackages
    addsitedir(sitedir, known_paths)
  File "/home/abhijeet/rohan/venvs/emea/lib/python3.7/site.py", line 211, in addsitedir
    addpackage(sitedir, name, known_paths)
  File "/home/abhijeet/rohan/venvs/emea/lib/python3.7/site.py", line 175, in addpackage
    for line in f:
  File "/home/abhijeet/rohan/venvs/emea/lib/python3.7/codecs.py", line 319, in decode
    def decode(self, input, final=False):
KeyboardInterrupt
Command exited with non-zero status 1
0.00user 0.01system 0:00.02elapsed 96%CPU (0avgtext+0avgdata 8840maxresident)k
72inputs+8outputs (0major+870minor)pagefaults 0swaps
PyTorch version 1.9.0+cu102 available.
11/21/2021 13:14:59 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:14:59 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/21/2021 13:14:59 - INFO - __main__ -   Seed = 1
11/21/2021 13:14:59 - INFO - root -   save model
11/21/2021 13:14:59 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:14:59 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/21/2021 13:15:01 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/21/2021 13:15:07 - INFO - __main__ -   Using lang2id = None
11/21/2021 13:15:07 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/21/2021 13:15:07 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
11/21/2021 13:15:07 - INFO - root -   Trying to decide if add adapter
11/21/2021 13:15:07 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_model_head.bin
11/21/2021 13:15:07 - INFO - root -   loading lang adpater hi/wiki@ukp
11/21/2021 13:15:07 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/21/2021 13:15:07 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/21/2021 13:15:07 - INFO - __main__ -   Language = hi
11/21/2021 13:15:07 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/21/2021 13:15:11 - INFO - __main__ -   Language adapter for de not found, using hi instead
11/21/2021 13:15:11 - INFO - __main__ -   Set active language adapter to hi
11/21/2021 13:15:11 - INFO - __main__ -   Args Adapter Weight = None
11/21/2021 13:15:11 - INFO - __main__ -   Adapter Languages = ['hi']
11/21/2021 13:15:11 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_de_bert-base-multilingual-cased_128
11/21/2021 13:15:14 - INFO - __main__ -   ***** Running evaluation  in de *****
11/21/2021 13:15:14 - INFO - __main__ -     Num examples = 22360
11/21/2021 13:15:14 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/699 [00:00<?, ?it/s]11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/699 [00:00<01:46,  6.53it/s]11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 2
Evaluating:   0%|          | 2/699 [00:00<01:43,  6.75it/s]11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 3
Evaluating:   0%|          | 3/699 [00:00<01:39,  6.96it/s]11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/699 [00:00<01:37,  7.14it/s]11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 5
Evaluating:   1%|          | 5/699 [00:00<01:36,  7.22it/s]11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 6
Evaluating:   1%|          | 6/699 [00:00<01:35,  7.28it/s]11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 7
Evaluating:   1%|          | 7/699 [00:00<01:34,  7.30it/s]11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 8
Evaluating:   1%|          | 8/699 [00:01<01:34,  7.30it/s]11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 9
Evaluating:   1%|▏         | 9/699 [00:01<01:34,  7.30it/s]11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 10
Evaluating:   1%|▏         | 10/699 [00:01<01:34,  7.32it/s]11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 11
Evaluating:   2%|▏         | 11/699 [00:01<01:34,  7.31it/s]11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 12
Evaluating:   2%|▏         | 12/699 [00:01<01:33,  7.33it/s]11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 13
Evaluating:   2%|▏         | 13/699 [00:01<01:33,  7.33it/s]11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 14
Evaluating:   2%|▏         | 14/699 [00:01<01:33,  7.34it/s]11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 15
Evaluating:   2%|▏         | 15/699 [00:02<01:33,  7.34it/s]11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 16
Evaluating:   2%|▏         | 16/699 [00:02<01:33,  7.31it/s]11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 17
Evaluating:   2%|▏         | 17/699 [00:02<01:33,  7.32it/s]11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 18
Evaluating:   3%|▎         | 18/699 [00:02<01:33,  7.32it/s]11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 19
Evaluating:   3%|▎         | 19/699 [00:02<01:32,  7.34it/s]11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 20
Evaluating:   3%|▎         | 20/699 [00:02<01:32,  7.34it/s]11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 21
Evaluating:   3%|▎         | 21/699 [00:02<01:32,  7.34it/s]11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 22
Evaluating:   3%|▎         | 22/699 [00:03<01:32,  7.33it/s]11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 23
Evaluating:   3%|▎         | 23/699 [00:03<01:32,  7.33it/s]11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 24
Evaluating:   3%|▎         | 24/699 [00:03<01:32,  7.29it/s]11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 25
Evaluating:   4%|▎         | 25/699 [00:03<01:32,  7.25it/s]11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 26
Evaluating:   4%|▎         | 26/699 [00:03<01:33,  7.23it/s]11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 27
Evaluating:   4%|▍         | 27/699 [00:03<01:32,  7.26it/s]11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 28
Evaluating:   4%|▍         | 28/699 [00:03<01:32,  7.28it/s]11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 29
Evaluating:   4%|▍         | 29/699 [00:03<01:32,  7.25it/s]11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 30
Evaluating:   4%|▍         | 30/699 [00:04<01:33,  7.19it/s]11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 31
Evaluating:   4%|▍         | 31/699 [00:04<01:32,  7.19it/s]11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 32
Evaluating:   5%|▍         | 32/699 [00:04<01:32,  7.22it/s]11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 33
Evaluating:   5%|▍         | 33/699 [00:04<01:32,  7.22it/s]11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 34
Evaluating:   5%|▍         | 34/699 [00:04<01:32,  7.22it/s]11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 35
Evaluating:   5%|▌         | 35/699 [00:04<01:32,  7.21it/s]11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 36
Evaluating:   5%|▌         | 36/699 [00:04<01:31,  7.22it/s]11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 37
Evaluating:   5%|▌         | 37/699 [00:05<01:31,  7.22it/s]11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 38
Evaluating:   5%|▌         | 38/699 [00:05<01:31,  7.23it/s]11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 39
Evaluating:   6%|▌         | 39/699 [00:05<01:31,  7.22it/s]11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 40
Evaluating:   6%|▌         | 40/699 [00:05<01:31,  7.23it/s]11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 41
Evaluating:   6%|▌         | 41/699 [00:05<01:30,  7.23it/s]11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 42
Evaluating:   6%|▌         | 42/699 [00:05<01:30,  7.24it/s]11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 43
Evaluating:   6%|▌         | 43/699 [00:05<01:31,  7.16it/s]11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 44
Evaluating:   6%|▋         | 44/699 [00:06<01:32,  7.06it/s]11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 45
Evaluating:   6%|▋         | 45/699 [00:06<01:33,  7.00it/s]11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 46
Evaluating:   7%|▋         | 46/699 [00:06<01:32,  7.04it/s]11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 47
Evaluating:   7%|▋         | 47/699 [00:06<01:31,  7.09it/s]11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 48
Evaluating:   7%|▋         | 48/699 [00:06<01:31,  7.11it/s]11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 49
Evaluating:   7%|▋         | 49/699 [00:06<01:31,  7.13it/s]11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 50
Evaluating:   7%|▋         | 50/699 [00:06<01:30,  7.15it/s]11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 51
Evaluating:   7%|▋         | 51/699 [00:07<01:30,  7.16it/s]11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 52
Evaluating:   7%|▋         | 52/699 [00:07<01:30,  7.16it/s]11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 53
Evaluating:   8%|▊         | 53/699 [00:07<01:30,  7.10it/s]11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 54
Evaluating:   8%|▊         | 54/699 [00:07<01:31,  7.02it/s]11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 55
Evaluating:   8%|▊         | 55/699 [00:07<01:31,  7.02it/s]11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 56
Evaluating:   8%|▊         | 56/699 [00:07<01:31,  7.06it/s]11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 57
Evaluating:   8%|▊         | 57/699 [00:07<01:30,  7.08it/s]11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 58
Evaluating:   8%|▊         | 58/699 [00:08<01:30,  7.08it/s]11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 59
Evaluating:   8%|▊         | 59/699 [00:08<01:29,  7.11it/s]11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 60
Evaluating:   9%|▊         | 60/699 [00:08<01:29,  7.12it/s]11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 61
Evaluating:   9%|▊         | 61/699 [00:08<01:29,  7.12it/s]11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 62
Evaluating:   9%|▉         | 62/699 [00:08<01:29,  7.13it/s]11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 63
Evaluating:   9%|▉         | 63/699 [00:08<01:29,  7.13it/s]11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 64
Evaluating:   9%|▉         | 64/699 [00:08<01:29,  7.12it/s]11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 65
Evaluating:   9%|▉         | 65/699 [00:09<01:28,  7.13it/s]11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 66
Evaluating:   9%|▉         | 66/699 [00:09<01:28,  7.14it/s]11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 67
Evaluating:  10%|▉         | 67/699 [00:09<01:29,  7.07it/s]11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 68
Evaluating:  10%|▉         | 68/699 [00:09<01:29,  7.01it/s]11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 69
Evaluating:  10%|▉         | 69/699 [00:09<01:29,  7.05it/s]11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 70
Evaluating:  10%|█         | 70/699 [00:09<01:29,  7.03it/s]11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 71
Evaluating:  10%|█         | 71/699 [00:09<01:29,  7.05it/s]11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 72
Evaluating:  10%|█         | 72/699 [00:10<01:28,  7.07it/s]11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 73
Evaluating:  10%|█         | 73/699 [00:10<01:28,  7.06it/s]11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 74
Evaluating:  11%|█         | 74/699 [00:10<01:28,  7.07it/s]11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 75
Evaluating:  11%|█         | 75/699 [00:10<01:28,  7.07it/s]11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 76
Evaluating:  11%|█         | 76/699 [00:10<01:28,  7.06it/s]11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 77
Evaluating:  11%|█         | 77/699 [00:10<01:27,  7.07it/s]11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 78
Evaluating:  11%|█         | 78/699 [00:10<01:27,  7.08it/s]11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 79
Evaluating:  11%|█▏        | 79/699 [00:11<01:37,  6.39it/s]11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 80
Evaluating:  11%|█▏        | 80/699 [00:11<01:34,  6.58it/s]11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 81
Evaluating:  12%|█▏        | 81/699 [00:11<01:31,  6.73it/s]11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 82
Evaluating:  12%|█▏        | 82/699 [00:11<01:30,  6.83it/s]11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 83
Evaluating:  12%|█▏        | 83/699 [00:11<01:29,  6.91it/s]11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 84
Evaluating:  12%|█▏        | 84/699 [00:11<01:28,  6.95it/s]11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 85
Evaluating:  12%|█▏        | 85/699 [00:11<01:28,  6.97it/s]11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 86
Evaluating:  12%|█▏        | 86/699 [00:12<01:27,  6.99it/s]11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 87
Evaluating:  12%|█▏        | 87/699 [00:12<01:27,  7.01it/s]11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 88
Evaluating:  13%|█▎        | 88/699 [00:12<01:27,  7.01it/s]11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 89
Evaluating:  13%|█▎        | 89/699 [00:12<01:26,  7.02it/s]11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 90
Evaluating:  13%|█▎        | 90/699 [00:12<01:26,  7.02it/s]11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 91
Evaluating:  13%|█▎        | 91/699 [00:12<01:26,  7.02it/s]11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 92
Evaluating:  13%|█▎        | 92/699 [00:12<01:26,  7.03it/s]11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 93
Evaluating:  13%|█▎        | 93/699 [00:13<01:27,  6.95it/s]11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 94
Evaluating:  13%|█▎        | 94/699 [00:13<01:28,  6.87it/s]11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 95
Evaluating:  14%|█▎        | 95/699 [00:13<01:27,  6.87it/s]11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 96
Evaluating:  14%|█▎        | 96/699 [00:13<01:28,  6.85it/s]11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 97
Evaluating:  14%|█▍        | 97/699 [00:13<01:28,  6.84it/s]11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 98
Evaluating:  14%|█▍        | 98/699 [00:13<01:28,  6.82it/s]11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 99
Evaluating:  14%|█▍        | 99/699 [00:13<01:28,  6.81it/s]11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 100
Evaluating:  14%|█▍        | 100/699 [00:14<01:28,  6.80it/s]11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 101
Evaluating:  14%|█▍        | 101/699 [00:14<01:27,  6.80it/s]11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 102
Evaluating:  15%|█▍        | 102/699 [00:14<01:27,  6.80it/s]11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 103
Evaluating:  15%|█▍        | 103/699 [00:14<01:27,  6.79it/s]11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 104
Evaluating:  15%|█▍        | 104/699 [00:14<01:28,  6.76it/s]11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 105
Evaluating:  15%|█▌        | 105/699 [00:14<01:28,  6.75it/s]11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 106
Evaluating:  15%|█▌        | 106/699 [00:14<01:28,  6.74it/s]11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 107
Evaluating:  15%|█▌        | 107/699 [00:15<01:27,  6.74it/s]11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 108
Evaluating:  15%|█▌        | 108/699 [00:15<01:27,  6.74it/s]11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 109
Evaluating:  16%|█▌        | 109/699 [00:15<01:27,  6.72it/s]11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 110
Evaluating:  16%|█▌        | 110/699 [00:15<01:28,  6.64it/s]11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 111
Evaluating:  16%|█▌        | 111/699 [00:15<01:29,  6.58it/s]11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 112
Evaluating:  16%|█▌        | 112/699 [00:15<01:28,  6.60it/s]11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 113
Evaluating:  16%|█▌        | 113/699 [00:16<01:33,  6.27it/s]11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 114
Evaluating:  16%|█▋        | 114/699 [00:16<01:34,  6.21it/s]11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 115
Evaluating:  16%|█▋        | 115/699 [00:16<01:34,  6.20it/s]11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 116
Evaluating:  17%|█▋        | 116/699 [00:16<01:33,  6.24it/s]11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 117
Evaluating:  17%|█▋        | 117/699 [00:16<01:32,  6.31it/s]11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 118
Evaluating:  17%|█▋        | 118/699 [00:16<01:31,  6.35it/s]11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 119
Evaluating:  17%|█▋        | 119/699 [00:17<01:30,  6.43it/s]11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 120
Evaluating:  17%|█▋        | 120/699 [00:17<01:28,  6.52it/s]11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 121
Evaluating:  17%|█▋        | 121/699 [00:17<01:28,  6.56it/s]11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 122
Evaluating:  17%|█▋        | 122/699 [00:17<01:27,  6.59it/s]11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 123
Evaluating:  18%|█▊        | 123/699 [00:17<01:27,  6.61it/s]11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 124
Evaluating:  18%|█▊        | 124/699 [00:17<01:26,  6.62it/s]11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 125
Evaluating:  18%|█▊        | 125/699 [00:17<01:26,  6.63it/s]11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 126
Evaluating:  18%|█▊        | 126/699 [00:18<01:26,  6.61it/s]11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 127
Evaluating:  18%|█▊        | 127/699 [00:18<01:26,  6.61it/s]11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 128
Evaluating:  18%|█▊        | 128/699 [00:18<01:26,  6.61it/s]11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 129
Evaluating:  18%|█▊        | 129/699 [00:18<01:26,  6.62it/s]11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 130
Evaluating:  19%|█▊        | 130/699 [00:18<01:26,  6.61it/s]11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 131
Evaluating:  19%|█▊        | 131/699 [00:18<01:25,  6.61it/s]11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 132
Evaluating:  19%|█▉        | 132/699 [00:18<01:25,  6.61it/s]11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 133
Evaluating:  19%|█▉        | 133/699 [00:19<01:25,  6.59it/s]11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 134
Evaluating:  19%|█▉        | 134/699 [00:19<01:26,  6.51it/s]11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 135
Evaluating:  19%|█▉        | 135/699 [00:19<01:27,  6.47it/s]11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 136
Evaluating:  19%|█▉        | 136/699 [00:19<01:26,  6.48it/s]11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 137
Evaluating:  20%|█▉        | 137/699 [00:19<01:26,  6.49it/s]11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 138
Evaluating:  20%|█▉        | 138/699 [00:19<01:27,  6.38it/s]11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 139
Evaluating:  20%|█▉        | 139/699 [00:20<01:28,  6.32it/s]11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 140
Evaluating:  20%|██        | 140/699 [00:20<01:27,  6.35it/s]11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 141
Evaluating:  20%|██        | 141/699 [00:20<01:27,  6.37it/s]11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 142
Evaluating:  20%|██        | 142/699 [00:20<01:26,  6.42it/s]11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 143
Evaluating:  20%|██        | 143/699 [00:20<01:26,  6.45it/s]11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 144
Evaluating:  21%|██        | 144/699 [00:20<01:25,  6.48it/s]11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 145
Evaluating:  21%|██        | 145/699 [00:20<01:25,  6.50it/s]11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 146
Evaluating:  21%|██        | 146/699 [00:21<01:24,  6.51it/s]11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 147
Evaluating:  21%|██        | 147/699 [00:21<01:24,  6.50it/s]11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 148
Evaluating:  21%|██        | 148/699 [00:21<01:24,  6.50it/s]11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 149
Evaluating:  21%|██▏       | 149/699 [00:21<01:24,  6.50it/s]11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 150
Evaluating:  21%|██▏       | 150/699 [00:21<01:24,  6.50it/s]11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 151
Evaluating:  22%|██▏       | 151/699 [00:21<01:24,  6.50it/s]11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 152
Evaluating:  22%|██▏       | 152/699 [00:22<01:24,  6.49it/s]11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 153
Evaluating:  22%|██▏       | 153/699 [00:22<01:24,  6.50it/s]11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 154
Evaluating:  22%|██▏       | 154/699 [00:22<01:23,  6.51it/s]11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 155
Evaluating:  22%|██▏       | 155/699 [00:22<01:23,  6.50it/s]11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 156
Evaluating:  22%|██▏       | 156/699 [00:22<01:23,  6.50it/s]11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 157
Evaluating:  22%|██▏       | 157/699 [00:22<01:23,  6.49it/s]11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 158
Evaluating:  23%|██▎       | 158/699 [00:22<01:23,  6.48it/s]11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 159
Evaluating:  23%|██▎       | 159/699 [00:23<01:23,  6.47it/s]11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 160
Evaluating:  23%|██▎       | 160/699 [00:23<01:23,  6.47it/s]11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 161
Evaluating:  23%|██▎       | 161/699 [00:23<01:23,  6.47it/s]11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 162
Evaluating:  23%|██▎       | 162/699 [00:23<01:23,  6.45it/s]11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 163
Evaluating:  23%|██▎       | 163/699 [00:23<01:23,  6.44it/s]11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 164
Evaluating:  23%|██▎       | 164/699 [00:23<01:23,  6.43it/s]11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 165
Evaluating:  24%|██▎       | 165/699 [00:24<01:22,  6.44it/s]11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 166
Evaluating:  24%|██▎       | 166/699 [00:24<01:22,  6.44it/s]11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 167
Evaluating:  24%|██▍       | 167/699 [00:24<01:24,  6.31it/s]11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 168
Evaluating:  24%|██▍       | 168/699 [00:24<01:24,  6.26it/s]11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 169
Evaluating:  24%|██▍       | 169/699 [00:24<01:24,  6.28it/s]11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 170
Evaluating:  24%|██▍       | 170/699 [00:24<01:23,  6.32it/s]11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 171
Evaluating:  24%|██▍       | 171/699 [00:25<01:23,  6.34it/s]11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 172
Evaluating:  25%|██▍       | 172/699 [00:25<01:23,  6.34it/s]11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 173
Evaluating:  25%|██▍       | 173/699 [00:25<01:22,  6.35it/s]11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 174
Evaluating:  25%|██▍       | 174/699 [00:25<01:22,  6.35it/s]11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 175
Evaluating:  25%|██▌       | 175/699 [00:25<01:22,  6.34it/s]11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 176
Evaluating:  25%|██▌       | 176/699 [00:25<01:23,  6.29it/s]11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 177
Evaluating:  25%|██▌       | 177/699 [00:25<01:23,  6.24it/s]11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 178
Evaluating:  25%|██▌       | 178/699 [00:26<01:23,  6.27it/s]11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 179
Evaluating:  26%|██▌       | 179/699 [00:26<01:22,  6.28it/s]11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 180
Evaluating:  26%|██▌       | 180/699 [00:26<01:23,  6.24it/s]11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 181
Evaluating:  26%|██▌       | 181/699 [00:26<01:23,  6.24it/s]11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 182
Evaluating:  26%|██▌       | 182/699 [00:26<01:22,  6.28it/s]11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 183
Evaluating:  26%|██▌       | 183/699 [00:26<01:21,  6.30it/s]11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 184
Evaluating:  26%|██▋       | 184/699 [00:27<01:21,  6.31it/s]11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 185
Evaluating:  26%|██▋       | 185/699 [00:27<01:21,  6.30it/s]11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 186
Evaluating:  27%|██▋       | 186/699 [00:27<01:21,  6.29it/s]11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 187
Evaluating:  27%|██▋       | 187/699 [00:27<01:21,  6.31it/s]11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 188
Evaluating:  27%|██▋       | 188/699 [00:27<01:21,  6.30it/s]11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 189
Evaluating:  27%|██▋       | 189/699 [00:27<01:20,  6.31it/s]11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 190
Evaluating:  27%|██▋       | 190/699 [00:28<01:20,  6.31it/s]11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 191
Evaluating:  27%|██▋       | 191/699 [00:28<01:20,  6.31it/s]11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 192
Evaluating:  27%|██▋       | 192/699 [00:28<01:20,  6.30it/s]11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 193
Evaluating:  28%|██▊       | 193/699 [00:28<01:20,  6.30it/s]11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 194
Evaluating:  28%|██▊       | 194/699 [00:28<01:20,  6.29it/s]11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 195
Evaluating:  28%|██▊       | 195/699 [00:28<01:19,  6.30it/s]11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 196
Evaluating:  28%|██▊       | 196/699 [00:29<01:19,  6.30it/s]11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 197
Evaluating:  28%|██▊       | 197/699 [00:29<01:20,  6.27it/s]11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 198
Evaluating:  28%|██▊       | 198/699 [00:29<01:21,  6.12it/s]11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 199
Evaluating:  28%|██▊       | 199/699 [00:29<01:22,  6.04it/s]11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 200
Evaluating:  29%|██▊       | 200/699 [00:29<01:22,  6.06it/s]11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 201
Evaluating:  29%|██▉       | 201/699 [00:29<01:21,  6.10it/s]11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 202
Evaluating:  29%|██▉       | 202/699 [00:30<01:21,  6.13it/s]11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 203
Evaluating:  29%|██▉       | 203/699 [00:30<01:22,  6.05it/s]11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 204
Evaluating:  29%|██▉       | 204/699 [00:30<01:22,  6.02it/s]11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 205
Evaluating:  29%|██▉       | 205/699 [00:30<01:21,  6.08it/s]11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 206
Evaluating:  29%|██▉       | 206/699 [00:30<01:20,  6.11it/s]11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 207
Evaluating:  30%|██▉       | 207/699 [00:30<01:20,  6.15it/s]11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 208
Evaluating:  30%|██▉       | 208/699 [00:30<01:20,  6.13it/s]11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 209
Evaluating:  30%|██▉       | 209/699 [00:31<01:19,  6.15it/s]11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 210
Evaluating:  30%|███       | 210/699 [00:31<01:19,  6.16it/s]11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 211
Evaluating:  30%|███       | 211/699 [00:31<01:19,  6.16it/s]11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 212
Evaluating:  30%|███       | 212/699 [00:31<01:19,  6.16it/s]11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 213
Evaluating:  30%|███       | 213/699 [00:31<01:20,  6.02it/s]11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 214
Evaluating:  31%|███       | 214/699 [00:31<01:21,  5.95it/s]11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 215
Evaluating:  31%|███       | 215/699 [00:32<01:21,  5.96it/s]11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 216
Evaluating:  31%|███       | 216/699 [00:32<01:20,  5.99it/s]11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 217
Evaluating:  31%|███       | 217/699 [00:32<01:19,  6.04it/s]11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 218
Evaluating:  31%|███       | 218/699 [00:32<01:19,  6.09it/s]11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 219
Evaluating:  31%|███▏      | 219/699 [00:32<01:18,  6.11it/s]11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 220
Evaluating:  31%|███▏      | 220/699 [00:32<01:18,  6.12it/s]11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 221
Evaluating:  32%|███▏      | 221/699 [00:33<01:17,  6.16it/s]11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 222
Evaluating:  32%|███▏      | 222/699 [00:33<01:17,  6.13it/s]11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 223
Evaluating:  32%|███▏      | 223/699 [00:33<01:17,  6.11it/s]11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 224
Evaluating:  32%|███▏      | 224/699 [00:33<01:17,  6.13it/s]11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 225
Evaluating:  32%|███▏      | 225/699 [00:33<01:17,  6.13it/s]11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 226
Evaluating:  32%|███▏      | 226/699 [00:33<01:17,  6.13it/s]11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 227
Evaluating:  32%|███▏      | 227/699 [00:34<01:17,  6.13it/s]11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 228
Evaluating:  33%|███▎      | 228/699 [00:34<01:17,  6.09it/s]11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 229
Evaluating:  33%|███▎      | 229/699 [00:34<01:17,  6.10it/s]11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 230
Evaluating:  33%|███▎      | 230/699 [00:34<01:16,  6.11it/s]11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 231
Evaluating:  33%|███▎      | 231/699 [00:34<01:16,  6.09it/s]11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 232
Evaluating:  33%|███▎      | 232/699 [00:34<01:16,  6.09it/s]11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 233
Evaluating:  33%|███▎      | 233/699 [00:35<01:16,  6.10it/s]11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 234
Evaluating:  33%|███▎      | 234/699 [00:35<01:16,  6.07it/s]11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 235
Evaluating:  34%|███▎      | 235/699 [00:35<01:16,  6.06it/s]11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 236
Evaluating:  34%|███▍      | 236/699 [00:35<01:16,  6.07it/s]11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 237
Evaluating:  34%|███▍      | 237/699 [00:35<01:16,  6.07it/s]11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 238
Evaluating:  34%|███▍      | 238/699 [00:35<01:16,  6.04it/s]11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 239
Evaluating:  34%|███▍      | 239/699 [00:36<01:17,  5.95it/s]11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 240
Evaluating:  34%|███▍      | 240/699 [00:36<01:16,  5.99it/s]11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 241
Evaluating:  34%|███▍      | 241/699 [00:36<01:16,  6.00it/s]11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 242
Evaluating:  35%|███▍      | 242/699 [00:36<01:15,  6.02it/s]11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 243
Evaluating:  35%|███▍      | 243/699 [00:36<01:15,  6.00it/s]11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 244
Evaluating:  35%|███▍      | 244/699 [00:36<01:17,  5.89it/s]11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 245
Evaluating:  35%|███▌      | 245/699 [00:37<01:18,  5.82it/s]11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 246
Evaluating:  35%|███▌      | 246/699 [00:37<01:17,  5.82it/s]11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 247
Evaluating:  35%|███▌      | 247/699 [00:37<01:17,  5.86it/s]11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 248
Evaluating:  35%|███▌      | 248/699 [00:37<01:16,  5.91it/s]11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 249
Evaluating:  36%|███▌      | 249/699 [00:37<01:15,  5.93it/s]11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 250
Evaluating:  36%|███▌      | 250/699 [00:37<01:16,  5.84it/s]11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 251
Evaluating:  36%|███▌      | 251/699 [00:38<01:16,  5.87it/s]11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 252
Evaluating:  36%|███▌      | 252/699 [00:38<01:15,  5.89it/s]11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 253
Evaluating:  36%|███▌      | 253/699 [00:38<01:15,  5.93it/s]11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 254
Evaluating:  36%|███▋      | 254/699 [00:38<01:14,  5.97it/s]11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 255
Evaluating:  36%|███▋      | 255/699 [00:38<01:14,  5.98it/s]11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 256
Evaluating:  37%|███▋      | 256/699 [00:38<01:15,  5.86it/s]11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 257
Evaluating:  37%|███▋      | 257/699 [00:39<01:15,  5.87it/s]11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 258
Evaluating:  37%|███▋      | 258/699 [00:39<01:14,  5.91it/s]11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 259
Evaluating:  37%|███▋      | 259/699 [00:39<01:14,  5.93it/s]11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 260
Evaluating:  37%|███▋      | 260/699 [00:39<01:13,  5.96it/s]11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 261
Evaluating:  37%|███▋      | 261/699 [00:39<01:13,  5.96it/s]11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 262
Evaluating:  37%|███▋      | 262/699 [00:39<01:13,  5.97it/s]11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 263
Evaluating:  38%|███▊      | 263/699 [00:40<01:12,  5.98it/s]11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 264
Evaluating:  38%|███▊      | 264/699 [00:40<01:12,  5.98it/s]11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 265
Evaluating:  38%|███▊      | 265/699 [00:40<01:12,  5.98it/s]11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 266
Evaluating:  38%|███▊      | 266/699 [00:40<01:12,  5.95it/s]11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 267
Evaluating:  38%|███▊      | 267/699 [00:40<01:14,  5.82it/s]11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 268
Evaluating:  38%|███▊      | 268/699 [00:41<01:14,  5.77it/s]11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 269
Evaluating:  38%|███▊      | 269/699 [00:41<01:14,  5.80it/s]11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 270
Evaluating:  39%|███▊      | 270/699 [00:41<01:13,  5.84it/s]11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 271
Evaluating:  39%|███▉      | 271/699 [00:41<01:13,  5.86it/s]11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 272
Evaluating:  39%|███▉      | 272/699 [00:41<01:12,  5.87it/s]11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 273
Evaluating:  39%|███▉      | 273/699 [00:41<01:13,  5.78it/s]11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 274
Evaluating:  39%|███▉      | 274/699 [00:42<01:14,  5.73it/s]11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 275
Evaluating:  39%|███▉      | 275/699 [00:42<01:13,  5.74it/s]11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 276
Evaluating:  39%|███▉      | 276/699 [00:42<01:13,  5.78it/s]11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 277
Evaluating:  40%|███▉      | 277/699 [00:42<01:12,  5.83it/s]11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 278
Evaluating:  40%|███▉      | 278/699 [00:42<01:11,  5.87it/s]11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 279
Evaluating:  40%|███▉      | 279/699 [00:42<01:11,  5.88it/s]11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 280
Evaluating:  40%|████      | 280/699 [00:43<01:11,  5.88it/s]11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 281
Evaluating:  40%|████      | 281/699 [00:43<01:10,  5.90it/s]11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 282
Evaluating:  40%|████      | 282/699 [00:43<01:10,  5.90it/s]11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 283
Evaluating:  40%|████      | 283/699 [00:43<01:10,  5.89it/s]11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 284
Evaluating:  41%|████      | 284/699 [00:43<01:10,  5.88it/s]11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 285
Evaluating:  41%|████      | 285/699 [00:43<01:11,  5.78it/s]11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 286
Evaluating:  41%|████      | 286/699 [00:44<01:12,  5.69it/s]11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 287
Evaluating:  41%|████      | 287/699 [00:44<01:12,  5.65it/s]11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 288
Evaluating:  41%|████      | 288/699 [00:44<01:12,  5.68it/s]11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 289
Evaluating:  41%|████▏     | 289/699 [00:44<01:11,  5.73it/s]11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 290
Evaluating:  41%|████▏     | 290/699 [00:44<01:10,  5.78it/s]11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 291
Evaluating:  42%|████▏     | 291/699 [00:44<01:10,  5.78it/s]11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 292
Evaluating:  42%|████▏     | 292/699 [00:45<01:11,  5.71it/s]11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 293
Evaluating:  42%|████▏     | 293/699 [00:45<01:11,  5.67it/s]11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 294
Evaluating:  42%|████▏     | 294/699 [00:45<01:11,  5.68it/s]11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 295
Evaluating:  42%|████▏     | 295/699 [00:45<01:10,  5.71it/s]11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 296
Evaluating:  42%|████▏     | 296/699 [00:45<01:09,  5.76it/s]11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 297
Evaluating:  42%|████▏     | 297/699 [00:46<01:09,  5.75it/s]11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 298
Evaluating:  43%|████▎     | 298/699 [00:46<01:09,  5.75it/s]11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 299
Evaluating:  43%|████▎     | 299/699 [00:46<01:10,  5.67it/s]11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 300
Evaluating:  43%|████▎     | 300/699 [00:46<01:10,  5.62it/s]11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 301
Evaluating:  43%|████▎     | 301/699 [00:46<01:10,  5.64it/s]11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 302
Evaluating:  43%|████▎     | 302/699 [00:46<01:09,  5.69it/s]11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 303
Evaluating:  43%|████▎     | 303/699 [00:47<01:09,  5.74it/s]11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 304
Evaluating:  43%|████▎     | 304/699 [00:47<01:08,  5.75it/s]11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 305
Evaluating:  44%|████▎     | 305/699 [00:47<01:08,  5.76it/s]11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 306
Evaluating:  44%|████▍     | 306/699 [00:47<01:09,  5.64it/s]11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 307
Evaluating:  44%|████▍     | 307/699 [00:47<01:09,  5.62it/s]11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 308
Evaluating:  44%|████▍     | 308/699 [00:47<01:09,  5.67it/s]11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 309
Evaluating:  44%|████▍     | 309/699 [00:48<01:08,  5.69it/s]11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 310
Evaluating:  44%|████▍     | 310/699 [00:48<01:07,  5.73it/s]11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 311
Evaluating:  44%|████▍     | 311/699 [00:48<01:07,  5.76it/s]11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 312
Evaluating:  45%|████▍     | 312/699 [00:48<01:07,  5.74it/s]11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 313
Evaluating:  45%|████▍     | 313/699 [00:48<01:08,  5.62it/s]11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 314
Evaluating:  45%|████▍     | 314/699 [00:49<01:08,  5.62it/s]11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 315
Evaluating:  45%|████▌     | 315/699 [00:49<01:08,  5.63it/s]11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 316
Evaluating:  45%|████▌     | 316/699 [00:49<01:07,  5.66it/s]11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 317
Evaluating:  45%|████▌     | 317/699 [00:49<01:07,  5.70it/s]11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 318
Evaluating:  45%|████▌     | 318/699 [00:49<01:06,  5.72it/s]11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 319
Evaluating:  46%|████▌     | 319/699 [00:49<01:06,  5.73it/s]11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 320
Evaluating:  46%|████▌     | 320/699 [00:50<01:06,  5.71it/s]11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 321
Evaluating:  46%|████▌     | 321/699 [00:50<01:06,  5.68it/s]11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 322
Evaluating:  46%|████▌     | 322/699 [00:50<01:06,  5.68it/s]11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 323
Evaluating:  46%|████▌     | 323/699 [00:50<01:05,  5.71it/s]11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 324
Evaluating:  46%|████▋     | 324/699 [00:50<01:05,  5.72it/s]11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 325
Evaluating:  46%|████▋     | 325/699 [00:50<01:05,  5.73it/s]11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 326
Evaluating:  47%|████▋     | 326/699 [00:51<01:05,  5.72it/s]11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 327
Evaluating:  47%|████▋     | 327/699 [00:51<01:06,  5.60it/s]11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 328
Evaluating:  47%|████▋     | 328/699 [00:51<01:06,  5.55it/s]11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 329
Evaluating:  47%|████▋     | 329/699 [00:51<01:06,  5.57it/s]11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 330
Evaluating:  47%|████▋     | 330/699 [00:51<01:05,  5.61it/s]11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 331
Evaluating:  47%|████▋     | 331/699 [00:52<01:05,  5.64it/s]11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 332
Evaluating:  47%|████▋     | 332/699 [00:52<01:04,  5.67it/s]11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 333
Evaluating:  48%|████▊     | 333/699 [00:52<01:04,  5.68it/s]11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 334
Evaluating:  48%|████▊     | 334/699 [00:52<01:04,  5.66it/s]11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 335
Evaluating:  48%|████▊     | 335/699 [00:52<01:05,  5.57it/s]11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 336
Evaluating:  48%|████▊     | 336/699 [00:52<01:05,  5.53it/s]11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 337
Evaluating:  48%|████▊     | 337/699 [00:53<01:05,  5.55it/s]11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 338
Evaluating:  48%|████▊     | 338/699 [00:53<01:04,  5.60it/s]11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 339
Evaluating:  48%|████▊     | 339/699 [00:53<01:03,  5.63it/s]11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 340
Evaluating:  49%|████▊     | 340/699 [00:53<01:03,  5.64it/s]11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 341
Evaluating:  49%|████▉     | 341/699 [00:53<01:03,  5.65it/s]11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 342
Evaluating:  49%|████▉     | 342/699 [00:53<01:03,  5.63it/s]11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 343
Evaluating:  49%|████▉     | 343/699 [00:54<01:04,  5.52it/s]11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 344
Evaluating:  49%|████▉     | 344/699 [00:54<01:04,  5.53it/s]11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 345
Evaluating:  49%|████▉     | 345/699 [00:54<01:03,  5.57it/s]11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 346
Evaluating:  49%|████▉     | 346/699 [00:54<01:02,  5.61it/s]11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 347
Evaluating:  50%|████▉     | 347/699 [00:54<01:02,  5.64it/s]11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 348
Evaluating:  50%|████▉     | 348/699 [00:55<01:02,  5.65it/s]11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 349
Evaluating:  50%|████▉     | 349/699 [00:55<01:01,  5.65it/s]11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 350
Evaluating:  50%|█████     | 350/699 [00:55<01:02,  5.62it/s]11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 351
Evaluating:  50%|█████     | 351/699 [00:55<01:03,  5.51it/s]11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 352
Evaluating:  50%|█████     | 352/699 [00:55<01:03,  5.45it/s]11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 353
Evaluating:  51%|█████     | 353/699 [00:55<01:03,  5.49it/s]11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 354
Evaluating:  51%|█████     | 354/699 [00:56<01:03,  5.45it/s]11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 355
Evaluating:  51%|█████     | 355/699 [00:56<01:02,  5.48it/s]11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 356
Evaluating:  51%|█████     | 356/699 [00:56<01:01,  5.54it/s]11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 357
Evaluating:  51%|█████     | 357/699 [00:56<01:01,  5.55it/s]11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 358
Evaluating:  51%|█████     | 358/699 [00:56<01:01,  5.57it/s]11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 359
Evaluating:  51%|█████▏    | 359/699 [00:57<01:00,  5.58it/s]11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 360
Evaluating:  52%|█████▏    | 360/699 [00:57<01:00,  5.56it/s]11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 361
Evaluating:  52%|█████▏    | 361/699 [00:57<01:00,  5.56it/s]11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 362
Evaluating:  52%|█████▏    | 362/699 [00:57<01:00,  5.57it/s]11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 363
Evaluating:  52%|█████▏    | 363/699 [00:57<01:00,  5.57it/s]11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 364
Evaluating:  52%|█████▏    | 364/699 [00:57<00:59,  5.59it/s]11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 365
Evaluating:  52%|█████▏    | 365/699 [00:58<00:59,  5.60it/s]11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 366
Evaluating:  52%|█████▏    | 366/699 [00:58<00:59,  5.60it/s]11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 367
Evaluating:  53%|█████▎    | 367/699 [00:58<01:00,  5.49it/s]11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 368
Evaluating:  53%|█████▎    | 368/699 [00:58<01:01,  5.41it/s]11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 369
Evaluating:  53%|█████▎    | 369/699 [00:58<01:01,  5.35it/s]11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 370
Evaluating:  53%|█████▎    | 370/699 [00:59<01:01,  5.39it/s]11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 371
Evaluating:  53%|█████▎    | 371/699 [00:59<01:00,  5.46it/s]11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 372
Evaluating:  53%|█████▎    | 372/699 [00:59<00:59,  5.49it/s]11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 373
Evaluating:  53%|█████▎    | 373/699 [00:59<00:59,  5.50it/s]11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 374
Evaluating:  54%|█████▎    | 374/699 [00:59<00:58,  5.53it/s]11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 375
Evaluating:  54%|█████▎    | 375/699 [00:59<00:58,  5.54it/s]11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 376
Evaluating:  54%|█████▍    | 376/699 [01:00<00:58,  5.53it/s]11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 377
Evaluating:  54%|█████▍    | 377/699 [01:00<00:59,  5.43it/s]11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 378
Evaluating:  54%|█████▍    | 378/699 [01:00<00:59,  5.36it/s]11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 379
Evaluating:  54%|█████▍    | 379/699 [01:00<00:59,  5.37it/s]11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 380
Evaluating:  54%|█████▍    | 380/699 [01:00<00:58,  5.43it/s]11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 381
Evaluating:  55%|█████▍    | 381/699 [01:01<00:58,  5.47it/s]11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 382
Evaluating:  55%|█████▍    | 382/699 [01:01<00:57,  5.49it/s]11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 383
Evaluating:  55%|█████▍    | 383/699 [01:01<00:57,  5.50it/s]11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 384
Evaluating:  55%|█████▍    | 384/699 [01:01<00:57,  5.49it/s]11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 385
Evaluating:  55%|█████▌    | 385/699 [01:01<00:57,  5.49it/s]11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 386
Evaluating:  55%|█████▌    | 386/699 [01:01<00:57,  5.45it/s]11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 387
Evaluating:  55%|█████▌    | 387/699 [01:02<00:58,  5.32it/s]11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 388
Evaluating:  56%|█████▌    | 388/699 [01:02<00:58,  5.31it/s]11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 389
Evaluating:  56%|█████▌    | 389/699 [01:02<00:58,  5.33it/s]11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 390
Evaluating:  56%|█████▌    | 390/699 [01:02<00:57,  5.37it/s]11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 391
Evaluating:  56%|█████▌    | 391/699 [01:02<00:56,  5.40it/s]11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 392
Evaluating:  56%|█████▌    | 392/699 [01:03<00:56,  5.44it/s]11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 393
Evaluating:  56%|█████▌    | 393/699 [01:03<00:56,  5.46it/s]11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 394
Evaluating:  56%|█████▋    | 394/699 [01:03<00:55,  5.47it/s]11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 395
Evaluating:  57%|█████▋    | 395/699 [01:03<00:55,  5.49it/s]11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 396
Evaluating:  57%|█████▋    | 396/699 [01:03<00:55,  5.47it/s]11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 397
Evaluating:  57%|█████▋    | 397/699 [01:04<00:56,  5.36it/s]11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 398
Evaluating:  57%|█████▋    | 398/699 [01:04<00:56,  5.30it/s]11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 399
Evaluating:  57%|█████▋    | 399/699 [01:04<00:56,  5.31it/s]11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 400
Evaluating:  57%|█████▋    | 400/699 [01:04<00:55,  5.35it/s]11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 401
Evaluating:  57%|█████▋    | 401/699 [01:04<00:55,  5.39it/s]11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 402
Evaluating:  58%|█████▊    | 402/699 [01:04<00:54,  5.41it/s]11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 403
Evaluating:  58%|█████▊    | 403/699 [01:05<00:54,  5.43it/s]11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 404
Evaluating:  58%|█████▊    | 404/699 [01:05<00:54,  5.42it/s]11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 405
Evaluating:  58%|█████▊    | 405/699 [01:05<00:54,  5.43it/s]11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 406
Evaluating:  58%|█████▊    | 406/699 [01:05<00:53,  5.43it/s]11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 407
Evaluating:  58%|█████▊    | 407/699 [01:05<00:54,  5.36it/s]11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 408
Evaluating:  58%|█████▊    | 408/699 [01:06<00:55,  5.28it/s]11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 409
Evaluating:  59%|█████▊    | 409/699 [01:06<00:55,  5.22it/s]11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 410
Evaluating:  59%|█████▊    | 410/699 [01:06<00:55,  5.22it/s]11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 411
Evaluating:  59%|█████▉    | 411/699 [01:06<00:54,  5.26it/s]11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 412
Evaluating:  59%|█████▉    | 412/699 [01:06<00:54,  5.31it/s]11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 413
Evaluating:  59%|█████▉    | 413/699 [01:07<00:53,  5.36it/s]11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 414
Evaluating:  59%|█████▉    | 414/699 [01:07<00:52,  5.38it/s]11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 415
Evaluating:  59%|█████▉    | 415/699 [01:07<00:52,  5.38it/s]11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 416
Evaluating:  60%|█████▉    | 416/699 [01:07<00:52,  5.40it/s]11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 417
Evaluating:  60%|█████▉    | 417/699 [01:07<00:52,  5.41it/s]11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 418
Evaluating:  60%|█████▉    | 418/699 [01:07<00:51,  5.41it/s]11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 419
Evaluating:  60%|█████▉    | 419/699 [01:08<00:52,  5.31it/s]11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 420
Evaluating:  60%|██████    | 420/699 [01:08<00:53,  5.23it/s]11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 421
Evaluating:  60%|██████    | 421/699 [01:08<00:53,  5.18it/s]11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 422
Evaluating:  60%|██████    | 422/699 [01:08<00:53,  5.15it/s]11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 423
Evaluating:  61%|██████    | 423/699 [01:08<00:53,  5.13it/s]11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 424
Evaluating:  61%|██████    | 424/699 [01:09<00:53,  5.17it/s]11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 425
Evaluating:  61%|██████    | 425/699 [01:09<00:52,  5.24it/s]11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 426
Evaluating:  61%|██████    | 426/699 [01:09<00:51,  5.29it/s]11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 427
Evaluating:  61%|██████    | 427/699 [01:09<00:51,  5.32it/s]11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 428
Evaluating:  61%|██████    | 428/699 [01:09<00:50,  5.34it/s]11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 429
Evaluating:  61%|██████▏   | 429/699 [01:10<00:50,  5.35it/s]11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 430
Evaluating:  62%|██████▏   | 430/699 [01:10<00:50,  5.36it/s]11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 431
Evaluating:  62%|██████▏   | 431/699 [01:10<00:49,  5.37it/s]11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 432
Evaluating:  62%|██████▏   | 432/699 [01:10<00:49,  5.36it/s]11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 433
Evaluating:  62%|██████▏   | 433/699 [01:10<00:50,  5.25it/s]11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 434
Evaluating:  62%|██████▏   | 434/699 [01:10<00:51,  5.19it/s]11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 435
Evaluating:  62%|██████▏   | 435/699 [01:11<00:51,  5.13it/s]11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 436
Evaluating:  62%|██████▏   | 436/699 [01:11<00:51,  5.10it/s]11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 437
Evaluating:  63%|██████▎   | 437/699 [01:11<00:51,  5.08it/s]11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 438
Evaluating:  63%|██████▎   | 438/699 [01:11<00:51,  5.09it/s]11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 439
Evaluating:  63%|██████▎   | 439/699 [01:11<00:50,  5.12it/s]11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 440
Evaluating:  63%|██████▎   | 440/699 [01:12<00:49,  5.18it/s]11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 441
Evaluating:  63%|██████▎   | 441/699 [01:12<00:49,  5.22it/s]11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 442
Evaluating:  63%|██████▎   | 442/699 [01:12<00:48,  5.25it/s]11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 443
Evaluating:  63%|██████▎   | 443/699 [01:12<00:48,  5.29it/s]11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 444
Evaluating:  64%|██████▎   | 444/699 [01:12<00:48,  5.30it/s]11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 445
Evaluating:  64%|██████▎   | 445/699 [01:13<00:47,  5.30it/s]11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 446
Evaluating:  64%|██████▍   | 446/699 [01:13<00:47,  5.31it/s]11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 447
Evaluating:  64%|██████▍   | 447/699 [01:13<00:47,  5.29it/s]11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 448
Evaluating:  64%|██████▍   | 448/699 [01:13<00:47,  5.24it/s]11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 449
Evaluating:  64%|██████▍   | 449/699 [01:13<00:48,  5.17it/s]11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 450
Evaluating:  64%|██████▍   | 450/699 [01:14<00:48,  5.11it/s]11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 451
Evaluating:  65%|██████▍   | 451/699 [01:14<00:48,  5.07it/s]11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 452
Evaluating:  65%|██████▍   | 452/699 [01:14<00:48,  5.05it/s]11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 453
Evaluating:  65%|██████▍   | 453/699 [01:14<00:48,  5.03it/s]11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 454
Evaluating:  65%|██████▍   | 454/699 [01:14<00:48,  5.01it/s]11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 455
Evaluating:  65%|██████▌   | 455/699 [01:15<00:48,  5.00it/s]11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 456
Evaluating:  65%|██████▌   | 456/699 [01:15<00:48,  4.99it/s]11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 457
Evaluating:  65%|██████▌   | 457/699 [01:15<00:48,  4.98it/s]11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 458
Evaluating:  66%|██████▌   | 458/699 [01:15<00:48,  4.98it/s]11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 459
Evaluating:  66%|██████▌   | 459/699 [01:15<00:48,  4.97it/s]11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 460
Evaluating:  66%|██████▌   | 460/699 [01:16<00:47,  5.01it/s]11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 461
Evaluating:  66%|██████▌   | 461/699 [01:16<00:47,  5.05it/s]11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 462
Evaluating:  66%|██████▌   | 462/699 [01:16<00:46,  5.11it/s]11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 463
Evaluating:  66%|██████▌   | 463/699 [01:16<00:45,  5.16it/s]11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 464
Evaluating:  66%|██████▋   | 464/699 [01:16<00:45,  5.20it/s]11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 465
Evaluating:  67%|██████▋   | 465/699 [01:17<00:44,  5.21it/s]11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 466
Evaluating:  67%|██████▋   | 466/699 [01:17<00:44,  5.22it/s]11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 467
Evaluating:  67%|██████▋   | 467/699 [01:17<00:44,  5.24it/s]11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 468
Evaluating:  67%|██████▋   | 468/699 [01:17<00:44,  5.24it/s]11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 469
Evaluating:  67%|██████▋   | 469/699 [01:17<00:43,  5.23it/s]11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 470
Evaluating:  67%|██████▋   | 470/699 [01:17<00:43,  5.25it/s]11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 471
Evaluating:  67%|██████▋   | 471/699 [01:18<00:44,  5.15it/s]11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 472
Evaluating:  68%|██████▊   | 472/699 [01:18<00:44,  5.08it/s]11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 473
Evaluating:  68%|██████▊   | 473/699 [01:18<00:44,  5.03it/s]11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 474
Evaluating:  68%|██████▊   | 474/699 [01:18<00:45,  4.98it/s]11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 475
Evaluating:  68%|██████▊   | 475/699 [01:19<00:45,  4.94it/s]11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 476
Evaluating:  68%|██████▊   | 476/699 [01:19<00:45,  4.93it/s]11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 477
Evaluating:  68%|██████▊   | 477/699 [01:19<00:45,  4.92it/s]11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 478
Evaluating:  68%|██████▊   | 478/699 [01:19<00:44,  4.92it/s]11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 479
Evaluating:  69%|██████▊   | 479/699 [01:19<00:44,  4.94it/s]11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 480
Evaluating:  69%|██████▊   | 480/699 [01:20<00:44,  4.97it/s]11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 481
Evaluating:  69%|██████▉   | 481/699 [01:20<00:44,  4.94it/s]11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 482
Evaluating:  69%|██████▉   | 482/699 [01:20<00:43,  4.93it/s]11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 483
Evaluating:  69%|██████▉   | 483/699 [01:20<00:43,  4.92it/s]11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 484
Evaluating:  69%|██████▉   | 484/699 [01:20<00:43,  4.93it/s]11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 485
Evaluating:  69%|██████▉   | 485/699 [01:21<00:42,  5.00it/s]11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 486
Evaluating:  70%|██████▉   | 486/699 [01:21<00:42,  5.05it/s]11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 487
Evaluating:  70%|██████▉   | 487/699 [01:21<00:41,  5.09it/s]11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 488
Evaluating:  70%|██████▉   | 488/699 [01:21<00:41,  5.13it/s]11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 489
Evaluating:  70%|██████▉   | 489/699 [01:21<00:40,  5.15it/s]11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 490
Evaluating:  70%|███████   | 490/699 [01:21<00:40,  5.16it/s]11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 491
Evaluating:  70%|███████   | 491/699 [01:22<00:40,  5.18it/s]11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 492
Evaluating:  70%|███████   | 492/699 [01:22<00:40,  5.17it/s]11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 493
Evaluating:  71%|███████   | 493/699 [01:22<00:39,  5.17it/s]11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 494
Evaluating:  71%|███████   | 494/699 [01:22<00:39,  5.17it/s]11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 495
Evaluating:  71%|███████   | 495/699 [01:22<00:39,  5.17it/s]11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 496
Evaluating:  71%|███████   | 496/699 [01:23<00:39,  5.17it/s]11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 497
Evaluating:  71%|███████   | 497/699 [01:23<00:39,  5.17it/s]11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 498
Evaluating:  71%|███████   | 498/699 [01:23<00:38,  5.17it/s]11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 499
Evaluating:  71%|███████▏  | 499/699 [01:23<00:38,  5.15it/s]11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 500
Evaluating:  72%|███████▏  | 500/699 [01:23<00:39,  5.07it/s]11/21/2021 13:16:38 - INFO - __main__ -   Batch number = 501
Evaluating:  72%|███████▏  | 501/699 [01:24<00:39,  5.00it/s]11/21/2021 13:16:38 - INFO - __main__ -   Batch number = 502
Evaluating:  72%|███████▏  | 502/699 [01:24<00:39,  4.98it/s]11/21/2021 13:16:38 - INFO - __main__ -   Batch number = 503
Evaluating:  72%|███████▏  | 503/699 [01:24<00:39,  4.97it/s]11/21/2021 13:16:38 - INFO - __main__ -   Batch number = 504
Evaluating:  72%|███████▏  | 504/699 [01:24<00:39,  4.93it/s]11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 505
Evaluating:  72%|███████▏  | 505/699 [01:24<00:39,  4.89it/s]11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 506
Evaluating:  72%|███████▏  | 506/699 [01:25<00:39,  4.91it/s]11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 507
Evaluating:  73%|███████▎  | 507/699 [01:25<00:38,  4.93it/s]11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 508
Evaluating:  73%|███████▎  | 508/699 [01:25<00:38,  4.95it/s]11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 509
Evaluating:  73%|███████▎  | 509/699 [01:25<00:38,  5.00it/s]11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 510
Evaluating:  73%|███████▎  | 510/699 [01:25<00:37,  5.04it/s]11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 511
Evaluating:  73%|███████▎  | 511/699 [01:26<00:37,  5.02it/s]11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 512
Evaluating:  73%|███████▎  | 512/699 [01:26<00:36,  5.06it/s]11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 513
Evaluating:  73%|███████▎  | 513/699 [01:26<00:36,  5.08it/s]11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 514
Evaluating:  74%|███████▎  | 514/699 [01:26<00:36,  5.08it/s]11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 515
Evaluating:  74%|███████▎  | 515/699 [01:26<00:36,  5.09it/s]11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 516
Evaluating:  74%|███████▍  | 516/699 [01:27<00:35,  5.09it/s]11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 517
Evaluating:  74%|███████▍  | 517/699 [01:27<00:35,  5.09it/s]11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 518
Evaluating:  74%|███████▍  | 518/699 [01:27<00:35,  5.09it/s]11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 519
Evaluating:  74%|███████▍  | 519/699 [01:27<00:35,  5.08it/s]11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 520
Evaluating:  74%|███████▍  | 520/699 [01:27<00:35,  5.08it/s]11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 521
Evaluating:  75%|███████▍  | 521/699 [01:28<00:34,  5.10it/s]11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 522
Evaluating:  75%|███████▍  | 522/699 [01:28<00:34,  5.09it/s]11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 523
Evaluating:  75%|███████▍  | 523/699 [01:28<00:34,  5.07it/s]11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 524
Evaluating:  75%|███████▍  | 524/699 [01:28<00:34,  5.09it/s]11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 525
Evaluating:  75%|███████▌  | 525/699 [01:28<00:34,  5.09it/s]11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 526
Evaluating:  75%|███████▌  | 526/699 [01:29<00:34,  5.08it/s]11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 527
Evaluating:  75%|███████▌  | 527/699 [01:29<00:33,  5.09it/s]11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 528
Evaluating:  76%|███████▌  | 528/699 [01:29<00:33,  5.09it/s]11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 529
Evaluating:  76%|███████▌  | 529/699 [01:29<00:33,  5.07it/s]11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 530
Evaluating:  76%|███████▌  | 530/699 [01:29<00:33,  5.08it/s]11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 531
Evaluating:  76%|███████▌  | 531/699 [01:30<00:33,  5.08it/s]11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 532
Evaluating:  76%|███████▌  | 532/699 [01:30<00:33,  5.02it/s]11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 533
Evaluating:  76%|███████▋  | 533/699 [01:30<00:33,  4.96it/s]11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 534
Evaluating:  76%|███████▋  | 534/699 [01:30<00:33,  4.91it/s]11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 535
Evaluating:  77%|███████▋  | 535/699 [01:30<00:33,  4.85it/s]11/21/2021 13:16:45 - INFO - __main__ -   Batch number = 536
Evaluating:  77%|███████▋  | 536/699 [01:31<00:36,  4.45it/s]11/21/2021 13:16:45 - INFO - __main__ -   Batch number = 537
Evaluating:  77%|███████▋  | 537/699 [01:31<00:35,  4.58it/s]11/21/2021 13:16:45 - INFO - __main__ -   Batch number = 538
Evaluating:  77%|███████▋  | 538/699 [01:31<00:34,  4.63it/s]11/21/2021 13:16:45 - INFO - __main__ -   Batch number = 539
Evaluating:  77%|███████▋  | 539/699 [01:31<00:34,  4.70it/s]11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 540
Evaluating:  77%|███████▋  | 540/699 [01:32<00:33,  4.76it/s]11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 541
Evaluating:  77%|███████▋  | 541/699 [01:32<00:32,  4.83it/s]11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 542
Evaluating:  78%|███████▊  | 542/699 [01:32<00:32,  4.90it/s]11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 543
Evaluating:  78%|███████▊  | 543/699 [01:32<00:31,  4.94it/s]11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 544
Evaluating:  78%|███████▊  | 544/699 [01:32<00:31,  4.97it/s]11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 545
Evaluating:  78%|███████▊  | 545/699 [01:32<00:30,  5.00it/s]11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 546
Evaluating:  78%|███████▊  | 546/699 [01:33<00:30,  4.98it/s]11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 547
Evaluating:  78%|███████▊  | 547/699 [01:33<00:30,  4.99it/s]11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 548
Evaluating:  78%|███████▊  | 548/699 [01:33<00:30,  4.99it/s]11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 549
Evaluating:  79%|███████▊  | 549/699 [01:33<00:30,  4.99it/s]11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 550
Evaluating:  79%|███████▊  | 550/699 [01:34<00:29,  4.99it/s]11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 551
Evaluating:  79%|███████▉  | 551/699 [01:34<00:29,  5.00it/s]11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 552
Evaluating:  79%|███████▉  | 552/699 [01:34<00:29,  5.00it/s]11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 553
Evaluating:  79%|███████▉  | 553/699 [01:34<00:29,  4.99it/s]11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 554
Evaluating:  79%|███████▉  | 554/699 [01:34<00:29,  4.95it/s]11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 555
Evaluating:  79%|███████▉  | 555/699 [01:35<00:29,  4.88it/s]11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 556
Evaluating:  80%|███████▉  | 556/699 [01:35<00:29,  4.85it/s]11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 557
Evaluating:  80%|███████▉  | 557/699 [01:35<00:29,  4.81it/s]11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 558
Evaluating:  80%|███████▉  | 558/699 [01:35<00:29,  4.78it/s]11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 559
Evaluating:  80%|███████▉  | 559/699 [01:35<00:29,  4.78it/s]11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 560
Evaluating:  80%|████████  | 560/699 [01:36<00:28,  4.81it/s]11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 561
Evaluating:  80%|████████  | 561/699 [01:36<00:28,  4.82it/s]11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 562
Evaluating:  80%|████████  | 562/699 [01:36<00:28,  4.79it/s]11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 563
Evaluating:  81%|████████  | 563/699 [01:36<00:28,  4.77it/s]11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 564
Evaluating:  81%|████████  | 564/699 [01:36<00:28,  4.79it/s]11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 565
Evaluating:  81%|████████  | 565/699 [01:37<00:27,  4.83it/s]11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 566
Evaluating:  81%|████████  | 566/699 [01:37<00:27,  4.87it/s]11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 567
Evaluating:  81%|████████  | 567/699 [01:37<00:26,  4.91it/s]11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 568
Evaluating:  81%|████████▏ | 568/699 [01:37<00:26,  4.92it/s]11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 569
Evaluating:  81%|████████▏ | 569/699 [01:37<00:26,  4.93it/s]11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 570
Evaluating:  82%|████████▏ | 570/699 [01:38<00:26,  4.92it/s]11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 571
Evaluating:  82%|████████▏ | 571/699 [01:38<00:25,  4.93it/s]11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 572
Evaluating:  82%|████████▏ | 572/699 [01:38<00:25,  4.94it/s]11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 573
Evaluating:  82%|████████▏ | 573/699 [01:38<00:25,  4.95it/s]11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 574
Evaluating:  82%|████████▏ | 574/699 [01:38<00:25,  4.95it/s]11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 575
Evaluating:  82%|████████▏ | 575/699 [01:39<00:25,  4.96it/s]11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 576
Evaluating:  82%|████████▏ | 576/699 [01:39<00:24,  4.94it/s]11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 577
Evaluating:  83%|████████▎ | 577/699 [01:39<00:24,  4.94it/s]11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 578
Evaluating:  83%|████████▎ | 578/699 [01:39<00:24,  4.95it/s]11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 579
Evaluating:  83%|████████▎ | 579/699 [01:39<00:24,  4.95it/s]11/21/2021 13:16:54 - INFO - __main__ -   Batch number = 580
Evaluating:  83%|████████▎ | 580/699 [01:40<00:24,  4.94it/s]11/21/2021 13:16:54 - INFO - __main__ -   Batch number = 581
Evaluating:  83%|████████▎ | 581/699 [01:40<00:23,  4.94it/s]11/21/2021 13:16:54 - INFO - __main__ -   Batch number = 582
Evaluating:  83%|████████▎ | 582/699 [01:40<00:23,  4.90it/s]11/21/2021 13:16:54 - INFO - __main__ -   Batch number = 583
Evaluating:  83%|████████▎ | 583/699 [01:40<00:24,  4.82it/s]11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 584
Evaluating:  84%|████████▎ | 584/699 [01:40<00:23,  4.80it/s]11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 585
Evaluating:  84%|████████▎ | 585/699 [01:41<00:23,  4.76it/s]11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 586
Evaluating:  84%|████████▍ | 586/699 [01:41<00:23,  4.72it/s]11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 587
Evaluating:  84%|████████▍ | 587/699 [01:41<00:23,  4.71it/s]11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 588
Evaluating:  84%|████████▍ | 588/699 [01:41<00:23,  4.73it/s]11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 589
Evaluating:  84%|████████▍ | 589/699 [01:42<00:23,  4.78it/s]11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 590
Evaluating:  84%|████████▍ | 590/699 [01:42<00:22,  4.82it/s]11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 591
Evaluating:  85%|████████▍ | 591/699 [01:42<00:22,  4.85it/s]11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 592
Evaluating:  85%|████████▍ | 592/699 [01:42<00:22,  4.85it/s]11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 593
Evaluating:  85%|████████▍ | 593/699 [01:42<00:21,  4.87it/s]11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 594
Evaluating:  85%|████████▍ | 594/699 [01:43<00:21,  4.87it/s]11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 595
Evaluating:  85%|████████▌ | 595/699 [01:43<00:21,  4.88it/s]11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 596
Evaluating:  85%|████████▌ | 596/699 [01:43<00:21,  4.88it/s]11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 597
Evaluating:  85%|████████▌ | 597/699 [01:43<00:20,  4.88it/s]11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 598
Evaluating:  86%|████████▌ | 598/699 [01:43<00:20,  4.89it/s]11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 599
Evaluating:  86%|████████▌ | 599/699 [01:44<00:20,  4.89it/s]11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 600
Evaluating:  86%|████████▌ | 600/699 [01:44<00:20,  4.89it/s]11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 601
Evaluating:  86%|████████▌ | 601/699 [01:44<00:20,  4.88it/s]11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 602
Evaluating:  86%|████████▌ | 602/699 [01:44<00:19,  4.88it/s]11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 603
Evaluating:  86%|████████▋ | 603/699 [01:44<00:19,  4.88it/s]11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 604
Evaluating:  86%|████████▋ | 604/699 [01:45<00:19,  4.88it/s]11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 605
Evaluating:  87%|████████▋ | 605/699 [01:45<00:19,  4.89it/s]11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 606
Evaluating:  87%|████████▋ | 606/699 [01:45<00:19,  4.88it/s]11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 607
Evaluating:  87%|████████▋ | 607/699 [01:45<00:18,  4.87it/s]11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 608
Evaluating:  87%|████████▋ | 608/699 [01:45<00:18,  4.87it/s]11/21/2021 13:17:00 - INFO - __main__ -   Batch number = 609
Evaluating:  87%|████████▋ | 609/699 [01:46<00:26,  3.42it/s]11/21/2021 13:17:00 - INFO - __main__ -   Batch number = 610
Evaluating:  87%|████████▋ | 610/699 [01:46<00:23,  3.76it/s]11/21/2021 13:17:00 - INFO - __main__ -   Batch number = 611
Evaluating:  87%|████████▋ | 611/699 [01:46<00:21,  4.03it/s]11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 612
Evaluating:  88%|████████▊ | 612/699 [01:47<00:20,  4.24it/s]11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 613
Evaluating:  88%|████████▊ | 613/699 [01:47<00:19,  4.41it/s]11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 614
Evaluating:  88%|████████▊ | 614/699 [01:47<00:18,  4.54it/s]11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 615
Evaluating:  88%|████████▊ | 615/699 [01:47<00:18,  4.62it/s]11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 616
Evaluating:  88%|████████▊ | 616/699 [01:47<00:17,  4.67it/s]11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 617
Evaluating:  88%|████████▊ | 617/699 [01:48<00:17,  4.72it/s]11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 618
Evaluating:  88%|████████▊ | 618/699 [01:48<00:17,  4.74it/s]11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 619
Evaluating:  89%|████████▊ | 619/699 [01:48<00:16,  4.77it/s]11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 620
Evaluating:  89%|████████▊ | 620/699 [01:48<00:16,  4.79it/s]11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 621
Evaluating:  89%|████████▉ | 621/699 [01:48<00:16,  4.79it/s]11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 622
Evaluating:  89%|████████▉ | 622/699 [01:49<00:16,  4.79it/s]11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 623
Evaluating:  89%|████████▉ | 623/699 [01:49<00:15,  4.81it/s]11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 624
Evaluating:  89%|████████▉ | 624/699 [01:49<00:15,  4.81it/s]11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 625
Evaluating:  89%|████████▉ | 625/699 [01:49<00:15,  4.81it/s]11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 626
Evaluating:  90%|████████▉ | 626/699 [01:49<00:15,  4.82it/s]11/21/2021 13:17:04 - INFO - __main__ -   Batch number = 627
Evaluating:  90%|████████▉ | 627/699 [01:50<00:14,  4.82it/s]11/21/2021 13:17:04 - INFO - __main__ -   Batch number = 628
Evaluating:  90%|████████▉ | 628/699 [01:50<00:14,  4.82it/s]11/21/2021 13:17:04 - INFO - __main__ -   Batch number = 629
Evaluating:  90%|████████▉ | 629/699 [01:50<00:14,  4.82it/s]11/21/2021 13:17:04 - INFO - __main__ -   Batch number = 630
Evaluating:  90%|█████████ | 630/699 [01:50<00:14,  4.81it/s]11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 631
Evaluating:  90%|█████████ | 631/699 [01:50<00:14,  4.81it/s]11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 632
Evaluating:  90%|█████████ | 632/699 [01:51<00:13,  4.82it/s]11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 633
Evaluating:  91%|█████████ | 633/699 [01:51<00:13,  4.79it/s]11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 634
Evaluating:  91%|█████████ | 634/699 [01:51<00:13,  4.72it/s]11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 635
Evaluating:  91%|█████████ | 635/699 [01:51<00:13,  4.68it/s]11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 636
Evaluating:  91%|█████████ | 636/699 [01:52<00:13,  4.63it/s]11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 637
Evaluating:  91%|█████████ | 637/699 [01:52<00:13,  4.59it/s]11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 638
Evaluating:  91%|█████████▏| 638/699 [01:52<00:13,  4.61it/s]11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 639
Evaluating:  91%|█████████▏| 639/699 [01:52<00:12,  4.65it/s]11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 640
Evaluating:  92%|█████████▏| 640/699 [01:52<00:12,  4.63it/s]11/21/2021 13:17:07 - INFO - __main__ -   Batch number = 641
Evaluating:  92%|█████████▏| 641/699 [01:53<00:12,  4.61it/s]11/21/2021 13:17:07 - INFO - __main__ -   Batch number = 642
Evaluating:  92%|█████████▏| 642/699 [01:53<00:12,  4.62it/s]11/21/2021 13:17:07 - INFO - __main__ -   Batch number = 643
Evaluating:  92%|█████████▏| 643/699 [01:53<00:12,  4.65it/s]11/21/2021 13:17:07 - INFO - __main__ -   Batch number = 644
Evaluating:  92%|█████████▏| 644/699 [01:53<00:11,  4.69it/s]11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 645
Evaluating:  92%|█████████▏| 645/699 [01:53<00:11,  4.68it/s]11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 646
Evaluating:  92%|█████████▏| 646/699 [01:54<00:11,  4.68it/s]11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 647
Evaluating:  93%|█████████▎| 647/699 [01:54<00:11,  4.70it/s]11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 648
Evaluating:  93%|█████████▎| 648/699 [01:54<00:10,  4.72it/s]11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 649
Evaluating:  93%|█████████▎| 649/699 [01:54<00:10,  4.73it/s]11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 650
Evaluating:  93%|█████████▎| 650/699 [01:55<00:10,  4.74it/s]11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 651
Evaluating:  93%|█████████▎| 651/699 [01:55<00:10,  4.74it/s]11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 652
Evaluating:  93%|█████████▎| 652/699 [01:55<00:09,  4.75it/s]11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 653
Evaluating:  93%|█████████▎| 653/699 [01:55<00:09,  4.75it/s]11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 654
Evaluating:  94%|█████████▎| 654/699 [01:55<00:09,  4.74it/s]11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 655
Evaluating:  94%|█████████▎| 655/699 [01:56<00:09,  4.74it/s]11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 656
Evaluating:  94%|█████████▍| 656/699 [01:56<00:09,  4.75it/s]11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 657
Evaluating:  94%|█████████▍| 657/699 [01:56<00:08,  4.74it/s]11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 658
Evaluating:  94%|█████████▍| 658/699 [01:56<00:08,  4.73it/s]11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 659
Evaluating:  94%|█████████▍| 659/699 [01:56<00:08,  4.74it/s]11/21/2021 13:17:11 - INFO - __main__ -   Batch number = 660
Evaluating:  94%|█████████▍| 660/699 [01:57<00:08,  4.73it/s]11/21/2021 13:17:11 - INFO - __main__ -   Batch number = 661
Evaluating:  95%|█████████▍| 661/699 [01:57<00:08,  4.73it/s]11/21/2021 13:17:11 - INFO - __main__ -   Batch number = 662
Evaluating:  95%|█████████▍| 662/699 [01:57<00:07,  4.74it/s]11/21/2021 13:17:11 - INFO - __main__ -   Batch number = 663
Evaluating:  95%|█████████▍| 663/699 [01:57<00:07,  4.73it/s]11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 664
Evaluating:  95%|█████████▍| 664/699 [01:57<00:07,  4.72it/s]11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 665
Evaluating:  95%|█████████▌| 665/699 [01:58<00:07,  4.72it/s]11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 666
Evaluating:  95%|█████████▌| 666/699 [01:58<00:06,  4.72it/s]11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 667
Evaluating:  95%|█████████▌| 667/699 [01:58<00:06,  4.71it/s]11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 668
Evaluating:  96%|█████████▌| 668/699 [01:58<00:06,  4.70it/s]11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 669
Evaluating:  96%|█████████▌| 669/699 [01:59<00:06,  4.69it/s]11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 670
Evaluating:  96%|█████████▌| 670/699 [01:59<00:06,  4.69it/s]11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 671
Evaluating:  96%|█████████▌| 671/699 [01:59<00:05,  4.71it/s]11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 672
Evaluating:  96%|█████████▌| 672/699 [01:59<00:05,  4.70it/s]11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 673
Evaluating:  96%|█████████▋| 673/699 [01:59<00:05,  4.70it/s]11/21/2021 13:17:14 - INFO - __main__ -   Batch number = 674
Evaluating:  96%|█████████▋| 674/699 [02:00<00:05,  4.70it/s]11/21/2021 13:17:14 - INFO - __main__ -   Batch number = 675
Evaluating:  97%|█████████▋| 675/699 [02:00<00:05,  4.69it/s]11/21/2021 13:17:14 - INFO - __main__ -   Batch number = 676
Evaluating:  97%|█████████▋| 676/699 [02:00<00:04,  4.70it/s]11/21/2021 13:17:14 - INFO - __main__ -   Batch number = 677
Evaluating:  97%|█████████▋| 677/699 [02:00<00:04,  4.70it/s]11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 678
Evaluating:  97%|█████████▋| 678/699 [02:00<00:04,  4.70it/s]11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 679
Evaluating:  97%|█████████▋| 679/699 [02:01<00:04,  4.57it/s]11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 680
Evaluating:  97%|█████████▋| 680/699 [02:01<00:04,  4.60it/s]11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 681
Evaluating:  97%|█████████▋| 681/699 [02:01<00:03,  4.62it/s]11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 682
Evaluating:  98%|█████████▊| 682/699 [02:01<00:03,  4.64it/s]11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 683
Evaluating:  98%|█████████▊| 683/699 [02:02<00:03,  4.66it/s]11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 684
Evaluating:  98%|█████████▊| 684/699 [02:02<00:03,  4.66it/s]11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 685
Evaluating:  98%|█████████▊| 685/699 [02:02<00:03,  4.66it/s]11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 686
Evaluating:  98%|█████████▊| 686/699 [02:02<00:02,  4.66it/s]11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 687
Evaluating:  98%|█████████▊| 687/699 [02:02<00:02,  4.65it/s]11/21/2021 13:17:17 - INFO - __main__ -   Batch number = 688
Evaluating:  98%|█████████▊| 688/699 [02:03<00:02,  4.65it/s]11/21/2021 13:17:17 - INFO - __main__ -   Batch number = 689
Evaluating:  99%|█████████▊| 689/699 [02:03<00:02,  4.66it/s]11/21/2021 13:17:17 - INFO - __main__ -   Batch number = 690
Evaluating:  99%|█████████▊| 690/699 [02:03<00:01,  4.65it/s]11/21/2021 13:17:17 - INFO - __main__ -   Batch number = 691
Evaluating:  99%|█████████▉| 691/699 [02:03<00:01,  4.65it/s]11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 692
Evaluating:  99%|█████████▉| 692/699 [02:03<00:01,  4.65it/s]11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 693
Evaluating:  99%|█████████▉| 693/699 [02:04<00:01,  4.65it/s]11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 694
Evaluating:  99%|█████████▉| 694/699 [02:04<00:01,  4.64it/s]11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 695
Evaluating:  99%|█████████▉| 695/699 [02:04<00:00,  4.64it/s]11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 696
Evaluating: 100%|█████████▉| 696/699 [02:04<00:00,  4.64it/s]11/21/2021 13:17:19 - INFO - __main__ -   Batch number = 697
Evaluating: 100%|█████████▉| 697/699 [02:05<00:00,  4.64it/s]11/21/2021 13:17:19 - INFO - __main__ -   Batch number = 698
Evaluating: 100%|█████████▉| 698/699 [02:05<00:00,  4.64it/s]11/21/2021 13:17:19 - INFO - __main__ -   Batch number = 699
Evaluating: 100%|██████████| 699/699 [02:05<00:00,  4.85it/s]Evaluating: 100%|██████████| 699/699 [02:05<00:00,  5.57it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/21/2021 13:17:28 - INFO - __main__ -   ***** Evaluation result  in de *****
11/21/2021 13:17:28 - INFO - __main__ -     f1 = 0.842724349147744
11/21/2021 13:17:28 - INFO - __main__ -     loss = 0.5379099446816505
11/21/2021 13:17:28 - INFO - __main__ -     precision = 0.8483568556066015
11/21/2021 13:17:28 - INFO - __main__ -     recall = 0.8371661413404115
114.13user 46.16system 2:31.38elapsed 105%CPU (0avgtext+0avgdata 3885508maxresident)k
0inputs+4248outputs (0major+1896466minor)pagefaults 0swaps
PyTorch version 1.9.0+cu102 available.
11/21/2021 13:17:30 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:17:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/21/2021 13:17:30 - INFO - __main__ -   Seed = 2
11/21/2021 13:17:30 - INFO - root -   save model
11/21/2021 13:17:30 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:17:30 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/21/2021 13:17:33 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/21/2021 13:17:38 - INFO - __main__ -   Using lang2id = None
11/21/2021 13:17:38 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/21/2021 13:17:38 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
11/21/2021 13:17:38 - INFO - root -   Trying to decide if add adapter
11/21/2021 13:17:38 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_model_head.bin
11/21/2021 13:17:38 - INFO - root -   loading lang adpater hi/wiki@ukp
11/21/2021 13:17:38 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/21/2021 13:17:38 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/21/2021 13:17:38 - INFO - __main__ -   Language = hi
11/21/2021 13:17:38 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/21/2021 13:17:42 - INFO - __main__ -   Language adapter for de not found, using hi instead
11/21/2021 13:17:42 - INFO - __main__ -   Set active language adapter to hi
11/21/2021 13:17:42 - INFO - __main__ -   Args Adapter Weight = None
11/21/2021 13:17:42 - INFO - __main__ -   Adapter Languages = ['hi']
11/21/2021 13:17:42 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_de_bert-base-multilingual-cased_128
11/21/2021 13:17:45 - INFO - __main__ -   ***** Running evaluation  in de *****
11/21/2021 13:17:45 - INFO - __main__ -     Num examples = 22360
11/21/2021 13:17:45 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/699 [00:00<?, ?it/s]11/21/2021 13:17:45 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/699 [00:00<01:46,  6.53it/s]11/21/2021 13:17:45 - INFO - __main__ -   Batch number = 2
Evaluating:   0%|          | 2/699 [00:00<01:41,  6.84it/s]11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 3
Evaluating:   0%|          | 3/699 [00:00<01:38,  7.06it/s]11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/699 [00:00<01:36,  7.20it/s]11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 5
Evaluating:   1%|          | 5/699 [00:00<01:35,  7.27it/s]11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 6
Evaluating:   1%|          | 6/699 [00:00<01:34,  7.32it/s]11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 7
Evaluating:   1%|          | 7/699 [00:00<01:34,  7.36it/s]11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 8
Evaluating:   1%|          | 8/699 [00:01<01:33,  7.36it/s]11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 9
Evaluating:   1%|▏         | 9/699 [00:01<01:34,  7.32it/s]11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 10
Evaluating:   1%|▏         | 10/699 [00:01<01:34,  7.30it/s]11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 11
Evaluating:   2%|▏         | 11/699 [00:01<01:34,  7.31it/s]11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 12
Evaluating:   2%|▏         | 12/699 [00:01<01:33,  7.33it/s]11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 13
Evaluating:   2%|▏         | 13/699 [00:01<01:33,  7.35it/s]11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 14
Evaluating:   2%|▏         | 14/699 [00:01<01:32,  7.37it/s]11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 15
Evaluating:   2%|▏         | 15/699 [00:02<01:32,  7.36it/s]11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 16
Evaluating:   2%|▏         | 16/699 [00:02<01:32,  7.36it/s]11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 17
Evaluating:   2%|▏         | 17/699 [00:02<01:33,  7.32it/s]11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 18
Evaluating:   3%|▎         | 18/699 [00:02<01:32,  7.33it/s]11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 19
Evaluating:   3%|▎         | 19/699 [00:02<01:32,  7.33it/s]11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 20
Evaluating:   3%|▎         | 20/699 [00:02<01:32,  7.33it/s]11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 21
Evaluating:   3%|▎         | 21/699 [00:02<01:32,  7.33it/s]11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 22
Evaluating:   3%|▎         | 22/699 [00:03<01:32,  7.33it/s]11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 23
Evaluating:   3%|▎         | 23/699 [00:03<01:32,  7.33it/s]11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 24
Evaluating:   3%|▎         | 24/699 [00:03<01:32,  7.30it/s]11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 25
Evaluating:   4%|▎         | 25/699 [00:03<01:32,  7.27it/s]11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 26
Evaluating:   4%|▎         | 26/699 [00:03<01:32,  7.29it/s]11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 27
Evaluating:   4%|▍         | 27/699 [00:03<01:32,  7.27it/s]11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 28
Evaluating:   4%|▍         | 28/699 [00:03<01:32,  7.26it/s]11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 29
Evaluating:   4%|▍         | 29/699 [00:03<01:32,  7.27it/s]11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 30
Evaluating:   4%|▍         | 30/699 [00:04<01:32,  7.23it/s]11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 31
Evaluating:   4%|▍         | 31/699 [00:04<01:33,  7.18it/s]11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 32
Evaluating:   5%|▍         | 32/699 [00:04<01:32,  7.22it/s]11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 33
Evaluating:   5%|▍         | 33/699 [00:04<01:31,  7.24it/s]11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 34
Evaluating:   5%|▍         | 34/699 [00:04<01:33,  7.08it/s]11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 35
Evaluating:   5%|▌         | 35/699 [00:04<01:32,  7.14it/s]11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 36
Evaluating:   5%|▌         | 36/699 [00:04<01:32,  7.17it/s]11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 37
Evaluating:   5%|▌         | 37/699 [00:05<01:32,  7.17it/s]11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 38
Evaluating:   5%|▌         | 38/699 [00:05<01:31,  7.19it/s]11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 39
Evaluating:   6%|▌         | 39/699 [00:05<01:31,  7.21it/s]11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 40
Evaluating:   6%|▌         | 40/699 [00:05<01:31,  7.20it/s]11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 41
Evaluating:   6%|▌         | 41/699 [00:05<01:31,  7.21it/s]11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 42
Evaluating:   6%|▌         | 42/699 [00:05<01:30,  7.22it/s]11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 43
Evaluating:   6%|▌         | 43/699 [00:05<01:31,  7.21it/s]11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 44
Evaluating:   6%|▋         | 44/699 [00:06<01:30,  7.22it/s]11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 45
Evaluating:   6%|▋         | 45/699 [00:06<01:30,  7.23it/s]11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 46
Evaluating:   7%|▋         | 46/699 [00:06<01:30,  7.22it/s]11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 47
Evaluating:   7%|▋         | 47/699 [00:06<01:30,  7.21it/s]11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 48
Evaluating:   7%|▋         | 48/699 [00:06<01:30,  7.21it/s]11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 49
Evaluating:   7%|▋         | 49/699 [00:06<01:30,  7.18it/s]11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 50
Evaluating:   7%|▋         | 50/699 [00:06<01:30,  7.20it/s]11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 51
Evaluating:   7%|▋         | 51/699 [00:07<01:30,  7.20it/s]11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 52
Evaluating:   7%|▋         | 52/699 [00:07<01:30,  7.16it/s]11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 53
Evaluating:   8%|▊         | 53/699 [00:07<01:30,  7.18it/s]11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 54
Evaluating:   8%|▊         | 54/699 [00:07<01:29,  7.18it/s]11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 55
Evaluating:   8%|▊         | 55/699 [00:07<01:30,  7.15it/s]11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 56
Evaluating:   8%|▊         | 56/699 [00:07<01:29,  7.17it/s]11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 57
Evaluating:   8%|▊         | 57/699 [00:07<01:29,  7.17it/s]11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 58
Evaluating:   8%|▊         | 58/699 [00:08<01:29,  7.17it/s]11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 59
Evaluating:   8%|▊         | 59/699 [00:08<01:29,  7.16it/s]11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 60
Evaluating:   9%|▊         | 60/699 [00:08<01:29,  7.17it/s]11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 61
Evaluating:   9%|▊         | 61/699 [00:08<01:29,  7.15it/s]11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 62
Evaluating:   9%|▉         | 62/699 [00:08<01:29,  7.12it/s]11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 63
Evaluating:   9%|▉         | 63/699 [00:08<01:29,  7.12it/s]11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 64
Evaluating:   9%|▉         | 64/699 [00:08<01:29,  7.10it/s]11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 65
Evaluating:   9%|▉         | 65/699 [00:09<01:29,  7.11it/s]11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 66
Evaluating:   9%|▉         | 66/699 [00:09<01:29,  7.05it/s]11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 67
Evaluating:  10%|▉         | 67/699 [00:09<01:30,  7.01it/s]11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 68
Evaluating:  10%|▉         | 68/699 [00:09<01:30,  6.99it/s]11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 69
Evaluating:  10%|▉         | 69/699 [00:09<01:30,  6.98it/s]11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 70
Evaluating:  10%|█         | 70/699 [00:09<01:30,  6.98it/s]11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 71
Evaluating:  10%|█         | 71/699 [00:09<01:29,  7.02it/s]11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 72
Evaluating:  10%|█         | 72/699 [00:10<01:29,  7.04it/s]11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 73
Evaluating:  10%|█         | 73/699 [00:10<01:29,  7.02it/s]11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 74
Evaluating:  11%|█         | 74/699 [00:10<01:30,  6.90it/s]11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 75
Evaluating:  11%|█         | 75/699 [00:10<01:30,  6.88it/s]11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 76
Evaluating:  11%|█         | 76/699 [00:10<01:30,  6.92it/s]11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 77
Evaluating:  11%|█         | 77/699 [00:10<01:29,  6.95it/s]11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 78
Evaluating:  11%|█         | 78/699 [00:10<01:28,  6.99it/s]11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 79
Evaluating:  11%|█▏        | 79/699 [00:11<01:28,  7.01it/s]11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 80
Evaluating:  11%|█▏        | 80/699 [00:11<01:27,  7.04it/s]11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 81
Evaluating:  12%|█▏        | 81/699 [00:11<01:27,  7.06it/s]11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 82
Evaluating:  12%|█▏        | 82/699 [00:11<01:27,  7.04it/s]11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 83
Evaluating:  12%|█▏        | 83/699 [00:11<01:27,  7.04it/s]11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 84
Evaluating:  12%|█▏        | 84/699 [00:11<01:27,  7.05it/s]11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 85
Evaluating:  12%|█▏        | 85/699 [00:11<01:27,  7.04it/s]11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 86
Evaluating:  12%|█▏        | 86/699 [00:12<01:26,  7.05it/s]11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 87
Evaluating:  12%|█▏        | 87/699 [00:12<01:28,  6.91it/s]11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 88
Evaluating:  13%|█▎        | 88/699 [00:12<01:29,  6.84it/s]11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 89
Evaluating:  13%|█▎        | 89/699 [00:12<01:28,  6.91it/s]11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 90
Evaluating:  13%|█▎        | 90/699 [00:12<01:27,  6.94it/s]11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 91
Evaluating:  13%|█▎        | 91/699 [00:12<01:27,  6.96it/s]11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 92
Evaluating:  13%|█▎        | 92/699 [00:12<01:26,  6.99it/s]11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 93
Evaluating:  13%|█▎        | 93/699 [00:13<01:26,  7.00it/s]11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 94
Evaluating:  13%|█▎        | 94/699 [00:13<01:27,  6.88it/s]11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 95
Evaluating:  14%|█▎        | 95/699 [00:13<01:28,  6.83it/s]11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 96
Evaluating:  14%|█▎        | 96/699 [00:13<01:28,  6.80it/s]11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 97
Evaluating:  14%|█▍        | 97/699 [00:13<01:28,  6.79it/s]11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 98
Evaluating:  14%|█▍        | 98/699 [00:13<01:28,  6.77it/s]11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 99
Evaluating:  14%|█▍        | 99/699 [00:13<01:28,  6.78it/s]11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 100
Evaluating:  14%|█▍        | 100/699 [00:14<01:28,  6.76it/s]11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 101
Evaluating:  14%|█▍        | 101/699 [00:14<01:28,  6.77it/s]11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 102
Evaluating:  15%|█▍        | 102/699 [00:14<01:28,  6.77it/s]11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 103
Evaluating:  15%|█▍        | 103/699 [00:14<01:28,  6.76it/s]11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 104
Evaluating:  15%|█▍        | 104/699 [00:14<01:36,  6.17it/s]11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 105
Evaluating:  15%|█▌        | 105/699 [00:14<01:33,  6.33it/s]11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 106
Evaluating:  15%|█▌        | 106/699 [00:14<01:32,  6.41it/s]11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 107
Evaluating:  15%|█▌        | 107/699 [00:15<01:30,  6.52it/s]11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 108
Evaluating:  15%|█▌        | 108/699 [00:15<01:29,  6.58it/s]11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 109
Evaluating:  16%|█▌        | 109/699 [00:15<01:29,  6.63it/s]11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 110
Evaluating:  16%|█▌        | 110/699 [00:15<01:28,  6.65it/s]11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 111
Evaluating:  16%|█▌        | 111/699 [00:15<01:28,  6.67it/s]11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 112
Evaluating:  16%|█▌        | 112/699 [00:15<01:28,  6.66it/s]11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 113
Evaluating:  16%|█▌        | 113/699 [00:16<01:27,  6.66it/s]11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 114
Evaluating:  16%|█▋        | 114/699 [00:16<01:27,  6.68it/s]11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 115
Evaluating:  16%|█▋        | 115/699 [00:16<01:27,  6.66it/s]11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 116
Evaluating:  17%|█▋        | 116/699 [00:16<01:27,  6.65it/s]11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 117
Evaluating:  17%|█▋        | 117/699 [00:16<01:27,  6.64it/s]11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 118
Evaluating:  17%|█▋        | 118/699 [00:16<01:27,  6.65it/s]11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 119
Evaluating:  17%|█▋        | 119/699 [00:16<01:27,  6.66it/s]11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 120
Evaluating:  17%|█▋        | 120/699 [00:17<01:26,  6.66it/s]11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 121
Evaluating:  17%|█▋        | 121/699 [00:17<01:26,  6.66it/s]11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 122
Evaluating:  17%|█▋        | 122/699 [00:17<01:26,  6.66it/s]11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 123
Evaluating:  18%|█▊        | 123/699 [00:17<01:26,  6.65it/s]11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 124
Evaluating:  18%|█▊        | 124/699 [00:17<01:26,  6.65it/s]11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 125
Evaluating:  18%|█▊        | 125/699 [00:17<01:26,  6.64it/s]11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 126
Evaluating:  18%|█▊        | 126/699 [00:17<01:26,  6.63it/s]11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 127
Evaluating:  18%|█▊        | 127/699 [00:18<01:26,  6.61it/s]11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 128
Evaluating:  18%|█▊        | 128/699 [00:18<01:26,  6.63it/s]11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 129
Evaluating:  18%|█▊        | 129/699 [00:18<01:26,  6.62it/s]11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 130
Evaluating:  19%|█▊        | 130/699 [00:18<01:25,  6.63it/s]11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 131
Evaluating:  19%|█▊        | 131/699 [00:18<01:25,  6.62it/s]11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 132
Evaluating:  19%|█▉        | 132/699 [00:18<01:25,  6.61it/s]11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 133
Evaluating:  19%|█▉        | 133/699 [00:19<01:25,  6.59it/s]11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 134
Evaluating:  19%|█▉        | 134/699 [00:19<01:26,  6.57it/s]11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 135
Evaluating:  19%|█▉        | 135/699 [00:19<01:27,  6.43it/s]11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 136
Evaluating:  19%|█▉        | 136/699 [00:19<01:29,  6.32it/s]11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 137
Evaluating:  20%|█▉        | 137/699 [00:19<01:42,  5.48it/s]11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 138
Evaluating:  20%|█▉        | 138/699 [00:19<01:37,  5.74it/s]11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 139
Evaluating:  20%|█▉        | 139/699 [00:20<01:33,  5.97it/s]11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 140
Evaluating:  20%|██        | 140/699 [00:20<01:31,  6.14it/s]11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 141
Evaluating:  20%|██        | 141/699 [00:20<01:29,  6.23it/s]11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 142
Evaluating:  20%|██        | 142/699 [00:20<01:28,  6.31it/s]11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 143
Evaluating:  20%|██        | 143/699 [00:20<01:26,  6.40it/s]11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 144
Evaluating:  21%|██        | 144/699 [00:20<01:25,  6.46it/s]11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 145
Evaluating:  21%|██        | 145/699 [00:21<01:27,  6.36it/s]11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 146
Evaluating:  21%|██        | 146/699 [00:21<01:27,  6.32it/s]11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 147
Evaluating:  21%|██        | 147/699 [00:21<01:27,  6.34it/s]11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 148
Evaluating:  21%|██        | 148/699 [00:21<01:26,  6.39it/s]11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 149
Evaluating:  21%|██▏       | 149/699 [00:21<01:26,  6.36it/s]11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 150
Evaluating:  21%|██▏       | 150/699 [00:21<01:26,  6.38it/s]11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 151
Evaluating:  22%|██▏       | 151/699 [00:21<01:25,  6.42it/s]11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 152
Evaluating:  22%|██▏       | 152/699 [00:22<01:24,  6.45it/s]11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 153
Evaluating:  22%|██▏       | 153/699 [00:22<01:24,  6.46it/s]11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 154
Evaluating:  22%|██▏       | 154/699 [00:22<01:24,  6.47it/s]11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 155
Evaluating:  22%|██▏       | 155/699 [00:22<01:24,  6.46it/s]11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 156
Evaluating:  22%|██▏       | 156/699 [00:22<01:24,  6.46it/s]11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 157
Evaluating:  22%|██▏       | 157/699 [00:22<01:23,  6.46it/s]11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 158
Evaluating:  23%|██▎       | 158/699 [00:23<01:23,  6.47it/s]11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 159
Evaluating:  23%|██▎       | 159/699 [00:23<01:23,  6.44it/s]11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 160
Evaluating:  23%|██▎       | 160/699 [00:23<01:23,  6.44it/s]11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 161
Evaluating:  23%|██▎       | 161/699 [00:23<01:23,  6.44it/s]11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 162
Evaluating:  23%|██▎       | 162/699 [00:23<01:23,  6.45it/s]11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 163
Evaluating:  23%|██▎       | 163/699 [00:23<01:23,  6.44it/s]11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 164
Evaluating:  23%|██▎       | 164/699 [00:23<01:22,  6.45it/s]11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 165
Evaluating:  24%|██▎       | 165/699 [00:24<01:23,  6.43it/s]11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 166
Evaluating:  24%|██▎       | 166/699 [00:24<01:22,  6.43it/s]11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 167
Evaluating:  24%|██▍       | 167/699 [00:24<01:22,  6.42it/s]11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 168
Evaluating:  24%|██▍       | 168/699 [00:24<01:22,  6.42it/s]11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 169
Evaluating:  24%|██▍       | 169/699 [00:24<01:23,  6.38it/s]11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 170
Evaluating:  24%|██▍       | 170/699 [00:24<01:24,  6.23it/s]11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 171
Evaluating:  24%|██▍       | 171/699 [00:25<01:26,  6.13it/s]11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 172
Evaluating:  25%|██▍       | 172/699 [00:25<01:25,  6.16it/s]11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 173
Evaluating:  25%|██▍       | 173/699 [00:25<01:25,  6.17it/s]11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 174
Evaluating:  25%|██▍       | 174/699 [00:25<01:24,  6.24it/s]11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 175
Evaluating:  25%|██▌       | 175/699 [00:25<01:23,  6.27it/s]11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 176
Evaluating:  25%|██▌       | 176/699 [00:25<01:23,  6.30it/s]11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 177
Evaluating:  25%|██▌       | 177/699 [00:26<01:22,  6.31it/s]11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 178
Evaluating:  25%|██▌       | 178/699 [00:26<01:22,  6.31it/s]11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 179
Evaluating:  26%|██▌       | 179/699 [00:26<01:24,  6.17it/s]11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 180
Evaluating:  26%|██▌       | 180/699 [00:26<01:25,  6.07it/s]11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 181
Evaluating:  26%|██▌       | 181/699 [00:26<01:25,  6.06it/s]11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 182
Evaluating:  26%|██▌       | 182/699 [00:26<01:24,  6.11it/s]11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 183
Evaluating:  26%|██▌       | 183/699 [00:27<01:23,  6.15it/s]11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 184
Evaluating:  26%|██▋       | 184/699 [00:27<01:24,  6.07it/s]11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 185
Evaluating:  26%|██▋       | 185/699 [00:27<01:25,  6.00it/s]11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 186
Evaluating:  27%|██▋       | 186/699 [00:27<01:24,  6.05it/s]11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 187
Evaluating:  27%|██▋       | 187/699 [00:27<01:23,  6.12it/s]11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 188
Evaluating:  27%|██▋       | 188/699 [00:27<01:22,  6.18it/s]11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 189
Evaluating:  27%|██▋       | 189/699 [00:27<01:22,  6.20it/s]11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 190
Evaluating:  27%|██▋       | 190/699 [00:28<01:21,  6.23it/s]11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 191
Evaluating:  27%|██▋       | 191/699 [00:28<01:21,  6.25it/s]11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 192
Evaluating:  27%|██▋       | 192/699 [00:28<01:20,  6.27it/s]11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 193
Evaluating:  28%|██▊       | 193/699 [00:28<01:20,  6.27it/s]11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 194
Evaluating:  28%|██▊       | 194/699 [00:28<01:21,  6.21it/s]11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 195
Evaluating:  28%|██▊       | 195/699 [00:28<01:21,  6.18it/s]11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 196
Evaluating:  28%|██▊       | 196/699 [00:29<01:21,  6.19it/s]11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 197
Evaluating:  28%|██▊       | 197/699 [00:29<01:21,  6.20it/s]11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 198
Evaluating:  28%|██▊       | 198/699 [00:29<01:22,  6.08it/s]11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 199
Evaluating:  28%|██▊       | 199/699 [00:29<01:23,  5.99it/s]11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 200
Evaluating:  29%|██▊       | 200/699 [00:29<01:23,  5.98it/s]11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 201
Evaluating:  29%|██▉       | 201/699 [00:29<01:22,  6.01it/s]11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 202
Evaluating:  29%|██▉       | 202/699 [00:30<01:21,  6.08it/s]11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 203
Evaluating:  29%|██▉       | 203/699 [00:30<01:21,  6.11it/s]11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 204
Evaluating:  29%|██▉       | 204/699 [00:30<01:21,  6.10it/s]11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 205
Evaluating:  29%|██▉       | 205/699 [00:30<01:20,  6.12it/s]11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 206
Evaluating:  29%|██▉       | 206/699 [00:30<01:20,  6.15it/s]11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 207
Evaluating:  30%|██▉       | 207/699 [00:30<01:19,  6.17it/s]11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 208
Evaluating:  30%|██▉       | 208/699 [00:31<01:19,  6.19it/s]11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 209
Evaluating:  30%|██▉       | 209/699 [00:31<01:20,  6.12it/s]11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 210
Evaluating:  30%|███       | 210/699 [00:31<01:20,  6.06it/s]11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 211
Evaluating:  30%|███       | 211/699 [00:31<01:20,  6.08it/s]11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 212
Evaluating:  30%|███       | 212/699 [00:31<01:19,  6.11it/s]11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 213
Evaluating:  30%|███       | 213/699 [00:31<01:19,  6.10it/s]11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 214
Evaluating:  31%|███       | 214/699 [00:32<01:21,  5.99it/s]11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 215
Evaluating:  31%|███       | 215/699 [00:32<01:21,  5.91it/s]11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 216
Evaluating:  31%|███       | 216/699 [00:32<01:21,  5.90it/s]11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 217
Evaluating:  31%|███       | 217/699 [00:32<01:21,  5.92it/s]11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 218
Evaluating:  31%|███       | 218/699 [00:32<01:20,  5.98it/s]11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 219
Evaluating:  31%|███▏      | 219/699 [00:32<01:19,  6.03it/s]11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 220
Evaluating:  31%|███▏      | 220/699 [00:33<01:19,  6.06it/s]11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 221
Evaluating:  32%|███▏      | 221/699 [00:33<01:18,  6.10it/s]11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 222
Evaluating:  32%|███▏      | 222/699 [00:33<01:17,  6.12it/s]11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 223
Evaluating:  32%|███▏      | 223/699 [00:33<01:17,  6.13it/s]11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 224
Evaluating:  32%|███▏      | 224/699 [00:33<01:17,  6.13it/s]11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 225
Evaluating:  32%|███▏      | 225/699 [00:33<01:17,  6.14it/s]11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 226
Evaluating:  32%|███▏      | 226/699 [00:34<01:17,  6.13it/s]11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 227
Evaluating:  32%|███▏      | 227/699 [00:34<01:16,  6.13it/s]11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 228
Evaluating:  33%|███▎      | 228/699 [00:34<01:16,  6.13it/s]11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 229
Evaluating:  33%|███▎      | 229/699 [00:34<01:17,  6.10it/s]11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 230
Evaluating:  33%|███▎      | 230/699 [00:34<01:26,  5.42it/s]11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 231
Evaluating:  33%|███▎      | 231/699 [00:34<01:25,  5.49it/s]11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 232
Evaluating:  33%|███▎      | 232/699 [00:35<01:23,  5.59it/s]11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 233
Evaluating:  33%|███▎      | 233/699 [00:35<01:21,  5.72it/s]11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 234
Evaluating:  33%|███▎      | 234/699 [00:35<01:19,  5.83it/s]11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 235
Evaluating:  34%|███▎      | 235/699 [00:35<01:18,  5.90it/s]11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 236
Evaluating:  34%|███▍      | 236/699 [00:35<01:18,  5.92it/s]11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 237
Evaluating:  34%|███▍      | 237/699 [00:35<01:17,  5.96it/s]11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 238
Evaluating:  34%|███▍      | 238/699 [00:36<01:16,  6.00it/s]11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 239
Evaluating:  34%|███▍      | 239/699 [00:36<01:16,  6.02it/s]11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 240
Evaluating:  34%|███▍      | 240/699 [00:36<01:16,  6.02it/s]11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 241
Evaluating:  34%|███▍      | 241/699 [00:36<01:16,  6.01it/s]11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 242
Evaluating:  35%|███▍      | 242/699 [00:36<01:17,  5.90it/s]11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 243
Evaluating:  35%|███▍      | 243/699 [00:36<01:18,  5.83it/s]11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 244
Evaluating:  35%|███▍      | 244/699 [00:37<01:17,  5.85it/s]11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 245
Evaluating:  35%|███▌      | 245/699 [00:37<01:17,  5.88it/s]11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 246
Evaluating:  35%|███▌      | 246/699 [00:37<01:16,  5.93it/s]11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 247
Evaluating:  35%|███▌      | 247/699 [00:37<01:16,  5.94it/s]11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 248
Evaluating:  35%|███▌      | 248/699 [00:37<01:17,  5.80it/s]11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 249
Evaluating:  36%|███▌      | 249/699 [00:38<01:18,  5.71it/s]11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 250
Evaluating:  36%|███▌      | 250/699 [00:38<01:17,  5.77it/s]11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 251
Evaluating:  36%|███▌      | 251/699 [00:38<01:17,  5.82it/s]11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 252
Evaluating:  36%|███▌      | 252/699 [00:38<01:16,  5.87it/s]11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 253
Evaluating:  36%|███▌      | 253/699 [00:38<01:15,  5.90it/s]11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 254
Evaluating:  36%|███▋      | 254/699 [00:38<01:16,  5.81it/s]11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 255
Evaluating:  36%|███▋      | 255/699 [00:39<01:17,  5.74it/s]11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 256
Evaluating:  37%|███▋      | 256/699 [00:39<01:16,  5.76it/s]11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 257
Evaluating:  37%|███▋      | 257/699 [00:39<01:16,  5.81it/s]11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 258
Evaluating:  37%|███▋      | 258/699 [00:39<01:15,  5.86it/s]11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 259
Evaluating:  37%|███▋      | 259/699 [00:39<01:16,  5.74it/s]11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 260
Evaluating:  37%|███▋      | 260/699 [00:39<01:17,  5.68it/s]11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 261
Evaluating:  37%|███▋      | 261/699 [00:40<01:17,  5.65it/s]11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 262
Evaluating:  37%|███▋      | 262/699 [00:40<01:16,  5.68it/s]11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 263
Evaluating:  38%|███▊      | 263/699 [00:40<01:16,  5.72it/s]11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 264
Evaluating:  38%|███▊      | 264/699 [00:40<01:15,  5.78it/s]11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 265
Evaluating:  38%|███▊      | 265/699 [00:40<01:14,  5.83it/s]11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 266
Evaluating:  38%|███▊      | 266/699 [00:40<01:14,  5.83it/s]11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 267
Evaluating:  38%|███▊      | 267/699 [00:41<01:15,  5.76it/s]11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 268
Evaluating:  38%|███▊      | 268/699 [00:41<01:14,  5.78it/s]11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 269
Evaluating:  38%|███▊      | 269/699 [00:41<01:13,  5.83it/s]11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 270
Evaluating:  39%|███▊      | 270/699 [00:41<01:13,  5.87it/s]11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 271
Evaluating:  39%|███▉      | 271/699 [00:41<01:12,  5.90it/s]11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 272
Evaluating:  39%|███▉      | 272/699 [00:41<01:12,  5.91it/s]11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 273
Evaluating:  39%|███▉      | 273/699 [00:42<01:13,  5.81it/s]11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 274
Evaluating:  39%|███▉      | 274/699 [00:42<01:13,  5.81it/s]11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 275
Evaluating:  39%|███▉      | 275/699 [00:42<01:12,  5.86it/s]11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 276
Evaluating:  39%|███▉      | 276/699 [00:42<01:12,  5.87it/s]11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 277
Evaluating:  40%|███▉      | 277/699 [00:42<01:11,  5.88it/s]11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 278
Evaluating:  40%|███▉      | 278/699 [00:42<01:11,  5.90it/s]11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 279
Evaluating:  40%|███▉      | 279/699 [00:43<01:12,  5.79it/s]11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 280
Evaluating:  40%|████      | 280/699 [00:43<01:12,  5.78it/s]11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 281
Evaluating:  40%|████      | 281/699 [00:43<01:11,  5.81it/s]11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 282
Evaluating:  40%|████      | 282/699 [00:43<01:11,  5.84it/s]11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 283
Evaluating:  40%|████      | 283/699 [00:43<01:11,  5.85it/s]11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 284
Evaluating:  41%|████      | 284/699 [00:44<01:10,  5.86it/s]11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 285
Evaluating:  41%|████      | 285/699 [00:44<01:11,  5.81it/s]11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 286
Evaluating:  41%|████      | 286/699 [00:44<01:10,  5.82it/s]11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 287
Evaluating:  41%|████      | 287/699 [00:44<01:10,  5.84it/s]11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 288
Evaluating:  41%|████      | 288/699 [00:44<01:11,  5.73it/s]11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 289
Evaluating:  41%|████▏     | 289/699 [00:44<01:11,  5.76it/s]11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 290
Evaluating:  41%|████▏     | 290/699 [00:45<01:10,  5.79it/s]11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 291
Evaluating:  42%|████▏     | 291/699 [00:45<01:10,  5.81it/s]11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 292
Evaluating:  42%|████▏     | 292/699 [00:45<01:11,  5.70it/s]11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 293
Evaluating:  42%|████▏     | 293/699 [00:45<01:11,  5.70it/s]11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 294
Evaluating:  42%|████▏     | 294/699 [00:45<01:10,  5.74it/s]11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 295
Evaluating:  42%|████▏     | 295/699 [00:45<01:10,  5.77it/s]11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 296
Evaluating:  42%|████▏     | 296/699 [00:46<01:09,  5.80it/s]11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 297
Evaluating:  42%|████▏     | 297/699 [00:46<01:09,  5.81it/s]11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 298
Evaluating:  43%|████▎     | 298/699 [00:46<01:09,  5.76it/s]11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 299
Evaluating:  43%|████▎     | 299/699 [00:46<01:09,  5.75it/s]11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 300
Evaluating:  43%|████▎     | 300/699 [00:46<01:09,  5.78it/s]11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 301
Evaluating:  43%|████▎     | 301/699 [00:46<01:08,  5.78it/s]11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 302
Evaluating:  43%|████▎     | 302/699 [00:47<01:08,  5.79it/s]11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 303
Evaluating:  43%|████▎     | 303/699 [00:47<01:08,  5.79it/s]11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 304
Evaluating:  43%|████▎     | 304/699 [00:47<01:08,  5.81it/s]11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 305
Evaluating:  44%|████▎     | 305/699 [00:47<01:08,  5.73it/s]11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 306
Evaluating:  44%|████▍     | 306/699 [00:47<01:08,  5.70it/s]11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 307
Evaluating:  44%|████▍     | 307/699 [00:48<01:08,  5.73it/s]11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 308
Evaluating:  44%|████▍     | 308/699 [00:48<01:08,  5.75it/s]11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 309
Evaluating:  44%|████▍     | 309/699 [00:48<01:07,  5.75it/s]11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 310
Evaluating:  44%|████▍     | 310/699 [00:48<01:07,  5.77it/s]11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 311
Evaluating:  44%|████▍     | 311/699 [00:48<01:07,  5.76it/s]11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 312
Evaluating:  45%|████▍     | 312/699 [00:48<01:07,  5.75it/s]11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 313
Evaluating:  45%|████▍     | 313/699 [00:49<01:07,  5.75it/s]11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 314
Evaluating:  45%|████▍     | 314/699 [00:49<01:06,  5.76it/s]11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 315
Evaluating:  45%|████▌     | 315/699 [00:49<01:06,  5.76it/s]11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 316
Evaluating:  45%|████▌     | 316/699 [00:49<01:06,  5.76it/s]11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 317
Evaluating:  45%|████▌     | 317/699 [00:49<01:06,  5.74it/s]11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 318
Evaluating:  45%|████▌     | 318/699 [00:49<01:07,  5.61it/s]11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 319
Evaluating:  46%|████▌     | 319/699 [00:50<01:08,  5.58it/s]11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 320
Evaluating:  46%|████▌     | 320/699 [00:50<01:07,  5.61it/s]11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 321
Evaluating:  46%|████▌     | 321/699 [00:50<01:06,  5.65it/s]11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 322
Evaluating:  46%|████▌     | 322/699 [00:50<01:06,  5.68it/s]11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 323
Evaluating:  46%|████▌     | 323/699 [00:50<01:05,  5.70it/s]11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 324
Evaluating:  46%|████▋     | 324/699 [00:51<01:05,  5.70it/s]11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 325
Evaluating:  46%|████▋     | 325/699 [00:51<01:06,  5.65it/s]11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 326
Evaluating:  47%|████▋     | 326/699 [00:51<01:06,  5.64it/s]11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 327
Evaluating:  47%|████▋     | 327/699 [00:51<01:05,  5.65it/s]11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 328
Evaluating:  47%|████▋     | 328/699 [00:51<01:05,  5.67it/s]11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 329
Evaluating:  47%|████▋     | 329/699 [00:51<01:05,  5.69it/s]11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 330
Evaluating:  47%|████▋     | 330/699 [00:52<01:04,  5.68it/s]11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 331
Evaluating:  47%|████▋     | 331/699 [00:52<01:04,  5.67it/s]11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 332
Evaluating:  47%|████▋     | 332/699 [00:52<01:05,  5.60it/s]11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 333
Evaluating:  48%|████▊     | 333/699 [00:52<01:05,  5.55it/s]11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 334
Evaluating:  48%|████▊     | 334/699 [00:52<01:06,  5.52it/s]11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 335
Evaluating:  48%|████▊     | 335/699 [00:52<01:05,  5.56it/s]11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 336
Evaluating:  48%|████▊     | 336/699 [00:53<01:04,  5.60it/s]11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 337
Evaluating:  48%|████▊     | 337/699 [00:53<01:04,  5.63it/s]11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 338
Evaluating:  48%|████▊     | 338/699 [00:53<01:04,  5.64it/s]11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 339
Evaluating:  48%|████▊     | 339/699 [00:53<01:03,  5.64it/s]11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 340
Evaluating:  49%|████▊     | 340/699 [00:53<01:04,  5.58it/s]11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 341
Evaluating:  49%|████▉     | 341/699 [00:54<01:05,  5.50it/s]11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 342
Evaluating:  49%|████▉     | 342/699 [00:54<01:05,  5.48it/s]11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 343
Evaluating:  49%|████▉     | 343/699 [00:54<01:04,  5.53it/s]11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 344
Evaluating:  49%|████▉     | 344/699 [00:54<01:03,  5.57it/s]11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 345
Evaluating:  49%|████▉     | 345/699 [00:54<01:03,  5.59it/s]11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 346
Evaluating:  49%|████▉     | 346/699 [00:54<01:02,  5.61it/s]11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 347
Evaluating:  50%|████▉     | 347/699 [00:55<01:02,  5.62it/s]11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 348
Evaluating:  50%|████▉     | 348/699 [00:55<01:02,  5.60it/s]11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 349
Evaluating:  50%|████▉     | 349/699 [00:55<01:03,  5.50it/s]11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 350
Evaluating:  50%|█████     | 350/699 [00:55<01:04,  5.43it/s]11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 351
Evaluating:  50%|█████     | 351/699 [00:55<01:04,  5.43it/s]11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 352
Evaluating:  50%|█████     | 352/699 [00:56<01:03,  5.48it/s]11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 353
Evaluating:  51%|█████     | 353/699 [00:56<01:02,  5.52it/s]11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 354
Evaluating:  51%|█████     | 354/699 [00:56<01:02,  5.55it/s]11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 355
Evaluating:  51%|█████     | 355/699 [00:56<01:01,  5.56it/s]11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 356
Evaluating:  51%|█████     | 356/699 [00:56<01:01,  5.58it/s]11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 357
Evaluating:  51%|█████     | 357/699 [00:56<01:01,  5.58it/s]11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 358
Evaluating:  51%|█████     | 358/699 [00:57<01:02,  5.47it/s]11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 359
Evaluating:  51%|█████▏    | 359/699 [00:57<01:02,  5.45it/s]11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 360
Evaluating:  52%|█████▏    | 360/699 [00:57<01:01,  5.49it/s]11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 361
Evaluating:  52%|█████▏    | 361/699 [00:57<01:01,  5.52it/s]11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 362
Evaluating:  52%|█████▏    | 362/699 [00:57<01:00,  5.54it/s]11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 363
Evaluating:  52%|█████▏    | 363/699 [00:58<01:00,  5.56it/s]11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 364
Evaluating:  52%|█████▏    | 364/699 [00:58<01:00,  5.56it/s]11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 365
Evaluating:  52%|█████▏    | 365/699 [00:58<01:00,  5.56it/s]11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 366
Evaluating:  52%|█████▏    | 366/699 [00:58<01:01,  5.46it/s]11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 367
Evaluating:  53%|█████▎    | 367/699 [00:58<01:01,  5.38it/s]11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 368
Evaluating:  53%|█████▎    | 368/699 [00:58<01:02,  5.33it/s]11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 369
Evaluating:  53%|█████▎    | 369/699 [00:59<01:01,  5.38it/s]11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 370
Evaluating:  53%|█████▎    | 370/699 [00:59<01:00,  5.43it/s]11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 371
Evaluating:  53%|█████▎    | 371/699 [00:59<00:59,  5.47it/s]11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 372
Evaluating:  53%|█████▎    | 372/699 [00:59<00:59,  5.50it/s]11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 373
Evaluating:  53%|█████▎    | 373/699 [00:59<00:59,  5.51it/s]11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 374
Evaluating:  54%|█████▎    | 374/699 [01:00<00:58,  5.53it/s]11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 375
Evaluating:  54%|█████▎    | 375/699 [01:00<00:59,  5.47it/s]11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 376
Evaluating:  54%|█████▍    | 376/699 [01:00<01:00,  5.37it/s]11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 377
Evaluating:  54%|█████▍    | 377/699 [01:00<01:00,  5.31it/s]11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 378
Evaluating:  54%|█████▍    | 378/699 [01:00<00:59,  5.36it/s]11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 379
Evaluating:  54%|█████▍    | 379/699 [01:00<00:59,  5.41it/s]11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 380
Evaluating:  54%|█████▍    | 380/699 [01:01<00:58,  5.45it/s]11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 381
Evaluating:  55%|█████▍    | 381/699 [01:01<00:58,  5.48it/s]11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 382
Evaluating:  55%|█████▍    | 382/699 [01:01<00:57,  5.49it/s]11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 383
Evaluating:  55%|█████▍    | 383/699 [01:01<00:57,  5.50it/s]11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 384
Evaluating:  55%|█████▍    | 384/699 [01:01<00:57,  5.49it/s]11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 385
Evaluating:  55%|█████▌    | 385/699 [01:02<00:58,  5.40it/s]11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 386
Evaluating:  55%|█████▌    | 386/699 [01:02<00:58,  5.32it/s]11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 387
Evaluating:  55%|█████▌    | 387/699 [01:02<00:59,  5.26it/s]11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 388
Evaluating:  56%|█████▌    | 388/699 [01:02<00:58,  5.30it/s]11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 389
Evaluating:  56%|█████▌    | 389/699 [01:02<00:57,  5.36it/s]11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 390
Evaluating:  56%|█████▌    | 390/699 [01:03<00:57,  5.41it/s]11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 391
Evaluating:  56%|█████▌    | 391/699 [01:03<00:56,  5.42it/s]11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 392
Evaluating:  56%|█████▌    | 392/699 [01:03<00:56,  5.45it/s]11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 393
Evaluating:  56%|█████▌    | 393/699 [01:03<00:56,  5.46it/s]11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 394
Evaluating:  56%|█████▋    | 394/699 [01:03<00:55,  5.47it/s]11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 395
Evaluating:  57%|█████▋    | 395/699 [01:03<00:55,  5.46it/s]11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 396
Evaluating:  57%|█████▋    | 396/699 [01:04<00:56,  5.37it/s]11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 397
Evaluating:  57%|█████▋    | 397/699 [01:04<00:57,  5.28it/s]11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 398
Evaluating:  57%|█████▋    | 398/699 [01:04<00:57,  5.23it/s]11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 399
Evaluating:  57%|█████▋    | 399/699 [01:04<00:57,  5.20it/s]11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 400
Evaluating:  57%|█████▋    | 400/699 [01:04<00:57,  5.18it/s]11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 401
Evaluating:  57%|█████▋    | 401/699 [01:05<00:57,  5.22it/s]11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 402
Evaluating:  58%|█████▊    | 402/699 [01:05<00:56,  5.28it/s]11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 403
Evaluating:  58%|█████▊    | 403/699 [01:05<00:55,  5.33it/s]11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 404
Evaluating:  58%|█████▊    | 404/699 [01:05<00:54,  5.37it/s]11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 405
Evaluating:  58%|█████▊    | 405/699 [01:05<00:54,  5.39it/s]11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 406
Evaluating:  58%|█████▊    | 406/699 [01:06<00:54,  5.40it/s]11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 407
Evaluating:  58%|█████▊    | 407/699 [01:06<00:54,  5.39it/s]11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 408
Evaluating:  58%|█████▊    | 408/699 [01:06<00:54,  5.31it/s]11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 409
Evaluating:  59%|█████▊    | 409/699 [01:06<00:55,  5.23it/s]11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 410
Evaluating:  59%|█████▊    | 410/699 [01:06<00:56,  5.14it/s]11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 411
Evaluating:  59%|█████▉    | 411/699 [01:06<00:56,  5.10it/s]11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 412
Evaluating:  59%|█████▉    | 412/699 [01:07<00:56,  5.09it/s]11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 413
Evaluating:  59%|█████▉    | 413/699 [01:07<00:56,  5.09it/s]11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 414
Evaluating:  59%|█████▉    | 414/699 [01:07<00:56,  5.09it/s]11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 415
Evaluating:  59%|█████▉    | 415/699 [01:07<00:55,  5.13it/s]11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 416
Evaluating:  60%|█████▉    | 416/699 [01:07<00:54,  5.18it/s]11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 417
Evaluating:  60%|█████▉    | 417/699 [01:08<00:53,  5.27it/s]11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 418
Evaluating:  60%|█████▉    | 418/699 [01:08<00:53,  5.30it/s]11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 419
Evaluating:  60%|█████▉    | 419/699 [01:08<00:52,  5.34it/s]11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 420
Evaluating:  60%|██████    | 420/699 [01:08<00:52,  5.35it/s]11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 421
Evaluating:  60%|██████    | 421/699 [01:08<00:51,  5.37it/s]11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 422
Evaluating:  60%|██████    | 422/699 [01:09<00:51,  5.37it/s]11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 423
Evaluating:  61%|██████    | 423/699 [01:09<00:51,  5.38it/s]11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 424
Evaluating:  61%|██████    | 424/699 [01:09<00:51,  5.35it/s]11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 425
Evaluating:  61%|██████    | 425/699 [01:09<00:52,  5.26it/s]11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 426
Evaluating:  61%|██████    | 426/699 [01:09<00:52,  5.18it/s]11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 427
Evaluating:  61%|██████    | 427/699 [01:10<00:53,  5.13it/s]11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 428
Evaluating:  61%|██████    | 428/699 [01:10<00:52,  5.12it/s]11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 429
Evaluating:  61%|██████▏   | 429/699 [01:10<00:52,  5.16it/s]11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 430
Evaluating:  62%|██████▏   | 430/699 [01:10<00:51,  5.22it/s]11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 431
Evaluating:  62%|██████▏   | 431/699 [01:10<00:50,  5.26it/s]11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 432
Evaluating:  62%|██████▏   | 432/699 [01:10<00:50,  5.29it/s]11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 433
Evaluating:  62%|██████▏   | 433/699 [01:11<00:50,  5.30it/s]11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 434
Evaluating:  62%|██████▏   | 434/699 [01:11<00:49,  5.32it/s]11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 435
Evaluating:  62%|██████▏   | 435/699 [01:11<00:49,  5.34it/s]11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 436
Evaluating:  62%|██████▏   | 436/699 [01:11<00:49,  5.35it/s]11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 437
Evaluating:  63%|██████▎   | 437/699 [01:11<00:48,  5.36it/s]11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 438
Evaluating:  63%|██████▎   | 438/699 [01:12<00:49,  5.27it/s]11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 439
Evaluating:  63%|██████▎   | 439/699 [01:12<00:50,  5.18it/s]11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 440
Evaluating:  63%|██████▎   | 440/699 [01:12<00:50,  5.12it/s]11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 441
Evaluating:  63%|██████▎   | 441/699 [01:12<00:50,  5.09it/s]11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 442
Evaluating:  63%|██████▎   | 442/699 [01:12<00:50,  5.06it/s]11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 443
Evaluating:  63%|██████▎   | 443/699 [01:13<00:50,  5.04it/s]11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 444
Evaluating:  64%|██████▎   | 444/699 [01:13<00:50,  5.02it/s]11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 445
Evaluating:  64%|██████▎   | 445/699 [01:13<00:50,  5.08it/s]11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 446
Evaluating:  64%|██████▍   | 446/699 [01:13<00:49,  5.14it/s]11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 447
Evaluating:  64%|██████▍   | 447/699 [01:13<00:48,  5.19it/s]11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 448
Evaluating:  64%|██████▍   | 448/699 [01:14<00:48,  5.23it/s]11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 449
Evaluating:  64%|██████▍   | 449/699 [01:14<00:47,  5.25it/s]11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 450
Evaluating:  64%|██████▍   | 450/699 [01:14<00:47,  5.27it/s]11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 451
Evaluating:  65%|██████▍   | 451/699 [01:14<00:46,  5.28it/s]11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 452
Evaluating:  65%|██████▍   | 452/699 [01:14<00:46,  5.29it/s]11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 453
Evaluating:  65%|██████▍   | 453/699 [01:15<00:46,  5.29it/s]11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 454
Evaluating:  65%|██████▍   | 454/699 [01:15<00:46,  5.29it/s]11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 455
Evaluating:  65%|██████▌   | 455/699 [01:15<00:46,  5.27it/s]11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 456
Evaluating:  65%|██████▌   | 456/699 [01:15<00:47,  5.17it/s]11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 457
Evaluating:  65%|██████▌   | 457/699 [01:15<00:47,  5.10it/s]11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 458
Evaluating:  66%|██████▌   | 458/699 [01:15<00:47,  5.05it/s]11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 459
Evaluating:  66%|██████▌   | 459/699 [01:16<00:47,  5.02it/s]11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 460
Evaluating:  66%|██████▌   | 460/699 [01:16<00:47,  4.99it/s]11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 461
Evaluating:  66%|██████▌   | 461/699 [01:16<00:47,  4.98it/s]11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 462
Evaluating:  66%|██████▌   | 462/699 [01:16<00:47,  4.97it/s]11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 463
Evaluating:  66%|██████▌   | 463/699 [01:17<00:47,  4.96it/s]11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 464
Evaluating:  66%|██████▋   | 464/699 [01:17<00:47,  4.95it/s]11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 465
Evaluating:  67%|██████▋   | 465/699 [01:17<00:47,  4.94it/s]11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 466
Evaluating:  67%|██████▋   | 466/699 [01:17<00:47,  4.93it/s]11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 467
Evaluating:  67%|██████▋   | 467/699 [01:17<00:46,  4.95it/s]11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 468
Evaluating:  67%|██████▋   | 468/699 [01:18<00:46,  4.94it/s]11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 469
Evaluating:  67%|██████▋   | 469/699 [01:18<00:46,  4.92it/s]11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 470
Evaluating:  67%|██████▋   | 470/699 [01:18<00:46,  4.93it/s]11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 471
Evaluating:  67%|██████▋   | 471/699 [01:18<00:46,  4.96it/s]11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 472
Evaluating:  68%|██████▊   | 472/699 [01:18<00:45,  4.99it/s]11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 473
Evaluating:  68%|██████▊   | 473/699 [01:19<00:44,  5.04it/s]11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 474
Evaluating:  68%|██████▊   | 474/699 [01:19<00:44,  5.11it/s]11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 475
Evaluating:  68%|██████▊   | 475/699 [01:19<00:43,  5.15it/s]11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 476
Evaluating:  68%|██████▊   | 476/699 [01:19<00:43,  5.18it/s]11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 477
Evaluating:  68%|██████▊   | 477/699 [01:19<00:42,  5.19it/s]11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 478
Evaluating:  68%|██████▊   | 478/699 [01:19<00:42,  5.19it/s]11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 479
Evaluating:  69%|██████▊   | 479/699 [01:20<00:42,  5.20it/s]11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 480
Evaluating:  69%|██████▊   | 480/699 [01:20<00:42,  5.20it/s]11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 481
Evaluating:  69%|██████▉   | 481/699 [01:20<00:41,  5.20it/s]11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 482
Evaluating:  69%|██████▉   | 482/699 [01:20<00:41,  5.20it/s]11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 483
Evaluating:  69%|██████▉   | 483/699 [01:20<00:41,  5.21it/s]11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 484
Evaluating:  69%|██████▉   | 484/699 [01:21<00:41,  5.17it/s]11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 485
Evaluating:  69%|██████▉   | 485/699 [01:21<00:42,  5.08it/s]11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 486
Evaluating:  70%|██████▉   | 486/699 [01:21<00:42,  5.01it/s]11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 487
Evaluating:  70%|██████▉   | 487/699 [01:21<00:42,  4.96it/s]11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 488
Evaluating:  70%|██████▉   | 488/699 [01:21<00:42,  4.93it/s]11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 489
Evaluating:  70%|██████▉   | 489/699 [01:22<00:42,  4.91it/s]11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 490
Evaluating:  70%|███████   | 490/699 [01:22<00:42,  4.89it/s]11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 491
Evaluating:  70%|███████   | 491/699 [01:22<00:42,  4.90it/s]11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 492
Evaluating:  70%|███████   | 492/699 [01:22<00:41,  4.93it/s]11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 493
Evaluating:  71%|███████   | 493/699 [01:22<00:41,  4.95it/s]11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 494
Evaluating:  71%|███████   | 494/699 [01:23<00:41,  4.96it/s]11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 495
Evaluating:  71%|███████   | 495/699 [01:23<00:41,  4.93it/s]11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 496
Evaluating:  71%|███████   | 496/699 [01:23<00:41,  4.91it/s]11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 497
Evaluating:  71%|███████   | 497/699 [01:23<00:40,  4.94it/s]11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 498
Evaluating:  71%|███████   | 498/699 [01:23<00:40,  4.99it/s]11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 499
Evaluating:  71%|███████▏  | 499/699 [01:24<00:39,  5.03it/s]11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 500
Evaluating:  72%|███████▏  | 500/699 [01:24<00:39,  5.07it/s]11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 501
Evaluating:  72%|███████▏  | 501/699 [01:24<00:38,  5.09it/s]11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 502
Evaluating:  72%|███████▏  | 502/699 [01:24<00:40,  4.88it/s]11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 503
Evaluating:  72%|███████▏  | 503/699 [01:24<00:39,  4.96it/s]11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 504
Evaluating:  72%|███████▏  | 504/699 [01:25<00:38,  5.02it/s]11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 505
Evaluating:  72%|███████▏  | 505/699 [01:25<00:38,  5.05it/s]11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 506
Evaluating:  72%|███████▏  | 506/699 [01:25<00:38,  5.07it/s]11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 507
Evaluating:  73%|███████▎  | 507/699 [01:25<00:37,  5.09it/s]11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 508
Evaluating:  73%|███████▎  | 508/699 [01:25<00:37,  5.10it/s]11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 509
Evaluating:  73%|███████▎  | 509/699 [01:26<00:37,  5.11it/s]11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 510
Evaluating:  73%|███████▎  | 510/699 [01:26<00:36,  5.11it/s]11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 511
Evaluating:  73%|███████▎  | 511/699 [01:26<00:36,  5.11it/s]11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 512
Evaluating:  73%|███████▎  | 512/699 [01:26<00:36,  5.12it/s]11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 513
Evaluating:  73%|███████▎  | 513/699 [01:26<00:36,  5.11it/s]11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 514
Evaluating:  74%|███████▎  | 514/699 [01:27<00:36,  5.11it/s]11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 515
Evaluating:  74%|███████▎  | 515/699 [01:27<00:36,  5.11it/s]11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 516
Evaluating:  74%|███████▍  | 516/699 [01:27<00:35,  5.11it/s]11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 517
Evaluating:  74%|███████▍  | 517/699 [01:27<00:35,  5.11it/s]11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 518
Evaluating:  74%|███████▍  | 518/699 [01:27<00:35,  5.04it/s]11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 519
Evaluating:  74%|███████▍  | 519/699 [01:28<00:36,  4.96it/s]11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 520
Evaluating:  74%|███████▍  | 520/699 [01:28<00:36,  4.90it/s]11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 521
Evaluating:  75%|███████▍  | 521/699 [01:28<00:36,  4.91it/s]11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 522
Evaluating:  75%|███████▍  | 522/699 [01:28<00:35,  4.92it/s]11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 523
Evaluating:  75%|███████▍  | 523/699 [01:28<00:36,  4.87it/s]11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 524
Evaluating:  75%|███████▍  | 524/699 [01:29<00:35,  4.91it/s]11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 525
Evaluating:  75%|███████▌  | 525/699 [01:29<00:35,  4.97it/s]11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 526
Evaluating:  75%|███████▌  | 526/699 [01:29<00:34,  5.00it/s]11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 527
Evaluating:  75%|███████▌  | 527/699 [01:29<00:36,  4.67it/s]11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 528
Evaluating:  76%|███████▌  | 528/699 [01:29<00:35,  4.77it/s]11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 529
Evaluating:  76%|███████▌  | 529/699 [01:30<00:35,  4.85it/s]11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 530
Evaluating:  76%|███████▌  | 530/699 [01:30<00:34,  4.91it/s]11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 531
Evaluating:  76%|███████▌  | 531/699 [01:30<00:33,  4.96it/s]11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 532
Evaluating:  76%|███████▌  | 532/699 [01:30<00:33,  4.96it/s]11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 533
Evaluating:  76%|███████▋  | 533/699 [01:30<00:33,  4.96it/s]11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 534
Evaluating:  76%|███████▋  | 534/699 [01:31<00:33,  4.99it/s]11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 535
Evaluating:  77%|███████▋  | 535/699 [01:31<00:33,  4.97it/s]11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 536
Evaluating:  77%|███████▋  | 536/699 [01:31<00:32,  4.98it/s]11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 537
Evaluating:  77%|███████▋  | 537/699 [01:31<00:33,  4.91it/s]11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 538
Evaluating:  77%|███████▋  | 538/699 [01:32<00:33,  4.85it/s]11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 539
Evaluating:  77%|███████▋  | 539/699 [01:32<00:33,  4.83it/s]11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 540
Evaluating:  77%|███████▋  | 540/699 [01:32<00:33,  4.80it/s]11/21/2021 13:19:18 - INFO - __main__ -   Batch number = 541
Evaluating:  77%|███████▋  | 541/699 [01:32<00:33,  4.77it/s]11/21/2021 13:19:18 - INFO - __main__ -   Batch number = 542
Evaluating:  78%|███████▊  | 542/699 [01:32<00:32,  4.79it/s]11/21/2021 13:19:18 - INFO - __main__ -   Batch number = 543
Evaluating:  78%|███████▊  | 543/699 [01:33<00:32,  4.81it/s]11/21/2021 13:19:18 - INFO - __main__ -   Batch number = 544
Evaluating:  78%|███████▊  | 544/699 [01:33<00:32,  4.83it/s]11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 545
Evaluating:  78%|███████▊  | 545/699 [01:33<00:31,  4.81it/s]11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 546
Evaluating:  78%|███████▊  | 546/699 [01:33<00:31,  4.78it/s]11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 547
Evaluating:  78%|███████▊  | 547/699 [01:33<00:31,  4.78it/s]11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 548
Evaluating:  78%|███████▊  | 548/699 [01:34<00:31,  4.83it/s]11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 549
Evaluating:  79%|███████▊  | 549/699 [01:34<00:30,  4.89it/s]11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 550
Evaluating:  79%|███████▊  | 550/699 [01:34<00:30,  4.93it/s]11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 551
Evaluating:  79%|███████▉  | 551/699 [01:34<00:29,  4.95it/s]11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 552
Evaluating:  79%|███████▉  | 552/699 [01:34<00:29,  4.97it/s]11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 553
Evaluating:  79%|███████▉  | 553/699 [01:35<00:29,  4.97it/s]11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 554
Evaluating:  79%|███████▉  | 554/699 [01:35<00:29,  4.98it/s]11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 555
Evaluating:  79%|███████▉  | 555/699 [01:35<00:29,  4.95it/s]11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 556
Evaluating:  80%|███████▉  | 556/699 [01:35<00:29,  4.89it/s]11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 557
Evaluating:  80%|███████▉  | 557/699 [01:35<00:29,  4.83it/s]11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 558
Evaluating:  80%|███████▉  | 558/699 [01:36<00:29,  4.78it/s]11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 559
Evaluating:  80%|███████▉  | 559/699 [01:36<00:29,  4.76it/s]11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 560
Evaluating:  80%|████████  | 560/699 [01:36<00:29,  4.78it/s]11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 561
Evaluating:  80%|████████  | 561/699 [01:36<00:28,  4.80it/s]11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 562
Evaluating:  80%|████████  | 562/699 [01:36<00:28,  4.77it/s]11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 563
Evaluating:  81%|████████  | 563/699 [01:37<00:28,  4.75it/s]11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 564
Evaluating:  81%|████████  | 564/699 [01:37<00:28,  4.78it/s]11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 565
Evaluating:  81%|████████  | 565/699 [01:37<00:27,  4.83it/s]11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 566
Evaluating:  81%|████████  | 566/699 [01:37<00:27,  4.87it/s]11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 567
Evaluating:  81%|████████  | 567/699 [01:37<00:26,  4.90it/s]11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 568
Evaluating:  81%|████████▏ | 568/699 [01:38<00:26,  4.91it/s]11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 569
Evaluating:  81%|████████▏ | 569/699 [01:38<00:26,  4.94it/s]11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 570
Evaluating:  82%|████████▏ | 570/699 [01:38<00:26,  4.94it/s]11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 571
Evaluating:  82%|████████▏ | 571/699 [01:38<00:25,  4.94it/s]11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 572
Evaluating:  82%|████████▏ | 572/699 [01:39<00:25,  4.94it/s]11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 573
Evaluating:  82%|████████▏ | 573/699 [01:39<00:25,  4.95it/s]11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 574
Evaluating:  82%|████████▏ | 574/699 [01:39<00:25,  4.95it/s]11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 575
Evaluating:  82%|████████▏ | 575/699 [01:39<00:25,  4.94it/s]11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 576
Evaluating:  82%|████████▏ | 576/699 [01:39<00:24,  4.94it/s]11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 577
Evaluating:  83%|████████▎ | 577/699 [01:40<00:24,  4.93it/s]11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 578
Evaluating:  83%|████████▎ | 578/699 [01:40<00:24,  4.94it/s]11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 579
Evaluating:  83%|████████▎ | 579/699 [01:40<00:24,  4.93it/s]11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 580
Evaluating:  83%|████████▎ | 580/699 [01:40<00:24,  4.84it/s]11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 581
Evaluating:  83%|████████▎ | 581/699 [01:40<00:24,  4.86it/s]11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 582
Evaluating:  83%|████████▎ | 582/699 [01:41<00:23,  4.88it/s]11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 583
Evaluating:  83%|████████▎ | 583/699 [01:41<00:23,  4.88it/s]11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 584
Evaluating:  84%|████████▎ | 584/699 [01:41<00:23,  4.90it/s]11/21/2021 13:19:27 - INFO - __main__ -   Batch number = 585
Evaluating:  84%|████████▎ | 585/699 [01:41<00:23,  4.90it/s]11/21/2021 13:19:27 - INFO - __main__ -   Batch number = 586
Evaluating:  84%|████████▍ | 586/699 [01:41<00:23,  4.89it/s]11/21/2021 13:19:27 - INFO - __main__ -   Batch number = 587
Evaluating:  84%|████████▍ | 587/699 [01:42<00:22,  4.89it/s]11/21/2021 13:19:27 - INFO - __main__ -   Batch number = 588
Evaluating:  84%|████████▍ | 588/699 [01:42<00:22,  4.90it/s]11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 589
Evaluating:  84%|████████▍ | 589/699 [01:42<00:22,  4.89it/s]11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 590
Evaluating:  84%|████████▍ | 590/699 [01:42<00:22,  4.90it/s]11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 591
Evaluating:  85%|████████▍ | 591/699 [01:42<00:22,  4.84it/s]11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 592
Evaluating:  85%|████████▍ | 592/699 [01:43<00:22,  4.86it/s]11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 593
Evaluating:  85%|████████▍ | 593/699 [01:43<00:21,  4.87it/s]11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 594
Evaluating:  85%|████████▍ | 594/699 [01:43<00:21,  4.88it/s]11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 595
Evaluating:  85%|████████▌ | 595/699 [01:43<00:21,  4.88it/s]11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 596
Evaluating:  85%|████████▌ | 596/699 [01:43<00:21,  4.88it/s]11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 597
Evaluating:  85%|████████▌ | 597/699 [01:44<00:20,  4.88it/s]11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 598
Evaluating:  86%|████████▌ | 598/699 [01:44<00:20,  4.87it/s]11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 599
Evaluating:  86%|████████▌ | 599/699 [01:44<00:20,  4.87it/s]11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 600
Evaluating:  86%|████████▌ | 600/699 [01:44<00:20,  4.87it/s]11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 601
Evaluating:  86%|████████▌ | 601/699 [01:44<00:20,  4.84it/s]11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 602
Evaluating:  86%|████████▌ | 602/699 [01:45<00:19,  4.86it/s]11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 603
Evaluating:  86%|████████▋ | 603/699 [01:45<00:19,  4.85it/s]11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 604
Evaluating:  86%|████████▋ | 604/699 [01:45<00:19,  4.85it/s]11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 605
Evaluating:  87%|████████▋ | 605/699 [01:45<00:19,  4.87it/s]11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 606
Evaluating:  87%|████████▋ | 606/699 [01:45<00:19,  4.82it/s]11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 607
Evaluating:  87%|████████▋ | 607/699 [01:46<00:19,  4.82it/s]11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 608
Evaluating:  87%|████████▋ | 608/699 [01:46<00:18,  4.83it/s]11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 609
Evaluating:  87%|████████▋ | 609/699 [01:46<00:18,  4.84it/s]11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 610
Evaluating:  87%|████████▋ | 610/699 [01:46<00:18,  4.84it/s]11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 611
Evaluating:  87%|████████▋ | 611/699 [01:47<00:18,  4.85it/s]11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 612
Evaluating:  88%|████████▊ | 612/699 [01:47<00:18,  4.83it/s]11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 613
Evaluating:  88%|████████▊ | 613/699 [01:47<00:17,  4.84it/s]11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 614
Evaluating:  88%|████████▊ | 614/699 [01:47<00:17,  4.84it/s]11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 615
Evaluating:  88%|████████▊ | 615/699 [01:47<00:17,  4.84it/s]11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 616
Evaluating:  88%|████████▊ | 616/699 [01:48<00:17,  4.82it/s]11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 617
Evaluating:  88%|████████▊ | 617/699 [01:48<00:16,  4.83it/s]11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 618
Evaluating:  88%|████████▊ | 618/699 [01:48<00:16,  4.83it/s]11/21/2021 13:19:34 - INFO - __main__ -   Batch number = 619
Evaluating:  89%|████████▊ | 619/699 [01:48<00:16,  4.77it/s]11/21/2021 13:19:34 - INFO - __main__ -   Batch number = 620
Evaluating:  89%|████████▊ | 620/699 [01:48<00:16,  4.78it/s]11/21/2021 13:19:34 - INFO - __main__ -   Batch number = 621
Evaluating:  89%|████████▉ | 621/699 [01:49<00:16,  4.79it/s]11/21/2021 13:19:34 - INFO - __main__ -   Batch number = 622
Evaluating:  89%|████████▉ | 622/699 [01:49<00:16,  4.79it/s]11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 623
Evaluating:  89%|████████▉ | 623/699 [01:49<00:15,  4.80it/s]11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 624
Evaluating:  89%|████████▉ | 624/699 [01:49<00:15,  4.81it/s]11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 625
Evaluating:  89%|████████▉ | 625/699 [01:49<00:15,  4.79it/s]11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 626
Evaluating:  90%|████████▉ | 626/699 [01:50<00:15,  4.80it/s]11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 627
Evaluating:  90%|████████▉ | 627/699 [01:50<00:14,  4.80it/s]11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 628
Evaluating:  90%|████████▉ | 628/699 [01:50<00:14,  4.80it/s]11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 629
Evaluating:  90%|████████▉ | 629/699 [01:50<00:14,  4.79it/s]11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 630
Evaluating:  90%|█████████ | 630/699 [01:50<00:14,  4.79it/s]11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 631
Evaluating:  90%|█████████ | 631/699 [01:51<00:14,  4.78it/s]11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 632
Evaluating:  90%|█████████ | 632/699 [01:51<00:13,  4.79it/s]11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 633
Evaluating:  91%|█████████ | 633/699 [01:51<00:13,  4.80it/s]11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 634
Evaluating:  91%|█████████ | 634/699 [01:51<00:13,  4.78it/s]11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 635
Evaluating:  91%|█████████ | 635/699 [01:52<00:13,  4.78it/s]11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 636
Evaluating:  91%|█████████ | 636/699 [01:52<00:13,  4.72it/s]11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 637
Evaluating:  91%|█████████ | 637/699 [01:52<00:13,  4.71it/s]11/21/2021 13:19:38 - INFO - __main__ -   Batch number = 638
Evaluating:  91%|█████████▏| 638/699 [01:52<00:12,  4.70it/s]11/21/2021 13:19:38 - INFO - __main__ -   Batch number = 639
Evaluating:  91%|█████████▏| 639/699 [01:52<00:12,  4.66it/s]11/21/2021 13:19:38 - INFO - __main__ -   Batch number = 640
Evaluating:  92%|█████████▏| 640/699 [01:53<00:12,  4.69it/s]11/21/2021 13:19:38 - INFO - __main__ -   Batch number = 641
Evaluating:  92%|█████████▏| 641/699 [01:53<00:12,  4.71it/s]11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 642
Evaluating:  92%|█████████▏| 642/699 [01:53<00:12,  4.73it/s]11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 643
Evaluating:  92%|█████████▏| 643/699 [01:53<00:11,  4.73it/s]11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 644
Evaluating:  92%|█████████▏| 644/699 [01:53<00:11,  4.65it/s]11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 645
Evaluating:  92%|█████████▏| 645/699 [01:54<00:11,  4.60it/s]11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 646
Evaluating:  92%|█████████▏| 646/699 [01:54<00:11,  4.55it/s]11/21/2021 13:19:40 - INFO - __main__ -   Batch number = 647
Evaluating:  93%|█████████▎| 647/699 [01:54<00:11,  4.56it/s]11/21/2021 13:19:40 - INFO - __main__ -   Batch number = 648
Evaluating:  93%|█████████▎| 648/699 [01:54<00:11,  4.52it/s]11/21/2021 13:19:40 - INFO - __main__ -   Batch number = 649
Evaluating:  93%|█████████▎| 649/699 [01:55<00:11,  4.51it/s]11/21/2021 13:19:40 - INFO - __main__ -   Batch number = 650
Evaluating:  93%|█████████▎| 650/699 [01:55<00:10,  4.50it/s]11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 651
Evaluating:  93%|█████████▎| 651/699 [01:55<00:10,  4.50it/s]11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 652
Evaluating:  93%|█████████▎| 652/699 [01:55<00:10,  4.51it/s]11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 653
Evaluating:  93%|█████████▎| 653/699 [01:55<00:10,  4.54it/s]11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 654
Evaluating:  94%|█████████▎| 654/699 [01:56<00:09,  4.58it/s]11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 655
Evaluating:  94%|█████████▎| 655/699 [01:56<00:09,  4.61it/s]11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 656
Evaluating:  94%|█████████▍| 656/699 [01:56<00:09,  4.65it/s]11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 657
Evaluating:  94%|█████████▍| 657/699 [01:56<00:09,  4.67it/s]11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 658
Evaluating:  94%|█████████▍| 658/699 [01:57<00:08,  4.67it/s]11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 659
Evaluating:  94%|█████████▍| 659/699 [01:57<00:08,  4.65it/s]11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 660
Evaluating:  94%|█████████▍| 660/699 [01:57<00:08,  4.63it/s]11/21/2021 13:19:43 - INFO - __main__ -   Batch number = 661
Evaluating:  95%|█████████▍| 661/699 [01:57<00:08,  4.65it/s]11/21/2021 13:19:43 - INFO - __main__ -   Batch number = 662
Evaluating:  95%|█████████▍| 662/699 [01:57<00:07,  4.65it/s]11/21/2021 13:19:43 - INFO - __main__ -   Batch number = 663
Evaluating:  95%|█████████▍| 663/699 [01:58<00:07,  4.66it/s]11/21/2021 13:19:43 - INFO - __main__ -   Batch number = 664
Evaluating:  95%|█████████▍| 664/699 [01:58<00:07,  4.67it/s]11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 665
Evaluating:  95%|█████████▌| 665/699 [01:58<00:07,  4.67it/s]11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 666
Evaluating:  95%|█████████▌| 666/699 [01:58<00:07,  4.68it/s]11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 667
Evaluating:  95%|█████████▌| 667/699 [01:58<00:06,  4.66it/s]11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 668
Evaluating:  96%|█████████▌| 668/699 [01:59<00:06,  4.67it/s]11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 669
Evaluating:  96%|█████████▌| 669/699 [01:59<00:06,  4.67it/s]11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 670
Evaluating:  96%|█████████▌| 670/699 [01:59<00:06,  4.67it/s]11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 671
Evaluating:  96%|█████████▌| 671/699 [01:59<00:06,  4.46it/s]11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 672
Evaluating:  96%|█████████▌| 672/699 [02:00<00:05,  4.54it/s]11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 673
Evaluating:  96%|█████████▋| 673/699 [02:00<00:05,  4.56it/s]11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 674
Evaluating:  96%|█████████▋| 674/699 [02:00<00:05,  4.60it/s]11/21/2021 13:19:46 - INFO - __main__ -   Batch number = 675
Evaluating:  97%|█████████▋| 675/699 [02:00<00:05,  4.63it/s]11/21/2021 13:19:46 - INFO - __main__ -   Batch number = 676
Evaluating:  97%|█████████▋| 676/699 [02:00<00:04,  4.64it/s]11/21/2021 13:19:46 - INFO - __main__ -   Batch number = 677
Evaluating:  97%|█████████▋| 677/699 [02:01<00:04,  4.62it/s]11/21/2021 13:19:46 - INFO - __main__ -   Batch number = 678
Evaluating:  97%|█████████▋| 678/699 [02:01<00:04,  4.60it/s]11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 679
Evaluating:  97%|█████████▋| 679/699 [02:01<00:04,  4.61it/s]11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 680
Evaluating:  97%|█████████▋| 680/699 [02:01<00:04,  4.62it/s]11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 681
Evaluating:  97%|█████████▋| 681/699 [02:01<00:03,  4.63it/s]11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 682
Evaluating:  98%|█████████▊| 682/699 [02:02<00:03,  4.62it/s]11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 683
Evaluating:  98%|█████████▊| 683/699 [02:02<00:03,  4.64it/s]11/21/2021 13:19:48 - INFO - __main__ -   Batch number = 684
Evaluating:  98%|█████████▊| 684/699 [02:02<00:03,  4.64it/s]11/21/2021 13:19:48 - INFO - __main__ -   Batch number = 685
Evaluating:  98%|█████████▊| 685/699 [02:02<00:03,  4.63it/s]11/21/2021 13:19:48 - INFO - __main__ -   Batch number = 686
Evaluating:  98%|█████████▊| 686/699 [02:03<00:02,  4.62it/s]11/21/2021 13:19:48 - INFO - __main__ -   Batch number = 687
Evaluating:  98%|█████████▊| 687/699 [02:03<00:02,  4.64it/s]11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 688
Evaluating:  98%|█████████▊| 688/699 [02:03<00:02,  4.63it/s]11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 689
Evaluating:  99%|█████████▊| 689/699 [02:03<00:02,  4.64it/s]11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 690
Evaluating:  99%|█████████▊| 690/699 [02:03<00:01,  4.65it/s]11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 691
Evaluating:  99%|█████████▉| 691/699 [02:04<00:01,  4.64it/s]11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 692
Evaluating:  99%|█████████▉| 692/699 [02:04<00:01,  4.64it/s]11/21/2021 13:19:50 - INFO - __main__ -   Batch number = 693
Evaluating:  99%|█████████▉| 693/699 [02:04<00:01,  4.64it/s]11/21/2021 13:19:50 - INFO - __main__ -   Batch number = 694
Evaluating:  99%|█████████▉| 694/699 [02:04<00:01,  4.26it/s]11/21/2021 13:19:50 - INFO - __main__ -   Batch number = 695
Evaluating:  99%|█████████▉| 695/699 [02:05<00:00,  4.37it/s]11/21/2021 13:19:50 - INFO - __main__ -   Batch number = 696
Evaluating: 100%|█████████▉| 696/699 [02:05<00:00,  4.45it/s]11/21/2021 13:19:51 - INFO - __main__ -   Batch number = 697
Evaluating: 100%|█████████▉| 697/699 [02:05<00:00,  4.49it/s]11/21/2021 13:19:51 - INFO - __main__ -   Batch number = 698
Evaluating: 100%|█████████▉| 698/699 [02:05<00:00,  4.52it/s]11/21/2021 13:19:51 - INFO - __main__ -   Batch number = 699
Evaluating: 100%|██████████| 699/699 [02:05<00:00,  4.76it/s]Evaluating: 100%|██████████| 699/699 [02:05<00:00,  5.55it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/21/2021 13:20:01 - INFO - __main__ -   ***** Evaluation result  in de *****
11/21/2021 13:20:01 - INFO - __main__ -     f1 = 0.852800798905937
11/21/2021 13:20:01 - INFO - __main__ -     loss = 0.5621825033673572
11/21/2021 13:20:01 - INFO - __main__ -     precision = 0.8578727734835032
11/21/2021 13:20:01 - INFO - __main__ -     recall = 0.8477884455872594
116.00user 45.32system 2:32.47elapsed 105%CPU (0avgtext+0avgdata 3871276maxresident)k
0inputs+4248outputs (0major+1809571minor)pagefaults 0swaps
PyTorch version 1.9.0+cu102 available.
11/21/2021 13:20:03 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:20:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/21/2021 13:20:03 - INFO - __main__ -   Seed = 3
11/21/2021 13:20:03 - INFO - root -   save model
11/21/2021 13:20:03 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:20:03 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
11/21/2021 13:20:05 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/21/2021 13:20:11 - INFO - __main__ -   Using lang2id = None
11/21/2021 13:20:11 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/21/2021 13:20:11 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
11/21/2021 13:20:11 - INFO - root -   Trying to decide if add adapter
11/21/2021 13:20:11 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_model_head.bin
11/21/2021 13:20:11 - INFO - root -   loading lang adpater hi/wiki@ukp
11/21/2021 13:20:11 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/21/2021 13:20:11 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/21/2021 13:20:11 - INFO - __main__ -   Language = hi
11/21/2021 13:20:11 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
11/21/2021 13:20:14 - INFO - __main__ -   Language adapter for de not found, using hi instead
11/21/2021 13:20:14 - INFO - __main__ -   Set active language adapter to hi
11/21/2021 13:20:14 - INFO - __main__ -   Args Adapter Weight = None
11/21/2021 13:20:14 - INFO - __main__ -   Adapter Languages = ['hi']
11/21/2021 13:20:14 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_de_bert-base-multilingual-cased_128
11/21/2021 13:20:17 - INFO - __main__ -   ***** Running evaluation  in de *****
11/21/2021 13:20:17 - INFO - __main__ -     Num examples = 22360
11/21/2021 13:20:17 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/699 [00:00<?, ?it/s]11/21/2021 13:20:17 - INFO - __main__ -   Batch number = 1
Evaluating:   0%|          | 1/699 [00:00<01:47,  6.50it/s]11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 2
Evaluating:   0%|          | 2/699 [00:00<01:43,  6.76it/s]11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 3
Evaluating:   0%|          | 3/699 [00:00<01:39,  6.97it/s]11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 4
Evaluating:   1%|          | 4/699 [00:00<01:37,  7.12it/s]11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 5
Evaluating:   1%|          | 5/699 [00:00<01:36,  7.19it/s]11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 6
Evaluating:   1%|          | 6/699 [00:00<01:35,  7.25it/s]11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 7
Evaluating:   1%|          | 7/699 [00:00<01:34,  7.29it/s]11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 8
Evaluating:   1%|          | 8/699 [00:01<01:34,  7.30it/s]11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 9
Evaluating:   1%|▏         | 9/699 [00:01<01:34,  7.30it/s]11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 10
Evaluating:   1%|▏         | 10/699 [00:01<01:34,  7.30it/s]11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 11
Evaluating:   2%|▏         | 11/699 [00:01<01:34,  7.31it/s]11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 12
Evaluating:   2%|▏         | 12/699 [00:01<01:33,  7.31it/s]11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 13
Evaluating:   2%|▏         | 13/699 [00:01<01:33,  7.32it/s]11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 14
Evaluating:   2%|▏         | 14/699 [00:01<01:33,  7.33it/s]11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 15
Evaluating:   2%|▏         | 15/699 [00:02<01:33,  7.33it/s]11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 16
Evaluating:   2%|▏         | 16/699 [00:02<01:33,  7.33it/s]11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 17
Evaluating:   2%|▏         | 17/699 [00:02<01:33,  7.31it/s]11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 18
Evaluating:   3%|▎         | 18/699 [00:02<01:33,  7.30it/s]11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 19
Evaluating:   3%|▎         | 19/699 [00:02<01:33,  7.27it/s]11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 20
Evaluating:   3%|▎         | 20/699 [00:02<01:33,  7.28it/s]11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 21
Evaluating:   3%|▎         | 21/699 [00:02<01:33,  7.29it/s]11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 22
Evaluating:   3%|▎         | 22/699 [00:03<01:33,  7.26it/s]11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 23
Evaluating:   3%|▎         | 23/699 [00:03<01:33,  7.24it/s]11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 24
Evaluating:   3%|▎         | 24/699 [00:03<01:33,  7.24it/s]11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 25
Evaluating:   4%|▎         | 25/699 [00:03<01:33,  7.24it/s]11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 26
Evaluating:   4%|▎         | 26/699 [00:03<01:33,  7.23it/s]11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 27
Evaluating:   4%|▍         | 27/699 [00:03<01:32,  7.24it/s]11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 28
Evaluating:   4%|▍         | 28/699 [00:03<01:32,  7.25it/s]11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 29
Evaluating:   4%|▍         | 29/699 [00:04<01:32,  7.23it/s]11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 30
Evaluating:   4%|▍         | 30/699 [00:04<01:32,  7.23it/s]11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 31
Evaluating:   4%|▍         | 31/699 [00:04<01:32,  7.22it/s]11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 32
Evaluating:   5%|▍         | 32/699 [00:04<01:32,  7.21it/s]11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 33
Evaluating:   5%|▍         | 33/699 [00:04<01:32,  7.22it/s]11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 34
Evaluating:   5%|▍         | 34/699 [00:04<01:32,  7.16it/s]11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 35
Evaluating:   5%|▌         | 35/699 [00:04<01:33,  7.10it/s]11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 36
Evaluating:   5%|▌         | 36/699 [00:04<01:32,  7.14it/s]11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 37
Evaluating:   5%|▌         | 37/699 [00:05<01:32,  7.15it/s]11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 38
Evaluating:   5%|▌         | 38/699 [00:05<01:32,  7.15it/s]11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 39
Evaluating:   6%|▌         | 39/699 [00:05<01:32,  7.12it/s]11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 40
Evaluating:   6%|▌         | 40/699 [00:05<01:32,  7.15it/s]11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 41
Evaluating:   6%|▌         | 41/699 [00:05<01:31,  7.17it/s]11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 42
Evaluating:   6%|▌         | 42/699 [00:05<01:31,  7.16it/s]11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 43
Evaluating:   6%|▌         | 43/699 [00:05<01:31,  7.14it/s]11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 44
Evaluating:   6%|▋         | 44/699 [00:06<01:31,  7.16it/s]11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 45
Evaluating:   6%|▋         | 45/699 [00:06<01:31,  7.17it/s]11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 46
Evaluating:   7%|▋         | 46/699 [00:06<01:31,  7.17it/s]11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 47
Evaluating:   7%|▋         | 47/699 [00:06<01:31,  7.15it/s]11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 48
Evaluating:   7%|▋         | 48/699 [00:06<01:30,  7.16it/s]11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 49
Evaluating:   7%|▋         | 49/699 [00:06<01:31,  7.14it/s]11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 50
Evaluating:   7%|▋         | 50/699 [00:06<01:31,  7.13it/s]11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 51
Evaluating:   7%|▋         | 51/699 [00:07<01:30,  7.14it/s]11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 52
Evaluating:   7%|▋         | 52/699 [00:07<01:30,  7.14it/s]11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 53
Evaluating:   8%|▊         | 53/699 [00:07<01:30,  7.14it/s]11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 54
Evaluating:   8%|▊         | 54/699 [00:07<01:30,  7.14it/s]11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 55
Evaluating:   8%|▊         | 55/699 [00:07<01:30,  7.13it/s]11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 56
Evaluating:   8%|▊         | 56/699 [00:07<01:30,  7.14it/s]11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 57
Evaluating:   8%|▊         | 57/699 [00:07<01:29,  7.13it/s]11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 58
Evaluating:   8%|▊         | 58/699 [00:08<01:30,  7.12it/s]11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 59
Evaluating:   8%|▊         | 59/699 [00:08<01:32,  6.90it/s]11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 60
Evaluating:   9%|▊         | 60/699 [00:08<01:31,  6.96it/s]11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 61
Evaluating:   9%|▊         | 61/699 [00:08<01:31,  6.99it/s]11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 62
Evaluating:   9%|▉         | 62/699 [00:08<01:30,  7.02it/s]11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 63
Evaluating:   9%|▉         | 63/699 [00:08<01:30,  7.05it/s]11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 64
Evaluating:   9%|▉         | 64/699 [00:08<01:30,  7.01it/s]11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 65
Evaluating:   9%|▉         | 65/699 [00:09<01:30,  7.04it/s]11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 66
Evaluating:   9%|▉         | 66/699 [00:09<01:29,  7.05it/s]11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 67
Evaluating:  10%|▉         | 67/699 [00:09<01:29,  7.06it/s]11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 68
Evaluating:  10%|▉         | 68/699 [00:09<01:29,  7.06it/s]11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 69
Evaluating:  10%|▉         | 69/699 [00:09<01:29,  7.07it/s]11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 70
Evaluating:  10%|█         | 70/699 [00:09<01:29,  7.06it/s]11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 71
Evaluating:  10%|█         | 71/699 [00:09<01:28,  7.07it/s]11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 72
Evaluating:  10%|█         | 72/699 [00:10<01:28,  7.08it/s]11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 73
Evaluating:  10%|█         | 73/699 [00:10<01:28,  7.06it/s]11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 74
Evaluating:  11%|█         | 74/699 [00:10<01:28,  7.04it/s]11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 75
Evaluating:  11%|█         | 75/699 [00:10<01:28,  7.04it/s]11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 76
Evaluating:  11%|█         | 76/699 [00:10<01:28,  7.03it/s]11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 77
Evaluating:  11%|█         | 77/699 [00:10<01:28,  7.03it/s]11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 78
Evaluating:  11%|█         | 78/699 [00:10<01:28,  7.04it/s]11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 79
Evaluating:  11%|█▏        | 79/699 [00:11<01:28,  7.03it/s]11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 80
Evaluating:  11%|█▏        | 80/699 [00:11<01:28,  7.03it/s]11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 81
Evaluating:  12%|█▏        | 81/699 [00:11<01:27,  7.03it/s]11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 82
Evaluating:  12%|█▏        | 82/699 [00:11<01:27,  7.03it/s]11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 83
Evaluating:  12%|█▏        | 83/699 [00:11<01:27,  7.03it/s]11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 84
Evaluating:  12%|█▏        | 84/699 [00:11<01:27,  7.03it/s]11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 85
Evaluating:  12%|█▏        | 85/699 [00:11<01:27,  7.01it/s]11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 86
Evaluating:  12%|█▏        | 86/699 [00:12<01:27,  7.01it/s]11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 87
Evaluating:  12%|█▏        | 87/699 [00:12<01:27,  7.00it/s]11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 88
Evaluating:  13%|█▎        | 88/699 [00:12<01:27,  7.00it/s]11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 89
Evaluating:  13%|█▎        | 89/699 [00:12<01:28,  6.92it/s]11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 90
Evaluating:  13%|█▎        | 90/699 [00:12<01:27,  6.95it/s]11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 91
Evaluating:  13%|█▎        | 91/699 [00:12<01:29,  6.81it/s]11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 92
Evaluating:  13%|█▎        | 92/699 [00:12<01:28,  6.83it/s]11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 93
Evaluating:  13%|█▎        | 93/699 [00:13<01:28,  6.88it/s]11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 94
Evaluating:  13%|█▎        | 94/699 [00:13<01:27,  6.92it/s]11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 95
Evaluating:  14%|█▎        | 95/699 [00:13<01:28,  6.86it/s]11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 96
Evaluating:  14%|█▎        | 96/699 [00:13<01:27,  6.88it/s]11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 97
Evaluating:  14%|█▍        | 97/699 [00:13<01:28,  6.82it/s]11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 98
Evaluating:  14%|█▍        | 98/699 [00:13<01:27,  6.87it/s]11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 99
Evaluating:  14%|█▍        | 99/699 [00:13<01:27,  6.83it/s]11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 100
Evaluating:  14%|█▍        | 100/699 [00:14<01:27,  6.88it/s]11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 101
Evaluating:  14%|█▍        | 101/699 [00:14<01:27,  6.83it/s]11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 102
Evaluating:  15%|█▍        | 102/699 [00:14<01:26,  6.90it/s]11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 103
Evaluating:  15%|█▍        | 103/699 [00:14<01:27,  6.84it/s]11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 104
Evaluating:  15%|█▍        | 104/699 [00:14<01:26,  6.89it/s]11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 105
Evaluating:  15%|█▌        | 105/699 [00:14<01:27,  6.82it/s]11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 106
Evaluating:  15%|█▌        | 106/699 [00:14<01:26,  6.87it/s]11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 107
Evaluating:  15%|█▌        | 107/699 [00:15<01:26,  6.82it/s]11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 108
Evaluating:  15%|█▌        | 108/699 [00:15<01:26,  6.85it/s]11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 109
Evaluating:  16%|█▌        | 109/699 [00:15<01:26,  6.79it/s]11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 110
Evaluating:  16%|█▌        | 110/699 [00:15<01:26,  6.82it/s]11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 111
Evaluating:  16%|█▌        | 111/699 [00:15<01:26,  6.76it/s]11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 112
Evaluating:  16%|█▌        | 112/699 [00:15<01:26,  6.82it/s]11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 113
Evaluating:  16%|█▌        | 113/699 [00:15<01:26,  6.77it/s]11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 114
Evaluating:  16%|█▋        | 114/699 [00:16<01:26,  6.80it/s]11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 115
Evaluating:  16%|█▋        | 115/699 [00:16<01:28,  6.62it/s]11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 116
Evaluating:  17%|█▋        | 116/699 [00:16<01:29,  6.48it/s]11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 117
Evaluating:  17%|█▋        | 117/699 [00:16<01:31,  6.36it/s]11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 118
Evaluating:  17%|█▋        | 118/699 [00:16<01:31,  6.36it/s]11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 119
Evaluating:  17%|█▋        | 119/699 [00:16<01:32,  6.29it/s]11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 120
Evaluating:  17%|█▋        | 120/699 [00:17<01:32,  6.29it/s]11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 121
Evaluating:  17%|█▋        | 121/699 [00:17<01:34,  6.14it/s]11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 122
Evaluating:  17%|█▋        | 122/699 [00:17<01:32,  6.22it/s]11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 123
Evaluating:  18%|█▊        | 123/699 [00:17<01:32,  6.22it/s]11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 124
Evaluating:  18%|█▊        | 124/699 [00:17<01:31,  6.27it/s]11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 125
Evaluating:  18%|█▊        | 125/699 [00:17<01:31,  6.26it/s]11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 126
Evaluating:  18%|█▊        | 126/699 [00:18<01:30,  6.33it/s]11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 127
Evaluating:  18%|█▊        | 127/699 [00:18<01:53,  5.03it/s]11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 128
Evaluating:  18%|█▊        | 128/699 [00:18<01:44,  5.46it/s]11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 129
Evaluating:  18%|█▊        | 129/699 [00:18<01:39,  5.75it/s]11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 130
Evaluating:  19%|█▊        | 130/699 [00:18<01:34,  6.02it/s]11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 131
Evaluating:  19%|█▊        | 131/699 [00:18<01:33,  6.06it/s]11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 132
Evaluating:  19%|█▉        | 132/699 [00:19<01:32,  6.13it/s]11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 133
Evaluating:  19%|█▉        | 133/699 [00:19<01:32,  6.10it/s]11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 134
Evaluating:  19%|█▉        | 134/699 [00:19<01:31,  6.16it/s]11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 135
Evaluating:  19%|█▉        | 135/699 [00:19<01:32,  6.11it/s]11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 136
Evaluating:  19%|█▉        | 136/699 [00:19<01:31,  6.15it/s]11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 137
Evaluating:  20%|█▉        | 137/699 [00:19<01:32,  6.11it/s]11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 138
Evaluating:  20%|█▉        | 138/699 [00:20<01:31,  6.16it/s]11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 139
Evaluating:  20%|█▉        | 139/699 [00:20<01:31,  6.15it/s]11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 140
Evaluating:  20%|██        | 140/699 [00:20<01:28,  6.30it/s]11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 141
Evaluating:  20%|██        | 141/699 [00:20<01:28,  6.32it/s]11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 142
Evaluating:  20%|██        | 142/699 [00:20<01:26,  6.44it/s]11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 143
Evaluating:  20%|██        | 143/699 [00:20<01:25,  6.48it/s]11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 144
Evaluating:  21%|██        | 144/699 [00:21<01:24,  6.60it/s]11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 145
Evaluating:  21%|██        | 145/699 [00:21<01:24,  6.57it/s]11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 146
Evaluating:  21%|██        | 146/699 [00:21<01:23,  6.65it/s]11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 147
Evaluating:  21%|██        | 147/699 [00:21<01:23,  6.61it/s]11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 148
Evaluating:  21%|██        | 148/699 [00:21<01:22,  6.69it/s]11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 149
Evaluating:  21%|██▏       | 149/699 [00:21<01:23,  6.62it/s]11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 150
Evaluating:  21%|██▏       | 150/699 [00:21<01:22,  6.67it/s]11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 151
Evaluating:  22%|██▏       | 151/699 [00:22<01:23,  6.60it/s]11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 152
Evaluating:  22%|██▏       | 152/699 [00:22<01:22,  6.62it/s]11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 153
Evaluating:  22%|██▏       | 153/699 [00:22<01:23,  6.57it/s]11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 154
Evaluating:  22%|██▏       | 154/699 [00:22<01:22,  6.63it/s]11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 155
Evaluating:  22%|██▏       | 155/699 [00:22<01:22,  6.57it/s]11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 156
Evaluating:  22%|██▏       | 156/699 [00:22<01:21,  6.64it/s]11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 157
Evaluating:  22%|██▏       | 157/699 [00:22<01:22,  6.58it/s]11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 158
Evaluating:  23%|██▎       | 158/699 [00:23<01:21,  6.64it/s]11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 159
Evaluating:  23%|██▎       | 159/699 [00:23<01:22,  6.58it/s]11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 160
Evaluating:  23%|██▎       | 160/699 [00:23<01:21,  6.64it/s]11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 161
Evaluating:  23%|██▎       | 161/699 [00:23<01:21,  6.58it/s]11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 162
Evaluating:  23%|██▎       | 162/699 [00:23<01:20,  6.64it/s]11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 163
Evaluating:  23%|██▎       | 163/699 [00:23<01:21,  6.56it/s]11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 164
Evaluating:  23%|██▎       | 164/699 [00:24<01:20,  6.63it/s]11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 165
Evaluating:  24%|██▎       | 165/699 [00:24<01:21,  6.57it/s]11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 166
Evaluating:  24%|██▎       | 166/699 [00:24<01:20,  6.61it/s]11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 167
Evaluating:  24%|██▍       | 167/699 [00:24<01:21,  6.51it/s]11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 168
Evaluating:  24%|██▍       | 168/699 [00:24<01:21,  6.53it/s]11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 169
Evaluating:  24%|██▍       | 169/699 [00:24<01:21,  6.48it/s]11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 170
Evaluating:  24%|██▍       | 170/699 [00:24<01:20,  6.55it/s]11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 171
Evaluating:  24%|██▍       | 171/699 [00:25<01:22,  6.41it/s]11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 172
Evaluating:  25%|██▍       | 172/699 [00:25<01:22,  6.42it/s]11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 173
Evaluating:  25%|██▍       | 173/699 [00:25<01:22,  6.38it/s]11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 174
Evaluating:  25%|██▍       | 174/699 [00:25<01:20,  6.49it/s]11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 175
Evaluating:  25%|██▌       | 175/699 [00:25<01:21,  6.45it/s]11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 176
Evaluating:  25%|██▌       | 176/699 [00:25<01:19,  6.54it/s]11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 177
Evaluating:  25%|██▌       | 177/699 [00:26<01:20,  6.47it/s]11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 178
Evaluating:  25%|██▌       | 178/699 [00:26<01:20,  6.43it/s]11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 179
Evaluating:  26%|██▌       | 179/699 [00:26<01:21,  6.41it/s]11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 180
Evaluating:  26%|██▌       | 180/699 [00:26<01:20,  6.48it/s]11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 181
Evaluating:  26%|██▌       | 181/699 [00:26<01:20,  6.43it/s]11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 182
Evaluating:  26%|██▌       | 182/699 [00:26<01:21,  6.38it/s]11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 183
Evaluating:  26%|██▌       | 183/699 [00:27<01:21,  6.32it/s]11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 184
Evaluating:  26%|██▋       | 184/699 [00:27<01:23,  6.17it/s]11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 185
Evaluating:  26%|██▋       | 185/699 [00:27<01:23,  6.15it/s]11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 186
Evaluating:  27%|██▋       | 186/699 [00:27<01:22,  6.19it/s]11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 187
Evaluating:  27%|██▋       | 187/699 [00:27<01:22,  6.22it/s]11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 188
Evaluating:  27%|██▋       | 188/699 [00:27<01:22,  6.23it/s]11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 189
Evaluating:  27%|██▋       | 189/699 [00:27<01:22,  6.20it/s]11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 190
Evaluating:  27%|██▋       | 190/699 [00:28<01:22,  6.19it/s]11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 191
Evaluating:  27%|██▋       | 191/699 [00:28<01:21,  6.22it/s]11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 192
Evaluating:  27%|██▋       | 192/699 [00:28<01:21,  6.23it/s]11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 193
Evaluating:  28%|██▊       | 193/699 [00:28<01:21,  6.24it/s]11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 194
Evaluating:  28%|██▊       | 194/699 [00:28<01:20,  6.23it/s]11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 195
Evaluating:  28%|██▊       | 195/699 [00:28<01:20,  6.24it/s]11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 196
Evaluating:  28%|██▊       | 196/699 [00:29<01:20,  6.25it/s]11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 197
Evaluating:  28%|██▊       | 197/699 [00:29<01:20,  6.23it/s]11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 198
Evaluating:  28%|██▊       | 198/699 [00:29<01:22,  6.10it/s]11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 199
Evaluating:  28%|██▊       | 199/699 [00:29<01:22,  6.04it/s]11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 200
Evaluating:  29%|██▊       | 200/699 [00:29<01:21,  6.09it/s]11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 201
Evaluating:  29%|██▉       | 201/699 [00:29<01:21,  6.14it/s]11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 202
Evaluating:  29%|██▉       | 202/699 [00:30<01:20,  6.16it/s]11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 203
Evaluating:  29%|██▉       | 203/699 [00:30<01:22,  6.03it/s]11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 204
Evaluating:  29%|██▉       | 204/699 [00:30<01:22,  6.03it/s]11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 205
Evaluating:  29%|██▉       | 205/699 [00:30<01:21,  6.07it/s]11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 206
Evaluating:  29%|██▉       | 206/699 [00:30<01:20,  6.11it/s]11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 207
Evaluating:  30%|██▉       | 207/699 [00:30<01:20,  6.11it/s]11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 208
Evaluating:  30%|██▉       | 208/699 [00:31<01:21,  6.00it/s]11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 209
Evaluating:  30%|██▉       | 209/699 [00:31<01:22,  5.93it/s]11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 210
Evaluating:  30%|███       | 210/699 [00:31<01:22,  5.94it/s]11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 211
Evaluating:  30%|███       | 211/699 [00:31<01:21,  5.99it/s]11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 212
Evaluating:  30%|███       | 212/699 [00:31<01:21,  6.01it/s]11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 213
Evaluating:  30%|███       | 213/699 [00:31<01:22,  5.92it/s]11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 214
Evaluating:  31%|███       | 214/699 [00:32<01:22,  5.87it/s]11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 215
Evaluating:  31%|███       | 215/699 [00:32<01:22,  5.87it/s]11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 216
Evaluating:  31%|███       | 216/699 [00:32<01:21,  5.90it/s]11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 217
Evaluating:  31%|███       | 217/699 [00:32<01:21,  5.94it/s]11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 218
Evaluating:  31%|███       | 218/699 [00:32<01:20,  5.96it/s]11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 219
Evaluating:  31%|███▏      | 219/699 [00:32<01:21,  5.86it/s]11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 220
Evaluating:  31%|███▏      | 220/699 [00:33<01:22,  5.81it/s]11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 221
Evaluating:  32%|███▏      | 221/699 [00:33<01:22,  5.78it/s]11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 222
Evaluating:  32%|███▏      | 222/699 [00:33<01:21,  5.83it/s]11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 223
Evaluating:  32%|███▏      | 223/699 [00:33<01:20,  5.89it/s]11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 224
Evaluating:  32%|███▏      | 224/699 [00:33<01:19,  5.94it/s]11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 225
Evaluating:  32%|███▏      | 225/699 [00:33<01:18,  6.00it/s]11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 226
Evaluating:  32%|███▏      | 226/699 [00:34<01:18,  6.04it/s]11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 227
Evaluating:  32%|███▏      | 227/699 [00:34<01:17,  6.06it/s]11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 228
Evaluating:  33%|███▎      | 228/699 [00:34<01:17,  6.08it/s]11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 229
Evaluating:  33%|███▎      | 229/699 [00:34<01:17,  6.09it/s]11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 230
Evaluating:  33%|███▎      | 230/699 [00:34<01:17,  6.09it/s]11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 231
Evaluating:  33%|███▎      | 231/699 [00:34<01:16,  6.09it/s]11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 232
Evaluating:  33%|███▎      | 232/699 [00:35<01:16,  6.09it/s]11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 233
Evaluating:  33%|███▎      | 233/699 [00:35<01:16,  6.09it/s]11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 234
Evaluating:  33%|███▎      | 234/699 [00:35<01:16,  6.07it/s]11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 235
Evaluating:  34%|███▎      | 235/699 [00:35<01:18,  5.95it/s]11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 236
Evaluating:  34%|███▍      | 236/699 [00:35<01:19,  5.85it/s]11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 237
Evaluating:  34%|███▍      | 237/699 [00:35<01:19,  5.80it/s]11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 238
Evaluating:  34%|███▍      | 238/699 [00:36<01:19,  5.82it/s]11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 239
Evaluating:  34%|███▍      | 239/699 [00:36<01:18,  5.85it/s]11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 240
Evaluating:  34%|███▍      | 240/699 [00:36<01:17,  5.90it/s]11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 241
Evaluating:  34%|███▍      | 241/699 [00:36<01:17,  5.94it/s]11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 242
Evaluating:  35%|███▍      | 242/699 [00:36<01:17,  5.88it/s]11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 243
Evaluating:  35%|███▍      | 243/699 [00:36<01:18,  5.81it/s]11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 244
Evaluating:  35%|███▍      | 244/699 [00:37<01:17,  5.84it/s]11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 245
Evaluating:  35%|███▌      | 245/699 [00:37<01:17,  5.86it/s]11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 246
Evaluating:  35%|███▌      | 246/699 [00:37<01:16,  5.90it/s]11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 247
Evaluating:  35%|███▌      | 247/699 [00:37<01:16,  5.93it/s]11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 248
Evaluating:  35%|███▌      | 248/699 [00:37<01:16,  5.89it/s]11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 249
Evaluating:  36%|███▌      | 249/699 [00:38<01:16,  5.89it/s]11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 250
Evaluating:  36%|███▌      | 250/699 [00:38<01:15,  5.93it/s]11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 251
Evaluating:  36%|███▌      | 251/699 [00:38<01:15,  5.93it/s]11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 252
Evaluating:  36%|███▌      | 252/699 [00:38<01:15,  5.96it/s]11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 253
Evaluating:  36%|███▌      | 253/699 [00:38<01:15,  5.92it/s]11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 254
Evaluating:  36%|███▋      | 254/699 [00:38<01:14,  5.94it/s]11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 255
Evaluating:  36%|███▋      | 255/699 [00:39<01:14,  5.95it/s]11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 256
Evaluating:  37%|███▋      | 256/699 [00:39<01:14,  5.97it/s]11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 257
Evaluating:  37%|███▋      | 257/699 [00:39<01:14,  5.96it/s]11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 258
Evaluating:  37%|███▋      | 258/699 [00:39<01:14,  5.93it/s]11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 259
Evaluating:  37%|███▋      | 259/699 [00:39<01:15,  5.80it/s]11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 260
Evaluating:  37%|███▋      | 260/699 [00:39<01:15,  5.79it/s]11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 261
Evaluating:  37%|███▋      | 261/699 [00:40<01:14,  5.84it/s]11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 262
Evaluating:  37%|███▋      | 262/699 [00:40<01:14,  5.88it/s]11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 263
Evaluating:  38%|███▊      | 263/699 [00:40<01:13,  5.90it/s]11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 264
Evaluating:  38%|███▊      | 264/699 [00:40<01:13,  5.90it/s]11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 265
Evaluating:  38%|███▊      | 265/699 [00:40<01:15,  5.78it/s]11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 266
Evaluating:  38%|███▊      | 266/699 [00:40<01:15,  5.74it/s]11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 267
Evaluating:  38%|███▊      | 267/699 [00:41<01:14,  5.80it/s]11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 268
Evaluating:  38%|███▊      | 268/699 [00:41<01:13,  5.84it/s]11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 269
Evaluating:  38%|███▊      | 269/699 [00:41<01:13,  5.87it/s]11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 270
Evaluating:  39%|███▊      | 270/699 [00:41<01:13,  5.86it/s]11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 271
Evaluating:  39%|███▉      | 271/699 [00:41<01:14,  5.76it/s]11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 272
Evaluating:  39%|███▉      | 272/699 [00:41<01:14,  5.74it/s]11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 273
Evaluating:  39%|███▉      | 273/699 [00:42<01:13,  5.79it/s]11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 274
Evaluating:  39%|███▉      | 274/699 [00:42<01:12,  5.83it/s]11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 275
Evaluating:  39%|███▉      | 275/699 [00:42<01:12,  5.85it/s]11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 276
Evaluating:  39%|███▉      | 276/699 [00:42<01:12,  5.87it/s]11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 277
Evaluating:  40%|███▉      | 277/699 [00:42<01:11,  5.87it/s]11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 278
Evaluating:  40%|███▉      | 278/699 [00:42<01:13,  5.75it/s]11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 279
Evaluating:  40%|███▉      | 279/699 [00:43<01:13,  5.73it/s]11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 280
Evaluating:  40%|████      | 280/699 [00:43<01:12,  5.78it/s]11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 281
Evaluating:  40%|████      | 281/699 [00:43<01:12,  5.80it/s]11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 282
Evaluating:  40%|████      | 282/699 [00:43<01:11,  5.83it/s]11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 283
Evaluating:  40%|████      | 283/699 [00:43<01:11,  5.83it/s]11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 284
Evaluating:  41%|████      | 284/699 [00:44<01:13,  5.68it/s]11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 285
Evaluating:  41%|████      | 285/699 [00:44<01:12,  5.68it/s]11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 286
Evaluating:  41%|████      | 286/699 [00:44<01:11,  5.75it/s]11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 287
Evaluating:  41%|████      | 287/699 [00:44<01:11,  5.79it/s]11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 288
Evaluating:  41%|████      | 288/699 [00:44<01:10,  5.81it/s]11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 289
Evaluating:  41%|████▏     | 289/699 [00:44<01:10,  5.85it/s]11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 290
Evaluating:  41%|████▏     | 290/699 [00:45<01:10,  5.80it/s]11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 291
Evaluating:  42%|████▏     | 291/699 [00:45<01:10,  5.77it/s]11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 292
Evaluating:  42%|████▏     | 292/699 [00:45<01:10,  5.80it/s]11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 293
Evaluating:  42%|████▏     | 293/699 [00:45<01:09,  5.81it/s]11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 294
Evaluating:  42%|████▏     | 294/699 [00:45<01:09,  5.81it/s]11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 295
Evaluating:  42%|████▏     | 295/699 [00:45<01:09,  5.81it/s]11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 296
Evaluating:  42%|████▏     | 296/699 [00:46<01:09,  5.78it/s]11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 297
Evaluating:  42%|████▏     | 297/699 [00:46<01:11,  5.66it/s]11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 298
Evaluating:  43%|████▎     | 298/699 [00:46<01:11,  5.59it/s]11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 299
Evaluating:  43%|████▎     | 299/699 [00:46<01:11,  5.61it/s]11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 300
Evaluating:  43%|████▎     | 300/699 [00:46<01:10,  5.66it/s]11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 301
Evaluating:  43%|████▎     | 301/699 [00:46<01:09,  5.71it/s]11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 302
Evaluating:  43%|████▎     | 302/699 [00:47<01:09,  5.73it/s]11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 303
Evaluating:  43%|████▎     | 303/699 [00:47<01:09,  5.72it/s]11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 304
Evaluating:  43%|████▎     | 304/699 [00:47<01:10,  5.62it/s]11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 305
Evaluating:  44%|████▎     | 305/699 [00:47<01:10,  5.55it/s]11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 306
Evaluating:  44%|████▍     | 306/699 [00:47<01:11,  5.52it/s]11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 307
Evaluating:  44%|████▍     | 307/699 [00:48<01:10,  5.55it/s]11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 308
Evaluating:  44%|████▍     | 308/699 [00:48<01:13,  5.29it/s]11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 309
Evaluating:  44%|████▍     | 309/699 [00:48<01:12,  5.41it/s]11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 310
Evaluating:  44%|████▍     | 310/699 [00:48<01:10,  5.52it/s]11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 311
Evaluating:  44%|████▍     | 311/699 [00:48<01:09,  5.59it/s]11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 312
Evaluating:  45%|████▍     | 312/699 [00:48<01:08,  5.64it/s]11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 313
Evaluating:  45%|████▍     | 313/699 [00:49<01:09,  5.59it/s]11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 314
Evaluating:  45%|████▍     | 314/699 [00:49<01:09,  5.57it/s]11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 315
Evaluating:  45%|████▌     | 315/699 [00:49<01:08,  5.61it/s]11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 316
Evaluating:  45%|████▌     | 316/699 [00:49<01:07,  5.65it/s]11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 317
Evaluating:  45%|████▌     | 317/699 [00:49<01:07,  5.68it/s]11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 318
Evaluating:  45%|████▌     | 318/699 [00:50<01:06,  5.69it/s]11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 319
Evaluating:  46%|████▌     | 319/699 [00:50<01:07,  5.67it/s]11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 320
Evaluating:  46%|████▌     | 320/699 [00:50<01:08,  5.56it/s]11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 321
Evaluating:  46%|████▌     | 321/699 [00:50<01:08,  5.51it/s]11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 322
Evaluating:  46%|████▌     | 322/699 [00:50<01:08,  5.52it/s]11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 323
Evaluating:  46%|████▌     | 323/699 [00:50<01:07,  5.57it/s]11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 324
Evaluating:  46%|████▋     | 324/699 [00:51<01:06,  5.62it/s]11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 325
Evaluating:  46%|████▋     | 325/699 [00:51<01:06,  5.65it/s]11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 326
Evaluating:  47%|████▋     | 326/699 [00:51<01:05,  5.67it/s]11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 327
Evaluating:  47%|████▋     | 327/699 [00:51<01:05,  5.67it/s]11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 328
Evaluating:  47%|████▋     | 328/699 [00:51<01:06,  5.56it/s]11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 329
Evaluating:  47%|████▋     | 329/699 [00:51<01:07,  5.49it/s]11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 330
Evaluating:  47%|████▋     | 330/699 [00:52<01:07,  5.50it/s]11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 331
Evaluating:  47%|████▋     | 331/699 [00:52<01:06,  5.56it/s]11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 332
Evaluating:  47%|████▋     | 332/699 [00:52<01:05,  5.59it/s]11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 333
Evaluating:  48%|████▊     | 333/699 [00:52<01:05,  5.62it/s]11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 334
Evaluating:  48%|████▊     | 334/699 [00:52<01:04,  5.64it/s]11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 335
Evaluating:  48%|████▊     | 335/699 [00:53<01:04,  5.63it/s]11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 336
Evaluating:  48%|████▊     | 336/699 [00:53<01:08,  5.33it/s]11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 337
Evaluating:  48%|████▊     | 337/699 [00:53<01:08,  5.31it/s]11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 338
Evaluating:  48%|████▊     | 338/699 [00:53<01:08,  5.29it/s]11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 339
Evaluating:  48%|████▊     | 339/699 [00:53<01:07,  5.35it/s]11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 340
Evaluating:  49%|████▊     | 340/699 [00:54<01:05,  5.44it/s]11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 341
Evaluating:  49%|████▉     | 341/699 [00:54<01:05,  5.50it/s]11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 342
Evaluating:  49%|████▉     | 342/699 [00:54<01:04,  5.55it/s]11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 343
Evaluating:  49%|████▉     | 343/699 [00:54<01:03,  5.58it/s]11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 344
Evaluating:  49%|████▉     | 344/699 [00:54<01:03,  5.60it/s]11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 345
Evaluating:  49%|████▉     | 345/699 [00:54<01:03,  5.54it/s]11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 346
Evaluating:  49%|████▉     | 346/699 [00:55<01:04,  5.46it/s]11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 347
Evaluating:  50%|████▉     | 347/699 [00:55<01:05,  5.39it/s]11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 348
Evaluating:  50%|████▉     | 348/699 [00:55<01:05,  5.37it/s]11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 349
Evaluating:  50%|████▉     | 349/699 [00:55<01:04,  5.43it/s]11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 350
Evaluating:  50%|█████     | 350/699 [00:55<01:03,  5.49it/s]11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 351
Evaluating:  50%|█████     | 351/699 [00:56<01:03,  5.52it/s]11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 352
Evaluating:  50%|█████     | 352/699 [00:56<01:02,  5.56it/s]11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 353
Evaluating:  51%|█████     | 353/699 [00:56<01:02,  5.57it/s]11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 354
Evaluating:  51%|█████     | 354/699 [00:56<01:02,  5.56it/s]11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 355
Evaluating:  51%|█████     | 355/699 [00:56<01:03,  5.44it/s]11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 356
Evaluating:  51%|█████     | 356/699 [00:56<01:03,  5.41it/s]11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 357
Evaluating:  51%|█████     | 357/699 [00:57<01:03,  5.42it/s]11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 358
Evaluating:  51%|█████     | 358/699 [00:57<01:02,  5.47it/s]11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 359
Evaluating:  51%|█████▏    | 359/699 [00:57<01:01,  5.51it/s]11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 360
Evaluating:  52%|█████▏    | 360/699 [00:57<01:01,  5.53it/s]11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 361
Evaluating:  52%|█████▏    | 361/699 [00:57<01:00,  5.55it/s]11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 362
Evaluating:  52%|█████▏    | 362/699 [00:57<01:00,  5.54it/s]11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 363
Evaluating:  52%|█████▏    | 363/699 [00:58<01:01,  5.44it/s]11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 364
Evaluating:  52%|█████▏    | 364/699 [00:58<01:02,  5.37it/s]11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 365
Evaluating:  52%|█████▏    | 365/699 [00:58<01:02,  5.32it/s]11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 366
Evaluating:  52%|█████▏    | 366/699 [00:58<01:03,  5.27it/s]11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 367
Evaluating:  53%|█████▎    | 367/699 [00:58<01:03,  5.24it/s]11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 368
Evaluating:  53%|█████▎    | 368/699 [00:59<01:02,  5.28it/s]11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 369
Evaluating:  53%|█████▎    | 369/699 [00:59<01:01,  5.35it/s]11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 370
Evaluating:  53%|█████▎    | 370/699 [00:59<01:00,  5.42it/s]11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 371
Evaluating:  53%|█████▎    | 371/699 [00:59<01:00,  5.45it/s]11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 372
Evaluating:  53%|█████▎    | 372/699 [00:59<00:59,  5.47it/s]11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 373
Evaluating:  53%|█████▎    | 373/699 [01:00<00:59,  5.49it/s]11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 374
Evaluating:  54%|█████▎    | 374/699 [01:00<00:59,  5.48it/s]11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 375
Evaluating:  54%|█████▎    | 375/699 [01:00<01:00,  5.40it/s]11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 376
Evaluating:  54%|█████▍    | 376/699 [01:00<01:00,  5.32it/s]11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 377
Evaluating:  54%|█████▍    | 377/699 [01:00<01:00,  5.34it/s]11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 378
Evaluating:  54%|█████▍    | 378/699 [01:00<00:59,  5.41it/s]11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 379
Evaluating:  54%|█████▍    | 379/699 [01:01<00:58,  5.46it/s]11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 380
Evaluating:  54%|█████▍    | 380/699 [01:01<00:58,  5.48it/s]11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 381
Evaluating:  55%|█████▍    | 381/699 [01:01<00:57,  5.49it/s]11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 382
Evaluating:  55%|█████▍    | 382/699 [01:01<00:57,  5.50it/s]11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 383
Evaluating:  55%|█████▍    | 383/699 [01:01<00:57,  5.50it/s]11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 384
Evaluating:  55%|█████▍    | 384/699 [01:02<00:57,  5.48it/s]11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 385
Evaluating:  55%|█████▌    | 385/699 [01:02<00:58,  5.39it/s]11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 386
Evaluating:  55%|█████▌    | 386/699 [01:02<00:58,  5.31it/s]11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 387
Evaluating:  55%|█████▌    | 387/699 [01:02<00:59,  5.26it/s]11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 388
Evaluating:  56%|█████▌    | 388/699 [01:02<00:58,  5.29it/s]11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 389
Evaluating:  56%|█████▌    | 389/699 [01:03<00:57,  5.35it/s]11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 390
Evaluating:  56%|█████▌    | 390/699 [01:03<01:01,  5.06it/s]11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 391
Evaluating:  56%|█████▌    | 391/699 [01:03<00:59,  5.17it/s]11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 392
Evaluating:  56%|█████▌    | 392/699 [01:03<00:58,  5.26it/s]11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 393
Evaluating:  56%|█████▌    | 393/699 [01:03<00:57,  5.31it/s]11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 394
Evaluating:  56%|█████▋    | 394/699 [01:03<00:56,  5.36it/s]11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 395
Evaluating:  57%|█████▋    | 395/699 [01:04<00:56,  5.39it/s]11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 396
Evaluating:  57%|█████▋    | 396/699 [01:04<00:55,  5.41it/s]11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 397
Evaluating:  57%|█████▋    | 397/699 [01:04<00:56,  5.35it/s]11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 398
Evaluating:  57%|█████▋    | 398/699 [01:04<00:57,  5.27it/s]11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 399
Evaluating:  57%|█████▋    | 399/699 [01:04<00:57,  5.21it/s]11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 400
Evaluating:  57%|█████▋    | 400/699 [01:05<00:57,  5.18it/s]11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 401
Evaluating:  57%|█████▋    | 401/699 [01:05<00:57,  5.16it/s]11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 402
Evaluating:  58%|█████▊    | 402/699 [01:05<00:56,  5.22it/s]11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 403
Evaluating:  58%|█████▊    | 403/699 [01:05<00:56,  5.28it/s]11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 404
Evaluating:  58%|█████▊    | 404/699 [01:05<00:55,  5.33it/s]11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 405
Evaluating:  58%|█████▊    | 405/699 [01:06<00:54,  5.36it/s]11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 406
Evaluating:  58%|█████▊    | 406/699 [01:06<00:54,  5.39it/s]11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 407
Evaluating:  58%|█████▊    | 407/699 [01:06<00:54,  5.38it/s]11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 408
Evaluating:  58%|█████▊    | 408/699 [01:06<00:54,  5.39it/s]11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 409
Evaluating:  59%|█████▊    | 409/699 [01:06<00:53,  5.41it/s]11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 410
Evaluating:  59%|█████▊    | 410/699 [01:06<00:53,  5.36it/s]11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 411
Evaluating:  59%|█████▉    | 411/699 [01:07<00:54,  5.26it/s]11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 412
Evaluating:  59%|█████▉    | 412/699 [01:07<00:55,  5.20it/s]11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 413
Evaluating:  59%|█████▉    | 413/699 [01:07<00:55,  5.18it/s]11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 414
Evaluating:  59%|█████▉    | 414/699 [01:07<00:54,  5.20it/s]11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 415
Evaluating:  59%|█████▉    | 415/699 [01:07<00:54,  5.24it/s]11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 416
Evaluating:  60%|█████▉    | 416/699 [01:08<00:53,  5.28it/s]11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 417
Evaluating:  60%|█████▉    | 417/699 [01:08<00:53,  5.32it/s]11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 418
Evaluating:  60%|█████▉    | 418/699 [01:08<00:52,  5.34it/s]11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 419
Evaluating:  60%|█████▉    | 419/699 [01:08<00:52,  5.36it/s]11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 420
Evaluating:  60%|██████    | 420/699 [01:08<00:52,  5.36it/s]11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 421
Evaluating:  60%|██████    | 421/699 [01:09<00:51,  5.38it/s]11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 422
Evaluating:  60%|██████    | 422/699 [01:09<00:51,  5.39it/s]11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 423
Evaluating:  61%|██████    | 423/699 [01:09<00:52,  5.30it/s]11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 424
Evaluating:  61%|██████    | 424/699 [01:09<00:52,  5.22it/s]11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 425
Evaluating:  61%|██████    | 425/699 [01:09<00:53,  5.16it/s]11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 426
Evaluating:  61%|██████    | 426/699 [01:10<00:53,  5.11it/s]11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 427
Evaluating:  61%|██████    | 427/699 [01:10<00:53,  5.09it/s]11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 428
Evaluating:  61%|██████    | 428/699 [01:10<00:53,  5.06it/s]11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 429
Evaluating:  61%|██████▏   | 429/699 [01:10<00:53,  5.06it/s]11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 430
Evaluating:  62%|██████▏   | 430/699 [01:10<00:52,  5.13it/s]11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 431
Evaluating:  62%|██████▏   | 431/699 [01:11<00:51,  5.20it/s]11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 432
Evaluating:  62%|██████▏   | 432/699 [01:11<00:51,  5.23it/s]11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 433
Evaluating:  62%|██████▏   | 433/699 [01:11<00:50,  5.27it/s]11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 434
Evaluating:  62%|██████▏   | 434/699 [01:11<00:50,  5.25it/s]11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 435
Evaluating:  62%|██████▏   | 435/699 [01:11<00:50,  5.27it/s]11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 436
Evaluating:  62%|██████▏   | 436/699 [01:11<00:49,  5.30it/s]11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 437
Evaluating:  63%|██████▎   | 437/699 [01:12<00:49,  5.31it/s]11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 438
Evaluating:  63%|██████▎   | 438/699 [01:12<00:49,  5.32it/s]11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 439
Evaluating:  63%|██████▎   | 439/699 [01:12<00:49,  5.22it/s]11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 440
Evaluating:  63%|██████▎   | 440/699 [01:12<00:50,  5.14it/s]11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 441
Evaluating:  63%|██████▎   | 441/699 [01:12<00:50,  5.09it/s]11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 442
Evaluating:  63%|██████▎   | 442/699 [01:13<00:50,  5.06it/s]11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 443
Evaluating:  63%|██████▎   | 443/699 [01:13<00:50,  5.03it/s]11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 444
Evaluating:  64%|██████▎   | 444/699 [01:13<00:50,  5.01it/s]11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 445
Evaluating:  64%|██████▎   | 445/699 [01:13<00:50,  5.00it/s]11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 446
Evaluating:  64%|██████▍   | 446/699 [01:13<00:50,  4.98it/s]11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 447
Evaluating:  64%|██████▍   | 447/699 [01:14<00:50,  4.97it/s]11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 448
Evaluating:  64%|██████▍   | 448/699 [01:14<00:50,  4.97it/s]11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 449
Evaluating:  64%|██████▍   | 449/699 [01:14<00:50,  4.96it/s]11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 450
Evaluating:  64%|██████▍   | 450/699 [01:14<00:50,  4.96it/s]11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 451
Evaluating:  65%|██████▍   | 451/699 [01:14<00:50,  4.95it/s]11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 452
Evaluating:  65%|██████▍   | 452/699 [01:15<00:49,  4.96it/s]11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 453
Evaluating:  65%|██████▍   | 453/699 [01:15<00:49,  5.00it/s]11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 454
Evaluating:  65%|██████▍   | 454/699 [01:15<00:48,  5.03it/s]11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 455
Evaluating:  65%|██████▌   | 455/699 [01:15<00:48,  4.99it/s]11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 456
Evaluating:  65%|██████▌   | 456/699 [01:15<00:48,  4.97it/s]11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 457
Evaluating:  65%|██████▌   | 457/699 [01:16<00:48,  4.98it/s]11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 458
Evaluating:  66%|██████▌   | 458/699 [01:16<00:48,  5.00it/s]11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 459
Evaluating:  66%|██████▌   | 459/699 [01:16<00:48,  4.99it/s]11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 460
Evaluating:  66%|██████▌   | 460/699 [01:16<00:47,  5.07it/s]11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 461
Evaluating:  66%|██████▌   | 461/699 [01:16<00:46,  5.13it/s]11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 462
Evaluating:  66%|██████▌   | 462/699 [01:17<00:45,  5.17it/s]11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 463
Evaluating:  66%|██████▌   | 463/699 [01:17<00:45,  5.21it/s]11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 464
Evaluating:  66%|██████▋   | 464/699 [01:17<00:45,  5.21it/s]11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 465
Evaluating:  67%|██████▋   | 465/699 [01:17<00:44,  5.22it/s]11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 466
Evaluating:  67%|██████▋   | 466/699 [01:17<00:44,  5.24it/s]11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 467
Evaluating:  67%|██████▋   | 467/699 [01:18<00:44,  5.23it/s]11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 468
Evaluating:  67%|██████▋   | 468/699 [01:18<00:44,  5.14it/s]11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 469
Evaluating:  67%|██████▋   | 469/699 [01:18<00:44,  5.12it/s]11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 470
Evaluating:  67%|██████▋   | 470/699 [01:18<00:44,  5.12it/s]11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 471
Evaluating:  67%|██████▋   | 471/699 [01:18<00:45,  5.05it/s]11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 472
Evaluating:  68%|██████▊   | 472/699 [01:19<00:45,  5.00it/s]11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 473
Evaluating:  68%|██████▊   | 473/699 [01:19<00:45,  4.96it/s]11/21/2021 13:21:37 - INFO - __main__ -   Batch number = 474
Evaluating:  68%|██████▊   | 474/699 [01:19<00:45,  4.93it/s]11/21/2021 13:21:37 - INFO - __main__ -   Batch number = 475
Evaluating:  68%|██████▊   | 475/699 [01:19<00:45,  4.95it/s]11/21/2021 13:21:37 - INFO - __main__ -   Batch number = 476
Evaluating:  68%|██████▊   | 476/699 [01:19<00:45,  4.92it/s]11/21/2021 13:21:37 - INFO - __main__ -   Batch number = 477
Evaluating:  68%|██████▊   | 477/699 [01:20<00:45,  4.90it/s]11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 478
Evaluating:  68%|██████▊   | 478/699 [01:20<00:44,  4.92it/s]11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 479
Evaluating:  69%|██████▊   | 479/699 [01:20<00:44,  4.94it/s]11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 480
Evaluating:  69%|██████▊   | 480/699 [01:20<00:43,  5.00it/s]11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 481
Evaluating:  69%|██████▉   | 481/699 [01:20<00:43,  5.05it/s]11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 482
Evaluating:  69%|██████▉   | 482/699 [01:21<00:42,  5.10it/s]11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 483
Evaluating:  69%|██████▉   | 483/699 [01:21<00:42,  5.12it/s]11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 484
Evaluating:  69%|██████▉   | 484/699 [01:21<00:41,  5.14it/s]11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 485
Evaluating:  69%|██████▉   | 485/699 [01:21<00:41,  5.14it/s]11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 486
Evaluating:  70%|██████▉   | 486/699 [01:21<00:41,  5.16it/s]11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 487
Evaluating:  70%|██████▉   | 487/699 [01:22<00:41,  5.16it/s]11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 488
Evaluating:  70%|██████▉   | 488/699 [01:22<00:40,  5.16it/s]11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 489
Evaluating:  70%|██████▉   | 489/699 [01:22<00:40,  5.16it/s]11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 490
Evaluating:  70%|███████   | 490/699 [01:22<00:40,  5.16it/s]11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 491
Evaluating:  70%|███████   | 491/699 [01:22<00:40,  5.16it/s]11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 492
Evaluating:  70%|███████   | 492/699 [01:23<00:40,  5.16it/s]11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 493
Evaluating:  71%|███████   | 493/699 [01:23<00:42,  4.80it/s]11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 494
Evaluating:  71%|███████   | 494/699 [01:23<00:41,  4.90it/s]11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 495
Evaluating:  71%|███████   | 495/699 [01:23<00:41,  4.97it/s]11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 496
Evaluating:  71%|███████   | 496/699 [01:23<00:40,  5.03it/s]11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 497
Evaluating:  71%|███████   | 497/699 [01:24<00:39,  5.06it/s]11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 498
Evaluating:  71%|███████   | 498/699 [01:24<00:39,  5.08it/s]11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 499
Evaluating:  71%|███████▏  | 499/699 [01:24<00:39,  5.11it/s]11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 500
Evaluating:  72%|███████▏  | 500/699 [01:24<00:39,  5.07it/s]11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 501
Evaluating:  72%|███████▏  | 501/699 [01:24<00:39,  4.98it/s]11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 502
Evaluating:  72%|███████▏  | 502/699 [01:25<00:39,  4.93it/s]11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 503
Evaluating:  72%|███████▏  | 503/699 [01:25<00:40,  4.90it/s]11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 504
Evaluating:  72%|███████▏  | 504/699 [01:25<00:40,  4.86it/s]11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 505
Evaluating:  72%|███████▏  | 505/699 [01:25<00:39,  4.86it/s]11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 506
Evaluating:  72%|███████▏  | 506/699 [01:25<00:39,  4.87it/s]11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 507
Evaluating:  73%|███████▎  | 507/699 [01:26<00:39,  4.84it/s]11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 508
Evaluating:  73%|███████▎  | 508/699 [01:26<00:39,  4.84it/s]11/21/2021 13:21:44 - INFO - __main__ -   Batch number = 509
Evaluating:  73%|███████▎  | 509/699 [01:26<00:39,  4.82it/s]11/21/2021 13:21:44 - INFO - __main__ -   Batch number = 510
Evaluating:  73%|███████▎  | 510/699 [01:26<00:39,  4.84it/s]11/21/2021 13:21:44 - INFO - __main__ -   Batch number = 511
Evaluating:  73%|███████▎  | 511/699 [01:26<00:38,  4.88it/s]11/21/2021 13:21:44 - INFO - __main__ -   Batch number = 512
Evaluating:  73%|███████▎  | 512/699 [01:27<00:37,  4.93it/s]11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 513
Evaluating:  73%|███████▎  | 513/699 [01:27<00:37,  4.97it/s]11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 514
Evaluating:  74%|███████▎  | 514/699 [01:27<00:37,  4.98it/s]11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 515
Evaluating:  74%|███████▎  | 515/699 [01:27<00:37,  4.97it/s]11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 516
Evaluating:  74%|███████▍  | 516/699 [01:27<00:36,  4.98it/s]11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 517
Evaluating:  74%|███████▍  | 517/699 [01:28<00:36,  5.01it/s]11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 518
Evaluating:  74%|███████▍  | 518/699 [01:28<00:36,  5.03it/s]11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 519
Evaluating:  74%|███████▍  | 519/699 [01:28<00:35,  5.04it/s]11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 520
Evaluating:  74%|███████▍  | 520/699 [01:28<00:35,  5.06it/s]11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 521
Evaluating:  75%|███████▍  | 521/699 [01:28<00:35,  5.07it/s]11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 522
Evaluating:  75%|███████▍  | 522/699 [01:29<00:34,  5.07it/s]11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 523
Evaluating:  75%|███████▍  | 523/699 [01:29<00:34,  5.07it/s]11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 524
Evaluating:  75%|███████▍  | 524/699 [01:29<00:34,  5.08it/s]11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 525
Evaluating:  75%|███████▌  | 525/699 [01:29<00:34,  5.06it/s]11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 526
Evaluating:  75%|███████▌  | 526/699 [01:29<00:34,  5.06it/s]11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 527
Evaluating:  75%|███████▌  | 527/699 [01:30<00:34,  5.06it/s]11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 528
Evaluating:  76%|███████▌  | 528/699 [01:30<00:33,  5.05it/s]11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 529
Evaluating:  76%|███████▌  | 529/699 [01:30<00:33,  5.06it/s]11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 530
Evaluating:  76%|███████▌  | 530/699 [01:30<00:33,  5.06it/s]11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 531
Evaluating:  76%|███████▌  | 531/699 [01:30<00:33,  5.05it/s]11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 532
Evaluating:  76%|███████▌  | 532/699 [01:31<00:33,  5.06it/s]11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 533
Evaluating:  76%|███████▋  | 533/699 [01:31<00:32,  5.05it/s]11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 534
Evaluating:  76%|███████▋  | 534/699 [01:31<00:32,  5.04it/s]11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 535
Evaluating:  77%|███████▋  | 535/699 [01:31<00:32,  5.05it/s]11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 536
Evaluating:  77%|███████▋  | 536/699 [01:31<00:32,  5.04it/s]11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 537
Evaluating:  77%|███████▋  | 537/699 [01:32<00:32,  5.04it/s]11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 538
Evaluating:  77%|███████▋  | 538/699 [01:32<00:31,  5.04it/s]11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 539
Evaluating:  77%|███████▋  | 539/699 [01:32<00:31,  5.04it/s]11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 540
Evaluating:  77%|███████▋  | 540/699 [01:32<00:31,  5.04it/s]11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 541
Evaluating:  77%|███████▋  | 541/699 [01:32<00:31,  5.04it/s]11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 542
Evaluating:  78%|███████▊  | 542/699 [01:33<00:31,  5.03it/s]11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 543
Evaluating:  78%|███████▊  | 543/699 [01:33<00:32,  4.75it/s]11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 544
Evaluating:  78%|███████▊  | 544/699 [01:33<00:32,  4.83it/s]11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 545
Evaluating:  78%|███████▊  | 545/699 [01:33<00:31,  4.89it/s]11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 546
Evaluating:  78%|███████▊  | 546/699 [01:33<00:31,  4.92it/s]11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 547
Evaluating:  78%|███████▊  | 547/699 [01:34<00:30,  4.95it/s]11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 548
Evaluating:  78%|███████▊  | 548/699 [01:34<00:30,  4.94it/s]11/21/2021 13:21:52 - INFO - __main__ -   Batch number = 549
Evaluating:  79%|███████▊  | 549/699 [01:34<00:30,  4.89it/s]11/21/2021 13:21:52 - INFO - __main__ -   Batch number = 550
Evaluating:  79%|███████▊  | 550/699 [01:34<00:30,  4.84it/s]11/21/2021 13:21:52 - INFO - __main__ -   Batch number = 551
Evaluating:  79%|███████▉  | 551/699 [01:34<00:30,  4.83it/s]11/21/2021 13:21:52 - INFO - __main__ -   Batch number = 552
Evaluating:  79%|███████▉  | 552/699 [01:35<00:30,  4.82it/s]11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 553
Evaluating:  79%|███████▉  | 553/699 [01:35<00:30,  4.78it/s]11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 554
Evaluating:  79%|███████▉  | 554/699 [01:35<00:30,  4.74it/s]11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 555
Evaluating:  79%|███████▉  | 555/699 [01:35<00:30,  4.74it/s]11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 556
Evaluating:  80%|███████▉  | 556/699 [01:35<00:29,  4.78it/s]11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 557
Evaluating:  80%|███████▉  | 557/699 [01:36<00:29,  4.84it/s]11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 558
Evaluating:  80%|███████▉  | 558/699 [01:36<00:28,  4.88it/s]11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 559
Evaluating:  80%|███████▉  | 559/699 [01:36<00:28,  4.90it/s]11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 560
Evaluating:  80%|████████  | 560/699 [01:36<00:28,  4.92it/s]11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 561
Evaluating:  80%|████████  | 561/699 [01:36<00:27,  4.93it/s]11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 562
Evaluating:  80%|████████  | 562/699 [01:37<00:27,  4.95it/s]11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 563
Evaluating:  81%|████████  | 563/699 [01:37<00:27,  4.95it/s]11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 564
Evaluating:  81%|████████  | 564/699 [01:37<00:27,  4.95it/s]11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 565
Evaluating:  81%|████████  | 565/699 [01:37<00:27,  4.94it/s]11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 566
Evaluating:  81%|████████  | 566/699 [01:37<00:26,  4.95it/s]11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 567
Evaluating:  81%|████████  | 567/699 [01:38<00:26,  4.94it/s]11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 568
Evaluating:  81%|████████▏ | 568/699 [01:38<00:26,  4.95it/s]11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 569
Evaluating:  81%|████████▏ | 569/699 [01:38<00:26,  4.94it/s]11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 570
Evaluating:  82%|████████▏ | 570/699 [01:38<00:26,  4.94it/s]11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 571
Evaluating:  82%|████████▏ | 571/699 [01:38<00:25,  4.94it/s]11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 572
Evaluating:  82%|████████▏ | 572/699 [01:39<00:25,  4.94it/s]11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 573
Evaluating:  82%|████████▏ | 573/699 [01:39<00:25,  4.92it/s]11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 574
Evaluating:  82%|████████▏ | 574/699 [01:39<00:25,  4.90it/s]11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 575
Evaluating:  82%|████████▏ | 575/699 [01:39<00:25,  4.87it/s]11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 576
Evaluating:  82%|████████▏ | 576/699 [01:40<00:25,  4.88it/s]11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 577
Evaluating:  83%|████████▎ | 577/699 [01:40<00:25,  4.88it/s]11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 578
Evaluating:  83%|████████▎ | 578/699 [01:40<00:25,  4.82it/s]11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 579
Evaluating:  83%|████████▎ | 579/699 [01:40<00:25,  4.79it/s]11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 580
Evaluating:  83%|████████▎ | 580/699 [01:40<00:25,  4.74it/s]11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 581
Evaluating:  83%|████████▎ | 581/699 [01:41<00:25,  4.70it/s]11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 582
Evaluating:  83%|████████▎ | 582/699 [01:41<00:24,  4.71it/s]11/21/2021 13:21:59 - INFO - __main__ -   Batch number = 583
Evaluating:  83%|████████▎ | 583/699 [01:41<00:24,  4.72it/s]11/21/2021 13:21:59 - INFO - __main__ -   Batch number = 584
Evaluating:  84%|████████▎ | 584/699 [01:41<00:24,  4.70it/s]11/21/2021 13:21:59 - INFO - __main__ -   Batch number = 585
Evaluating:  84%|████████▎ | 585/699 [01:41<00:24,  4.67it/s]11/21/2021 13:21:59 - INFO - __main__ -   Batch number = 586
Evaluating:  84%|████████▍ | 586/699 [01:42<00:24,  4.69it/s]11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 587
Evaluating:  84%|████████▍ | 587/699 [01:42<00:23,  4.74it/s]11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 588
Evaluating:  84%|████████▍ | 588/699 [01:42<00:23,  4.79it/s]11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 589
Evaluating:  84%|████████▍ | 589/699 [01:42<00:22,  4.83it/s]11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 590
Evaluating:  84%|████████▍ | 590/699 [01:42<00:22,  4.84it/s]11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 591
Evaluating:  85%|████████▍ | 591/699 [01:43<00:22,  4.84it/s]11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 592
Evaluating:  85%|████████▍ | 592/699 [01:43<00:22,  4.86it/s]11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 593
Evaluating:  85%|████████▍ | 593/699 [01:43<00:21,  4.87it/s]11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 594
Evaluating:  85%|████████▍ | 594/699 [01:43<00:21,  4.87it/s]11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 595
Evaluating:  85%|████████▌ | 595/699 [01:43<00:21,  4.87it/s]11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 596
Evaluating:  85%|████████▌ | 596/699 [01:44<00:21,  4.87it/s]11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 597
Evaluating:  85%|████████▌ | 597/699 [01:44<00:20,  4.87it/s]11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 598
Evaluating:  86%|████████▌ | 598/699 [01:44<00:20,  4.87it/s]11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 599
Evaluating:  86%|████████▌ | 599/699 [01:44<00:20,  4.87it/s]11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 600
Evaluating:  86%|████████▌ | 600/699 [01:45<00:20,  4.86it/s]11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 601
Evaluating:  86%|████████▌ | 601/699 [01:45<00:20,  4.86it/s]11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 602
Evaluating:  86%|████████▌ | 602/699 [01:45<00:19,  4.86it/s]11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 603
Evaluating:  86%|████████▋ | 603/699 [01:45<00:19,  4.85it/s]11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 604
Evaluating:  86%|████████▋ | 604/699 [01:45<00:19,  4.85it/s]11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 605
Evaluating:  87%|████████▋ | 605/699 [01:46<00:19,  4.85it/s]11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 606
Evaluating:  87%|████████▋ | 606/699 [01:46<00:19,  4.84it/s]11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 607
Evaluating:  87%|████████▋ | 607/699 [01:46<00:19,  4.84it/s]11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 608
Evaluating:  87%|████████▋ | 608/699 [01:46<00:18,  4.84it/s]11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 609
Evaluating:  87%|████████▋ | 609/699 [01:46<00:18,  4.83it/s]11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 610
Evaluating:  87%|████████▋ | 610/699 [01:47<00:18,  4.85it/s]11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 611
Evaluating:  87%|████████▋ | 611/699 [01:47<00:18,  4.84it/s]11/21/2021 13:22:05 - INFO - __main__ -   Batch number = 612
Evaluating:  88%|████████▊ | 612/699 [01:47<00:18,  4.83it/s]11/21/2021 13:22:05 - INFO - __main__ -   Batch number = 613
Evaluating:  88%|████████▊ | 613/699 [01:47<00:17,  4.84it/s]11/21/2021 13:22:05 - INFO - __main__ -   Batch number = 614
Evaluating:  88%|████████▊ | 614/699 [01:47<00:17,  4.83it/s]11/21/2021 13:22:05 - INFO - __main__ -   Batch number = 615
Evaluating:  88%|████████▊ | 615/699 [01:48<00:17,  4.84it/s]11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 616
Evaluating:  88%|████████▊ | 616/699 [01:48<00:17,  4.84it/s]11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 617
Evaluating:  88%|████████▊ | 617/699 [01:48<00:16,  4.83it/s]11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 618
Evaluating:  88%|████████▊ | 618/699 [01:48<00:16,  4.83it/s]11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 619
Evaluating:  89%|████████▊ | 619/699 [01:48<00:16,  4.83it/s]11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 620
Evaluating:  89%|████████▊ | 620/699 [01:49<00:16,  4.83it/s]11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 621
Evaluating:  89%|████████▉ | 621/699 [01:49<00:16,  4.82it/s]11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 622
Evaluating:  89%|████████▉ | 622/699 [01:49<00:15,  4.82it/s]11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 623
Evaluating:  89%|████████▉ | 623/699 [01:49<00:15,  4.82it/s]11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 624
Evaluating:  89%|████████▉ | 624/699 [01:49<00:15,  4.82it/s]11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 625
Evaluating:  89%|████████▉ | 625/699 [01:50<00:15,  4.81it/s]11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 626
Evaluating:  90%|████████▉ | 626/699 [01:50<00:15,  4.80it/s]11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 627
Evaluating:  90%|████████▉ | 627/699 [01:50<00:15,  4.80it/s]11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 628
Evaluating:  90%|████████▉ | 628/699 [01:50<00:14,  4.81it/s]11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 629
Evaluating:  90%|████████▉ | 629/699 [01:51<00:14,  4.79it/s]11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 630
Evaluating:  90%|█████████ | 630/699 [01:51<00:14,  4.78it/s]11/21/2021 13:22:09 - INFO - __main__ -   Batch number = 631
Evaluating:  90%|█████████ | 631/699 [01:51<00:14,  4.79it/s]11/21/2021 13:22:09 - INFO - __main__ -   Batch number = 632
Evaluating:  90%|█████████ | 632/699 [01:51<00:14,  4.77it/s]11/21/2021 13:22:09 - INFO - __main__ -   Batch number = 633
Evaluating:  91%|█████████ | 633/699 [01:51<00:14,  4.68it/s]11/21/2021 13:22:09 - INFO - __main__ -   Batch number = 634
Evaluating:  91%|█████████ | 634/699 [01:52<00:14,  4.63it/s]11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 635
Evaluating:  91%|█████████ | 635/699 [01:52<00:13,  4.62it/s]11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 636
Evaluating:  91%|█████████ | 636/699 [01:52<00:13,  4.59it/s]11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 637
Evaluating:  91%|█████████ | 637/699 [01:52<00:13,  4.56it/s]11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 638
Evaluating:  91%|█████████▏| 638/699 [01:52<00:13,  4.57it/s]11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 639
Evaluating:  91%|█████████▏| 639/699 [01:53<00:13,  4.61it/s]11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 640
Evaluating:  92%|█████████▏| 640/699 [01:53<00:12,  4.64it/s]11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 641
Evaluating:  92%|█████████▏| 641/699 [01:53<00:12,  4.60it/s]11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 642
Evaluating:  92%|█████████▏| 642/699 [01:53<00:12,  4.60it/s]11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 643
Evaluating:  92%|█████████▏| 643/699 [01:54<00:12,  4.63it/s]11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 644
Evaluating:  92%|█████████▏| 644/699 [01:54<00:11,  4.67it/s]11/21/2021 13:22:12 - INFO - __main__ -   Batch number = 645
Evaluating:  92%|█████████▏| 645/699 [01:54<00:11,  4.70it/s]11/21/2021 13:22:12 - INFO - __main__ -   Batch number = 646
Evaluating:  92%|█████████▏| 646/699 [01:54<00:11,  4.72it/s]11/21/2021 13:22:12 - INFO - __main__ -   Batch number = 647
Evaluating:  93%|█████████▎| 647/699 [01:54<00:11,  4.71it/s]11/21/2021 13:22:12 - INFO - __main__ -   Batch number = 648
Evaluating:  93%|█████████▎| 648/699 [01:55<00:10,  4.72it/s]11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 649
Evaluating:  93%|█████████▎| 649/699 [01:55<00:10,  4.73it/s]11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 650
Evaluating:  93%|█████████▎| 650/699 [01:55<00:10,  4.73it/s]11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 651
Evaluating:  93%|█████████▎| 651/699 [01:55<00:10,  4.73it/s]11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 652
Evaluating:  93%|█████████▎| 652/699 [01:55<00:09,  4.72it/s]11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 653
Evaluating:  93%|█████████▎| 653/699 [01:56<00:09,  4.72it/s]11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 654
Evaluating:  94%|█████████▎| 654/699 [01:56<00:09,  4.72it/s]11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 655
Evaluating:  94%|█████████▎| 655/699 [01:56<00:09,  4.73it/s]11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 656
Evaluating:  94%|█████████▍| 656/699 [01:56<00:09,  4.72it/s]11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 657
Evaluating:  94%|█████████▍| 657/699 [01:57<00:09,  4.63it/s]11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 658
Evaluating:  94%|█████████▍| 658/699 [01:57<00:08,  4.59it/s]11/21/2021 13:22:15 - INFO - __main__ -   Batch number = 659
Evaluating:  94%|█████████▍| 659/699 [01:57<00:08,  4.54it/s]11/21/2021 13:22:15 - INFO - __main__ -   Batch number = 660
Evaluating:  94%|█████████▍| 660/699 [01:57<00:08,  4.52it/s]11/21/2021 13:22:15 - INFO - __main__ -   Batch number = 661
Evaluating:  95%|█████████▍| 661/699 [01:57<00:08,  4.52it/s]11/21/2021 13:22:15 - INFO - __main__ -   Batch number = 662
Evaluating:  95%|█████████▍| 662/699 [01:58<00:08,  4.54it/s]11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 663
Evaluating:  95%|█████████▍| 663/699 [01:58<00:07,  4.51it/s]11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 664
Evaluating:  95%|█████████▍| 664/699 [01:58<00:07,  4.51it/s]11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 665
Evaluating:  95%|█████████▌| 665/699 [01:58<00:07,  4.55it/s]11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 666
Evaluating:  95%|█████████▌| 666/699 [01:59<00:07,  4.60it/s]11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 667
Evaluating:  95%|█████████▌| 667/699 [01:59<00:06,  4.61it/s]11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 668
Evaluating:  96%|█████████▌| 668/699 [01:59<00:06,  4.61it/s]11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 669
Evaluating:  96%|█████████▌| 669/699 [01:59<00:06,  4.64it/s]11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 670
Evaluating:  96%|█████████▌| 670/699 [01:59<00:06,  4.67it/s]11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 671
Evaluating:  96%|█████████▌| 671/699 [02:00<00:05,  4.68it/s]11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 672
Evaluating:  96%|█████████▌| 672/699 [02:00<00:05,  4.68it/s]11/21/2021 13:22:18 - INFO - __main__ -   Batch number = 673
Evaluating:  96%|█████████▋| 673/699 [02:00<00:05,  4.68it/s]11/21/2021 13:22:18 - INFO - __main__ -   Batch number = 674
Evaluating:  96%|█████████▋| 674/699 [02:00<00:05,  4.68it/s]11/21/2021 13:22:18 - INFO - __main__ -   Batch number = 675
Evaluating:  97%|█████████▋| 675/699 [02:00<00:05,  4.69it/s]11/21/2021 13:22:18 - INFO - __main__ -   Batch number = 676
Evaluating:  97%|█████████▋| 676/699 [02:01<00:04,  4.70it/s]11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 677
Evaluating:  97%|█████████▋| 677/699 [02:01<00:04,  4.69it/s]11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 678
Evaluating:  97%|█████████▋| 678/699 [02:01<00:04,  4.67it/s]11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 679
Evaluating:  97%|█████████▋| 679/699 [02:01<00:04,  4.67it/s]11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 680
Evaluating:  97%|█████████▋| 680/699 [02:02<00:04,  4.67it/s]11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 681
Evaluating:  97%|█████████▋| 681/699 [02:02<00:03,  4.68it/s]11/21/2021 13:22:20 - INFO - __main__ -   Batch number = 682
Evaluating:  98%|█████████▊| 682/699 [02:02<00:03,  4.67it/s]11/21/2021 13:22:20 - INFO - __main__ -   Batch number = 683
Evaluating:  98%|█████████▊| 683/699 [02:02<00:03,  4.65it/s]11/21/2021 13:22:20 - INFO - __main__ -   Batch number = 684
Evaluating:  98%|█████████▊| 684/699 [02:02<00:03,  4.66it/s]11/21/2021 13:22:20 - INFO - __main__ -   Batch number = 685
Evaluating:  98%|█████████▊| 685/699 [02:03<00:03,  4.66it/s]11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 686
Evaluating:  98%|█████████▊| 686/699 [02:03<00:02,  4.34it/s]11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 687
Evaluating:  98%|█████████▊| 687/699 [02:03<00:02,  4.43it/s]11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 688
Evaluating:  98%|█████████▊| 688/699 [02:03<00:02,  4.49it/s]11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 689
Evaluating:  99%|█████████▊| 689/699 [02:03<00:02,  4.53it/s]11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 690
Evaluating:  99%|█████████▊| 690/699 [02:04<00:01,  4.57it/s]11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 691
Evaluating:  99%|█████████▉| 691/699 [02:04<00:01,  4.60it/s]11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 692
Evaluating:  99%|█████████▉| 692/699 [02:04<00:01,  4.60it/s]11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 693
Evaluating:  99%|█████████▉| 693/699 [02:04<00:01,  4.60it/s]11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 694
Evaluating:  99%|█████████▉| 694/699 [02:05<00:01,  4.61it/s]11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 695
Evaluating:  99%|█████████▉| 695/699 [02:05<00:00,  4.62it/s]11/21/2021 13:22:23 - INFO - __main__ -   Batch number = 696
Evaluating: 100%|█████████▉| 696/699 [02:05<00:00,  4.61it/s]11/21/2021 13:22:23 - INFO - __main__ -   Batch number = 697
Evaluating: 100%|█████████▉| 697/699 [02:05<00:00,  4.62it/s]11/21/2021 13:22:23 - INFO - __main__ -   Batch number = 698
Evaluating: 100%|█████████▉| 698/699 [02:05<00:00,  4.61it/s]11/21/2021 13:22:23 - INFO - __main__ -   Batch number = 699
Evaluating: 100%|██████████| 699/699 [02:06<00:00,  4.80it/s]Evaluating: 100%|██████████| 699/699 [02:06<00:00,  5.54it/s]
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/emea/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
11/21/2021 13:22:32 - INFO - __main__ -   ***** Evaluation result  in de *****
11/21/2021 13:22:32 - INFO - __main__ -     f1 = 0.8558524023730361
11/21/2021 13:22:32 - INFO - __main__ -     loss = 0.5121344268663076
11/21/2021 13:22:32 - INFO - __main__ -     precision = 0.8610549955661432
11/21/2021 13:22:32 - INFO - __main__ -     recall = 0.850712300928998
115.50user 46.11system 2:31.77elapsed 106%CPU (0avgtext+0avgdata 3875648maxresident)k
0inputs+4248outputs (0major+1692732minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/10/2022 16:18:12 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:18:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/10/2022 16:18:12 - INFO - __main__ -   Seed = 1
01/10/2022 16:18:12 - INFO - root -   save model
01/10/2022 16:18:12 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:18:12 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/10/2022 16:18:15 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/10/2022 16:18:21 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:18:21 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/10/2022 16:18:21 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/10/2022 16:18:21 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:18:21 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_model_head.bin
01/10/2022 16:18:21 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:18:21 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:18:21 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:18:21 - INFO - __main__ -   Language = hi
01/10/2022 16:18:21 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/10/2022 16:18:30 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:18:30 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:18:30 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:18:30 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:18:30 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_hi_bert-base-multilingual-cased_128
01/10/2022 16:18:30 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:18:30 - INFO - __main__ -     Num examples = 2685
01/10/2022 16:18:30 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/84 [00:00<?, ?it/s]01/10/2022 16:18:30 - INFO - __main__ -   Batch number = 1
Evaluating:   1%|          | 1/84 [00:00<00:28,  2.93it/s]01/10/2022 16:18:30 - INFO - __main__ -   Batch number = 2
Evaluating:   2%|▏         | 2/84 [00:00<00:27,  2.93it/s]01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 3
Evaluating:   4%|▎         | 3/84 [00:01<00:27,  2.96it/s]01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 4
Evaluating:   5%|▍         | 4/84 [00:01<00:21,  3.67it/s]01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 5
Evaluating:   6%|▌         | 5/84 [00:01<00:18,  4.23it/s]01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 6
Evaluating:   7%|▋         | 6/84 [00:01<00:16,  4.66it/s]01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 7
Evaluating:   8%|▊         | 7/84 [00:01<00:15,  4.96it/s]01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 8
Evaluating:  10%|▉         | 8/84 [00:01<00:14,  5.19it/s]01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 9
Evaluating:  11%|█         | 9/84 [00:02<00:14,  5.34it/s]01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 10
Evaluating:  12%|█▏        | 10/84 [00:02<00:13,  5.46it/s]01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 11
Evaluating:  13%|█▎        | 11/84 [00:02<00:13,  5.54it/s]01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 12
Evaluating:  14%|█▍        | 12/84 [00:02<00:12,  5.60it/s]01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 13
Evaluating:  15%|█▌        | 13/84 [00:02<00:12,  5.65it/s]01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 14
Evaluating:  17%|█▋        | 14/84 [00:02<00:12,  5.67it/s]01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 15
Evaluating:  18%|█▊        | 15/84 [00:03<00:12,  5.70it/s]01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 16
Evaluating:  19%|█▉        | 16/84 [00:03<00:11,  5.72it/s]01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 17
Evaluating:  20%|██        | 17/84 [00:03<00:13,  4.84it/s]01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 18
Evaluating:  21%|██▏       | 18/84 [00:03<00:15,  4.18it/s]01/10/2022 16:18:34 - INFO - __main__ -   Batch number = 19
Evaluating:  23%|██▎       | 19/84 [00:04<00:17,  3.82it/s]01/10/2022 16:18:34 - INFO - __main__ -   Batch number = 20
Evaluating:  24%|██▍       | 20/84 [00:04<00:17,  3.59it/s]01/10/2022 16:18:34 - INFO - __main__ -   Batch number = 21
Evaluating:  25%|██▌       | 21/84 [00:04<00:18,  3.45it/s]01/10/2022 16:18:35 - INFO - __main__ -   Batch number = 22
Evaluating:  26%|██▌       | 22/84 [00:05<00:18,  3.36it/s]01/10/2022 16:18:35 - INFO - __main__ -   Batch number = 23
Evaluating:  27%|██▋       | 23/84 [00:05<00:18,  3.30it/s]01/10/2022 16:18:35 - INFO - __main__ -   Batch number = 24
Evaluating:  29%|██▊       | 24/84 [00:05<00:18,  3.27it/s]01/10/2022 16:18:36 - INFO - __main__ -   Batch number = 25
Evaluating:  30%|██▉       | 25/84 [00:06<00:18,  3.25it/s]01/10/2022 16:18:36 - INFO - __main__ -   Batch number = 26
Evaluating:  31%|███       | 26/84 [00:06<00:17,  3.24it/s]01/10/2022 16:18:36 - INFO - __main__ -   Batch number = 27
Evaluating:  32%|███▏      | 27/84 [00:06<00:17,  3.23it/s]01/10/2022 16:18:37 - INFO - __main__ -   Batch number = 28
Evaluating:  33%|███▎      | 28/84 [00:07<00:17,  3.15it/s]01/10/2022 16:18:37 - INFO - __main__ -   Batch number = 29
Evaluating:  35%|███▍      | 29/84 [00:07<00:17,  3.15it/s]01/10/2022 16:18:37 - INFO - __main__ -   Batch number = 30
Evaluating:  36%|███▌      | 30/84 [00:07<00:17,  3.12it/s]01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 31
Evaluating:  37%|███▋      | 31/84 [00:08<00:17,  3.10it/s]01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 32
Evaluating:  38%|███▊      | 32/84 [00:08<00:15,  3.32it/s]01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 33
Evaluating:  39%|███▉      | 33/84 [00:08<00:13,  3.89it/s]01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 34
Evaluating:  40%|████      | 34/84 [00:08<00:11,  4.43it/s]01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 35
Evaluating:  42%|████▏     | 35/84 [00:08<00:12,  3.92it/s]01/10/2022 16:18:39 - INFO - __main__ -   Batch number = 36
Evaluating:  43%|████▎     | 36/84 [00:09<00:13,  3.57it/s]01/10/2022 16:18:39 - INFO - __main__ -   Batch number = 37
Evaluating:  44%|████▍     | 37/84 [00:09<00:14,  3.35it/s]01/10/2022 16:18:39 - INFO - __main__ -   Batch number = 38
Evaluating:  45%|████▌     | 38/84 [00:09<00:14,  3.20it/s]01/10/2022 16:18:40 - INFO - __main__ -   Batch number = 39
Evaluating:  46%|████▋     | 39/84 [00:10<00:14,  3.11it/s]01/10/2022 16:18:40 - INFO - __main__ -   Batch number = 40
Evaluating:  48%|████▊     | 40/84 [00:10<00:13,  3.32it/s]01/10/2022 16:18:40 - INFO - __main__ -   Batch number = 41
Evaluating:  49%|████▉     | 41/84 [00:10<00:11,  3.79it/s]01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 42
Evaluating:  50%|█████     | 42/84 [00:10<00:09,  4.22it/s]01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 43
Evaluating:  51%|█████     | 43/84 [00:11<00:08,  4.57it/s]01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 44
Evaluating:  52%|█████▏    | 44/84 [00:11<00:08,  4.85it/s]01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 45
Evaluating:  54%|█████▎    | 45/84 [00:11<00:07,  5.08it/s]01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 46
Evaluating:  55%|█████▍    | 46/84 [00:11<00:07,  5.25it/s]01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 47
Evaluating:  56%|█████▌    | 47/84 [00:11<00:06,  5.36it/s]01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 48
Evaluating:  57%|█████▋    | 48/84 [00:11<00:06,  5.46it/s]01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 49
Evaluating:  58%|█████▊    | 49/84 [00:12<00:06,  5.52it/s]01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 50
Evaluating:  60%|█████▉    | 50/84 [00:12<00:06,  5.55it/s]01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 51
Evaluating:  61%|██████    | 51/84 [00:12<00:05,  5.58it/s]01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 52
Evaluating:  62%|██████▏   | 52/84 [00:12<00:05,  5.65it/s]01/10/2022 16:18:43 - INFO - __main__ -   Batch number = 53
Evaluating:  63%|██████▎   | 53/84 [00:12<00:06,  4.46it/s]01/10/2022 16:18:43 - INFO - __main__ -   Batch number = 54
Evaluating:  64%|██████▍   | 54/84 [00:13<00:07,  3.87it/s]01/10/2022 16:18:43 - INFO - __main__ -   Batch number = 55
Evaluating:  65%|██████▌   | 55/84 [00:13<00:08,  3.53it/s]01/10/2022 16:18:44 - INFO - __main__ -   Batch number = 56
Evaluating:  67%|██████▋   | 56/84 [00:13<00:08,  3.32it/s]01/10/2022 16:18:44 - INFO - __main__ -   Batch number = 57
Evaluating:  68%|██████▊   | 57/84 [00:14<00:08,  3.17it/s]01/10/2022 16:18:44 - INFO - __main__ -   Batch number = 58
Evaluating:  69%|██████▉   | 58/84 [00:14<00:08,  3.09it/s]01/10/2022 16:18:45 - INFO - __main__ -   Batch number = 59
Evaluating:  70%|███████   | 59/84 [00:15<00:08,  3.05it/s]01/10/2022 16:18:45 - INFO - __main__ -   Batch number = 60
Evaluating:  71%|███████▏  | 60/84 [00:15<00:07,  3.02it/s]01/10/2022 16:18:45 - INFO - __main__ -   Batch number = 61
Evaluating:  73%|███████▎  | 61/84 [00:15<00:07,  2.99it/s]01/10/2022 16:18:46 - INFO - __main__ -   Batch number = 62
Evaluating:  74%|███████▍  | 62/84 [00:16<00:07,  2.98it/s]01/10/2022 16:18:46 - INFO - __main__ -   Batch number = 63
Evaluating:  75%|███████▌  | 63/84 [00:16<00:07,  2.96it/s]01/10/2022 16:18:46 - INFO - __main__ -   Batch number = 64
Evaluating:  76%|███████▌  | 64/84 [00:16<00:06,  2.96it/s]01/10/2022 16:18:47 - INFO - __main__ -   Batch number = 65
Evaluating:  77%|███████▋  | 65/84 [00:17<00:07,  2.68it/s]01/10/2022 16:18:47 - INFO - __main__ -   Batch number = 66
Evaluating:  79%|███████▊  | 66/84 [00:17<00:06,  2.92it/s]01/10/2022 16:18:47 - INFO - __main__ -   Batch number = 67
Evaluating:  80%|███████▉  | 67/84 [00:17<00:04,  3.48it/s]01/10/2022 16:18:48 - INFO - __main__ -   Batch number = 68
Evaluating:  81%|████████  | 68/84 [00:17<00:03,  4.03it/s]01/10/2022 16:18:48 - INFO - __main__ -   Batch number = 69
Evaluating:  82%|████████▏ | 69/84 [00:18<00:03,  3.81it/s]01/10/2022 16:18:48 - INFO - __main__ -   Batch number = 70
Evaluating:  83%|████████▎ | 70/84 [00:18<00:04,  3.48it/s]01/10/2022 16:18:48 - INFO - __main__ -   Batch number = 71
Evaluating:  85%|████████▍ | 71/84 [00:18<00:03,  3.27it/s]01/10/2022 16:18:49 - INFO - __main__ -   Batch number = 72
Evaluating:  86%|████████▌ | 72/84 [00:19<00:03,  3.15it/s]01/10/2022 16:18:49 - INFO - __main__ -   Batch number = 73
Evaluating:  87%|████████▋ | 73/84 [00:19<00:03,  3.07it/s]01/10/2022 16:18:49 - INFO - __main__ -   Batch number = 74
Evaluating:  88%|████████▊ | 74/84 [00:19<00:03,  3.23it/s]01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 75
Evaluating:  89%|████████▉ | 75/84 [00:19<00:02,  3.68it/s]01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 76
Evaluating:  90%|█████████ | 76/84 [00:20<00:01,  4.12it/s]01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 77
Evaluating:  92%|█████████▏| 77/84 [00:20<00:01,  4.48it/s]01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 78
Evaluating:  93%|█████████▎| 78/84 [00:20<00:01,  4.77it/s]01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 79
Evaluating:  94%|█████████▍| 79/84 [00:20<00:01,  4.99it/s]01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 80
Evaluating:  95%|█████████▌| 80/84 [00:20<00:00,  5.16it/s]01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 81
Evaluating:  96%|█████████▋| 81/84 [00:20<00:00,  5.29it/s]01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 82
Evaluating:  98%|█████████▊| 82/84 [00:21<00:00,  5.39it/s]01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 83
Evaluating:  99%|█████████▉| 83/84 [00:21<00:00,  5.46it/s]01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 84
Evaluating: 100%|██████████| 84/84 [00:21<00:00,  5.60it/s]Evaluating: 100%|██████████| 84/84 [00:21<00:00,  3.91it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/10/2022 16:18:53 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:18:53 - INFO - __main__ -     f1 = 0.6192915973860252
01/10/2022 16:18:53 - INFO - __main__ -     loss = 1.1742158837261654
01/10/2022 16:18:53 - INFO - __main__ -     precision = 0.6252147095565271
01/10/2022 16:18:53 - INFO - __main__ -     recall = 0.6134796598483108
01/10/2022 16:18:53 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/10/2022 16:18:56 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/10/2022 16:19:01 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:19:01 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/10/2022 16:19:01 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/10/2022 16:19:01 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:19:01 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_model_head.bin
01/10/2022 16:19:01 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:19:01 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:19:01 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:19:01 - INFO - __main__ -   Language = hi
01/10/2022 16:19:01 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/10/2022 16:19:02 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:19:02 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:19:02 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:19:02 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:19:02 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_hi_bert-base-multilingual-cased_128
01/10/2022 16:19:03 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:19:03 - INFO - __main__ -     Num examples = 1664
01/10/2022 16:19:03 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/52 [00:00<?, ?it/s]01/10/2022 16:19:03 - INFO - __main__ -   Batch number = 1
Evaluating:   2%|▏         | 1/52 [00:00<00:17,  2.96it/s]01/10/2022 16:19:03 - INFO - __main__ -   Batch number = 2
Evaluating:   4%|▍         | 2/52 [00:00<00:16,  2.95it/s]01/10/2022 16:19:03 - INFO - __main__ -   Batch number = 3
Evaluating:   6%|▌         | 3/52 [00:01<00:16,  2.96it/s]01/10/2022 16:19:04 - INFO - __main__ -   Batch number = 4
Evaluating:   8%|▊         | 4/52 [00:01<00:16,  2.95it/s]01/10/2022 16:19:04 - INFO - __main__ -   Batch number = 5
Evaluating:  10%|▉         | 5/52 [00:01<00:15,  2.96it/s]01/10/2022 16:19:04 - INFO - __main__ -   Batch number = 6
Evaluating:  12%|█▏        | 6/52 [00:01<00:13,  3.30it/s]01/10/2022 16:19:04 - INFO - __main__ -   Batch number = 7
Evaluating:  13%|█▎        | 7/52 [00:02<00:11,  3.84it/s]01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 8
Evaluating:  15%|█▌        | 8/52 [00:02<00:10,  4.29it/s]01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 9
Evaluating:  17%|█▋        | 9/52 [00:02<00:09,  4.65it/s]01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 10
Evaluating:  19%|█▉        | 10/52 [00:02<00:08,  4.95it/s]01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 11
Evaluating:  21%|██        | 11/52 [00:02<00:07,  5.16it/s]01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 12
Evaluating:  23%|██▎       | 12/52 [00:02<00:07,  5.31it/s]01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 13
Evaluating:  25%|██▌       | 13/52 [00:03<00:07,  5.44it/s]01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 14
Evaluating:  27%|██▋       | 14/52 [00:03<00:06,  5.52it/s]01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 15
Evaluating:  29%|██▉       | 15/52 [00:03<00:06,  5.59it/s]01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 16
Evaluating:  31%|███       | 16/52 [00:03<00:06,  5.64it/s]01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 17
Evaluating:  33%|███▎      | 17/52 [00:03<00:06,  5.66it/s]01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 18
Evaluating:  35%|███▍      | 18/52 [00:04<00:05,  5.69it/s]01/10/2022 16:19:07 - INFO - __main__ -   Batch number = 19
Evaluating:  37%|███▋      | 19/52 [00:04<00:07,  4.38it/s]01/10/2022 16:19:07 - INFO - __main__ -   Batch number = 20
Evaluating:  38%|███▊      | 20/52 [00:04<00:08,  3.88it/s]01/10/2022 16:19:07 - INFO - __main__ -   Batch number = 21
Evaluating:  40%|████      | 21/52 [00:05<00:08,  3.59it/s]01/10/2022 16:19:08 - INFO - __main__ -   Batch number = 22
Evaluating:  42%|████▏     | 22/52 [00:05<00:08,  3.38it/s]01/10/2022 16:19:08 - INFO - __main__ -   Batch number = 23
Evaluating:  44%|████▍     | 23/52 [00:05<00:08,  3.24it/s]01/10/2022 16:19:08 - INFO - __main__ -   Batch number = 24
Evaluating:  46%|████▌     | 24/52 [00:06<00:08,  3.14it/s]01/10/2022 16:19:09 - INFO - __main__ -   Batch number = 25
Evaluating:  48%|████▊     | 25/52 [00:06<00:08,  3.08it/s]01/10/2022 16:19:09 - INFO - __main__ -   Batch number = 26
Evaluating:  50%|█████     | 26/52 [00:06<00:08,  3.05it/s]01/10/2022 16:19:09 - INFO - __main__ -   Batch number = 27
Evaluating:  52%|█████▏    | 27/52 [00:07<00:08,  3.04it/s]01/10/2022 16:19:10 - INFO - __main__ -   Batch number = 28
Evaluating:  54%|█████▍    | 28/52 [00:07<00:07,  3.03it/s]01/10/2022 16:19:10 - INFO - __main__ -   Batch number = 29
Evaluating:  56%|█████▌    | 29/52 [00:07<00:07,  3.03it/s]01/10/2022 16:19:10 - INFO - __main__ -   Batch number = 30
Evaluating:  58%|█████▊    | 30/52 [00:08<00:07,  3.04it/s]01/10/2022 16:19:11 - INFO - __main__ -   Batch number = 31
Evaluating:  60%|█████▉    | 31/52 [00:08<00:06,  3.04it/s]01/10/2022 16:19:11 - INFO - __main__ -   Batch number = 32
Evaluating:  62%|██████▏   | 32/52 [00:08<00:06,  3.02it/s]01/10/2022 16:19:11 - INFO - __main__ -   Batch number = 33
Evaluating:  63%|██████▎   | 33/52 [00:09<00:06,  3.06it/s]01/10/2022 16:19:12 - INFO - __main__ -   Batch number = 34
Evaluating:  65%|██████▌   | 34/52 [00:09<00:05,  3.27it/s]01/10/2022 16:19:12 - INFO - __main__ -   Batch number = 35
Evaluating:  67%|██████▋   | 35/52 [00:09<00:04,  3.64it/s]01/10/2022 16:19:12 - INFO - __main__ -   Batch number = 36
Evaluating:  69%|██████▉   | 36/52 [00:09<00:04,  3.38it/s]01/10/2022 16:19:12 - INFO - __main__ -   Batch number = 37
Evaluating:  71%|███████   | 37/52 [00:10<00:04,  3.22it/s]01/10/2022 16:19:13 - INFO - __main__ -   Batch number = 38
Evaluating:  73%|███████▎  | 38/52 [00:10<00:04,  3.13it/s]01/10/2022 16:19:13 - INFO - __main__ -   Batch number = 39
Evaluating:  75%|███████▌  | 39/52 [00:10<00:04,  3.07it/s]01/10/2022 16:19:13 - INFO - __main__ -   Batch number = 40
Evaluating:  77%|███████▋  | 40/52 [00:11<00:03,  3.02it/s]01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 41
Evaluating:  79%|███████▉  | 41/52 [00:11<00:03,  3.48it/s]01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 42
Evaluating:  81%|████████  | 42/52 [00:11<00:02,  3.94it/s]01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 43
Evaluating:  83%|████████▎ | 43/52 [00:11<00:02,  4.34it/s]01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 44
Evaluating:  85%|████████▍ | 44/52 [00:11<00:01,  4.67it/s]01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 45
Evaluating:  87%|████████▋ | 45/52 [00:12<00:01,  4.93it/s]01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 46
Evaluating:  88%|████████▊ | 46/52 [00:12<00:01,  5.13it/s]01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 47
Evaluating:  90%|█████████ | 47/52 [00:12<00:00,  5.28it/s]01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 48
Evaluating:  92%|█████████▏| 48/52 [00:12<00:00,  5.40it/s]01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 49
Evaluating:  94%|█████████▍| 49/52 [00:12<00:00,  5.48it/s]01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 50
Evaluating:  96%|█████████▌| 50/52 [00:12<00:00,  5.54it/s]01/10/2022 16:19:16 - INFO - __main__ -   Batch number = 51
Evaluating:  98%|█████████▊| 51/52 [00:13<00:00,  5.58it/s]01/10/2022 16:19:16 - INFO - __main__ -   Batch number = 52
Evaluating: 100%|██████████| 52/52 [00:13<00:00,  5.61it/s]Evaluating: 100%|██████████| 52/52 [00:13<00:00,  3.91it/s]
01/10/2022 16:19:17 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:19:17 - INFO - __main__ -     f1 = 0.606455210417555
01/10/2022 16:19:17 - INFO - __main__ -     loss = 1.206090427362002
01/10/2022 16:19:17 - INFO - __main__ -     precision = 0.6115705213019317
01/10/2022 16:19:17 - INFO - __main__ -     recall = 0.6014247609134084
53.86user 18.46system 1:06.71elapsed 108%CPU (0avgtext+0avgdata 4818424maxresident)k
0inputs+1120outputs (0major+1874144minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/10/2022 16:19:19 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:19:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/10/2022 16:19:19 - INFO - __main__ -   Seed = 2
01/10/2022 16:19:19 - INFO - root -   save model
01/10/2022 16:19:19 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:19:19 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/10/2022 16:19:22 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/10/2022 16:19:27 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:19:27 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/10/2022 16:19:27 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/10/2022 16:19:27 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:19:27 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_model_head.bin
01/10/2022 16:19:27 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:19:27 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:19:27 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:19:27 - INFO - __main__ -   Language = hi
01/10/2022 16:19:27 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/10/2022 16:19:35 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:19:35 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:19:35 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:19:35 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:19:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_hi_bert-base-multilingual-cased_128
01/10/2022 16:19:35 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:19:35 - INFO - __main__ -     Num examples = 2685
01/10/2022 16:19:35 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/84 [00:00<?, ?it/s]01/10/2022 16:19:35 - INFO - __main__ -   Batch number = 1
Evaluating:   1%|          | 1/84 [00:00<00:19,  4.23it/s]01/10/2022 16:19:36 - INFO - __main__ -   Batch number = 2
Evaluating:   2%|▏         | 2/84 [00:00<00:24,  3.40it/s]01/10/2022 16:19:36 - INFO - __main__ -   Batch number = 3
Evaluating:   4%|▎         | 3/84 [00:00<00:25,  3.17it/s]01/10/2022 16:19:36 - INFO - __main__ -   Batch number = 4
Evaluating:   5%|▍         | 4/84 [00:01<00:25,  3.09it/s]01/10/2022 16:19:37 - INFO - __main__ -   Batch number = 5
Evaluating:   6%|▌         | 5/84 [00:01<00:28,  2.82it/s]01/10/2022 16:19:37 - INFO - __main__ -   Batch number = 6
Evaluating:   7%|▋         | 6/84 [00:01<00:24,  3.13it/s]01/10/2022 16:19:37 - INFO - __main__ -   Batch number = 7
Evaluating:   8%|▊         | 7/84 [00:02<00:20,  3.69it/s]01/10/2022 16:19:37 - INFO - __main__ -   Batch number = 8
Evaluating:  10%|▉         | 8/84 [00:02<00:18,  4.19it/s]01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 9
Evaluating:  11%|█         | 9/84 [00:02<00:16,  4.58it/s]01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 10
Evaluating:  12%|█▏        | 10/84 [00:02<00:15,  4.88it/s]01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 11
Evaluating:  13%|█▎        | 11/84 [00:02<00:14,  5.11it/s]01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 12
Evaluating:  14%|█▍        | 12/84 [00:02<00:13,  5.28it/s]01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 13
Evaluating:  15%|█▌        | 13/84 [00:03<00:13,  5.42it/s]01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 14
Evaluating:  17%|█▋        | 14/84 [00:03<00:12,  5.51it/s]01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 15
Evaluating:  18%|█▊        | 15/84 [00:03<00:12,  5.57it/s]01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 16
Evaluating:  19%|█▉        | 16/84 [00:03<00:12,  5.65it/s]01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 17
Evaluating:  20%|██        | 17/84 [00:03<00:11,  5.71it/s]01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 18
Evaluating:  21%|██▏       | 18/84 [00:03<00:11,  5.72it/s]01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 19
Evaluating:  23%|██▎       | 19/84 [00:04<00:12,  5.31it/s]01/10/2022 16:19:40 - INFO - __main__ -   Batch number = 20
Evaluating:  24%|██▍       | 20/84 [00:04<00:14,  4.31it/s]01/10/2022 16:19:40 - INFO - __main__ -   Batch number = 21
Evaluating:  25%|██▌       | 21/84 [00:04<00:16,  3.79it/s]01/10/2022 16:19:40 - INFO - __main__ -   Batch number = 22
Evaluating:  26%|██▌       | 22/84 [00:05<00:17,  3.49it/s]01/10/2022 16:19:41 - INFO - __main__ -   Batch number = 23
Evaluating:  27%|██▋       | 23/84 [00:05<00:18,  3.31it/s]01/10/2022 16:19:41 - INFO - __main__ -   Batch number = 24
Evaluating:  29%|██▊       | 24/84 [00:05<00:18,  3.19it/s]01/10/2022 16:19:41 - INFO - __main__ -   Batch number = 25
Evaluating:  30%|██▉       | 25/84 [00:06<00:18,  3.13it/s]01/10/2022 16:19:42 - INFO - __main__ -   Batch number = 26
Evaluating:  31%|███       | 26/84 [00:06<00:19,  3.03it/s]01/10/2022 16:19:42 - INFO - __main__ -   Batch number = 27
Evaluating:  32%|███▏      | 27/84 [00:06<00:18,  3.01it/s]01/10/2022 16:19:42 - INFO - __main__ -   Batch number = 28
Evaluating:  33%|███▎      | 28/84 [00:07<00:18,  3.00it/s]01/10/2022 16:19:43 - INFO - __main__ -   Batch number = 29
Evaluating:  35%|███▍      | 29/84 [00:07<00:18,  2.99it/s]01/10/2022 16:19:43 - INFO - __main__ -   Batch number = 30
Evaluating:  36%|███▌      | 30/84 [00:07<00:17,  3.00it/s]01/10/2022 16:19:43 - INFO - __main__ -   Batch number = 31
Evaluating:  37%|███▋      | 31/84 [00:08<00:17,  3.00it/s]01/10/2022 16:19:44 - INFO - __main__ -   Batch number = 32
Evaluating:  38%|███▊      | 32/84 [00:08<00:17,  3.00it/s]01/10/2022 16:19:44 - INFO - __main__ -   Batch number = 33
Evaluating:  39%|███▉      | 33/84 [00:08<00:16,  3.00it/s]01/10/2022 16:19:44 - INFO - __main__ -   Batch number = 34
Evaluating:  40%|████      | 34/84 [00:09<00:14,  3.48it/s]01/10/2022 16:19:45 - INFO - __main__ -   Batch number = 35
Evaluating:  42%|████▏     | 35/84 [00:09<00:12,  4.03it/s]01/10/2022 16:19:45 - INFO - __main__ -   Batch number = 36
Evaluating:  43%|████▎     | 36/84 [00:09<00:11,  4.15it/s]01/10/2022 16:19:45 - INFO - __main__ -   Batch number = 37
Evaluating:  44%|████▍     | 37/84 [00:09<00:12,  3.68it/s]01/10/2022 16:19:45 - INFO - __main__ -   Batch number = 38
Evaluating:  45%|████▌     | 38/84 [00:10<00:13,  3.41it/s]01/10/2022 16:19:46 - INFO - __main__ -   Batch number = 39
Evaluating:  46%|████▋     | 39/84 [00:10<00:13,  3.25it/s]01/10/2022 16:19:46 - INFO - __main__ -   Batch number = 40
Evaluating:  48%|████▊     | 40/84 [00:10<00:13,  3.15it/s]01/10/2022 16:19:46 - INFO - __main__ -   Batch number = 41
Evaluating:  49%|████▉     | 41/84 [00:11<00:13,  3.08it/s]01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 42
Evaluating:  50%|█████     | 42/84 [00:11<00:12,  3.35it/s]01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 43
Evaluating:  51%|█████     | 43/84 [00:11<00:10,  3.87it/s]01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 44
Evaluating:  52%|█████▏    | 44/84 [00:11<00:09,  4.35it/s]01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 45
Evaluating:  54%|█████▎    | 45/84 [00:11<00:08,  4.75it/s]01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 46
Evaluating:  55%|█████▍    | 46/84 [00:12<00:07,  5.07it/s]01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 47
Evaluating:  56%|█████▌    | 47/84 [00:12<00:06,  5.29it/s]01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 48
Evaluating:  57%|█████▋    | 48/84 [00:12<00:06,  5.42it/s]01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 49
Evaluating:  58%|█████▊    | 49/84 [00:12<00:06,  5.51it/s]01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 50
Evaluating:  60%|█████▉    | 50/84 [00:12<00:06,  5.58it/s]01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 51
Evaluating:  61%|██████    | 51/84 [00:12<00:05,  5.64it/s]01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 52
Evaluating:  62%|██████▏   | 52/84 [00:13<00:05,  5.64it/s]01/10/2022 16:19:49 - INFO - __main__ -   Batch number = 53
Evaluating:  63%|██████▎   | 53/84 [00:13<00:07,  4.41it/s]01/10/2022 16:19:49 - INFO - __main__ -   Batch number = 54
Evaluating:  64%|██████▍   | 54/84 [00:13<00:07,  3.83it/s]01/10/2022 16:19:49 - INFO - __main__ -   Batch number = 55
Evaluating:  65%|██████▌   | 55/84 [00:14<00:08,  3.51it/s]01/10/2022 16:19:50 - INFO - __main__ -   Batch number = 56
Evaluating:  67%|██████▋   | 56/84 [00:14<00:08,  3.31it/s]01/10/2022 16:19:50 - INFO - __main__ -   Batch number = 57
Evaluating:  68%|██████▊   | 57/84 [00:14<00:08,  3.19it/s]01/10/2022 16:19:50 - INFO - __main__ -   Batch number = 58
Evaluating:  69%|██████▉   | 58/84 [00:15<00:08,  3.11it/s]01/10/2022 16:19:51 - INFO - __main__ -   Batch number = 59
Evaluating:  70%|███████   | 59/84 [00:15<00:08,  3.06it/s]01/10/2022 16:19:51 - INFO - __main__ -   Batch number = 60
Evaluating:  71%|███████▏  | 60/84 [00:15<00:07,  3.02it/s]01/10/2022 16:19:51 - INFO - __main__ -   Batch number = 61
Evaluating:  73%|███████▎  | 61/84 [00:16<00:07,  2.99it/s]01/10/2022 16:19:52 - INFO - __main__ -   Batch number = 62
Evaluating:  74%|███████▍  | 62/84 [00:16<00:07,  2.83it/s]01/10/2022 16:19:52 - INFO - __main__ -   Batch number = 63
Evaluating:  75%|███████▌  | 63/84 [00:16<00:07,  2.86it/s]01/10/2022 16:19:52 - INFO - __main__ -   Batch number = 64
Evaluating:  76%|███████▌  | 64/84 [00:17<00:06,  2.88it/s]01/10/2022 16:19:53 - INFO - __main__ -   Batch number = 65
Evaluating:  77%|███████▋  | 65/84 [00:17<00:06,  2.90it/s]01/10/2022 16:19:53 - INFO - __main__ -   Batch number = 66
Evaluating:  79%|███████▊  | 66/84 [00:17<00:06,  2.95it/s]01/10/2022 16:19:53 - INFO - __main__ -   Batch number = 67
Evaluating:  80%|███████▉  | 67/84 [00:18<00:04,  3.51it/s]01/10/2022 16:19:54 - INFO - __main__ -   Batch number = 68
Evaluating:  81%|████████  | 68/84 [00:18<00:03,  4.05it/s]01/10/2022 16:19:54 - INFO - __main__ -   Batch number = 69
Evaluating:  82%|████████▏ | 69/84 [00:18<00:03,  3.93it/s]01/10/2022 16:19:54 - INFO - __main__ -   Batch number = 70
Evaluating:  83%|████████▎ | 70/84 [00:18<00:03,  3.56it/s]01/10/2022 16:19:54 - INFO - __main__ -   Batch number = 71
Evaluating:  85%|████████▍ | 71/84 [00:19<00:03,  3.32it/s]01/10/2022 16:19:55 - INFO - __main__ -   Batch number = 72
Evaluating:  86%|████████▌ | 72/84 [00:19<00:03,  3.18it/s]01/10/2022 16:19:55 - INFO - __main__ -   Batch number = 73
Evaluating:  87%|████████▋ | 73/84 [00:19<00:03,  3.08it/s]01/10/2022 16:19:55 - INFO - __main__ -   Batch number = 74
Evaluating:  88%|████████▊ | 74/84 [00:20<00:03,  3.20it/s]01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 75
Evaluating:  89%|████████▉ | 75/84 [00:20<00:02,  3.67it/s]01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 76
Evaluating:  90%|█████████ | 76/84 [00:20<00:01,  4.12it/s]01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 77
Evaluating:  92%|█████████▏| 77/84 [00:20<00:01,  4.48it/s]01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 78
Evaluating:  93%|█████████▎| 78/84 [00:20<00:01,  4.79it/s]01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 79
Evaluating:  94%|█████████▍| 79/84 [00:21<00:00,  5.00it/s]01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 80
Evaluating:  95%|█████████▌| 80/84 [00:21<00:00,  5.15it/s]01/10/2022 16:19:57 - INFO - __main__ -   Batch number = 81
Evaluating:  96%|█████████▋| 81/84 [00:21<00:00,  5.06it/s]01/10/2022 16:19:57 - INFO - __main__ -   Batch number = 82
Evaluating:  98%|█████████▊| 82/84 [00:21<00:00,  5.27it/s]01/10/2022 16:19:57 - INFO - __main__ -   Batch number = 83
Evaluating:  99%|█████████▉| 83/84 [00:21<00:00,  5.41it/s]01/10/2022 16:19:57 - INFO - __main__ -   Batch number = 84
Evaluating: 100%|██████████| 84/84 [00:21<00:00,  5.61it/s]Evaluating: 100%|██████████| 84/84 [00:21<00:00,  3.82it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/10/2022 16:19:59 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:19:59 - INFO - __main__ -     f1 = 0.6557828103053508
01/10/2022 16:19:59 - INFO - __main__ -     loss = 1.1010813315709431
01/10/2022 16:19:59 - INFO - __main__ -     precision = 0.6588123864383191
01/10/2022 16:19:59 - INFO - __main__ -     recall = 0.6527809698919789
01/10/2022 16:19:59 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/10/2022 16:20:02 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/10/2022 16:20:07 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:20:07 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/10/2022 16:20:07 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/10/2022 16:20:07 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:20:07 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_model_head.bin
01/10/2022 16:20:07 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:20:07 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:20:07 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:20:07 - INFO - __main__ -   Language = hi
01/10/2022 16:20:07 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/10/2022 16:20:08 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:20:08 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:20:08 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:20:08 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:20:08 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_hi_bert-base-multilingual-cased_128
01/10/2022 16:20:09 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:20:09 - INFO - __main__ -     Num examples = 1664
01/10/2022 16:20:09 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/52 [00:00<?, ?it/s]01/10/2022 16:20:09 - INFO - __main__ -   Batch number = 1
Evaluating:   2%|▏         | 1/52 [00:00<00:17,  2.95it/s]01/10/2022 16:20:09 - INFO - __main__ -   Batch number = 2
Evaluating:   4%|▍         | 2/52 [00:00<00:16,  2.95it/s]01/10/2022 16:20:09 - INFO - __main__ -   Batch number = 3
Evaluating:   6%|▌         | 3/52 [00:01<00:16,  2.95it/s]01/10/2022 16:20:10 - INFO - __main__ -   Batch number = 4
Evaluating:   8%|▊         | 4/52 [00:01<00:16,  2.95it/s]01/10/2022 16:20:10 - INFO - __main__ -   Batch number = 5
Evaluating:  10%|▉         | 5/52 [00:01<00:15,  2.95it/s]01/10/2022 16:20:10 - INFO - __main__ -   Batch number = 6
Evaluating:  12%|█▏        | 6/52 [00:01<00:13,  3.51it/s]01/10/2022 16:20:10 - INFO - __main__ -   Batch number = 7
Evaluating:  13%|█▎        | 7/52 [00:02<00:11,  4.02it/s]01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 8
Evaluating:  15%|█▌        | 8/52 [00:02<00:09,  4.44it/s]01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 9
Evaluating:  17%|█▋        | 9/52 [00:02<00:09,  4.77it/s]01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 10
Evaluating:  19%|█▉        | 10/52 [00:02<00:08,  5.03it/s]01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 11
Evaluating:  21%|██        | 11/52 [00:02<00:07,  5.23it/s]01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 12
Evaluating:  23%|██▎       | 12/52 [00:02<00:07,  5.36it/s]01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 13
Evaluating:  25%|██▌       | 13/52 [00:03<00:07,  5.47it/s]01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 14
Evaluating:  27%|██▋       | 14/52 [00:03<00:06,  5.54it/s]01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 15
Evaluating:  29%|██▉       | 15/52 [00:03<00:06,  5.60it/s]01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 16
Evaluating:  31%|███       | 16/52 [00:03<00:06,  5.66it/s]01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 17
Evaluating:  33%|███▎      | 17/52 [00:03<00:06,  5.68it/s]01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 18
Evaluating:  35%|███▍      | 18/52 [00:03<00:05,  5.69it/s]01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 19
Evaluating:  37%|███▋      | 19/52 [00:04<00:06,  4.77it/s]01/10/2022 16:20:13 - INFO - __main__ -   Batch number = 20
Evaluating:  38%|███▊      | 20/52 [00:04<00:07,  4.10it/s]01/10/2022 16:20:13 - INFO - __main__ -   Batch number = 21
Evaluating:  40%|████      | 21/52 [00:04<00:08,  3.71it/s]01/10/2022 16:20:13 - INFO - __main__ -   Batch number = 22
Evaluating:  42%|████▏     | 22/52 [00:05<00:08,  3.45it/s]01/10/2022 16:20:14 - INFO - __main__ -   Batch number = 23
Evaluating:  44%|████▍     | 23/52 [00:05<00:08,  3.29it/s]01/10/2022 16:20:14 - INFO - __main__ -   Batch number = 24
Evaluating:  46%|████▌     | 24/52 [00:05<00:08,  3.18it/s]01/10/2022 16:20:14 - INFO - __main__ -   Batch number = 25
Evaluating:  48%|████▊     | 25/52 [00:06<00:08,  3.11it/s]01/10/2022 16:20:15 - INFO - __main__ -   Batch number = 26
Evaluating:  50%|█████     | 26/52 [00:06<00:08,  3.06it/s]01/10/2022 16:20:15 - INFO - __main__ -   Batch number = 27
Evaluating:  52%|█████▏    | 27/52 [00:06<00:08,  3.03it/s]01/10/2022 16:20:15 - INFO - __main__ -   Batch number = 28
Evaluating:  54%|█████▍    | 28/52 [00:07<00:07,  3.01it/s]01/10/2022 16:20:16 - INFO - __main__ -   Batch number = 29
Evaluating:  56%|█████▌    | 29/52 [00:07<00:07,  2.99it/s]01/10/2022 16:20:16 - INFO - __main__ -   Batch number = 30
Evaluating:  58%|█████▊    | 30/52 [00:07<00:07,  2.98it/s]01/10/2022 16:20:16 - INFO - __main__ -   Batch number = 31
Evaluating:  60%|█████▉    | 31/52 [00:08<00:07,  2.97it/s]01/10/2022 16:20:17 - INFO - __main__ -   Batch number = 32
Evaluating:  62%|██████▏   | 32/52 [00:08<00:06,  2.97it/s]01/10/2022 16:20:17 - INFO - __main__ -   Batch number = 33
Evaluating:  63%|██████▎   | 33/52 [00:08<00:06,  3.03it/s]01/10/2022 16:20:17 - INFO - __main__ -   Batch number = 34
Evaluating:  65%|██████▌   | 34/52 [00:09<00:05,  3.59it/s]01/10/2022 16:20:18 - INFO - __main__ -   Batch number = 35
Evaluating:  67%|██████▋   | 35/52 [00:09<00:04,  4.14it/s]01/10/2022 16:20:18 - INFO - __main__ -   Batch number = 36
Evaluating:  69%|██████▉   | 36/52 [00:09<00:04,  3.95it/s]01/10/2022 16:20:18 - INFO - __main__ -   Batch number = 37
Evaluating:  71%|███████   | 37/52 [00:09<00:04,  3.57it/s]01/10/2022 16:20:18 - INFO - __main__ -   Batch number = 38
Evaluating:  73%|███████▎  | 38/52 [00:10<00:04,  3.35it/s]01/10/2022 16:20:19 - INFO - __main__ -   Batch number = 39
Evaluating:  75%|███████▌  | 39/52 [00:10<00:04,  3.21it/s]01/10/2022 16:20:19 - INFO - __main__ -   Batch number = 40
Evaluating:  77%|███████▋  | 40/52 [00:10<00:03,  3.11it/s]01/10/2022 16:20:19 - INFO - __main__ -   Batch number = 41
Evaluating:  79%|███████▉  | 41/52 [00:11<00:03,  3.20it/s]01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 42
Evaluating:  81%|████████  | 42/52 [00:11<00:02,  3.67it/s]01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 43
Evaluating:  83%|████████▎ | 43/52 [00:11<00:02,  4.11it/s]01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 44
Evaluating:  85%|████████▍ | 44/52 [00:11<00:01,  4.48it/s]01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 45
Evaluating:  87%|████████▋ | 45/52 [00:11<00:01,  4.80it/s]01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 46
Evaluating:  88%|████████▊ | 46/52 [00:12<00:01,  5.04it/s]01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 47
Evaluating:  90%|█████████ | 47/52 [00:12<00:00,  5.22it/s]01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 48
Evaluating:  92%|█████████▏| 48/52 [00:12<00:00,  5.34it/s]01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 49
Evaluating:  94%|█████████▍| 49/52 [00:12<00:00,  5.43it/s]01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 50
Evaluating:  96%|█████████▌| 50/52 [00:12<00:00,  5.50it/s]01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 51
Evaluating:  98%|█████████▊| 51/52 [00:12<00:00,  5.54it/s]01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 52
Evaluating: 100%|██████████| 52/52 [00:13<00:00,  5.58it/s]Evaluating: 100%|██████████| 52/52 [00:13<00:00,  3.92it/s]
01/10/2022 16:20:23 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:20:23 - INFO - __main__ -     f1 = 0.6480516095399453
01/10/2022 16:20:23 - INFO - __main__ -     loss = 1.0889393905034432
01/10/2022 16:20:23 - INFO - __main__ -     precision = 0.6491090659878598
01/10/2022 16:20:23 - INFO - __main__ -     recall = 0.6469975928696897
53.80user 19.48system 1:06.13elapsed 110%CPU (0avgtext+0avgdata 4789536maxresident)k
0inputs+1080outputs (0major+1783000minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/10/2022 16:20:25 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:20:25 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/10/2022 16:20:25 - INFO - __main__ -   Seed = 3
01/10/2022 16:20:25 - INFO - root -   save model
01/10/2022 16:20:25 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:20:25 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/10/2022 16:20:28 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/10/2022 16:20:34 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:20:34 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/10/2022 16:20:34 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/10/2022 16:20:34 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:20:34 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_model_head.bin
01/10/2022 16:20:34 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:20:34 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:20:34 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:20:34 - INFO - __main__ -   Language = hi
01/10/2022 16:20:34 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/10/2022 16:20:41 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:20:41 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:20:41 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:20:41 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:20:41 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_hi_bert-base-multilingual-cased_128
01/10/2022 16:20:41 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:20:41 - INFO - __main__ -     Num examples = 2685
01/10/2022 16:20:41 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/84 [00:00<?, ?it/s]01/10/2022 16:20:41 - INFO - __main__ -   Batch number = 1
Evaluating:   1%|          | 1/84 [00:00<00:32,  2.52it/s]01/10/2022 16:20:42 - INFO - __main__ -   Batch number = 2
Evaluating:   2%|▏         | 2/84 [00:00<00:29,  2.74it/s]01/10/2022 16:20:42 - INFO - __main__ -   Batch number = 3
Evaluating:   4%|▎         | 3/84 [00:01<00:28,  2.83it/s]01/10/2022 16:20:42 - INFO - __main__ -   Batch number = 4
Evaluating:   5%|▍         | 4/84 [00:01<00:27,  2.87it/s]01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 5
Evaluating:   6%|▌         | 5/84 [00:01<00:22,  3.47it/s]01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 6
Evaluating:   7%|▋         | 6/84 [00:01<00:19,  4.00it/s]01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 7
Evaluating:   8%|▊         | 7/84 [00:01<00:17,  4.45it/s]01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 8
Evaluating:  10%|▉         | 8/84 [00:02<00:15,  4.81it/s]01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 9
Evaluating:  11%|█         | 9/84 [00:02<00:14,  5.06it/s]01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 10
Evaluating:  12%|█▏        | 10/84 [00:02<00:14,  5.25it/s]01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 11
Evaluating:  13%|█▎        | 11/84 [00:02<00:13,  5.38it/s]01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 12
Evaluating:  14%|█▍        | 12/84 [00:02<00:13,  5.48it/s]01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 13
Evaluating:  15%|█▌        | 13/84 [00:02<00:12,  5.56it/s]01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 14
Evaluating:  17%|█▋        | 14/84 [00:03<00:12,  5.67it/s]01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 15
Evaluating:  18%|█▊        | 15/84 [00:03<00:11,  5.88it/s]01/10/2022 16:20:45 - INFO - __main__ -   Batch number = 16
Evaluating:  19%|█▉        | 16/84 [00:03<00:11,  6.04it/s]01/10/2022 16:20:45 - INFO - __main__ -   Batch number = 17
Evaluating:  20%|██        | 17/84 [00:03<00:11,  6.06it/s]01/10/2022 16:20:45 - INFO - __main__ -   Batch number = 18
Evaluating:  21%|██▏       | 18/84 [00:03<00:14,  4.57it/s]01/10/2022 16:20:45 - INFO - __main__ -   Batch number = 19
Evaluating:  23%|██▎       | 19/84 [00:04<00:16,  3.91it/s]01/10/2022 16:20:46 - INFO - __main__ -   Batch number = 20
Evaluating:  24%|██▍       | 20/84 [00:04<00:17,  3.56it/s]01/10/2022 16:20:46 - INFO - __main__ -   Batch number = 21
Evaluating:  25%|██▌       | 21/84 [00:05<00:18,  3.34it/s]01/10/2022 16:20:46 - INFO - __main__ -   Batch number = 22
Evaluating:  26%|██▌       | 22/84 [00:05<00:19,  3.20it/s]01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 23
Evaluating:  27%|██▋       | 23/84 [00:05<00:17,  3.48it/s]01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 24
Evaluating:  29%|██▊       | 24/84 [00:05<00:15,  3.94it/s]01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 25
Evaluating:  30%|██▉       | 25/84 [00:05<00:13,  4.34it/s]01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 26
Evaluating:  31%|███       | 26/84 [00:06<00:12,  4.68it/s]01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 27
Evaluating:  32%|███▏      | 27/84 [00:06<00:11,  4.92it/s]01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 28
Evaluating:  33%|███▎      | 28/84 [00:06<00:10,  5.13it/s]01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 29
Evaluating:  35%|███▍      | 29/84 [00:06<00:10,  5.29it/s]01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 30
Evaluating:  36%|███▌      | 30/84 [00:06<00:10,  5.40it/s]01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 31
Evaluating:  37%|███▋      | 31/84 [00:06<00:09,  5.48it/s]01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 32
Evaluating:  38%|███▊      | 32/84 [00:07<00:09,  5.55it/s]01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 33
Evaluating:  39%|███▉      | 33/84 [00:07<00:09,  5.59it/s]01/10/2022 16:20:49 - INFO - __main__ -   Batch number = 34
Evaluating:  40%|████      | 34/84 [00:07<00:08,  5.62it/s]01/10/2022 16:20:49 - INFO - __main__ -   Batch number = 35
Evaluating:  42%|████▏     | 35/84 [00:07<00:08,  5.56it/s]01/10/2022 16:20:49 - INFO - __main__ -   Batch number = 36
Evaluating:  43%|████▎     | 36/84 [00:07<00:10,  4.63it/s]01/10/2022 16:20:49 - INFO - __main__ -   Batch number = 37
Evaluating:  44%|████▍     | 37/84 [00:08<00:11,  3.94it/s]01/10/2022 16:20:50 - INFO - __main__ -   Batch number = 38
Evaluating:  45%|████▌     | 38/84 [00:08<00:12,  3.58it/s]01/10/2022 16:20:50 - INFO - __main__ -   Batch number = 39
Evaluating:  46%|████▋     | 39/84 [00:09<00:13,  3.36it/s]01/10/2022 16:20:50 - INFO - __main__ -   Batch number = 40
Evaluating:  48%|████▊     | 40/84 [00:09<00:13,  3.22it/s]01/10/2022 16:20:51 - INFO - __main__ -   Batch number = 41
Evaluating:  49%|████▉     | 41/84 [00:09<00:13,  3.14it/s]01/10/2022 16:20:51 - INFO - __main__ -   Batch number = 42
Evaluating:  50%|█████     | 42/84 [00:10<00:13,  3.07it/s]01/10/2022 16:20:51 - INFO - __main__ -   Batch number = 43
Evaluating:  51%|█████     | 43/84 [00:10<00:13,  3.03it/s]01/10/2022 16:20:52 - INFO - __main__ -   Batch number = 44
Evaluating:  52%|█████▏    | 44/84 [00:10<00:13,  3.00it/s]01/10/2022 16:20:52 - INFO - __main__ -   Batch number = 45
Evaluating:  54%|█████▎    | 45/84 [00:11<00:13,  2.98it/s]01/10/2022 16:20:52 - INFO - __main__ -   Batch number = 46
Evaluating:  55%|█████▍    | 46/84 [00:11<00:12,  2.97it/s]01/10/2022 16:20:53 - INFO - __main__ -   Batch number = 47
Evaluating:  56%|█████▌    | 47/84 [00:11<00:12,  2.96it/s]01/10/2022 16:20:53 - INFO - __main__ -   Batch number = 48
Evaluating:  57%|█████▋    | 48/84 [00:12<00:12,  2.95it/s]01/10/2022 16:20:53 - INFO - __main__ -   Batch number = 49
Evaluating:  58%|█████▊    | 49/84 [00:12<00:11,  2.94it/s]01/10/2022 16:20:54 - INFO - __main__ -   Batch number = 50
Evaluating:  60%|█████▉    | 50/84 [00:12<00:10,  3.12it/s]01/10/2022 16:20:54 - INFO - __main__ -   Batch number = 51
Evaluating:  61%|██████    | 51/84 [00:12<00:08,  3.68it/s]01/10/2022 16:20:54 - INFO - __main__ -   Batch number = 52
Evaluating:  62%|██████▏   | 52/84 [00:13<00:07,  4.21it/s]01/10/2022 16:20:54 - INFO - __main__ -   Batch number = 53
Evaluating:  63%|██████▎   | 53/84 [00:13<00:08,  3.87it/s]01/10/2022 16:20:55 - INFO - __main__ -   Batch number = 54
Evaluating:  64%|██████▍   | 54/84 [00:13<00:08,  3.51it/s]01/10/2022 16:20:55 - INFO - __main__ -   Batch number = 55
Evaluating:  65%|██████▌   | 55/84 [00:14<00:08,  3.31it/s]01/10/2022 16:20:55 - INFO - __main__ -   Batch number = 56
Evaluating:  67%|██████▋   | 56/84 [00:14<00:08,  3.18it/s]01/10/2022 16:20:56 - INFO - __main__ -   Batch number = 57
Evaluating:  68%|██████▊   | 57/84 [00:14<00:08,  3.09it/s]01/10/2022 16:20:56 - INFO - __main__ -   Batch number = 58
Evaluating:  69%|██████▉   | 58/84 [00:14<00:07,  3.27it/s]01/10/2022 16:20:56 - INFO - __main__ -   Batch number = 59
Evaluating:  70%|███████   | 59/84 [00:15<00:06,  3.74it/s]01/10/2022 16:20:56 - INFO - __main__ -   Batch number = 60
Evaluating:  71%|███████▏  | 60/84 [00:15<00:05,  4.15it/s]01/10/2022 16:20:57 - INFO - __main__ -   Batch number = 61
Evaluating:  73%|███████▎  | 61/84 [00:15<00:05,  4.51it/s]01/10/2022 16:20:57 - INFO - __main__ -   Batch number = 62
Evaluating:  74%|███████▍  | 62/84 [00:15<00:06,  3.66it/s]01/10/2022 16:20:57 - INFO - __main__ -   Batch number = 63
Evaluating:  75%|███████▌  | 63/84 [00:16<00:05,  4.06it/s]01/10/2022 16:20:57 - INFO - __main__ -   Batch number = 64
Evaluating:  76%|███████▌  | 64/84 [00:16<00:04,  4.04it/s]01/10/2022 16:20:58 - INFO - __main__ -   Batch number = 65
Evaluating:  77%|███████▋  | 65/84 [00:16<00:05,  3.63it/s]01/10/2022 16:20:58 - INFO - __main__ -   Batch number = 66
Evaluating:  79%|███████▊  | 66/84 [00:17<00:05,  3.39it/s]01/10/2022 16:20:58 - INFO - __main__ -   Batch number = 67
Evaluating:  80%|███████▉  | 67/84 [00:17<00:05,  3.23it/s]01/10/2022 16:20:59 - INFO - __main__ -   Batch number = 68
Evaluating:  81%|████████  | 68/84 [00:17<00:05,  3.13it/s]01/10/2022 16:20:59 - INFO - __main__ -   Batch number = 69
Evaluating:  82%|████████▏ | 69/84 [00:18<00:04,  3.06it/s]01/10/2022 16:20:59 - INFO - __main__ -   Batch number = 70
Evaluating:  83%|████████▎ | 70/84 [00:18<00:04,  3.03it/s]01/10/2022 16:21:00 - INFO - __main__ -   Batch number = 71
Evaluating:  85%|████████▍ | 71/84 [00:18<00:04,  3.00it/s]01/10/2022 16:21:00 - INFO - __main__ -   Batch number = 72
Evaluating:  86%|████████▌ | 72/84 [00:19<00:04,  2.97it/s]01/10/2022 16:21:00 - INFO - __main__ -   Batch number = 73
Evaluating:  87%|████████▋ | 73/84 [00:19<00:03,  2.95it/s]01/10/2022 16:21:01 - INFO - __main__ -   Batch number = 74
Evaluating:  88%|████████▊ | 74/84 [00:19<00:03,  2.88it/s]01/10/2022 16:21:01 - INFO - __main__ -   Batch number = 75
Evaluating:  89%|████████▉ | 75/84 [00:20<00:03,  2.90it/s]01/10/2022 16:21:01 - INFO - __main__ -   Batch number = 76
Evaluating:  90%|█████████ | 76/84 [00:20<00:02,  2.91it/s]01/10/2022 16:21:02 - INFO - __main__ -   Batch number = 77
Evaluating:  92%|█████████▏| 77/84 [00:20<00:02,  2.90it/s]01/10/2022 16:21:02 - INFO - __main__ -   Batch number = 78
Evaluating:  93%|█████████▎| 78/84 [00:21<00:01,  3.08it/s]01/10/2022 16:21:02 - INFO - __main__ -   Batch number = 79
Evaluating:  94%|█████████▍| 79/84 [00:21<00:01,  3.63it/s]01/10/2022 16:21:02 - INFO - __main__ -   Batch number = 80
Evaluating:  95%|█████████▌| 80/84 [00:21<00:00,  4.15it/s]01/10/2022 16:21:03 - INFO - __main__ -   Batch number = 81
Evaluating:  96%|█████████▋| 81/84 [00:21<00:00,  3.79it/s]01/10/2022 16:21:03 - INFO - __main__ -   Batch number = 82
Evaluating:  98%|█████████▊| 82/84 [00:22<00:00,  3.48it/s]01/10/2022 16:21:03 - INFO - __main__ -   Batch number = 83
Evaluating:  99%|█████████▉| 83/84 [00:22<00:00,  3.27it/s]01/10/2022 16:21:04 - INFO - __main__ -   Batch number = 84
Evaluating: 100%|██████████| 84/84 [00:22<00:00,  3.19it/s]Evaluating: 100%|██████████| 84/84 [00:22<00:00,  3.69it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/10/2022 16:21:05 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:21:05 - INFO - __main__ -     f1 = 0.6698534220751741
01/10/2022 16:21:05 - INFO - __main__ -     loss = 1.0617101788520813
01/10/2022 16:21:05 - INFO - __main__ -     precision = 0.6727782071097372
01/10/2022 16:21:05 - INFO - __main__ -     recall = 0.6669539569447637
01/10/2022 16:21:05 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/10/2022 16:21:08 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/10/2022 16:21:13 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:21:13 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/10/2022 16:21:13 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/10/2022 16:21:13 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:21:13 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_model_head.bin
01/10/2022 16:21:14 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:21:14 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:21:14 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:21:14 - INFO - __main__ -   Language = hi
01/10/2022 16:21:14 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/10/2022 16:21:15 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:21:15 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:21:15 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:21:15 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:21:15 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_hi_bert-base-multilingual-cased_128
01/10/2022 16:21:15 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:21:15 - INFO - __main__ -     Num examples = 1664
01/10/2022 16:21:15 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/52 [00:00<?, ?it/s]01/10/2022 16:21:15 - INFO - __main__ -   Batch number = 1
Evaluating:   2%|▏         | 1/52 [00:00<00:12,  4.07it/s]01/10/2022 16:21:15 - INFO - __main__ -   Batch number = 2
Evaluating:   4%|▍         | 2/52 [00:00<00:09,  5.22it/s]01/10/2022 16:21:16 - INFO - __main__ -   Batch number = 3
Evaluating:   6%|▌         | 3/52 [00:00<00:08,  5.73it/s]01/10/2022 16:21:16 - INFO - __main__ -   Batch number = 4
Evaluating:   8%|▊         | 4/52 [00:00<00:11,  4.15it/s]01/10/2022 16:21:16 - INFO - __main__ -   Batch number = 5
Evaluating:  10%|▉         | 5/52 [00:01<00:13,  3.61it/s]01/10/2022 16:21:16 - INFO - __main__ -   Batch number = 6
Evaluating:  12%|█▏        | 6/52 [00:01<00:13,  3.36it/s]01/10/2022 16:21:17 - INFO - __main__ -   Batch number = 7
Evaluating:  13%|█▎        | 7/52 [00:01<00:14,  3.21it/s]01/10/2022 16:21:17 - INFO - __main__ -   Batch number = 8
Evaluating:  15%|█▌        | 8/52 [00:02<00:14,  3.11it/s]01/10/2022 16:21:17 - INFO - __main__ -   Batch number = 9
Evaluating:  17%|█▋        | 9/52 [00:02<00:12,  3.37it/s]01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 10
Evaluating:  19%|█▉        | 10/52 [00:02<00:10,  3.86it/s]01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 11
Evaluating:  21%|██        | 11/52 [00:02<00:09,  4.29it/s]01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 12
Evaluating:  23%|██▎       | 12/52 [00:03<00:08,  4.64it/s]01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 13
Evaluating:  25%|██▌       | 13/52 [00:03<00:07,  4.93it/s]01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 14
Evaluating:  27%|██▋       | 14/52 [00:03<00:07,  5.15it/s]01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 15
Evaluating:  29%|██▉       | 15/52 [00:03<00:06,  5.31it/s]01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 16
Evaluating:  31%|███       | 16/52 [00:03<00:06,  5.43it/s]01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 17
Evaluating:  33%|███▎      | 17/52 [00:03<00:06,  5.52it/s]01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 18
Evaluating:  35%|███▍      | 18/52 [00:04<00:06,  5.57it/s]01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 19
Evaluating:  37%|███▋      | 19/52 [00:04<00:05,  5.62it/s]01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 20
Evaluating:  38%|███▊      | 20/52 [00:04<00:05,  5.65it/s]01/10/2022 16:21:20 - INFO - __main__ -   Batch number = 21
Evaluating:  40%|████      | 21/52 [00:04<00:05,  5.67it/s]01/10/2022 16:21:20 - INFO - __main__ -   Batch number = 22
Evaluating:  42%|████▏     | 22/52 [00:04<00:05,  5.38it/s]01/10/2022 16:21:20 - INFO - __main__ -   Batch number = 23
Evaluating:  44%|████▍     | 23/52 [00:05<00:06,  4.42it/s]01/10/2022 16:21:20 - INFO - __main__ -   Batch number = 24
Evaluating:  46%|████▌     | 24/52 [00:05<00:07,  3.92it/s]01/10/2022 16:21:21 - INFO - __main__ -   Batch number = 25
Evaluating:  48%|████▊     | 25/52 [00:05<00:07,  3.62it/s]01/10/2022 16:21:21 - INFO - __main__ -   Batch number = 26
Evaluating:  50%|█████     | 26/52 [00:06<00:07,  3.45it/s]01/10/2022 16:21:21 - INFO - __main__ -   Batch number = 27
Evaluating:  52%|█████▏    | 27/52 [00:06<00:07,  3.30it/s]01/10/2022 16:21:22 - INFO - __main__ -   Batch number = 28
Evaluating:  54%|█████▍    | 28/52 [00:06<00:07,  3.18it/s]01/10/2022 16:21:22 - INFO - __main__ -   Batch number = 29
Evaluating:  56%|█████▌    | 29/52 [00:07<00:07,  3.10it/s]01/10/2022 16:21:22 - INFO - __main__ -   Batch number = 30
Evaluating:  58%|█████▊    | 30/52 [00:07<00:07,  3.06it/s]01/10/2022 16:21:23 - INFO - __main__ -   Batch number = 31
Evaluating:  60%|█████▉    | 31/52 [00:07<00:06,  3.01it/s]01/10/2022 16:21:23 - INFO - __main__ -   Batch number = 32
Evaluating:  62%|██████▏   | 32/52 [00:08<00:06,  2.99it/s]01/10/2022 16:21:23 - INFO - __main__ -   Batch number = 33
Evaluating:  63%|██████▎   | 33/52 [00:08<00:06,  2.98it/s]01/10/2022 16:21:24 - INFO - __main__ -   Batch number = 34
Evaluating:  65%|██████▌   | 34/52 [00:08<00:06,  2.97it/s]01/10/2022 16:21:24 - INFO - __main__ -   Batch number = 35
Evaluating:  67%|██████▋   | 35/52 [00:09<00:05,  2.96it/s]01/10/2022 16:21:24 - INFO - __main__ -   Batch number = 36
Evaluating:  69%|██████▉   | 36/52 [00:09<00:05,  2.96it/s]01/10/2022 16:21:25 - INFO - __main__ -   Batch number = 37
Evaluating:  71%|███████   | 37/52 [00:09<00:04,  3.25it/s]01/10/2022 16:21:25 - INFO - __main__ -   Batch number = 38
Evaluating:  73%|███████▎  | 38/52 [00:09<00:03,  3.81it/s]01/10/2022 16:21:25 - INFO - __main__ -   Batch number = 39
Evaluating:  75%|███████▌  | 39/52 [00:10<00:03,  4.29it/s]01/10/2022 16:21:25 - INFO - __main__ -   Batch number = 40
Evaluating:  77%|███████▋  | 40/52 [00:10<00:03,  3.76it/s]01/10/2022 16:21:26 - INFO - __main__ -   Batch number = 41
Evaluating:  79%|███████▉  | 41/52 [00:10<00:03,  3.46it/s]01/10/2022 16:21:26 - INFO - __main__ -   Batch number = 42
Evaluating:  81%|████████  | 42/52 [00:11<00:03,  3.28it/s]01/10/2022 16:21:26 - INFO - __main__ -   Batch number = 43
Evaluating:  83%|████████▎ | 43/52 [00:11<00:02,  3.16it/s]01/10/2022 16:21:27 - INFO - __main__ -   Batch number = 44
Evaluating:  85%|████████▍ | 44/52 [00:11<00:02,  3.08it/s]01/10/2022 16:21:27 - INFO - __main__ -   Batch number = 45
Evaluating:  87%|████████▋ | 45/52 [00:11<00:02,  3.41it/s]01/10/2022 16:21:27 - INFO - __main__ -   Batch number = 46
Evaluating:  88%|████████▊ | 46/52 [00:12<00:01,  3.87it/s]01/10/2022 16:21:27 - INFO - __main__ -   Batch number = 47
Evaluating:  90%|█████████ | 47/52 [00:12<00:01,  4.30it/s]01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 48
Evaluating:  92%|█████████▏| 48/52 [00:12<00:00,  4.64it/s]01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 49
Evaluating:  94%|█████████▍| 49/52 [00:12<00:00,  4.90it/s]01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 50
Evaluating:  96%|█████████▌| 50/52 [00:12<00:00,  5.09it/s]01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 51
Evaluating:  98%|█████████▊| 51/52 [00:13<00:00,  5.25it/s]01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 52
Evaluating: 100%|██████████| 52/52 [00:13<00:00,  5.36it/s]Evaluating: 100%|██████████| 52/52 [00:13<00:00,  3.93it/s]
01/10/2022 16:21:29 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:21:29 - INFO - __main__ -     f1 = 0.6616311248575615
01/10/2022 16:21:29 - INFO - __main__ -     loss = 1.0752558650878759
01/10/2022 16:21:29 - INFO - __main__ -     precision = 0.6622132429614181
01/10/2022 16:21:29 - INFO - __main__ -     recall = 0.6610500292759092
54.79user 19.84system 1:06.37elapsed 112%CPU (0avgtext+0avgdata 4789124maxresident)k
0inputs+1088outputs (0major+1724726minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/15/2022 02:39:06 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:39:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 02:39:06 - INFO - __main__ -   Seed = 1
01/15/2022 02:39:06 - INFO - root -   save model
01/15/2022 02:39:06 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:39:06 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/15/2022 02:39:09 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/15/2022 02:39:14 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:39:14 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 02:39:14 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/15/2022 02:39:14 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:39:14 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_model_head.bin
01/15/2022 02:39:14 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:39:14 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:39:14 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:39:14 - INFO - __main__ -   Language = hi
01/15/2022 02:39:14 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/15/2022 02:39:19 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:39:19 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:19 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:19 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:19 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
01/15/2022 02:39:19 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:39:19 - INFO - __main__ -     Num examples = 47
01/15/2022 02:39:19 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]01/15/2022 02:39:19 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  5.93it/s]01/15/2022 02:39:19 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  8.16it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/15/2022 02:39:20 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:39:20 - INFO - __main__ -     f1 = 0.5079365079365079
01/15/2022 02:39:20 - INFO - __main__ -     loss = 1.494471788406372
01/15/2022 02:39:20 - INFO - __main__ -     precision = 0.5387205387205387
01/15/2022 02:39:20 - INFO - __main__ -     recall = 0.4804804804804805
01/15/2022 02:39:20 - INFO - __main__ -   Language adapter for bho not found, using hi instead
01/15/2022 02:39:20 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:20 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:20 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:20 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_bho_bert-base-multilingual-cased_128
01/15/2022 02:39:20 - INFO - __main__ -   ***** Running evaluation  in bho *****
01/15/2022 02:39:20 - INFO - __main__ -     Num examples = 361
01/15/2022 02:39:20 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 1
Evaluating:   8%|▊         | 1/12 [00:00<00:01,  6.98it/s]01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 2
Evaluating:  17%|█▋        | 2/12 [00:00<00:01,  7.20it/s]01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 3
Evaluating:  25%|██▌       | 3/12 [00:00<00:01,  7.25it/s]01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 4
Evaluating:  33%|███▎      | 4/12 [00:00<00:01,  7.27it/s]01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 5
Evaluating:  42%|████▏     | 5/12 [00:00<00:00,  7.28it/s]01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 6
Evaluating:  50%|█████     | 6/12 [00:00<00:00,  7.29it/s]01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 7
Evaluating:  58%|█████▊    | 7/12 [00:01<00:00,  6.24it/s]01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 8
Evaluating:  67%|██████▋   | 8/12 [00:01<00:00,  6.53it/s]01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 9
Evaluating:  75%|███████▌  | 9/12 [00:01<00:00,  6.72it/s]01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 10
Evaluating:  83%|████████▎ | 10/12 [00:01<00:00,  6.88it/s]01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 11
Evaluating:  92%|█████████▏| 11/12 [00:01<00:00,  6.98it/s]01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 12
Evaluating: 100%|██████████| 12/12 [00:01<00:00,  7.32it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/15/2022 02:39:21 - INFO - __main__ -   ***** Evaluation result  in bho *****
01/15/2022 02:39:21 - INFO - __main__ -     f1 = 0.46695576756287943
01/15/2022 02:39:21 - INFO - __main__ -     loss = 2.092569281657537
01/15/2022 02:39:21 - INFO - __main__ -     precision = 0.48900999091734787
01/15/2022 02:39:21 - INFO - __main__ -     recall = 0.446804979253112
01/15/2022 02:39:22 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:39:22 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:22 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:22 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:22 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_ta_bert-base-multilingual-cased_128
01/15/2022 02:39:22 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:39:22 - INFO - __main__ -     Num examples = 656
01/15/2022 02:39:22 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 1
Evaluating:   5%|▍         | 1/21 [00:00<00:02,  7.38it/s]01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 2
Evaluating:  10%|▉         | 2/21 [00:00<00:02,  7.30it/s]01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 3
Evaluating:  14%|█▍        | 3/21 [00:00<00:02,  7.32it/s]01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 4
Evaluating:  19%|█▉        | 4/21 [00:00<00:02,  7.31it/s]01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 5
Evaluating:  24%|██▍       | 5/21 [00:00<00:02,  7.30it/s]01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 6
Evaluating:  29%|██▊       | 6/21 [00:00<00:02,  7.31it/s]01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 7
Evaluating:  33%|███▎      | 7/21 [00:00<00:01,  7.29it/s]01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 8
Evaluating:  38%|███▊      | 8/21 [00:01<00:01,  7.28it/s]01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 9
Evaluating:  43%|████▎     | 9/21 [00:01<00:01,  7.26it/s]01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 10
Evaluating:  48%|████▊     | 10/21 [00:01<00:01,  7.18it/s]01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 11
Evaluating:  52%|█████▏    | 11/21 [00:01<00:01,  7.20it/s]01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 12
Evaluating:  57%|█████▋    | 12/21 [00:01<00:01,  7.21it/s]01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 13
Evaluating:  62%|██████▏   | 13/21 [00:01<00:01,  7.19it/s]01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 14
Evaluating:  67%|██████▋   | 14/21 [00:01<00:00,  7.14it/s]01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 15
Evaluating:  71%|███████▏  | 15/21 [00:02<00:00,  7.16it/s]01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 16
Evaluating:  76%|███████▌  | 16/21 [00:02<00:00,  7.18it/s]01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 17
Evaluating:  81%|████████  | 17/21 [00:02<00:00,  7.20it/s]01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 18
Evaluating:  86%|████████▌ | 18/21 [00:02<00:00,  7.20it/s]01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 19
Evaluating:  90%|█████████ | 19/21 [00:02<00:00,  7.20it/s]01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 20
Evaluating:  95%|█████████▌| 20/21 [00:02<00:00,  7.20it/s]01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 21
Evaluating: 100%|██████████| 21/21 [00:02<00:00,  7.39it/s]
01/15/2022 02:39:25 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:39:25 - INFO - __main__ -     f1 = 0.5443276744812718
01/15/2022 02:39:25 - INFO - __main__ -     loss = 1.3883723389534723
01/15/2022 02:39:25 - INFO - __main__ -     precision = 0.5732122587968218
01/15/2022 02:39:25 - INFO - __main__ -     recall = 0.5182144689584403
01/15/2022 02:39:25 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/15/2022 02:39:27 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/15/2022 02:39:34 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:39:34 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/15/2022 02:39:34 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/15/2022 02:39:34 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:39:34 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/pytorch_model_head.bin
01/15/2022 02:39:34 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:39:34 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:39:34 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:39:34 - INFO - __main__ -   Language = hi
01/15/2022 02:39:34 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/15/2022 02:39:35 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:39:35 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:35 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:35 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_mr_bert-base-multilingual-cased_128
01/15/2022 02:39:35 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:39:35 - INFO - __main__ -     Num examples = 46
01/15/2022 02:39:35 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  6.58it/s]01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  9.02it/s]
01/15/2022 02:39:35 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:39:35 - INFO - __main__ -     f1 = 0.5152439024390244
01/15/2022 02:39:35 - INFO - __main__ -     loss = 1.5474462509155273
01/15/2022 02:39:35 - INFO - __main__ -     precision = 0.5504885993485342
01/15/2022 02:39:35 - INFO - __main__ -     recall = 0.48424068767908307
01/15/2022 02:39:35 - INFO - __main__ -   Language bho, split dev does not exist
01/15/2022 02:39:35 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:39:35 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:35 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:35 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_ta_bert-base-multilingual-cased_128
01/15/2022 02:39:35 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:39:35 - INFO - __main__ -     Num examples = 81
01/15/2022 02:39:35 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 1
Evaluating:  33%|███▎      | 1/3 [00:00<00:00,  7.24it/s]01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 2
Evaluating:  67%|██████▋   | 2/3 [00:00<00:00,  7.30it/s]01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 3
Evaluating: 100%|██████████| 3/3 [00:00<00:00,  8.55it/s]
01/15/2022 02:39:35 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:39:35 - INFO - __main__ -     f1 = 0.5410628019323672
01/15/2022 02:39:35 - INFO - __main__ -     loss = 1.4334317843119304
01/15/2022 02:39:35 - INFO - __main__ -     precision = 0.5618729096989966
01/15/2022 02:39:35 - INFO - __main__ -     recall = 0.5217391304347826
29.14user 12.88system 0:31.30elapsed 134%CPU (0avgtext+0avgdata 4813232maxresident)k
0inputs+304outputs (0major+1898189minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/15/2022 02:39:37 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:39:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 02:39:37 - INFO - __main__ -   Seed = 2
01/15/2022 02:39:37 - INFO - root -   save model
01/15/2022 02:39:37 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:39:37 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/15/2022 02:39:40 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/15/2022 02:39:46 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:39:46 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 02:39:46 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/15/2022 02:39:46 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:39:46 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_model_head.bin
01/15/2022 02:39:46 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:39:46 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:39:46 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:39:46 - INFO - __main__ -   Language = hi
01/15/2022 02:39:46 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/15/2022 02:39:50 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:39:50 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:50 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:50 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:50 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
01/15/2022 02:39:50 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:39:50 - INFO - __main__ -     Num examples = 47
01/15/2022 02:39:50 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  7.18it/s]01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  9.46it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/15/2022 02:39:50 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:39:50 - INFO - __main__ -     f1 = 0.5297805642633229
01/15/2022 02:39:50 - INFO - __main__ -     loss = 1.4993797540664673
01/15/2022 02:39:50 - INFO - __main__ -     precision = 0.5540983606557377
01/15/2022 02:39:50 - INFO - __main__ -     recall = 0.5075075075075075
01/15/2022 02:39:50 - INFO - __main__ -   Language adapter for bho not found, using hi instead
01/15/2022 02:39:50 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:50 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:50 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:50 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_bho_bert-base-multilingual-cased_128
01/15/2022 02:39:50 - INFO - __main__ -   ***** Running evaluation  in bho *****
01/15/2022 02:39:50 - INFO - __main__ -     Num examples = 361
01/15/2022 02:39:50 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 1
Evaluating:   8%|▊         | 1/12 [00:00<00:01,  7.36it/s]01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 2
Evaluating:  17%|█▋        | 2/12 [00:00<00:01,  7.34it/s]01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 3
Evaluating:  25%|██▌       | 3/12 [00:00<00:01,  7.30it/s]01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 4
Evaluating:  33%|███▎      | 4/12 [00:00<00:01,  7.30it/s]01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 5
Evaluating:  42%|████▏     | 5/12 [00:00<00:00,  7.29it/s]01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 6
Evaluating:  50%|█████     | 6/12 [00:00<00:00,  7.29it/s]01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 7
Evaluating:  58%|█████▊    | 7/12 [00:00<00:00,  7.28it/s]01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 8
Evaluating:  67%|██████▋   | 8/12 [00:01<00:00,  7.27it/s]01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 9
Evaluating:  75%|███████▌  | 9/12 [00:01<00:00,  6.40it/s]01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 10
Evaluating:  83%|████████▎ | 10/12 [00:01<00:00,  6.63it/s]01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 11
Evaluating:  92%|█████████▏| 11/12 [00:01<00:00,  6.79it/s]01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 12
Evaluating: 100%|██████████| 12/12 [00:01<00:00,  7.42it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/15/2022 02:39:52 - INFO - __main__ -   ***** Evaluation result  in bho *****
01/15/2022 02:39:52 - INFO - __main__ -     f1 = 0.44758029607826155
01/15/2022 02:39:52 - INFO - __main__ -     loss = 2.311605175336202
01/15/2022 02:39:52 - INFO - __main__ -     precision = 0.4677886355410785
01/15/2022 02:39:52 - INFO - __main__ -     recall = 0.42904564315352695
01/15/2022 02:39:52 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:39:52 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:52 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:52 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:52 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_ta_bert-base-multilingual-cased_128
01/15/2022 02:39:52 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:39:52 - INFO - __main__ -     Num examples = 656
01/15/2022 02:39:52 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 1
Evaluating:   5%|▍         | 1/21 [00:00<00:02,  7.35it/s]01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 2
Evaluating:  10%|▉         | 2/21 [00:00<00:02,  7.30it/s]01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 3
Evaluating:  14%|█▍        | 3/21 [00:00<00:02,  7.29it/s]01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 4
Evaluating:  19%|█▉        | 4/21 [00:00<00:02,  7.28it/s]01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 5
Evaluating:  24%|██▍       | 5/21 [00:00<00:02,  7.28it/s]01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 6
Evaluating:  29%|██▊       | 6/21 [00:00<00:02,  7.26it/s]01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 7
Evaluating:  33%|███▎      | 7/21 [00:00<00:01,  7.25it/s]01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 8
Evaluating:  38%|███▊      | 8/21 [00:01<00:01,  7.25it/s]01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 9
Evaluating:  43%|████▎     | 9/21 [00:01<00:01,  7.24it/s]01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 10
Evaluating:  48%|████▊     | 10/21 [00:01<00:01,  7.24it/s]01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 11
Evaluating:  52%|█████▏    | 11/21 [00:01<00:01,  7.24it/s]01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 12
Evaluating:  57%|█████▋    | 12/21 [00:01<00:01,  7.23it/s]01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 13
Evaluating:  62%|██████▏   | 13/21 [00:01<00:01,  7.23it/s]01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 14
Evaluating:  67%|██████▋   | 14/21 [00:01<00:00,  7.23it/s]01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 15
Evaluating:  71%|███████▏  | 15/21 [00:02<00:00,  7.22it/s]01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 16
Evaluating:  76%|███████▌  | 16/21 [00:02<00:00,  7.21it/s]01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 17
Evaluating:  81%|████████  | 17/21 [00:02<00:00,  7.20it/s]01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 18
Evaluating:  86%|████████▌ | 18/21 [00:02<00:00,  7.20it/s]01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 19
Evaluating:  90%|█████████ | 19/21 [00:02<00:00,  7.19it/s]01/15/2022 02:39:55 - INFO - __main__ -   Batch number = 20
Evaluating:  95%|█████████▌| 20/21 [00:02<00:00,  7.19it/s]01/15/2022 02:39:55 - INFO - __main__ -   Batch number = 21
Evaluating: 100%|██████████| 21/21 [00:02<00:00,  7.39it/s]
01/15/2022 02:39:55 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:39:55 - INFO - __main__ -     f1 = 0.5581893665461364
01/15/2022 02:39:55 - INFO - __main__ -     loss = 1.3866249237741743
01/15/2022 02:39:55 - INFO - __main__ -     precision = 0.5839170636032502
01/15/2022 02:39:55 - INFO - __main__ -     recall = 0.534633145202668
01/15/2022 02:39:55 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/15/2022 02:39:58 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/15/2022 02:40:03 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:40:03 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/15/2022 02:40:03 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/15/2022 02:40:03 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:40:03 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/pytorch_model_head.bin
01/15/2022 02:40:03 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:40:03 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:40:03 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:40:03 - INFO - __main__ -   Language = hi
01/15/2022 02:40:03 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/15/2022 02:40:04 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:40:04 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:04 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:04 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:04 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_mr_bert-base-multilingual-cased_128
01/15/2022 02:40:04 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:40:04 - INFO - __main__ -     Num examples = 46
01/15/2022 02:40:04 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]01/15/2022 02:40:04 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  7.31it/s]01/15/2022 02:40:05 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  9.87it/s]
01/15/2022 02:40:05 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:40:05 - INFO - __main__ -     f1 = 0.5802650957290133
01/15/2022 02:40:05 - INFO - __main__ -     loss = 1.5113340616226196
01/15/2022 02:40:05 - INFO - __main__ -     precision = 0.5969696969696969
01/15/2022 02:40:05 - INFO - __main__ -     recall = 0.5644699140401146
01/15/2022 02:40:05 - INFO - __main__ -   Language bho, split dev does not exist
01/15/2022 02:40:05 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:40:05 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:05 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:05 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:05 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_ta_bert-base-multilingual-cased_128
01/15/2022 02:40:05 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:40:05 - INFO - __main__ -     Num examples = 81
01/15/2022 02:40:05 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]01/15/2022 02:40:05 - INFO - __main__ -   Batch number = 1
Evaluating:  33%|███▎      | 1/3 [00:00<00:00,  7.31it/s]01/15/2022 02:40:05 - INFO - __main__ -   Batch number = 2
Evaluating:  67%|██████▋   | 2/3 [00:00<00:00,  7.27it/s]01/15/2022 02:40:05 - INFO - __main__ -   Batch number = 3
Evaluating: 100%|██████████| 3/3 [00:00<00:00,  8.53it/s]
01/15/2022 02:40:05 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:40:05 - INFO - __main__ -     f1 = 0.5151843817787418
01/15/2022 02:40:05 - INFO - __main__ -     loss = 1.5761994520823162
01/15/2022 02:40:05 - INFO - __main__ -     precision = 0.541002277904328
01/15/2022 02:40:05 - INFO - __main__ -     recall = 0.4917184265010352
29.87user 12.29system 0:30.28elapsed 139%CPU (0avgtext+0avgdata 4811232maxresident)k
0inputs+304outputs (0major+1648135minor)pagefaults 0swaps
PyTorch version 1.10.1+cu102 available.
01/15/2022 02:40:08 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:40:08 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 02:40:08 - INFO - __main__ -   Seed = 3
01/15/2022 02:40:08 - INFO - root -   save model
01/15/2022 02:40:08 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:40:08 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/15/2022 02:40:10 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/15/2022 02:40:16 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:40:16 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 02:40:16 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/15/2022 02:40:16 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:40:16 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_model_head.bin
01/15/2022 02:40:16 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:40:16 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:40:16 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:40:16 - INFO - __main__ -   Language = hi
01/15/2022 02:40:16 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/15/2022 02:40:20 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:40:20 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:20 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:20 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:20 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
01/15/2022 02:40:20 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:40:20 - INFO - __main__ -     Num examples = 47
01/15/2022 02:40:20 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]01/15/2022 02:40:20 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  6.26it/s]01/15/2022 02:40:20 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  8.40it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/15/2022 02:40:20 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:40:20 - INFO - __main__ -     f1 = 0.5795275590551181
01/15/2022 02:40:20 - INFO - __main__ -     loss = 1.4103432893753052
01/15/2022 02:40:20 - INFO - __main__ -     precision = 0.609271523178808
01/15/2022 02:40:20 - INFO - __main__ -     recall = 0.5525525525525525
01/15/2022 02:40:20 - INFO - __main__ -   Language adapter for bho not found, using hi instead
01/15/2022 02:40:20 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:20 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:20 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:20 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_bho_bert-base-multilingual-cased_128
01/15/2022 02:40:20 - INFO - __main__ -   ***** Running evaluation  in bho *****
01/15/2022 02:40:20 - INFO - __main__ -     Num examples = 361
01/15/2022 02:40:20 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]01/15/2022 02:40:20 - INFO - __main__ -   Batch number = 1
Evaluating:   8%|▊         | 1/12 [00:00<00:01,  7.08it/s]01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 2
Evaluating:  17%|█▋        | 2/12 [00:00<00:01,  7.19it/s]01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 3
Evaluating:  25%|██▌       | 3/12 [00:00<00:01,  5.49it/s]01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 4
Evaluating:  33%|███▎      | 4/12 [00:00<00:01,  6.08it/s]01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 5
Evaluating:  42%|████▏     | 5/12 [00:00<00:01,  6.43it/s]01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 6
Evaluating:  50%|█████     | 6/12 [00:00<00:00,  6.68it/s]01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 7
Evaluating:  58%|█████▊    | 7/12 [00:01<00:00,  6.86it/s]01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 8
Evaluating:  67%|██████▋   | 8/12 [00:01<00:00,  6.96it/s]01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 9
Evaluating:  75%|███████▌  | 9/12 [00:01<00:00,  7.03it/s]01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 10
Evaluating:  83%|████████▎ | 10/12 [00:01<00:00,  7.07it/s]01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 11
Evaluating:  92%|█████████▏| 11/12 [00:01<00:00,  7.09it/s]01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 12
Evaluating: 100%|██████████| 12/12 [00:01<00:00,  7.19it/s]
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
/home/abhijeet/rohan/venvs/cloud-emea-copy/lib/python3.6/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.
  warnings.warn('{} seems not to be NE tag.'.format(chunk))
01/15/2022 02:40:22 - INFO - __main__ -   ***** Evaluation result  in bho *****
01/15/2022 02:40:22 - INFO - __main__ -     f1 = 0.48433442963475853
01/15/2022 02:40:22 - INFO - __main__ -     loss = 2.09591473142306
01/15/2022 02:40:22 - INFO - __main__ -     precision = 0.5060589618375837
01/15/2022 02:40:22 - INFO - __main__ -     recall = 0.46439834024896265
01/15/2022 02:40:22 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:40:22 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:22 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:22 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:22 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_ta_bert-base-multilingual-cased_128
01/15/2022 02:40:22 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:40:22 - INFO - __main__ -     Num examples = 656
01/15/2022 02:40:22 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/21 [00:00<?, ?it/s]01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 1
Evaluating:   5%|▍         | 1/21 [00:00<00:02,  7.22it/s]01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 2
Evaluating:  10%|▉         | 2/21 [00:00<00:02,  7.22it/s]01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 3
Evaluating:  14%|█▍        | 3/21 [00:00<00:02,  7.21it/s]01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 4
Evaluating:  19%|█▉        | 4/21 [00:00<00:02,  7.21it/s]01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 5
Evaluating:  24%|██▍       | 5/21 [00:00<00:02,  7.21it/s]01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 6
Evaluating:  29%|██▊       | 6/21 [00:00<00:02,  7.19it/s]01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 7
Evaluating:  33%|███▎      | 7/21 [00:00<00:01,  7.19it/s]01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 8
Evaluating:  38%|███▊      | 8/21 [00:01<00:01,  7.19it/s]01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 9
Evaluating:  43%|████▎     | 9/21 [00:01<00:01,  7.17it/s]01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 10
Evaluating:  48%|████▊     | 10/21 [00:01<00:01,  7.17it/s]01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 11
Evaluating:  52%|█████▏    | 11/21 [00:01<00:01,  7.15it/s]01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 12
Evaluating:  57%|█████▋    | 12/21 [00:01<00:01,  7.14it/s]01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 13
Evaluating:  62%|██████▏   | 13/21 [00:01<00:01,  7.15it/s]01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 14
Evaluating:  67%|██████▋   | 14/21 [00:01<00:00,  7.15it/s]01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 15
Evaluating:  71%|███████▏  | 15/21 [00:02<00:00,  7.16it/s]01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 16
Evaluating:  76%|███████▌  | 16/21 [00:02<00:00,  7.16it/s]01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 17
Evaluating:  81%|████████  | 17/21 [00:02<00:00,  7.14it/s]01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 18
Evaluating:  86%|████████▌ | 18/21 [00:02<00:00,  7.13it/s]01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 19
Evaluating:  90%|█████████ | 19/21 [00:02<00:00,  7.13it/s]01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 20
Evaluating:  95%|█████████▌| 20/21 [00:02<00:00,  7.11it/s]01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 21
Evaluating: 100%|██████████| 21/21 [00:02<00:00,  7.32it/s]
01/15/2022 02:40:25 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:40:25 - INFO - __main__ -     f1 = 0.5879370162796905
01/15/2022 02:40:25 - INFO - __main__ -     loss = 1.2563766127540952
01/15/2022 02:40:25 - INFO - __main__ -     precision = 0.6126251390433816
01/15/2022 02:40:25 - INFO - __main__ -     recall = 0.5651616213442792
01/15/2022 02:40:26 - INFO - __main__ -   Loading pretrained model and tokenizer
loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2",
    "3": "LABEL_3",
    "4": "LABEL_4",
    "5": "LABEL_5",
    "6": "LABEL_6",
    "7": "LABEL_7",
    "8": "LABEL_8",
    "9": "LABEL_9",
    "10": "LABEL_10",
    "11": "LABEL_11",
    "12": "LABEL_12",
    "13": "LABEL_13",
    "14": "LABEL_14",
    "15": "LABEL_15",
    "16": "LABEL_16",
    "17": "LABEL_17"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_10": 10,
    "LABEL_11": 11,
    "LABEL_12": 12,
    "LABEL_13": 13,
    "LABEL_14": 14,
    "LABEL_15": 15,
    "LABEL_16": 16,
    "LABEL_17": 17,
    "LABEL_2": 2,
    "LABEL_3": 3,
    "LABEL_4": 4,
    "LABEL_5": 5,
    "LABEL_6": 6,
    "LABEL_7": 7,
    "LABEL_8": 8,
    "LABEL_9": 9
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /home/abhijeet/.cache/torch/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c
Model config BertConfig {
  "adapters": {
    "adapters": {},
    "config_map": {}
  },
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 119547
}

loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /home/abhijeet/.cache/torch/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29
01/15/2022 02:40:28 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /home/abhijeet/.cache/torch/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/15/2022 02:40:34 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:40:34 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/15/2022 02:40:34 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/15/2022 02:40:34 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:40:34 - INFO - root -   loading task adapter
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/adapter_config.json
Adding adapter 'udpos' of type 'text_task'.
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_adapter.bin
Loading module configuration from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/head_config.json
Loading module weights from output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/pytorch_model_head.bin
01/15/2022 02:40:34 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:40:34 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:40:34 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:40:34 - INFO - __main__ -   Language = hi
01/15/2022 02:40:34 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
No exactly matching adapter config found for this specifier, falling back to default.
Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_lang/hi/bert-base-multilingual-cased/pfeiffer/hi_pfeiffer_gelu_nd_200k.zip.
Loading module configuration from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/adapter_config.json
Adding adapter 'hi' of type 'text_lang'.
Loading module weights from /home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted/pytorch_adapter.bin
No matching prediction head found in '/home/abhijeet/.cache/torch/adapters/074d5b7e47a2e35f3d06d1f3bcdba40b0709c9e5ce81b3c3533bc81cd8e35505-6d8198b7d99138cfc02cbf557a60122f7492f9ee1ed400529bf29c8180688fec-extracted'
01/15/2022 02:40:35 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:40:35 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:35 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:35 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_mr_bert-base-multilingual-cased_128
01/15/2022 02:40:35 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:40:35 - INFO - __main__ -     Num examples = 46
01/15/2022 02:40:35 - INFO - __main__ -     Batch size = 32
**********
Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]01/15/2022 02:40:35 - INFO - __main__ -   Batch number = 1
Evaluating:  50%|█████     | 1/2 [00:00<00:00,  7.29it/s]01/15/2022 02:40:35 - INFO - __main__ -   Batch number = 2
Evaluating: 100%|██████████| 2/2 [00:00<00:00,  9.78it/s]
01/15/2022 02:40:35 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:40:35 - INFO - __main__ -     f1 = 0.6005917159763314
01/15/2022 02:40:35 - INFO - __main__ -     loss = 1.369255542755127
01/15/2022 02:40:35 - INFO - __main__ -     precision = 0.6207951070336392
01/15/2022 02:40:35 - INFO - __main__ -     recall = 0.5816618911174785
01/15/2022 02:40:36 - INFO - __main__ -   Language bho, split dev does not exist
01/15/2022 02:40:36 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:40:36 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:36 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:36 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:36 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_ta_bert-base-multilingual-cased_128
01/15/2022 02:40:36 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:40:36 - INFO - __main__ -     Num examples = 81
01/15/2022 02:40:36 - INFO - __main__ -     Batch size = 32
Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]01/15/2022 02:40:36 - INFO - __main__ -   Batch number = 1
Evaluating:  33%|███▎      | 1/3 [00:00<00:00,  7.29it/s]01/15/2022 02:40:36 - INFO - __main__ -   Batch number = 2
Evaluating:  67%|██████▋   | 2/3 [00:00<00:00,  7.25it/s]01/15/2022 02:40:36 - INFO - __main__ -   Batch number = 3
Evaluating: 100%|██████████| 3/3 [00:00<00:00,  7.24it/s]Evaluating: 100%|██████████| 3/3 [00:00<00:00,  7.24it/s]
01/15/2022 02:40:36 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:40:36 - INFO - __main__ -     f1 = 0.5217391304347826
01/15/2022 02:40:36 - INFO - __main__ -     loss = 1.47808039188385
01/15/2022 02:40:36 - INFO - __main__ -     precision = 0.5491990846681922
01/15/2022 02:40:36 - INFO - __main__ -     recall = 0.4968944099378882
28.32user 12.77system 0:30.64elapsed 134%CPU (0avgtext+0avgdata 4784252maxresident)k
0inputs+304outputs (0major+1964976minor)pagefaults 0swaps
