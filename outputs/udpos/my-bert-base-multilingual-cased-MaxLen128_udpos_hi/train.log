11/20/2021 22:23:49 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:23:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:23:49 - INFO - __main__ -   Seed = 1
11/20/2021 22:23:49 - INFO - root -   save model
11/20/2021 22:23:49 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:23:49 - INFO - __main__ -   Loading pretrained model and tokenizer
11/20/2021 22:23:51 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/20/2021 22:23:57 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:23:57 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:23:57 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
11/20/2021 22:23:57 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:23:57 - INFO - root -   loading task adapter
11/20/2021 22:23:57 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:23:57 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:23:57 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:23:57 - INFO - __main__ -   Language = hi
11/20/2021 22:23:57 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/20/2021 22:24:01 - INFO - __main__ -   Language adapter for mr not found, using hi instead
11/20/2021 22:24:01 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:24:01 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:24:01 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:24:01 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
11/20/2021 22:24:01 - INFO - __main__ -   ***** Running evaluation  in mr *****
11/20/2021 22:24:01 - INFO - __main__ -     Num examples = 47
11/20/2021 22:24:01 - INFO - __main__ -     Batch size = 32
11/20/2021 22:24:01 - INFO - __main__ -   Batch number = 1
11/20/2021 22:24:01 - INFO - __main__ -   Batch number = 2
11/20/2021 22:24:02 - INFO - __main__ -   ***** Evaluation result  in mr *****
11/20/2021 22:24:02 - INFO - __main__ -     f1 = 0.5079365079365079
11/20/2021 22:24:02 - INFO - __main__ -     loss = 1.4944716095924377
11/20/2021 22:24:02 - INFO - __main__ -     precision = 0.5387205387205387
11/20/2021 22:24:02 - INFO - __main__ -     recall = 0.4804804804804805
11/20/2021 22:24:03 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:24:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:24:03 - INFO - __main__ -   Seed = 2
11/20/2021 22:24:03 - INFO - root -   save model
11/20/2021 22:24:03 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:24:03 - INFO - __main__ -   Loading pretrained model and tokenizer
11/20/2021 22:24:06 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/20/2021 22:24:12 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:24:12 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:24:12 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
11/20/2021 22:24:12 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:24:12 - INFO - root -   loading task adapter
11/20/2021 22:24:12 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:24:12 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:24:12 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:24:12 - INFO - __main__ -   Language = hi
11/20/2021 22:24:12 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/20/2021 22:24:15 - INFO - __main__ -   Language adapter for mr not found, using hi instead
11/20/2021 22:24:15 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:24:15 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:24:15 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:24:15 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
11/20/2021 22:24:15 - INFO - __main__ -   ***** Running evaluation  in mr *****
11/20/2021 22:24:15 - INFO - __main__ -     Num examples = 47
11/20/2021 22:24:15 - INFO - __main__ -     Batch size = 32
11/20/2021 22:24:15 - INFO - __main__ -   Batch number = 1
11/20/2021 22:24:16 - INFO - __main__ -   Batch number = 2
11/20/2021 22:24:16 - INFO - __main__ -   ***** Evaluation result  in mr *****
11/20/2021 22:24:16 - INFO - __main__ -     f1 = 0.5297805642633229
11/20/2021 22:24:16 - INFO - __main__ -     loss = 1.4993798732757568
11/20/2021 22:24:16 - INFO - __main__ -     precision = 0.5540983606557377
11/20/2021 22:24:16 - INFO - __main__ -     recall = 0.5075075075075075
11/20/2021 22:24:18 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:24:18 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:24:18 - INFO - __main__ -   Seed = 3
11/20/2021 22:24:18 - INFO - root -   save model
11/20/2021 22:24:18 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:24:18 - INFO - __main__ -   Loading pretrained model and tokenizer
11/20/2021 22:24:20 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/20/2021 22:24:26 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:24:26 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:24:26 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
11/20/2021 22:24:26 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:24:26 - INFO - root -   loading task adapter
11/20/2021 22:24:26 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:24:26 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:24:26 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:24:26 - INFO - __main__ -   Language = hi
11/20/2021 22:24:26 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/20/2021 22:24:30 - INFO - __main__ -   Language adapter for mr not found, using hi instead
11/20/2021 22:24:30 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:24:30 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:24:30 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:24:30 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
11/20/2021 22:24:30 - INFO - __main__ -   ***** Running evaluation  in mr *****
11/20/2021 22:24:30 - INFO - __main__ -     Num examples = 47
11/20/2021 22:24:30 - INFO - __main__ -     Batch size = 32
11/20/2021 22:24:30 - INFO - __main__ -   Batch number = 1
11/20/2021 22:24:30 - INFO - __main__ -   Batch number = 2
11/20/2021 22:24:30 - INFO - __main__ -   ***** Evaluation result  in mr *****
11/20/2021 22:24:30 - INFO - __main__ -     f1 = 0.5795275590551181
11/20/2021 22:24:30 - INFO - __main__ -     loss = 1.4103431105613708
11/20/2021 22:24:30 - INFO - __main__ -     precision = 0.609271523178808
11/20/2021 22:24:30 - INFO - __main__ -     recall = 0.5525525525525525
11/20/2021 22:48:46 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:48:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:48:46 - INFO - __main__ -   Seed = 1
11/20/2021 22:48:46 - INFO - root -   save model
11/20/2021 22:48:46 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:48:46 - INFO - __main__ -   Loading pretrained model and tokenizer
11/20/2021 22:48:49 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/20/2021 22:48:54 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:48:54 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:48:54 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
11/20/2021 22:48:54 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:48:54 - INFO - root -   loading task adapter
11/20/2021 22:48:55 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:48:55 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:48:55 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:48:55 - INFO - __main__ -   Language = hi
11/20/2021 22:48:55 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/20/2021 22:48:59 - INFO - __main__ -   Language adapter for en not found, using hi instead
11/20/2021 22:48:59 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:48:59 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:48:59 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:48:59 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
11/20/2021 22:48:59 - INFO - __main__ -   ***** Running evaluation  in en *****
11/20/2021 22:48:59 - INFO - __main__ -     Num examples = 5441
11/20/2021 22:48:59 - INFO - __main__ -     Batch size = 32
11/20/2021 22:48:59 - INFO - __main__ -   Batch number = 1
11/20/2021 22:48:59 - INFO - __main__ -   Batch number = 2
11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 3
11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 4
11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 5
11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 6
11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 7
11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 8
11/20/2021 22:49:00 - INFO - __main__ -   Batch number = 9
11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 10
11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 11
11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 12
11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 13
11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 14
11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 15
11/20/2021 22:49:01 - INFO - __main__ -   Batch number = 16
11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 17
11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 18
11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 19
11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 20
11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 21
11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 22
11/20/2021 22:49:02 - INFO - __main__ -   Batch number = 23
11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 24
11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 25
11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 26
11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 27
11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 28
11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 29
11/20/2021 22:49:03 - INFO - __main__ -   Batch number = 30
11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 31
11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 32
11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 33
11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 34
11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 35
11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 36
11/20/2021 22:49:04 - INFO - __main__ -   Batch number = 37
11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 38
11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 39
11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 40
11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 41
11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 42
11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 43
11/20/2021 22:49:05 - INFO - __main__ -   Batch number = 44
11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 45
11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 46
11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 47
11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 48
11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 49
11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 50
11/20/2021 22:49:06 - INFO - __main__ -   Batch number = 51
11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 52
11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 53
11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 54
11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 55
11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 56
11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 57
11/20/2021 22:49:07 - INFO - __main__ -   Batch number = 58
11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 59
11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 60
11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 61
11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 62
11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 63
11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 64
11/20/2021 22:49:08 - INFO - __main__ -   Batch number = 65
11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 66
11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 67
11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 68
11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 69
11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 70
11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 71
11/20/2021 22:49:09 - INFO - __main__ -   Batch number = 72
11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 73
11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 74
11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 75
11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 76
11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 77
11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 78
11/20/2021 22:49:10 - INFO - __main__ -   Batch number = 79
11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 80
11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 81
11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 82
11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 83
11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 84
11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 85
11/20/2021 22:49:11 - INFO - __main__ -   Batch number = 86
11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 87
11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 88
11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 89
11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 90
11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 91
11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 92
11/20/2021 22:49:12 - INFO - __main__ -   Batch number = 93
11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 94
11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 95
11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 96
11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 97
11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 98
11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 99
11/20/2021 22:49:13 - INFO - __main__ -   Batch number = 100
11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 101
11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 102
11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 103
11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 104
11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 105
11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 106
11/20/2021 22:49:14 - INFO - __main__ -   Batch number = 107
11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 108
11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 109
11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 110
11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 111
11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 112
11/20/2021 22:49:15 - INFO - __main__ -   Batch number = 113
11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 114
11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 115
11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 116
11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 117
11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 118
11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 119
11/20/2021 22:49:16 - INFO - __main__ -   Batch number = 120
11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 121
11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 122
11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 123
11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 124
11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 125
11/20/2021 22:49:17 - INFO - __main__ -   Batch number = 126
11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 127
11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 128
11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 129
11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 130
11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 131
11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 132
11/20/2021 22:49:18 - INFO - __main__ -   Batch number = 133
11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 134
11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 135
11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 136
11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 137
11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 138
11/20/2021 22:49:19 - INFO - __main__ -   Batch number = 139
11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 140
11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 141
11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 142
11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 143
11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 144
11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 145
11/20/2021 22:49:20 - INFO - __main__ -   Batch number = 146
11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 147
11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 148
11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 149
11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 150
11/20/2021 22:49:21 - INFO - __main__ -   Batch number = 151
11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 152
11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 153
11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 154
11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 155
11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 156
11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 157
11/20/2021 22:49:22 - INFO - __main__ -   Batch number = 158
11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 159
11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 160
11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 161
11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 162
11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 163
11/20/2021 22:49:23 - INFO - __main__ -   Batch number = 164
11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 165
11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 166
11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 167
11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 168
11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 169
11/20/2021 22:49:24 - INFO - __main__ -   Batch number = 170
11/20/2021 22:49:25 - INFO - __main__ -   Batch number = 171
11/20/2021 22:49:26 - INFO - __main__ -   ***** Evaluation result  in en *****
11/20/2021 22:49:26 - INFO - __main__ -     f1 = 0.9412752207306991
11/20/2021 22:49:26 - INFO - __main__ -     loss = 0.15675296131739316
11/20/2021 22:49:26 - INFO - __main__ -     precision = 0.9402367833772521
11/20/2021 22:49:26 - INFO - __main__ -     recall = 0.9423159544087544
11/20/2021 22:49:28 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:49:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:49:28 - INFO - __main__ -   Seed = 2
11/20/2021 22:49:28 - INFO - root -   save model
11/20/2021 22:49:28 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:49:28 - INFO - __main__ -   Loading pretrained model and tokenizer
11/20/2021 22:49:31 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/20/2021 22:49:36 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:49:36 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:49:36 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
11/20/2021 22:49:36 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:49:36 - INFO - root -   loading task adapter
11/20/2021 22:49:36 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:49:36 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:49:36 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:49:36 - INFO - __main__ -   Language = hi
11/20/2021 22:49:36 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/20/2021 22:49:40 - INFO - __main__ -   Language adapter for en not found, using hi instead
11/20/2021 22:49:40 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:49:40 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:49:40 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:49:40 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
11/20/2021 22:49:40 - INFO - __main__ -   ***** Running evaluation  in en *****
11/20/2021 22:49:40 - INFO - __main__ -     Num examples = 5441
11/20/2021 22:49:40 - INFO - __main__ -     Batch size = 32
11/20/2021 22:49:40 - INFO - __main__ -   Batch number = 1
11/20/2021 22:49:40 - INFO - __main__ -   Batch number = 2
11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 3
11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 4
11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 5
11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 6
11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 7
11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 8
11/20/2021 22:49:41 - INFO - __main__ -   Batch number = 9
11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 10
11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 11
11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 12
11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 13
11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 14
11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 15
11/20/2021 22:49:42 - INFO - __main__ -   Batch number = 16
11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 17
11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 18
11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 19
11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 20
11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 21
11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 22
11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 23
11/20/2021 22:49:43 - INFO - __main__ -   Batch number = 24
11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 25
11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 26
11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 27
11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 28
11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 29
11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 30
11/20/2021 22:49:44 - INFO - __main__ -   Batch number = 31
11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 32
11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 33
11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 34
11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 35
11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 36
11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 37
11/20/2021 22:49:45 - INFO - __main__ -   Batch number = 38
11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 39
11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 40
11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 41
11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 42
11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 43
11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 44
11/20/2021 22:49:46 - INFO - __main__ -   Batch number = 45
11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 46
11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 47
11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 48
11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 49
11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 50
11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 51
11/20/2021 22:49:47 - INFO - __main__ -   Batch number = 52
11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 53
11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 54
11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 55
11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 56
11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 57
11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 58
11/20/2021 22:49:48 - INFO - __main__ -   Batch number = 59
11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 60
11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 61
11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 62
11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 63
11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 64
11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 65
11/20/2021 22:49:49 - INFO - __main__ -   Batch number = 66
11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 67
11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 68
11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 69
11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 70
11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 71
11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 72
11/20/2021 22:49:50 - INFO - __main__ -   Batch number = 73
11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 74
11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 75
11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 76
11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 77
11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 78
11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 79
11/20/2021 22:49:51 - INFO - __main__ -   Batch number = 80
11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 81
11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 82
11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 83
11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 84
11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 85
11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 86
11/20/2021 22:49:52 - INFO - __main__ -   Batch number = 87
11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 88
11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 89
11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 90
11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 91
11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 92
11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 93
11/20/2021 22:49:53 - INFO - __main__ -   Batch number = 94
11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 95
11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 96
11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 97
11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 98
11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 99
11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 100
11/20/2021 22:49:54 - INFO - __main__ -   Batch number = 101
11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 102
11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 103
11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 104
11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 105
11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 106
11/20/2021 22:49:55 - INFO - __main__ -   Batch number = 107
11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 108
11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 109
11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 110
11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 111
11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 112
11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 113
11/20/2021 22:49:56 - INFO - __main__ -   Batch number = 114
11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 115
11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 116
11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 117
11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 118
11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 119
11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 120
11/20/2021 22:49:57 - INFO - __main__ -   Batch number = 121
11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 122
11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 123
11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 124
11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 125
11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 126
11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 127
11/20/2021 22:49:58 - INFO - __main__ -   Batch number = 128
11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 129
11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 130
11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 131
11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 132
11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 133
11/20/2021 22:49:59 - INFO - __main__ -   Batch number = 134
11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 135
11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 136
11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 137
11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 138
11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 139
11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 140
11/20/2021 22:50:00 - INFO - __main__ -   Batch number = 141
11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 142
11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 143
11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 144
11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 145
11/20/2021 22:50:01 - INFO - __main__ -   Batch number = 146
11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 147
11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 148
11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 149
11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 150
11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 151
11/20/2021 22:50:02 - INFO - __main__ -   Batch number = 152
11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 153
11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 154
11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 155
11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 156
11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 157
11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 158
11/20/2021 22:50:03 - INFO - __main__ -   Batch number = 159
11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 160
11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 161
11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 162
11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 163
11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 164
11/20/2021 22:50:04 - INFO - __main__ -   Batch number = 165
11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 166
11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 167
11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 168
11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 169
11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 170
11/20/2021 22:50:05 - INFO - __main__ -   Batch number = 171
11/20/2021 22:50:07 - INFO - __main__ -   ***** Evaluation result  in en *****
11/20/2021 22:50:07 - INFO - __main__ -     f1 = 0.9426692085295492
11/20/2021 22:50:07 - INFO - __main__ -     loss = 0.16115038460583497
11/20/2021 22:50:07 - INFO - __main__ -     precision = 0.941848731015692
11/20/2021 22:50:07 - INFO - __main__ -     recall = 0.9434911167833405
11/20/2021 22:50:09 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:50:09 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/20/2021 22:50:09 - INFO - __main__ -   Seed = 3
11/20/2021 22:50:09 - INFO - root -   save model
11/20/2021 22:50:09 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='en', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/20/2021 22:50:09 - INFO - __main__ -   Loading pretrained model and tokenizer
11/20/2021 22:50:12 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/20/2021 22:50:17 - INFO - __main__ -   Using lang2id = None
11/20/2021 22:50:17 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/20/2021 22:50:17 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
11/20/2021 22:50:17 - INFO - root -   Trying to decide if add adapter
11/20/2021 22:50:17 - INFO - root -   loading task adapter
11/20/2021 22:50:17 - INFO - root -   loading lang adpater hi/wiki@ukp
11/20/2021 22:50:17 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/20/2021 22:50:17 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/20/2021 22:50:17 - INFO - __main__ -   Language = hi
11/20/2021 22:50:17 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/20/2021 22:50:21 - INFO - __main__ -   Language adapter for en not found, using hi instead
11/20/2021 22:50:21 - INFO - __main__ -   Set active language adapter to hi
11/20/2021 22:50:21 - INFO - __main__ -   Args Adapter Weight = None
11/20/2021 22:50:21 - INFO - __main__ -   Adapter Languages = ['hi']
11/20/2021 22:50:21 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_en_bert-base-multilingual-cased_128
11/20/2021 22:50:22 - INFO - __main__ -   ***** Running evaluation  in en *****
11/20/2021 22:50:22 - INFO - __main__ -     Num examples = 5441
11/20/2021 22:50:22 - INFO - __main__ -     Batch size = 32
11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 1
11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 2
11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 3
11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 4
11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 5
11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 6
11/20/2021 22:50:22 - INFO - __main__ -   Batch number = 7
11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 8
11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 9
11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 10
11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 11
11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 12
11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 13
11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 14
11/20/2021 22:50:23 - INFO - __main__ -   Batch number = 15
11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 16
11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 17
11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 18
11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 19
11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 20
11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 21
11/20/2021 22:50:24 - INFO - __main__ -   Batch number = 22
11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 23
11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 24
11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 25
11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 26
11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 27
11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 28
11/20/2021 22:50:25 - INFO - __main__ -   Batch number = 29
11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 30
11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 31
11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 32
11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 33
11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 34
11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 35
11/20/2021 22:50:26 - INFO - __main__ -   Batch number = 36
11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 37
11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 38
11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 39
11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 40
11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 41
11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 42
11/20/2021 22:50:27 - INFO - __main__ -   Batch number = 43
11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 44
11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 45
11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 46
11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 47
11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 48
11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 49
11/20/2021 22:50:28 - INFO - __main__ -   Batch number = 50
11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 51
11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 52
11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 53
11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 54
11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 55
11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 56
11/20/2021 22:50:29 - INFO - __main__ -   Batch number = 57
11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 58
11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 59
11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 60
11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 61
11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 62
11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 63
11/20/2021 22:50:30 - INFO - __main__ -   Batch number = 64
11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 65
11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 66
11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 67
11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 68
11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 69
11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 70
11/20/2021 22:50:31 - INFO - __main__ -   Batch number = 71
11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 72
11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 73
11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 74
11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 75
11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 76
11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 77
11/20/2021 22:50:32 - INFO - __main__ -   Batch number = 78
11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 79
11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 80
11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 81
11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 82
11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 83
11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 84
11/20/2021 22:50:33 - INFO - __main__ -   Batch number = 85
11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 86
11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 87
11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 88
11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 89
11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 90
11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 91
11/20/2021 22:50:34 - INFO - __main__ -   Batch number = 92
11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 93
11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 94
11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 95
11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 96
11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 97
11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 98
11/20/2021 22:50:35 - INFO - __main__ -   Batch number = 99
11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 100
11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 101
11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 102
11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 103
11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 104
11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 105
11/20/2021 22:50:36 - INFO - __main__ -   Batch number = 106
11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 107
11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 108
11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 109
11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 110
11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 111
11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 112
11/20/2021 22:50:37 - INFO - __main__ -   Batch number = 113
11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 114
11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 115
11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 116
11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 117
11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 118
11/20/2021 22:50:38 - INFO - __main__ -   Batch number = 119
11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 120
11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 121
11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 122
11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 123
11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 124
11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 125
11/20/2021 22:50:39 - INFO - __main__ -   Batch number = 126
11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 127
11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 128
11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 129
11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 130
11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 131
11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 132
11/20/2021 22:50:40 - INFO - __main__ -   Batch number = 133
11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 134
11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 135
11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 136
11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 137
11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 138
11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 139
11/20/2021 22:50:41 - INFO - __main__ -   Batch number = 140
11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 141
11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 142
11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 143
11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 144
11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 145
11/20/2021 22:50:42 - INFO - __main__ -   Batch number = 146
11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 147
11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 148
11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 149
11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 150
11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 151
11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 152
11/20/2021 22:50:43 - INFO - __main__ -   Batch number = 153
11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 154
11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 155
11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 156
11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 157
11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 158
11/20/2021 22:50:44 - INFO - __main__ -   Batch number = 159
11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 160
11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 161
11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 162
11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 163
11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 164
11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 165
11/20/2021 22:50:45 - INFO - __main__ -   Batch number = 166
11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 167
11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 168
11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 169
11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 170
11/20/2021 22:50:46 - INFO - __main__ -   Batch number = 171
11/20/2021 22:50:48 - INFO - __main__ -   ***** Evaluation result  in en *****
11/20/2021 22:50:48 - INFO - __main__ -     f1 = 0.9433838342374659
11/20/2021 22:50:48 - INFO - __main__ -     loss = 0.1522504466487781
11/20/2021 22:50:48 - INFO - __main__ -     precision = 0.942961027156005
11/20/2021 22:50:48 - INFO - __main__ -     recall = 0.9438070206474766
11/21/2021 13:14:59 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:14:59 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/21/2021 13:14:59 - INFO - __main__ -   Seed = 1
11/21/2021 13:14:59 - INFO - root -   save model
11/21/2021 13:14:59 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:14:59 - INFO - __main__ -   Loading pretrained model and tokenizer
11/21/2021 13:15:01 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/21/2021 13:15:07 - INFO - __main__ -   Using lang2id = None
11/21/2021 13:15:07 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/21/2021 13:15:07 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
11/21/2021 13:15:07 - INFO - root -   Trying to decide if add adapter
11/21/2021 13:15:07 - INFO - root -   loading task adapter
11/21/2021 13:15:07 - INFO - root -   loading lang adpater hi/wiki@ukp
11/21/2021 13:15:07 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/21/2021 13:15:07 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/21/2021 13:15:07 - INFO - __main__ -   Language = hi
11/21/2021 13:15:07 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/21/2021 13:15:11 - INFO - __main__ -   Language adapter for de not found, using hi instead
11/21/2021 13:15:11 - INFO - __main__ -   Set active language adapter to hi
11/21/2021 13:15:11 - INFO - __main__ -   Args Adapter Weight = None
11/21/2021 13:15:11 - INFO - __main__ -   Adapter Languages = ['hi']
11/21/2021 13:15:11 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_de_bert-base-multilingual-cased_128
11/21/2021 13:15:14 - INFO - __main__ -   ***** Running evaluation  in de *****
11/21/2021 13:15:14 - INFO - __main__ -     Num examples = 22360
11/21/2021 13:15:14 - INFO - __main__ -     Batch size = 32
11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 1
11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 2
11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 3
11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 4
11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 5
11/21/2021 13:15:14 - INFO - __main__ -   Batch number = 6
11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 7
11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 8
11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 9
11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 10
11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 11
11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 12
11/21/2021 13:15:15 - INFO - __main__ -   Batch number = 13
11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 14
11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 15
11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 16
11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 17
11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 18
11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 19
11/21/2021 13:15:16 - INFO - __main__ -   Batch number = 20
11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 21
11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 22
11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 23
11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 24
11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 25
11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 26
11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 27
11/21/2021 13:15:17 - INFO - __main__ -   Batch number = 28
11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 29
11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 30
11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 31
11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 32
11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 33
11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 34
11/21/2021 13:15:18 - INFO - __main__ -   Batch number = 35
11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 36
11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 37
11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 38
11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 39
11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 40
11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 41
11/21/2021 13:15:19 - INFO - __main__ -   Batch number = 42
11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 43
11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 44
11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 45
11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 46
11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 47
11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 48
11/21/2021 13:15:20 - INFO - __main__ -   Batch number = 49
11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 50
11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 51
11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 52
11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 53
11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 54
11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 55
11/21/2021 13:15:21 - INFO - __main__ -   Batch number = 56
11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 57
11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 58
11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 59
11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 60
11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 61
11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 62
11/21/2021 13:15:22 - INFO - __main__ -   Batch number = 63
11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 64
11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 65
11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 66
11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 67
11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 68
11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 69
11/21/2021 13:15:23 - INFO - __main__ -   Batch number = 70
11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 71
11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 72
11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 73
11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 74
11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 75
11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 76
11/21/2021 13:15:24 - INFO - __main__ -   Batch number = 77
11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 78
11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 79
11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 80
11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 81
11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 82
11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 83
11/21/2021 13:15:25 - INFO - __main__ -   Batch number = 84
11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 85
11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 86
11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 87
11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 88
11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 89
11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 90
11/21/2021 13:15:26 - INFO - __main__ -   Batch number = 91
11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 92
11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 93
11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 94
11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 95
11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 96
11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 97
11/21/2021 13:15:27 - INFO - __main__ -   Batch number = 98
11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 99
11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 100
11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 101
11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 102
11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 103
11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 104
11/21/2021 13:15:28 - INFO - __main__ -   Batch number = 105
11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 106
11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 107
11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 108
11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 109
11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 110
11/21/2021 13:15:29 - INFO - __main__ -   Batch number = 111
11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 112
11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 113
11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 114
11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 115
11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 116
11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 117
11/21/2021 13:15:30 - INFO - __main__ -   Batch number = 118
11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 119
11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 120
11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 121
11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 122
11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 123
11/21/2021 13:15:31 - INFO - __main__ -   Batch number = 124
11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 125
11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 126
11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 127
11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 128
11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 129
11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 130
11/21/2021 13:15:32 - INFO - __main__ -   Batch number = 131
11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 132
11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 133
11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 134
11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 135
11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 136
11/21/2021 13:15:33 - INFO - __main__ -   Batch number = 137
11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 138
11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 139
11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 140
11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 141
11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 142
11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 143
11/21/2021 13:15:34 - INFO - __main__ -   Batch number = 144
11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 145
11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 146
11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 147
11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 148
11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 149
11/21/2021 13:15:35 - INFO - __main__ -   Batch number = 150
11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 151
11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 152
11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 153
11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 154
11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 155
11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 156
11/21/2021 13:15:36 - INFO - __main__ -   Batch number = 157
11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 158
11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 159
11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 160
11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 161
11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 162
11/21/2021 13:15:37 - INFO - __main__ -   Batch number = 163
11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 164
11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 165
11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 166
11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 167
11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 168
11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 169
11/21/2021 13:15:38 - INFO - __main__ -   Batch number = 170
11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 171
11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 172
11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 173
11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 174
11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 175
11/21/2021 13:15:39 - INFO - __main__ -   Batch number = 176
11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 177
11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 178
11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 179
11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 180
11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 181
11/21/2021 13:15:40 - INFO - __main__ -   Batch number = 182
11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 183
11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 184
11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 185
11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 186
11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 187
11/21/2021 13:15:41 - INFO - __main__ -   Batch number = 188
11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 189
11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 190
11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 191
11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 192
11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 193
11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 194
11/21/2021 13:15:42 - INFO - __main__ -   Batch number = 195
11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 196
11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 197
11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 198
11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 199
11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 200
11/21/2021 13:15:43 - INFO - __main__ -   Batch number = 201
11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 202
11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 203
11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 204
11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 205
11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 206
11/21/2021 13:15:44 - INFO - __main__ -   Batch number = 207
11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 208
11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 209
11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 210
11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 211
11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 212
11/21/2021 13:15:45 - INFO - __main__ -   Batch number = 213
11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 214
11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 215
11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 216
11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 217
11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 218
11/21/2021 13:15:46 - INFO - __main__ -   Batch number = 219
11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 220
11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 221
11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 222
11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 223
11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 224
11/21/2021 13:15:47 - INFO - __main__ -   Batch number = 225
11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 226
11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 227
11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 228
11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 229
11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 230
11/21/2021 13:15:48 - INFO - __main__ -   Batch number = 231
11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 232
11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 233
11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 234
11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 235
11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 236
11/21/2021 13:15:49 - INFO - __main__ -   Batch number = 237
11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 238
11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 239
11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 240
11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 241
11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 242
11/21/2021 13:15:50 - INFO - __main__ -   Batch number = 243
11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 244
11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 245
11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 246
11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 247
11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 248
11/21/2021 13:15:51 - INFO - __main__ -   Batch number = 249
11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 250
11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 251
11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 252
11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 253
11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 254
11/21/2021 13:15:52 - INFO - __main__ -   Batch number = 255
11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 256
11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 257
11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 258
11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 259
11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 260
11/21/2021 13:15:53 - INFO - __main__ -   Batch number = 261
11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 262
11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 263
11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 264
11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 265
11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 266
11/21/2021 13:15:54 - INFO - __main__ -   Batch number = 267
11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 268
11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 269
11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 270
11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 271
11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 272
11/21/2021 13:15:55 - INFO - __main__ -   Batch number = 273
11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 274
11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 275
11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 276
11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 277
11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 278
11/21/2021 13:15:56 - INFO - __main__ -   Batch number = 279
11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 280
11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 281
11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 282
11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 283
11/21/2021 13:15:57 - INFO - __main__ -   Batch number = 284
11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 285
11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 286
11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 287
11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 288
11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 289
11/21/2021 13:15:58 - INFO - __main__ -   Batch number = 290
11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 291
11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 292
11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 293
11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 294
11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 295
11/21/2021 13:15:59 - INFO - __main__ -   Batch number = 296
11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 297
11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 298
11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 299
11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 300
11/21/2021 13:16:00 - INFO - __main__ -   Batch number = 301
11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 302
11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 303
11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 304
11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 305
11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 306
11/21/2021 13:16:01 - INFO - __main__ -   Batch number = 307
11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 308
11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 309
11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 310
11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 311
11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 312
11/21/2021 13:16:02 - INFO - __main__ -   Batch number = 313
11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 314
11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 315
11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 316
11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 317
11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 318
11/21/2021 13:16:03 - INFO - __main__ -   Batch number = 319
11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 320
11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 321
11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 322
11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 323
11/21/2021 13:16:04 - INFO - __main__ -   Batch number = 324
11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 325
11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 326
11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 327
11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 328
11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 329
11/21/2021 13:16:05 - INFO - __main__ -   Batch number = 330
11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 331
11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 332
11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 333
11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 334
11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 335
11/21/2021 13:16:06 - INFO - __main__ -   Batch number = 336
11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 337
11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 338
11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 339
11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 340
11/21/2021 13:16:07 - INFO - __main__ -   Batch number = 341
11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 342
11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 343
11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 344
11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 345
11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 346
11/21/2021 13:16:08 - INFO - __main__ -   Batch number = 347
11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 348
11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 349
11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 350
11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 351
11/21/2021 13:16:09 - INFO - __main__ -   Batch number = 352
11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 353
11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 354
11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 355
11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 356
11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 357
11/21/2021 13:16:10 - INFO - __main__ -   Batch number = 358
11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 359
11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 360
11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 361
11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 362
11/21/2021 13:16:11 - INFO - __main__ -   Batch number = 363
11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 364
11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 365
11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 366
11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 367
11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 368
11/21/2021 13:16:12 - INFO - __main__ -   Batch number = 369
11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 370
11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 371
11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 372
11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 373
11/21/2021 13:16:13 - INFO - __main__ -   Batch number = 374
11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 375
11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 376
11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 377
11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 378
11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 379
11/21/2021 13:16:14 - INFO - __main__ -   Batch number = 380
11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 381
11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 382
11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 383
11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 384
11/21/2021 13:16:15 - INFO - __main__ -   Batch number = 385
11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 386
11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 387
11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 388
11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 389
11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 390
11/21/2021 13:16:16 - INFO - __main__ -   Batch number = 391
11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 392
11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 393
11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 394
11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 395
11/21/2021 13:16:17 - INFO - __main__ -   Batch number = 396
11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 397
11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 398
11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 399
11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 400
11/21/2021 13:16:18 - INFO - __main__ -   Batch number = 401
11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 402
11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 403
11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 404
11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 405
11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 406
11/21/2021 13:16:19 - INFO - __main__ -   Batch number = 407
11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 408
11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 409
11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 410
11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 411
11/21/2021 13:16:20 - INFO - __main__ -   Batch number = 412
11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 413
11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 414
11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 415
11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 416
11/21/2021 13:16:21 - INFO - __main__ -   Batch number = 417
11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 418
11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 419
11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 420
11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 421
11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 422
11/21/2021 13:16:22 - INFO - __main__ -   Batch number = 423
11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 424
11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 425
11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 426
11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 427
11/21/2021 13:16:23 - INFO - __main__ -   Batch number = 428
11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 429
11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 430
11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 431
11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 432
11/21/2021 13:16:24 - INFO - __main__ -   Batch number = 433
11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 434
11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 435
11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 436
11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 437
11/21/2021 13:16:25 - INFO - __main__ -   Batch number = 438
11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 439
11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 440
11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 441
11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 442
11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 443
11/21/2021 13:16:26 - INFO - __main__ -   Batch number = 444
11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 445
11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 446
11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 447
11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 448
11/21/2021 13:16:27 - INFO - __main__ -   Batch number = 449
11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 450
11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 451
11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 452
11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 453
11/21/2021 13:16:28 - INFO - __main__ -   Batch number = 454
11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 455
11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 456
11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 457
11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 458
11/21/2021 13:16:29 - INFO - __main__ -   Batch number = 459
11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 460
11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 461
11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 462
11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 463
11/21/2021 13:16:30 - INFO - __main__ -   Batch number = 464
11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 465
11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 466
11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 467
11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 468
11/21/2021 13:16:31 - INFO - __main__ -   Batch number = 469
11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 470
11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 471
11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 472
11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 473
11/21/2021 13:16:32 - INFO - __main__ -   Batch number = 474
11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 475
11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 476
11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 477
11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 478
11/21/2021 13:16:33 - INFO - __main__ -   Batch number = 479
11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 480
11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 481
11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 482
11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 483
11/21/2021 13:16:34 - INFO - __main__ -   Batch number = 484
11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 485
11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 486
11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 487
11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 488
11/21/2021 13:16:35 - INFO - __main__ -   Batch number = 489
11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 490
11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 491
11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 492
11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 493
11/21/2021 13:16:36 - INFO - __main__ -   Batch number = 494
11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 495
11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 496
11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 497
11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 498
11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 499
11/21/2021 13:16:37 - INFO - __main__ -   Batch number = 500
11/21/2021 13:16:38 - INFO - __main__ -   Batch number = 501
11/21/2021 13:16:38 - INFO - __main__ -   Batch number = 502
11/21/2021 13:16:38 - INFO - __main__ -   Batch number = 503
11/21/2021 13:16:38 - INFO - __main__ -   Batch number = 504
11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 505
11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 506
11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 507
11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 508
11/21/2021 13:16:39 - INFO - __main__ -   Batch number = 509
11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 510
11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 511
11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 512
11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 513
11/21/2021 13:16:40 - INFO - __main__ -   Batch number = 514
11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 515
11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 516
11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 517
11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 518
11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 519
11/21/2021 13:16:41 - INFO - __main__ -   Batch number = 520
11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 521
11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 522
11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 523
11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 524
11/21/2021 13:16:42 - INFO - __main__ -   Batch number = 525
11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 526
11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 527
11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 528
11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 529
11/21/2021 13:16:43 - INFO - __main__ -   Batch number = 530
11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 531
11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 532
11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 533
11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 534
11/21/2021 13:16:44 - INFO - __main__ -   Batch number = 535
11/21/2021 13:16:45 - INFO - __main__ -   Batch number = 536
11/21/2021 13:16:45 - INFO - __main__ -   Batch number = 537
11/21/2021 13:16:45 - INFO - __main__ -   Batch number = 538
11/21/2021 13:16:45 - INFO - __main__ -   Batch number = 539
11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 540
11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 541
11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 542
11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 543
11/21/2021 13:16:46 - INFO - __main__ -   Batch number = 544
11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 545
11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 546
11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 547
11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 548
11/21/2021 13:16:47 - INFO - __main__ -   Batch number = 549
11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 550
11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 551
11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 552
11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 553
11/21/2021 13:16:48 - INFO - __main__ -   Batch number = 554
11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 555
11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 556
11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 557
11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 558
11/21/2021 13:16:49 - INFO - __main__ -   Batch number = 559
11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 560
11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 561
11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 562
11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 563
11/21/2021 13:16:50 - INFO - __main__ -   Batch number = 564
11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 565
11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 566
11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 567
11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 568
11/21/2021 13:16:51 - INFO - __main__ -   Batch number = 569
11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 570
11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 571
11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 572
11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 573
11/21/2021 13:16:52 - INFO - __main__ -   Batch number = 574
11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 575
11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 576
11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 577
11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 578
11/21/2021 13:16:53 - INFO - __main__ -   Batch number = 579
11/21/2021 13:16:54 - INFO - __main__ -   Batch number = 580
11/21/2021 13:16:54 - INFO - __main__ -   Batch number = 581
11/21/2021 13:16:54 - INFO - __main__ -   Batch number = 582
11/21/2021 13:16:54 - INFO - __main__ -   Batch number = 583
11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 584
11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 585
11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 586
11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 587
11/21/2021 13:16:55 - INFO - __main__ -   Batch number = 588
11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 589
11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 590
11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 591
11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 592
11/21/2021 13:16:56 - INFO - __main__ -   Batch number = 593
11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 594
11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 595
11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 596
11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 597
11/21/2021 13:16:57 - INFO - __main__ -   Batch number = 598
11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 599
11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 600
11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 601
11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 602
11/21/2021 13:16:58 - INFO - __main__ -   Batch number = 603
11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 604
11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 605
11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 606
11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 607
11/21/2021 13:16:59 - INFO - __main__ -   Batch number = 608
11/21/2021 13:17:00 - INFO - __main__ -   Batch number = 609
11/21/2021 13:17:00 - INFO - __main__ -   Batch number = 610
11/21/2021 13:17:00 - INFO - __main__ -   Batch number = 611
11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 612
11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 613
11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 614
11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 615
11/21/2021 13:17:01 - INFO - __main__ -   Batch number = 616
11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 617
11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 618
11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 619
11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 620
11/21/2021 13:17:02 - INFO - __main__ -   Batch number = 621
11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 622
11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 623
11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 624
11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 625
11/21/2021 13:17:03 - INFO - __main__ -   Batch number = 626
11/21/2021 13:17:04 - INFO - __main__ -   Batch number = 627
11/21/2021 13:17:04 - INFO - __main__ -   Batch number = 628
11/21/2021 13:17:04 - INFO - __main__ -   Batch number = 629
11/21/2021 13:17:04 - INFO - __main__ -   Batch number = 630
11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 631
11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 632
11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 633
11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 634
11/21/2021 13:17:05 - INFO - __main__ -   Batch number = 635
11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 636
11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 637
11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 638
11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 639
11/21/2021 13:17:06 - INFO - __main__ -   Batch number = 640
11/21/2021 13:17:07 - INFO - __main__ -   Batch number = 641
11/21/2021 13:17:07 - INFO - __main__ -   Batch number = 642
11/21/2021 13:17:07 - INFO - __main__ -   Batch number = 643
11/21/2021 13:17:07 - INFO - __main__ -   Batch number = 644
11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 645
11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 646
11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 647
11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 648
11/21/2021 13:17:08 - INFO - __main__ -   Batch number = 649
11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 650
11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 651
11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 652
11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 653
11/21/2021 13:17:09 - INFO - __main__ -   Batch number = 654
11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 655
11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 656
11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 657
11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 658
11/21/2021 13:17:10 - INFO - __main__ -   Batch number = 659
11/21/2021 13:17:11 - INFO - __main__ -   Batch number = 660
11/21/2021 13:17:11 - INFO - __main__ -   Batch number = 661
11/21/2021 13:17:11 - INFO - __main__ -   Batch number = 662
11/21/2021 13:17:11 - INFO - __main__ -   Batch number = 663
11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 664
11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 665
11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 666
11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 667
11/21/2021 13:17:12 - INFO - __main__ -   Batch number = 668
11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 669
11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 670
11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 671
11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 672
11/21/2021 13:17:13 - INFO - __main__ -   Batch number = 673
11/21/2021 13:17:14 - INFO - __main__ -   Batch number = 674
11/21/2021 13:17:14 - INFO - __main__ -   Batch number = 675
11/21/2021 13:17:14 - INFO - __main__ -   Batch number = 676
11/21/2021 13:17:14 - INFO - __main__ -   Batch number = 677
11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 678
11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 679
11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 680
11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 681
11/21/2021 13:17:15 - INFO - __main__ -   Batch number = 682
11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 683
11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 684
11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 685
11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 686
11/21/2021 13:17:16 - INFO - __main__ -   Batch number = 687
11/21/2021 13:17:17 - INFO - __main__ -   Batch number = 688
11/21/2021 13:17:17 - INFO - __main__ -   Batch number = 689
11/21/2021 13:17:17 - INFO - __main__ -   Batch number = 690
11/21/2021 13:17:17 - INFO - __main__ -   Batch number = 691
11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 692
11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 693
11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 694
11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 695
11/21/2021 13:17:18 - INFO - __main__ -   Batch number = 696
11/21/2021 13:17:19 - INFO - __main__ -   Batch number = 697
11/21/2021 13:17:19 - INFO - __main__ -   Batch number = 698
11/21/2021 13:17:19 - INFO - __main__ -   Batch number = 699
11/21/2021 13:17:28 - INFO - __main__ -   ***** Evaluation result  in de *****
11/21/2021 13:17:28 - INFO - __main__ -     f1 = 0.842724349147744
11/21/2021 13:17:28 - INFO - __main__ -     loss = 0.5379099446816505
11/21/2021 13:17:28 - INFO - __main__ -     precision = 0.8483568556066015
11/21/2021 13:17:28 - INFO - __main__ -     recall = 0.8371661413404115
11/21/2021 13:17:30 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:17:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/21/2021 13:17:30 - INFO - __main__ -   Seed = 2
11/21/2021 13:17:30 - INFO - root -   save model
11/21/2021 13:17:30 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:17:30 - INFO - __main__ -   Loading pretrained model and tokenizer
11/21/2021 13:17:33 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/21/2021 13:17:38 - INFO - __main__ -   Using lang2id = None
11/21/2021 13:17:38 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/21/2021 13:17:38 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
11/21/2021 13:17:38 - INFO - root -   Trying to decide if add adapter
11/21/2021 13:17:38 - INFO - root -   loading task adapter
11/21/2021 13:17:38 - INFO - root -   loading lang adpater hi/wiki@ukp
11/21/2021 13:17:38 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/21/2021 13:17:38 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/21/2021 13:17:38 - INFO - __main__ -   Language = hi
11/21/2021 13:17:38 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/21/2021 13:17:42 - INFO - __main__ -   Language adapter for de not found, using hi instead
11/21/2021 13:17:42 - INFO - __main__ -   Set active language adapter to hi
11/21/2021 13:17:42 - INFO - __main__ -   Args Adapter Weight = None
11/21/2021 13:17:42 - INFO - __main__ -   Adapter Languages = ['hi']
11/21/2021 13:17:42 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_de_bert-base-multilingual-cased_128
11/21/2021 13:17:45 - INFO - __main__ -   ***** Running evaluation  in de *****
11/21/2021 13:17:45 - INFO - __main__ -     Num examples = 22360
11/21/2021 13:17:45 - INFO - __main__ -     Batch size = 32
11/21/2021 13:17:45 - INFO - __main__ -   Batch number = 1
11/21/2021 13:17:45 - INFO - __main__ -   Batch number = 2
11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 3
11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 4
11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 5
11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 6
11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 7
11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 8
11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 9
11/21/2021 13:17:46 - INFO - __main__ -   Batch number = 10
11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 11
11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 12
11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 13
11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 14
11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 15
11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 16
11/21/2021 13:17:47 - INFO - __main__ -   Batch number = 17
11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 18
11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 19
11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 20
11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 21
11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 22
11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 23
11/21/2021 13:17:48 - INFO - __main__ -   Batch number = 24
11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 25
11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 26
11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 27
11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 28
11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 29
11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 30
11/21/2021 13:17:49 - INFO - __main__ -   Batch number = 31
11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 32
11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 33
11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 34
11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 35
11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 36
11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 37
11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 38
11/21/2021 13:17:50 - INFO - __main__ -   Batch number = 39
11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 40
11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 41
11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 42
11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 43
11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 44
11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 45
11/21/2021 13:17:51 - INFO - __main__ -   Batch number = 46
11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 47
11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 48
11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 49
11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 50
11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 51
11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 52
11/21/2021 13:17:52 - INFO - __main__ -   Batch number = 53
11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 54
11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 55
11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 56
11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 57
11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 58
11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 59
11/21/2021 13:17:53 - INFO - __main__ -   Batch number = 60
11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 61
11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 62
11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 63
11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 64
11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 65
11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 66
11/21/2021 13:17:54 - INFO - __main__ -   Batch number = 67
11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 68
11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 69
11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 70
11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 71
11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 72
11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 73
11/21/2021 13:17:55 - INFO - __main__ -   Batch number = 74
11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 75
11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 76
11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 77
11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 78
11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 79
11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 80
11/21/2021 13:17:56 - INFO - __main__ -   Batch number = 81
11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 82
11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 83
11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 84
11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 85
11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 86
11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 87
11/21/2021 13:17:57 - INFO - __main__ -   Batch number = 88
11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 89
11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 90
11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 91
11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 92
11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 93
11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 94
11/21/2021 13:17:58 - INFO - __main__ -   Batch number = 95
11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 96
11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 97
11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 98
11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 99
11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 100
11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 101
11/21/2021 13:17:59 - INFO - __main__ -   Batch number = 102
11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 103
11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 104
11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 105
11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 106
11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 107
11/21/2021 13:18:00 - INFO - __main__ -   Batch number = 108
11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 109
11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 110
11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 111
11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 112
11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 113
11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 114
11/21/2021 13:18:01 - INFO - __main__ -   Batch number = 115
11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 116
11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 117
11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 118
11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 119
11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 120
11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 121
11/21/2021 13:18:02 - INFO - __main__ -   Batch number = 122
11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 123
11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 124
11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 125
11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 126
11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 127
11/21/2021 13:18:03 - INFO - __main__ -   Batch number = 128
11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 129
11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 130
11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 131
11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 132
11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 133
11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 134
11/21/2021 13:18:04 - INFO - __main__ -   Batch number = 135
11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 136
11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 137
11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 138
11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 139
11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 140
11/21/2021 13:18:05 - INFO - __main__ -   Batch number = 141
11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 142
11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 143
11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 144
11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 145
11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 146
11/21/2021 13:18:06 - INFO - __main__ -   Batch number = 147
11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 148
11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 149
11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 150
11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 151
11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 152
11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 153
11/21/2021 13:18:07 - INFO - __main__ -   Batch number = 154
11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 155
11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 156
11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 157
11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 158
11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 159
11/21/2021 13:18:08 - INFO - __main__ -   Batch number = 160
11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 161
11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 162
11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 163
11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 164
11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 165
11/21/2021 13:18:09 - INFO - __main__ -   Batch number = 166
11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 167
11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 168
11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 169
11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 170
11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 171
11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 172
11/21/2021 13:18:10 - INFO - __main__ -   Batch number = 173
11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 174
11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 175
11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 176
11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 177
11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 178
11/21/2021 13:18:11 - INFO - __main__ -   Batch number = 179
11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 180
11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 181
11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 182
11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 183
11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 184
11/21/2021 13:18:12 - INFO - __main__ -   Batch number = 185
11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 186
11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 187
11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 188
11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 189
11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 190
11/21/2021 13:18:13 - INFO - __main__ -   Batch number = 191
11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 192
11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 193
11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 194
11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 195
11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 196
11/21/2021 13:18:14 - INFO - __main__ -   Batch number = 197
11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 198
11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 199
11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 200
11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 201
11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 202
11/21/2021 13:18:15 - INFO - __main__ -   Batch number = 203
11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 204
11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 205
11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 206
11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 207
11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 208
11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 209
11/21/2021 13:18:16 - INFO - __main__ -   Batch number = 210
11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 211
11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 212
11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 213
11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 214
11/21/2021 13:18:17 - INFO - __main__ -   Batch number = 215
11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 216
11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 217
11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 218
11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 219
11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 220
11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 221
11/21/2021 13:18:18 - INFO - __main__ -   Batch number = 222
11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 223
11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 224
11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 225
11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 226
11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 227
11/21/2021 13:18:19 - INFO - __main__ -   Batch number = 228
11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 229
11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 230
11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 231
11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 232
11/21/2021 13:18:20 - INFO - __main__ -   Batch number = 233
11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 234
11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 235
11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 236
11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 237
11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 238
11/21/2021 13:18:21 - INFO - __main__ -   Batch number = 239
11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 240
11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 241
11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 242
11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 243
11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 244
11/21/2021 13:18:22 - INFO - __main__ -   Batch number = 245
11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 246
11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 247
11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 248
11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 249
11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 250
11/21/2021 13:18:23 - INFO - __main__ -   Batch number = 251
11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 252
11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 253
11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 254
11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 255
11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 256
11/21/2021 13:18:24 - INFO - __main__ -   Batch number = 257
11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 258
11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 259
11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 260
11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 261
11/21/2021 13:18:25 - INFO - __main__ -   Batch number = 262
11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 263
11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 264
11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 265
11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 266
11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 267
11/21/2021 13:18:26 - INFO - __main__ -   Batch number = 268
11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 269
11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 270
11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 271
11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 272
11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 273
11/21/2021 13:18:27 - INFO - __main__ -   Batch number = 274
11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 275
11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 276
11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 277
11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 278
11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 279
11/21/2021 13:18:28 - INFO - __main__ -   Batch number = 280
11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 281
11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 282
11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 283
11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 284
11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 285
11/21/2021 13:18:29 - INFO - __main__ -   Batch number = 286
11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 287
11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 288
11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 289
11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 290
11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 291
11/21/2021 13:18:30 - INFO - __main__ -   Batch number = 292
11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 293
11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 294
11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 295
11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 296
11/21/2021 13:18:31 - INFO - __main__ -   Batch number = 297
11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 298
11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 299
11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 300
11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 301
11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 302
11/21/2021 13:18:32 - INFO - __main__ -   Batch number = 303
11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 304
11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 305
11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 306
11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 307
11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 308
11/21/2021 13:18:33 - INFO - __main__ -   Batch number = 309
11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 310
11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 311
11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 312
11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 313
11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 314
11/21/2021 13:18:34 - INFO - __main__ -   Batch number = 315
11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 316
11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 317
11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 318
11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 319
11/21/2021 13:18:35 - INFO - __main__ -   Batch number = 320
11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 321
11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 322
11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 323
11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 324
11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 325
11/21/2021 13:18:36 - INFO - __main__ -   Batch number = 326
11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 327
11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 328
11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 329
11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 330
11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 331
11/21/2021 13:18:37 - INFO - __main__ -   Batch number = 332
11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 333
11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 334
11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 335
11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 336
11/21/2021 13:18:38 - INFO - __main__ -   Batch number = 337
11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 338
11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 339
11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 340
11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 341
11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 342
11/21/2021 13:18:39 - INFO - __main__ -   Batch number = 343
11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 344
11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 345
11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 346
11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 347
11/21/2021 13:18:40 - INFO - __main__ -   Batch number = 348
11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 349
11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 350
11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 351
11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 352
11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 353
11/21/2021 13:18:41 - INFO - __main__ -   Batch number = 354
11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 355
11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 356
11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 357
11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 358
11/21/2021 13:18:42 - INFO - __main__ -   Batch number = 359
11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 360
11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 361
11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 362
11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 363
11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 364
11/21/2021 13:18:43 - INFO - __main__ -   Batch number = 365
11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 366
11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 367
11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 368
11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 369
11/21/2021 13:18:44 - INFO - __main__ -   Batch number = 370
11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 371
11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 372
11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 373
11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 374
11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 375
11/21/2021 13:18:45 - INFO - __main__ -   Batch number = 376
11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 377
11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 378
11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 379
11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 380
11/21/2021 13:18:46 - INFO - __main__ -   Batch number = 381
11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 382
11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 383
11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 384
11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 385
11/21/2021 13:18:47 - INFO - __main__ -   Batch number = 386
11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 387
11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 388
11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 389
11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 390
11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 391
11/21/2021 13:18:48 - INFO - __main__ -   Batch number = 392
11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 393
11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 394
11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 395
11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 396
11/21/2021 13:18:49 - INFO - __main__ -   Batch number = 397
11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 398
11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 399
11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 400
11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 401
11/21/2021 13:18:50 - INFO - __main__ -   Batch number = 402
11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 403
11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 404
11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 405
11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 406
11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 407
11/21/2021 13:18:51 - INFO - __main__ -   Batch number = 408
11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 409
11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 410
11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 411
11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 412
11/21/2021 13:18:52 - INFO - __main__ -   Batch number = 413
11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 414
11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 415
11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 416
11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 417
11/21/2021 13:18:53 - INFO - __main__ -   Batch number = 418
11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 419
11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 420
11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 421
11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 422
11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 423
11/21/2021 13:18:54 - INFO - __main__ -   Batch number = 424
11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 425
11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 426
11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 427
11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 428
11/21/2021 13:18:55 - INFO - __main__ -   Batch number = 429
11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 430
11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 431
11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 432
11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 433
11/21/2021 13:18:56 - INFO - __main__ -   Batch number = 434
11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 435
11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 436
11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 437
11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 438
11/21/2021 13:18:57 - INFO - __main__ -   Batch number = 439
11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 440
11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 441
11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 442
11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 443
11/21/2021 13:18:58 - INFO - __main__ -   Batch number = 444
11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 445
11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 446
11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 447
11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 448
11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 449
11/21/2021 13:18:59 - INFO - __main__ -   Batch number = 450
11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 451
11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 452
11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 453
11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 454
11/21/2021 13:19:00 - INFO - __main__ -   Batch number = 455
11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 456
11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 457
11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 458
11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 459
11/21/2021 13:19:01 - INFO - __main__ -   Batch number = 460
11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 461
11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 462
11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 463
11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 464
11/21/2021 13:19:02 - INFO - __main__ -   Batch number = 465
11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 466
11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 467
11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 468
11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 469
11/21/2021 13:19:03 - INFO - __main__ -   Batch number = 470
11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 471
11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 472
11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 473
11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 474
11/21/2021 13:19:04 - INFO - __main__ -   Batch number = 475
11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 476
11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 477
11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 478
11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 479
11/21/2021 13:19:05 - INFO - __main__ -   Batch number = 480
11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 481
11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 482
11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 483
11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 484
11/21/2021 13:19:06 - INFO - __main__ -   Batch number = 485
11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 486
11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 487
11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 488
11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 489
11/21/2021 13:19:07 - INFO - __main__ -   Batch number = 490
11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 491
11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 492
11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 493
11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 494
11/21/2021 13:19:08 - INFO - __main__ -   Batch number = 495
11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 496
11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 497
11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 498
11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 499
11/21/2021 13:19:09 - INFO - __main__ -   Batch number = 500
11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 501
11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 502
11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 503
11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 504
11/21/2021 13:19:10 - INFO - __main__ -   Batch number = 505
11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 506
11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 507
11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 508
11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 509
11/21/2021 13:19:11 - INFO - __main__ -   Batch number = 510
11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 511
11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 512
11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 513
11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 514
11/21/2021 13:19:12 - INFO - __main__ -   Batch number = 515
11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 516
11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 517
11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 518
11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 519
11/21/2021 13:19:13 - INFO - __main__ -   Batch number = 520
11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 521
11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 522
11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 523
11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 524
11/21/2021 13:19:14 - INFO - __main__ -   Batch number = 525
11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 526
11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 527
11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 528
11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 529
11/21/2021 13:19:15 - INFO - __main__ -   Batch number = 530
11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 531
11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 532
11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 533
11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 534
11/21/2021 13:19:16 - INFO - __main__ -   Batch number = 535
11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 536
11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 537
11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 538
11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 539
11/21/2021 13:19:17 - INFO - __main__ -   Batch number = 540
11/21/2021 13:19:18 - INFO - __main__ -   Batch number = 541
11/21/2021 13:19:18 - INFO - __main__ -   Batch number = 542
11/21/2021 13:19:18 - INFO - __main__ -   Batch number = 543
11/21/2021 13:19:18 - INFO - __main__ -   Batch number = 544
11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 545
11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 546
11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 547
11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 548
11/21/2021 13:19:19 - INFO - __main__ -   Batch number = 549
11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 550
11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 551
11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 552
11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 553
11/21/2021 13:19:20 - INFO - __main__ -   Batch number = 554
11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 555
11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 556
11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 557
11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 558
11/21/2021 13:19:21 - INFO - __main__ -   Batch number = 559
11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 560
11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 561
11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 562
11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 563
11/21/2021 13:19:22 - INFO - __main__ -   Batch number = 564
11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 565
11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 566
11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 567
11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 568
11/21/2021 13:19:23 - INFO - __main__ -   Batch number = 569
11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 570
11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 571
11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 572
11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 573
11/21/2021 13:19:24 - INFO - __main__ -   Batch number = 574
11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 575
11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 576
11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 577
11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 578
11/21/2021 13:19:25 - INFO - __main__ -   Batch number = 579
11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 580
11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 581
11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 582
11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 583
11/21/2021 13:19:26 - INFO - __main__ -   Batch number = 584
11/21/2021 13:19:27 - INFO - __main__ -   Batch number = 585
11/21/2021 13:19:27 - INFO - __main__ -   Batch number = 586
11/21/2021 13:19:27 - INFO - __main__ -   Batch number = 587
11/21/2021 13:19:27 - INFO - __main__ -   Batch number = 588
11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 589
11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 590
11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 591
11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 592
11/21/2021 13:19:28 - INFO - __main__ -   Batch number = 593
11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 594
11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 595
11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 596
11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 597
11/21/2021 13:19:29 - INFO - __main__ -   Batch number = 598
11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 599
11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 600
11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 601
11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 602
11/21/2021 13:19:30 - INFO - __main__ -   Batch number = 603
11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 604
11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 605
11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 606
11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 607
11/21/2021 13:19:31 - INFO - __main__ -   Batch number = 608
11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 609
11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 610
11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 611
11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 612
11/21/2021 13:19:32 - INFO - __main__ -   Batch number = 613
11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 614
11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 615
11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 616
11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 617
11/21/2021 13:19:33 - INFO - __main__ -   Batch number = 618
11/21/2021 13:19:34 - INFO - __main__ -   Batch number = 619
11/21/2021 13:19:34 - INFO - __main__ -   Batch number = 620
11/21/2021 13:19:34 - INFO - __main__ -   Batch number = 621
11/21/2021 13:19:34 - INFO - __main__ -   Batch number = 622
11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 623
11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 624
11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 625
11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 626
11/21/2021 13:19:35 - INFO - __main__ -   Batch number = 627
11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 628
11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 629
11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 630
11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 631
11/21/2021 13:19:36 - INFO - __main__ -   Batch number = 632
11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 633
11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 634
11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 635
11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 636
11/21/2021 13:19:37 - INFO - __main__ -   Batch number = 637
11/21/2021 13:19:38 - INFO - __main__ -   Batch number = 638
11/21/2021 13:19:38 - INFO - __main__ -   Batch number = 639
11/21/2021 13:19:38 - INFO - __main__ -   Batch number = 640
11/21/2021 13:19:38 - INFO - __main__ -   Batch number = 641
11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 642
11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 643
11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 644
11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 645
11/21/2021 13:19:39 - INFO - __main__ -   Batch number = 646
11/21/2021 13:19:40 - INFO - __main__ -   Batch number = 647
11/21/2021 13:19:40 - INFO - __main__ -   Batch number = 648
11/21/2021 13:19:40 - INFO - __main__ -   Batch number = 649
11/21/2021 13:19:40 - INFO - __main__ -   Batch number = 650
11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 651
11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 652
11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 653
11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 654
11/21/2021 13:19:41 - INFO - __main__ -   Batch number = 655
11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 656
11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 657
11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 658
11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 659
11/21/2021 13:19:42 - INFO - __main__ -   Batch number = 660
11/21/2021 13:19:43 - INFO - __main__ -   Batch number = 661
11/21/2021 13:19:43 - INFO - __main__ -   Batch number = 662
11/21/2021 13:19:43 - INFO - __main__ -   Batch number = 663
11/21/2021 13:19:43 - INFO - __main__ -   Batch number = 664
11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 665
11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 666
11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 667
11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 668
11/21/2021 13:19:44 - INFO - __main__ -   Batch number = 669
11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 670
11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 671
11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 672
11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 673
11/21/2021 13:19:45 - INFO - __main__ -   Batch number = 674
11/21/2021 13:19:46 - INFO - __main__ -   Batch number = 675
11/21/2021 13:19:46 - INFO - __main__ -   Batch number = 676
11/21/2021 13:19:46 - INFO - __main__ -   Batch number = 677
11/21/2021 13:19:46 - INFO - __main__ -   Batch number = 678
11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 679
11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 680
11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 681
11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 682
11/21/2021 13:19:47 - INFO - __main__ -   Batch number = 683
11/21/2021 13:19:48 - INFO - __main__ -   Batch number = 684
11/21/2021 13:19:48 - INFO - __main__ -   Batch number = 685
11/21/2021 13:19:48 - INFO - __main__ -   Batch number = 686
11/21/2021 13:19:48 - INFO - __main__ -   Batch number = 687
11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 688
11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 689
11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 690
11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 691
11/21/2021 13:19:49 - INFO - __main__ -   Batch number = 692
11/21/2021 13:19:50 - INFO - __main__ -   Batch number = 693
11/21/2021 13:19:50 - INFO - __main__ -   Batch number = 694
11/21/2021 13:19:50 - INFO - __main__ -   Batch number = 695
11/21/2021 13:19:50 - INFO - __main__ -   Batch number = 696
11/21/2021 13:19:51 - INFO - __main__ -   Batch number = 697
11/21/2021 13:19:51 - INFO - __main__ -   Batch number = 698
11/21/2021 13:19:51 - INFO - __main__ -   Batch number = 699
11/21/2021 13:20:01 - INFO - __main__ -   ***** Evaluation result  in de *****
11/21/2021 13:20:01 - INFO - __main__ -     f1 = 0.852800798905937
11/21/2021 13:20:01 - INFO - __main__ -     loss = 0.5621825033673572
11/21/2021 13:20:01 - INFO - __main__ -     precision = 0.8578727734835032
11/21/2021 13:20:01 - INFO - __main__ -     recall = 0.8477884455872594
11/21/2021 13:20:03 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:20:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
11/21/2021 13:20:03 - INFO - __main__ -   Seed = 3
11/21/2021 13:20:03 - INFO - root -   save model
11/21/2021 13:20:03 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=False, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='de', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
11/21/2021 13:20:03 - INFO - __main__ -   Loading pretrained model and tokenizer
11/21/2021 13:20:05 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
11/21/2021 13:20:11 - INFO - __main__ -   Using lang2id = None
11/21/2021 13:20:11 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
11/21/2021 13:20:11 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
11/21/2021 13:20:11 - INFO - root -   Trying to decide if add adapter
11/21/2021 13:20:11 - INFO - root -   loading task adapter
11/21/2021 13:20:11 - INFO - root -   loading lang adpater hi/wiki@ukp
11/21/2021 13:20:11 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
11/21/2021 13:20:11 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
11/21/2021 13:20:11 - INFO - __main__ -   Language = hi
11/21/2021 13:20:11 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
11/21/2021 13:20:14 - INFO - __main__ -   Language adapter for de not found, using hi instead
11/21/2021 13:20:14 - INFO - __main__ -   Set active language adapter to hi
11/21/2021 13:20:14 - INFO - __main__ -   Args Adapter Weight = None
11/21/2021 13:20:14 - INFO - __main__ -   Adapter Languages = ['hi']
11/21/2021 13:20:14 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea/data//udpos/udpos_processed_maxlen128/cached_test_de_bert-base-multilingual-cased_128
11/21/2021 13:20:17 - INFO - __main__ -   ***** Running evaluation  in de *****
11/21/2021 13:20:17 - INFO - __main__ -     Num examples = 22360
11/21/2021 13:20:17 - INFO - __main__ -     Batch size = 32
11/21/2021 13:20:17 - INFO - __main__ -   Batch number = 1
11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 2
11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 3
11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 4
11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 5
11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 6
11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 7
11/21/2021 13:20:18 - INFO - __main__ -   Batch number = 8
11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 9
11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 10
11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 11
11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 12
11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 13
11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 14
11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 15
11/21/2021 13:20:19 - INFO - __main__ -   Batch number = 16
11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 17
11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 18
11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 19
11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 20
11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 21
11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 22
11/21/2021 13:20:20 - INFO - __main__ -   Batch number = 23
11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 24
11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 25
11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 26
11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 27
11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 28
11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 29
11/21/2021 13:20:21 - INFO - __main__ -   Batch number = 30
11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 31
11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 32
11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 33
11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 34
11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 35
11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 36
11/21/2021 13:20:22 - INFO - __main__ -   Batch number = 37
11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 38
11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 39
11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 40
11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 41
11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 42
11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 43
11/21/2021 13:20:23 - INFO - __main__ -   Batch number = 44
11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 45
11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 46
11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 47
11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 48
11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 49
11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 50
11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 51
11/21/2021 13:20:24 - INFO - __main__ -   Batch number = 52
11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 53
11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 54
11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 55
11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 56
11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 57
11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 58
11/21/2021 13:20:25 - INFO - __main__ -   Batch number = 59
11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 60
11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 61
11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 62
11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 63
11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 64
11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 65
11/21/2021 13:20:26 - INFO - __main__ -   Batch number = 66
11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 67
11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 68
11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 69
11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 70
11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 71
11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 72
11/21/2021 13:20:27 - INFO - __main__ -   Batch number = 73
11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 74
11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 75
11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 76
11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 77
11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 78
11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 79
11/21/2021 13:20:28 - INFO - __main__ -   Batch number = 80
11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 81
11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 82
11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 83
11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 84
11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 85
11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 86
11/21/2021 13:20:29 - INFO - __main__ -   Batch number = 87
11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 88
11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 89
11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 90
11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 91
11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 92
11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 93
11/21/2021 13:20:30 - INFO - __main__ -   Batch number = 94
11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 95
11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 96
11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 97
11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 98
11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 99
11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 100
11/21/2021 13:20:31 - INFO - __main__ -   Batch number = 101
11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 102
11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 103
11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 104
11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 105
11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 106
11/21/2021 13:20:32 - INFO - __main__ -   Batch number = 107
11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 108
11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 109
11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 110
11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 111
11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 112
11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 113
11/21/2021 13:20:33 - INFO - __main__ -   Batch number = 114
11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 115
11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 116
11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 117
11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 118
11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 119
11/21/2021 13:20:34 - INFO - __main__ -   Batch number = 120
11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 121
11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 122
11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 123
11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 124
11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 125
11/21/2021 13:20:35 - INFO - __main__ -   Batch number = 126
11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 127
11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 128
11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 129
11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 130
11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 131
11/21/2021 13:20:36 - INFO - __main__ -   Batch number = 132
11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 133
11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 134
11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 135
11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 136
11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 137
11/21/2021 13:20:37 - INFO - __main__ -   Batch number = 138
11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 139
11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 140
11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 141
11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 142
11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 143
11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 144
11/21/2021 13:20:38 - INFO - __main__ -   Batch number = 145
11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 146
11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 147
11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 148
11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 149
11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 150
11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 151
11/21/2021 13:20:39 - INFO - __main__ -   Batch number = 152
11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 153
11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 154
11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 155
11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 156
11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 157
11/21/2021 13:20:40 - INFO - __main__ -   Batch number = 158
11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 159
11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 160
11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 161
11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 162
11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 163
11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 164
11/21/2021 13:20:41 - INFO - __main__ -   Batch number = 165
11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 166
11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 167
11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 168
11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 169
11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 170
11/21/2021 13:20:42 - INFO - __main__ -   Batch number = 171
11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 172
11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 173
11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 174
11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 175
11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 176
11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 177
11/21/2021 13:20:43 - INFO - __main__ -   Batch number = 178
11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 179
11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 180
11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 181
11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 182
11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 183
11/21/2021 13:20:44 - INFO - __main__ -   Batch number = 184
11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 185
11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 186
11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 187
11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 188
11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 189
11/21/2021 13:20:45 - INFO - __main__ -   Batch number = 190
11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 191
11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 192
11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 193
11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 194
11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 195
11/21/2021 13:20:46 - INFO - __main__ -   Batch number = 196
11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 197
11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 198
11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 199
11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 200
11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 201
11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 202
11/21/2021 13:20:47 - INFO - __main__ -   Batch number = 203
11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 204
11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 205
11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 206
11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 207
11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 208
11/21/2021 13:20:48 - INFO - __main__ -   Batch number = 209
11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 210
11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 211
11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 212
11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 213
11/21/2021 13:20:49 - INFO - __main__ -   Batch number = 214
11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 215
11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 216
11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 217
11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 218
11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 219
11/21/2021 13:20:50 - INFO - __main__ -   Batch number = 220
11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 221
11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 222
11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 223
11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 224
11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 225
11/21/2021 13:20:51 - INFO - __main__ -   Batch number = 226
11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 227
11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 228
11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 229
11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 230
11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 231
11/21/2021 13:20:52 - INFO - __main__ -   Batch number = 232
11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 233
11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 234
11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 235
11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 236
11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 237
11/21/2021 13:20:53 - INFO - __main__ -   Batch number = 238
11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 239
11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 240
11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 241
11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 242
11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 243
11/21/2021 13:20:54 - INFO - __main__ -   Batch number = 244
11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 245
11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 246
11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 247
11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 248
11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 249
11/21/2021 13:20:55 - INFO - __main__ -   Batch number = 250
11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 251
11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 252
11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 253
11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 254
11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 255
11/21/2021 13:20:56 - INFO - __main__ -   Batch number = 256
11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 257
11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 258
11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 259
11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 260
11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 261
11/21/2021 13:20:57 - INFO - __main__ -   Batch number = 262
11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 263
11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 264
11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 265
11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 266
11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 267
11/21/2021 13:20:58 - INFO - __main__ -   Batch number = 268
11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 269
11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 270
11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 271
11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 272
11/21/2021 13:20:59 - INFO - __main__ -   Batch number = 273
11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 274
11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 275
11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 276
11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 277
11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 278
11/21/2021 13:21:00 - INFO - __main__ -   Batch number = 279
11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 280
11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 281
11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 282
11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 283
11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 284
11/21/2021 13:21:01 - INFO - __main__ -   Batch number = 285
11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 286
11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 287
11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 288
11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 289
11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 290
11/21/2021 13:21:02 - INFO - __main__ -   Batch number = 291
11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 292
11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 293
11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 294
11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 295
11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 296
11/21/2021 13:21:03 - INFO - __main__ -   Batch number = 297
11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 298
11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 299
11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 300
11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 301
11/21/2021 13:21:04 - INFO - __main__ -   Batch number = 302
11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 303
11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 304
11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 305
11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 306
11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 307
11/21/2021 13:21:05 - INFO - __main__ -   Batch number = 308
11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 309
11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 310
11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 311
11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 312
11/21/2021 13:21:06 - INFO - __main__ -   Batch number = 313
11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 314
11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 315
11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 316
11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 317
11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 318
11/21/2021 13:21:07 - INFO - __main__ -   Batch number = 319
11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 320
11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 321
11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 322
11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 323
11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 324
11/21/2021 13:21:08 - INFO - __main__ -   Batch number = 325
11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 326
11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 327
11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 328
11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 329
11/21/2021 13:21:09 - INFO - __main__ -   Batch number = 330
11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 331
11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 332
11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 333
11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 334
11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 335
11/21/2021 13:21:10 - INFO - __main__ -   Batch number = 336
11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 337
11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 338
11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 339
11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 340
11/21/2021 13:21:11 - INFO - __main__ -   Batch number = 341
11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 342
11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 343
11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 344
11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 345
11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 346
11/21/2021 13:21:12 - INFO - __main__ -   Batch number = 347
11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 348
11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 349
11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 350
11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 351
11/21/2021 13:21:13 - INFO - __main__ -   Batch number = 352
11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 353
11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 354
11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 355
11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 356
11/21/2021 13:21:14 - INFO - __main__ -   Batch number = 357
11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 358
11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 359
11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 360
11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 361
11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 362
11/21/2021 13:21:15 - INFO - __main__ -   Batch number = 363
11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 364
11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 365
11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 366
11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 367
11/21/2021 13:21:16 - INFO - __main__ -   Batch number = 368
11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 369
11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 370
11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 371
11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 372
11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 373
11/21/2021 13:21:17 - INFO - __main__ -   Batch number = 374
11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 375
11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 376
11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 377
11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 378
11/21/2021 13:21:18 - INFO - __main__ -   Batch number = 379
11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 380
11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 381
11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 382
11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 383
11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 384
11/21/2021 13:21:19 - INFO - __main__ -   Batch number = 385
11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 386
11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 387
11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 388
11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 389
11/21/2021 13:21:20 - INFO - __main__ -   Batch number = 390
11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 391
11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 392
11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 393
11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 394
11/21/2021 13:21:21 - INFO - __main__ -   Batch number = 395
11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 396
11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 397
11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 398
11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 399
11/21/2021 13:21:22 - INFO - __main__ -   Batch number = 400
11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 401
11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 402
11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 403
11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 404
11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 405
11/21/2021 13:21:23 - INFO - __main__ -   Batch number = 406
11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 407
11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 408
11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 409
11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 410
11/21/2021 13:21:24 - INFO - __main__ -   Batch number = 411
11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 412
11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 413
11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 414
11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 415
11/21/2021 13:21:25 - INFO - __main__ -   Batch number = 416
11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 417
11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 418
11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 419
11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 420
11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 421
11/21/2021 13:21:26 - INFO - __main__ -   Batch number = 422
11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 423
11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 424
11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 425
11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 426
11/21/2021 13:21:27 - INFO - __main__ -   Batch number = 427
11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 428
11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 429
11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 430
11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 431
11/21/2021 13:21:28 - INFO - __main__ -   Batch number = 432
11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 433
11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 434
11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 435
11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 436
11/21/2021 13:21:29 - INFO - __main__ -   Batch number = 437
11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 438
11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 439
11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 440
11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 441
11/21/2021 13:21:30 - INFO - __main__ -   Batch number = 442
11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 443
11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 444
11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 445
11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 446
11/21/2021 13:21:31 - INFO - __main__ -   Batch number = 447
11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 448
11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 449
11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 450
11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 451
11/21/2021 13:21:32 - INFO - __main__ -   Batch number = 452
11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 453
11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 454
11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 455
11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 456
11/21/2021 13:21:33 - INFO - __main__ -   Batch number = 457
11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 458
11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 459
11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 460
11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 461
11/21/2021 13:21:34 - INFO - __main__ -   Batch number = 462
11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 463
11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 464
11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 465
11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 466
11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 467
11/21/2021 13:21:35 - INFO - __main__ -   Batch number = 468
11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 469
11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 470
11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 471
11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 472
11/21/2021 13:21:36 - INFO - __main__ -   Batch number = 473
11/21/2021 13:21:37 - INFO - __main__ -   Batch number = 474
11/21/2021 13:21:37 - INFO - __main__ -   Batch number = 475
11/21/2021 13:21:37 - INFO - __main__ -   Batch number = 476
11/21/2021 13:21:37 - INFO - __main__ -   Batch number = 477
11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 478
11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 479
11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 480
11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 481
11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 482
11/21/2021 13:21:38 - INFO - __main__ -   Batch number = 483
11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 484
11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 485
11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 486
11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 487
11/21/2021 13:21:39 - INFO - __main__ -   Batch number = 488
11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 489
11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 490
11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 491
11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 492
11/21/2021 13:21:40 - INFO - __main__ -   Batch number = 493
11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 494
11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 495
11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 496
11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 497
11/21/2021 13:21:41 - INFO - __main__ -   Batch number = 498
11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 499
11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 500
11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 501
11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 502
11/21/2021 13:21:42 - INFO - __main__ -   Batch number = 503
11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 504
11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 505
11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 506
11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 507
11/21/2021 13:21:43 - INFO - __main__ -   Batch number = 508
11/21/2021 13:21:44 - INFO - __main__ -   Batch number = 509
11/21/2021 13:21:44 - INFO - __main__ -   Batch number = 510
11/21/2021 13:21:44 - INFO - __main__ -   Batch number = 511
11/21/2021 13:21:44 - INFO - __main__ -   Batch number = 512
11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 513
11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 514
11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 515
11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 516
11/21/2021 13:21:45 - INFO - __main__ -   Batch number = 517
11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 518
11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 519
11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 520
11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 521
11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 522
11/21/2021 13:21:46 - INFO - __main__ -   Batch number = 523
11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 524
11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 525
11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 526
11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 527
11/21/2021 13:21:47 - INFO - __main__ -   Batch number = 528
11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 529
11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 530
11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 531
11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 532
11/21/2021 13:21:48 - INFO - __main__ -   Batch number = 533
11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 534
11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 535
11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 536
11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 537
11/21/2021 13:21:49 - INFO - __main__ -   Batch number = 538
11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 539
11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 540
11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 541
11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 542
11/21/2021 13:21:50 - INFO - __main__ -   Batch number = 543
11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 544
11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 545
11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 546
11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 547
11/21/2021 13:21:51 - INFO - __main__ -   Batch number = 548
11/21/2021 13:21:52 - INFO - __main__ -   Batch number = 549
11/21/2021 13:21:52 - INFO - __main__ -   Batch number = 550
11/21/2021 13:21:52 - INFO - __main__ -   Batch number = 551
11/21/2021 13:21:52 - INFO - __main__ -   Batch number = 552
11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 553
11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 554
11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 555
11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 556
11/21/2021 13:21:53 - INFO - __main__ -   Batch number = 557
11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 558
11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 559
11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 560
11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 561
11/21/2021 13:21:54 - INFO - __main__ -   Batch number = 562
11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 563
11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 564
11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 565
11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 566
11/21/2021 13:21:55 - INFO - __main__ -   Batch number = 567
11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 568
11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 569
11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 570
11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 571
11/21/2021 13:21:56 - INFO - __main__ -   Batch number = 572
11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 573
11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 574
11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 575
11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 576
11/21/2021 13:21:57 - INFO - __main__ -   Batch number = 577
11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 578
11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 579
11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 580
11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 581
11/21/2021 13:21:58 - INFO - __main__ -   Batch number = 582
11/21/2021 13:21:59 - INFO - __main__ -   Batch number = 583
11/21/2021 13:21:59 - INFO - __main__ -   Batch number = 584
11/21/2021 13:21:59 - INFO - __main__ -   Batch number = 585
11/21/2021 13:21:59 - INFO - __main__ -   Batch number = 586
11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 587
11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 588
11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 589
11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 590
11/21/2021 13:22:00 - INFO - __main__ -   Batch number = 591
11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 592
11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 593
11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 594
11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 595
11/21/2021 13:22:01 - INFO - __main__ -   Batch number = 596
11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 597
11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 598
11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 599
11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 600
11/21/2021 13:22:02 - INFO - __main__ -   Batch number = 601
11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 602
11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 603
11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 604
11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 605
11/21/2021 13:22:03 - INFO - __main__ -   Batch number = 606
11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 607
11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 608
11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 609
11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 610
11/21/2021 13:22:04 - INFO - __main__ -   Batch number = 611
11/21/2021 13:22:05 - INFO - __main__ -   Batch number = 612
11/21/2021 13:22:05 - INFO - __main__ -   Batch number = 613
11/21/2021 13:22:05 - INFO - __main__ -   Batch number = 614
11/21/2021 13:22:05 - INFO - __main__ -   Batch number = 615
11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 616
11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 617
11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 618
11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 619
11/21/2021 13:22:06 - INFO - __main__ -   Batch number = 620
11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 621
11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 622
11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 623
11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 624
11/21/2021 13:22:07 - INFO - __main__ -   Batch number = 625
11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 626
11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 627
11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 628
11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 629
11/21/2021 13:22:08 - INFO - __main__ -   Batch number = 630
11/21/2021 13:22:09 - INFO - __main__ -   Batch number = 631
11/21/2021 13:22:09 - INFO - __main__ -   Batch number = 632
11/21/2021 13:22:09 - INFO - __main__ -   Batch number = 633
11/21/2021 13:22:09 - INFO - __main__ -   Batch number = 634
11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 635
11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 636
11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 637
11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 638
11/21/2021 13:22:10 - INFO - __main__ -   Batch number = 639
11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 640
11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 641
11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 642
11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 643
11/21/2021 13:22:11 - INFO - __main__ -   Batch number = 644
11/21/2021 13:22:12 - INFO - __main__ -   Batch number = 645
11/21/2021 13:22:12 - INFO - __main__ -   Batch number = 646
11/21/2021 13:22:12 - INFO - __main__ -   Batch number = 647
11/21/2021 13:22:12 - INFO - __main__ -   Batch number = 648
11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 649
11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 650
11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 651
11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 652
11/21/2021 13:22:13 - INFO - __main__ -   Batch number = 653
11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 654
11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 655
11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 656
11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 657
11/21/2021 13:22:14 - INFO - __main__ -   Batch number = 658
11/21/2021 13:22:15 - INFO - __main__ -   Batch number = 659
11/21/2021 13:22:15 - INFO - __main__ -   Batch number = 660
11/21/2021 13:22:15 - INFO - __main__ -   Batch number = 661
11/21/2021 13:22:15 - INFO - __main__ -   Batch number = 662
11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 663
11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 664
11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 665
11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 666
11/21/2021 13:22:16 - INFO - __main__ -   Batch number = 667
11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 668
11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 669
11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 670
11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 671
11/21/2021 13:22:17 - INFO - __main__ -   Batch number = 672
11/21/2021 13:22:18 - INFO - __main__ -   Batch number = 673
11/21/2021 13:22:18 - INFO - __main__ -   Batch number = 674
11/21/2021 13:22:18 - INFO - __main__ -   Batch number = 675
11/21/2021 13:22:18 - INFO - __main__ -   Batch number = 676
11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 677
11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 678
11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 679
11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 680
11/21/2021 13:22:19 - INFO - __main__ -   Batch number = 681
11/21/2021 13:22:20 - INFO - __main__ -   Batch number = 682
11/21/2021 13:22:20 - INFO - __main__ -   Batch number = 683
11/21/2021 13:22:20 - INFO - __main__ -   Batch number = 684
11/21/2021 13:22:20 - INFO - __main__ -   Batch number = 685
11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 686
11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 687
11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 688
11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 689
11/21/2021 13:22:21 - INFO - __main__ -   Batch number = 690
11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 691
11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 692
11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 693
11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 694
11/21/2021 13:22:22 - INFO - __main__ -   Batch number = 695
11/21/2021 13:22:23 - INFO - __main__ -   Batch number = 696
11/21/2021 13:22:23 - INFO - __main__ -   Batch number = 697
11/21/2021 13:22:23 - INFO - __main__ -   Batch number = 698
11/21/2021 13:22:23 - INFO - __main__ -   Batch number = 699
11/21/2021 13:22:32 - INFO - __main__ -   ***** Evaluation result  in de *****
11/21/2021 13:22:32 - INFO - __main__ -     f1 = 0.8558524023730361
11/21/2021 13:22:32 - INFO - __main__ -     loss = 0.5121344268663076
11/21/2021 13:22:32 - INFO - __main__ -     precision = 0.8610549955661432
11/21/2021 13:22:32 - INFO - __main__ -     recall = 0.850712300928998
01/10/2022 16:18:12 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:18:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/10/2022 16:18:12 - INFO - __main__ -   Seed = 1
01/10/2022 16:18:12 - INFO - root -   save model
01/10/2022 16:18:12 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:18:12 - INFO - __main__ -   Loading pretrained model and tokenizer
01/10/2022 16:18:15 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/10/2022 16:18:21 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:18:21 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/10/2022 16:18:21 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/10/2022 16:18:21 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:18:21 - INFO - root -   loading task adapter
01/10/2022 16:18:21 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:18:21 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:18:21 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:18:21 - INFO - __main__ -   Language = hi
01/10/2022 16:18:21 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/10/2022 16:18:30 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:18:30 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:18:30 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:18:30 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:18:30 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_hi_bert-base-multilingual-cased_128
01/10/2022 16:18:30 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:18:30 - INFO - __main__ -     Num examples = 2685
01/10/2022 16:18:30 - INFO - __main__ -     Batch size = 32
01/10/2022 16:18:30 - INFO - __main__ -   Batch number = 1
01/10/2022 16:18:30 - INFO - __main__ -   Batch number = 2
01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 3
01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 4
01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 5
01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 6
01/10/2022 16:18:31 - INFO - __main__ -   Batch number = 7
01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 8
01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 9
01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 10
01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 11
01/10/2022 16:18:32 - INFO - __main__ -   Batch number = 12
01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 13
01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 14
01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 15
01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 16
01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 17
01/10/2022 16:18:33 - INFO - __main__ -   Batch number = 18
01/10/2022 16:18:34 - INFO - __main__ -   Batch number = 19
01/10/2022 16:18:34 - INFO - __main__ -   Batch number = 20
01/10/2022 16:18:34 - INFO - __main__ -   Batch number = 21
01/10/2022 16:18:35 - INFO - __main__ -   Batch number = 22
01/10/2022 16:18:35 - INFO - __main__ -   Batch number = 23
01/10/2022 16:18:35 - INFO - __main__ -   Batch number = 24
01/10/2022 16:18:36 - INFO - __main__ -   Batch number = 25
01/10/2022 16:18:36 - INFO - __main__ -   Batch number = 26
01/10/2022 16:18:36 - INFO - __main__ -   Batch number = 27
01/10/2022 16:18:37 - INFO - __main__ -   Batch number = 28
01/10/2022 16:18:37 - INFO - __main__ -   Batch number = 29
01/10/2022 16:18:37 - INFO - __main__ -   Batch number = 30
01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 31
01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 32
01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 33
01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 34
01/10/2022 16:18:38 - INFO - __main__ -   Batch number = 35
01/10/2022 16:18:39 - INFO - __main__ -   Batch number = 36
01/10/2022 16:18:39 - INFO - __main__ -   Batch number = 37
01/10/2022 16:18:39 - INFO - __main__ -   Batch number = 38
01/10/2022 16:18:40 - INFO - __main__ -   Batch number = 39
01/10/2022 16:18:40 - INFO - __main__ -   Batch number = 40
01/10/2022 16:18:40 - INFO - __main__ -   Batch number = 41
01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 42
01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 43
01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 44
01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 45
01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 46
01/10/2022 16:18:41 - INFO - __main__ -   Batch number = 47
01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 48
01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 49
01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 50
01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 51
01/10/2022 16:18:42 - INFO - __main__ -   Batch number = 52
01/10/2022 16:18:43 - INFO - __main__ -   Batch number = 53
01/10/2022 16:18:43 - INFO - __main__ -   Batch number = 54
01/10/2022 16:18:43 - INFO - __main__ -   Batch number = 55
01/10/2022 16:18:44 - INFO - __main__ -   Batch number = 56
01/10/2022 16:18:44 - INFO - __main__ -   Batch number = 57
01/10/2022 16:18:44 - INFO - __main__ -   Batch number = 58
01/10/2022 16:18:45 - INFO - __main__ -   Batch number = 59
01/10/2022 16:18:45 - INFO - __main__ -   Batch number = 60
01/10/2022 16:18:45 - INFO - __main__ -   Batch number = 61
01/10/2022 16:18:46 - INFO - __main__ -   Batch number = 62
01/10/2022 16:18:46 - INFO - __main__ -   Batch number = 63
01/10/2022 16:18:46 - INFO - __main__ -   Batch number = 64
01/10/2022 16:18:47 - INFO - __main__ -   Batch number = 65
01/10/2022 16:18:47 - INFO - __main__ -   Batch number = 66
01/10/2022 16:18:47 - INFO - __main__ -   Batch number = 67
01/10/2022 16:18:48 - INFO - __main__ -   Batch number = 68
01/10/2022 16:18:48 - INFO - __main__ -   Batch number = 69
01/10/2022 16:18:48 - INFO - __main__ -   Batch number = 70
01/10/2022 16:18:48 - INFO - __main__ -   Batch number = 71
01/10/2022 16:18:49 - INFO - __main__ -   Batch number = 72
01/10/2022 16:18:49 - INFO - __main__ -   Batch number = 73
01/10/2022 16:18:49 - INFO - __main__ -   Batch number = 74
01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 75
01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 76
01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 77
01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 78
01/10/2022 16:18:50 - INFO - __main__ -   Batch number = 79
01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 80
01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 81
01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 82
01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 83
01/10/2022 16:18:51 - INFO - __main__ -   Batch number = 84
01/10/2022 16:18:53 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:18:53 - INFO - __main__ -     f1 = 0.6192915973860252
01/10/2022 16:18:53 - INFO - __main__ -     loss = 1.1742158837261654
01/10/2022 16:18:53 - INFO - __main__ -     precision = 0.6252147095565271
01/10/2022 16:18:53 - INFO - __main__ -     recall = 0.6134796598483108
01/10/2022 16:18:53 - INFO - __main__ -   Loading pretrained model and tokenizer
01/10/2022 16:18:56 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/10/2022 16:19:01 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:19:01 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/10/2022 16:19:01 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/10/2022 16:19:01 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:19:01 - INFO - root -   loading task adapter
01/10/2022 16:19:01 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:19:01 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:19:01 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:19:01 - INFO - __main__ -   Language = hi
01/10/2022 16:19:01 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/10/2022 16:19:02 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:19:02 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:19:02 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:19:02 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:19:02 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_hi_bert-base-multilingual-cased_128
01/10/2022 16:19:03 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:19:03 - INFO - __main__ -     Num examples = 1664
01/10/2022 16:19:03 - INFO - __main__ -     Batch size = 32
01/10/2022 16:19:03 - INFO - __main__ -   Batch number = 1
01/10/2022 16:19:03 - INFO - __main__ -   Batch number = 2
01/10/2022 16:19:03 - INFO - __main__ -   Batch number = 3
01/10/2022 16:19:04 - INFO - __main__ -   Batch number = 4
01/10/2022 16:19:04 - INFO - __main__ -   Batch number = 5
01/10/2022 16:19:04 - INFO - __main__ -   Batch number = 6
01/10/2022 16:19:04 - INFO - __main__ -   Batch number = 7
01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 8
01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 9
01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 10
01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 11
01/10/2022 16:19:05 - INFO - __main__ -   Batch number = 12
01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 13
01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 14
01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 15
01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 16
01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 17
01/10/2022 16:19:06 - INFO - __main__ -   Batch number = 18
01/10/2022 16:19:07 - INFO - __main__ -   Batch number = 19
01/10/2022 16:19:07 - INFO - __main__ -   Batch number = 20
01/10/2022 16:19:07 - INFO - __main__ -   Batch number = 21
01/10/2022 16:19:08 - INFO - __main__ -   Batch number = 22
01/10/2022 16:19:08 - INFO - __main__ -   Batch number = 23
01/10/2022 16:19:08 - INFO - __main__ -   Batch number = 24
01/10/2022 16:19:09 - INFO - __main__ -   Batch number = 25
01/10/2022 16:19:09 - INFO - __main__ -   Batch number = 26
01/10/2022 16:19:09 - INFO - __main__ -   Batch number = 27
01/10/2022 16:19:10 - INFO - __main__ -   Batch number = 28
01/10/2022 16:19:10 - INFO - __main__ -   Batch number = 29
01/10/2022 16:19:10 - INFO - __main__ -   Batch number = 30
01/10/2022 16:19:11 - INFO - __main__ -   Batch number = 31
01/10/2022 16:19:11 - INFO - __main__ -   Batch number = 32
01/10/2022 16:19:11 - INFO - __main__ -   Batch number = 33
01/10/2022 16:19:12 - INFO - __main__ -   Batch number = 34
01/10/2022 16:19:12 - INFO - __main__ -   Batch number = 35
01/10/2022 16:19:12 - INFO - __main__ -   Batch number = 36
01/10/2022 16:19:12 - INFO - __main__ -   Batch number = 37
01/10/2022 16:19:13 - INFO - __main__ -   Batch number = 38
01/10/2022 16:19:13 - INFO - __main__ -   Batch number = 39
01/10/2022 16:19:13 - INFO - __main__ -   Batch number = 40
01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 41
01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 42
01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 43
01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 44
01/10/2022 16:19:14 - INFO - __main__ -   Batch number = 45
01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 46
01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 47
01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 48
01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 49
01/10/2022 16:19:15 - INFO - __main__ -   Batch number = 50
01/10/2022 16:19:16 - INFO - __main__ -   Batch number = 51
01/10/2022 16:19:16 - INFO - __main__ -   Batch number = 52
01/10/2022 16:19:17 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:19:17 - INFO - __main__ -     f1 = 0.606455210417555
01/10/2022 16:19:17 - INFO - __main__ -     loss = 1.206090427362002
01/10/2022 16:19:17 - INFO - __main__ -     precision = 0.6115705213019317
01/10/2022 16:19:17 - INFO - __main__ -     recall = 0.6014247609134084
01/10/2022 16:19:19 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:19:19 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/10/2022 16:19:19 - INFO - __main__ -   Seed = 2
01/10/2022 16:19:19 - INFO - root -   save model
01/10/2022 16:19:19 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:19:19 - INFO - __main__ -   Loading pretrained model and tokenizer
01/10/2022 16:19:22 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/10/2022 16:19:27 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:19:27 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/10/2022 16:19:27 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/10/2022 16:19:27 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:19:27 - INFO - root -   loading task adapter
01/10/2022 16:19:27 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:19:27 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:19:27 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:19:27 - INFO - __main__ -   Language = hi
01/10/2022 16:19:27 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/10/2022 16:19:35 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:19:35 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:19:35 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:19:35 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:19:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_hi_bert-base-multilingual-cased_128
01/10/2022 16:19:35 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:19:35 - INFO - __main__ -     Num examples = 2685
01/10/2022 16:19:35 - INFO - __main__ -     Batch size = 32
01/10/2022 16:19:35 - INFO - __main__ -   Batch number = 1
01/10/2022 16:19:36 - INFO - __main__ -   Batch number = 2
01/10/2022 16:19:36 - INFO - __main__ -   Batch number = 3
01/10/2022 16:19:36 - INFO - __main__ -   Batch number = 4
01/10/2022 16:19:37 - INFO - __main__ -   Batch number = 5
01/10/2022 16:19:37 - INFO - __main__ -   Batch number = 6
01/10/2022 16:19:37 - INFO - __main__ -   Batch number = 7
01/10/2022 16:19:37 - INFO - __main__ -   Batch number = 8
01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 9
01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 10
01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 11
01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 12
01/10/2022 16:19:38 - INFO - __main__ -   Batch number = 13
01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 14
01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 15
01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 16
01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 17
01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 18
01/10/2022 16:19:39 - INFO - __main__ -   Batch number = 19
01/10/2022 16:19:40 - INFO - __main__ -   Batch number = 20
01/10/2022 16:19:40 - INFO - __main__ -   Batch number = 21
01/10/2022 16:19:40 - INFO - __main__ -   Batch number = 22
01/10/2022 16:19:41 - INFO - __main__ -   Batch number = 23
01/10/2022 16:19:41 - INFO - __main__ -   Batch number = 24
01/10/2022 16:19:41 - INFO - __main__ -   Batch number = 25
01/10/2022 16:19:42 - INFO - __main__ -   Batch number = 26
01/10/2022 16:19:42 - INFO - __main__ -   Batch number = 27
01/10/2022 16:19:42 - INFO - __main__ -   Batch number = 28
01/10/2022 16:19:43 - INFO - __main__ -   Batch number = 29
01/10/2022 16:19:43 - INFO - __main__ -   Batch number = 30
01/10/2022 16:19:43 - INFO - __main__ -   Batch number = 31
01/10/2022 16:19:44 - INFO - __main__ -   Batch number = 32
01/10/2022 16:19:44 - INFO - __main__ -   Batch number = 33
01/10/2022 16:19:44 - INFO - __main__ -   Batch number = 34
01/10/2022 16:19:45 - INFO - __main__ -   Batch number = 35
01/10/2022 16:19:45 - INFO - __main__ -   Batch number = 36
01/10/2022 16:19:45 - INFO - __main__ -   Batch number = 37
01/10/2022 16:19:45 - INFO - __main__ -   Batch number = 38
01/10/2022 16:19:46 - INFO - __main__ -   Batch number = 39
01/10/2022 16:19:46 - INFO - __main__ -   Batch number = 40
01/10/2022 16:19:46 - INFO - __main__ -   Batch number = 41
01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 42
01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 43
01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 44
01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 45
01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 46
01/10/2022 16:19:47 - INFO - __main__ -   Batch number = 47
01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 48
01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 49
01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 50
01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 51
01/10/2022 16:19:48 - INFO - __main__ -   Batch number = 52
01/10/2022 16:19:49 - INFO - __main__ -   Batch number = 53
01/10/2022 16:19:49 - INFO - __main__ -   Batch number = 54
01/10/2022 16:19:49 - INFO - __main__ -   Batch number = 55
01/10/2022 16:19:50 - INFO - __main__ -   Batch number = 56
01/10/2022 16:19:50 - INFO - __main__ -   Batch number = 57
01/10/2022 16:19:50 - INFO - __main__ -   Batch number = 58
01/10/2022 16:19:51 - INFO - __main__ -   Batch number = 59
01/10/2022 16:19:51 - INFO - __main__ -   Batch number = 60
01/10/2022 16:19:51 - INFO - __main__ -   Batch number = 61
01/10/2022 16:19:52 - INFO - __main__ -   Batch number = 62
01/10/2022 16:19:52 - INFO - __main__ -   Batch number = 63
01/10/2022 16:19:52 - INFO - __main__ -   Batch number = 64
01/10/2022 16:19:53 - INFO - __main__ -   Batch number = 65
01/10/2022 16:19:53 - INFO - __main__ -   Batch number = 66
01/10/2022 16:19:53 - INFO - __main__ -   Batch number = 67
01/10/2022 16:19:54 - INFO - __main__ -   Batch number = 68
01/10/2022 16:19:54 - INFO - __main__ -   Batch number = 69
01/10/2022 16:19:54 - INFO - __main__ -   Batch number = 70
01/10/2022 16:19:54 - INFO - __main__ -   Batch number = 71
01/10/2022 16:19:55 - INFO - __main__ -   Batch number = 72
01/10/2022 16:19:55 - INFO - __main__ -   Batch number = 73
01/10/2022 16:19:55 - INFO - __main__ -   Batch number = 74
01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 75
01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 76
01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 77
01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 78
01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 79
01/10/2022 16:19:56 - INFO - __main__ -   Batch number = 80
01/10/2022 16:19:57 - INFO - __main__ -   Batch number = 81
01/10/2022 16:19:57 - INFO - __main__ -   Batch number = 82
01/10/2022 16:19:57 - INFO - __main__ -   Batch number = 83
01/10/2022 16:19:57 - INFO - __main__ -   Batch number = 84
01/10/2022 16:19:59 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:19:59 - INFO - __main__ -     f1 = 0.6557828103053508
01/10/2022 16:19:59 - INFO - __main__ -     loss = 1.1010813315709431
01/10/2022 16:19:59 - INFO - __main__ -     precision = 0.6588123864383191
01/10/2022 16:19:59 - INFO - __main__ -     recall = 0.6527809698919789
01/10/2022 16:19:59 - INFO - __main__ -   Loading pretrained model and tokenizer
01/10/2022 16:20:02 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/10/2022 16:20:07 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:20:07 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/10/2022 16:20:07 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/10/2022 16:20:07 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:20:07 - INFO - root -   loading task adapter
01/10/2022 16:20:07 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:20:07 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:20:07 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:20:07 - INFO - __main__ -   Language = hi
01/10/2022 16:20:07 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/10/2022 16:20:08 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:20:08 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:20:08 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:20:08 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:20:08 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_hi_bert-base-multilingual-cased_128
01/10/2022 16:20:09 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:20:09 - INFO - __main__ -     Num examples = 1664
01/10/2022 16:20:09 - INFO - __main__ -     Batch size = 32
01/10/2022 16:20:09 - INFO - __main__ -   Batch number = 1
01/10/2022 16:20:09 - INFO - __main__ -   Batch number = 2
01/10/2022 16:20:09 - INFO - __main__ -   Batch number = 3
01/10/2022 16:20:10 - INFO - __main__ -   Batch number = 4
01/10/2022 16:20:10 - INFO - __main__ -   Batch number = 5
01/10/2022 16:20:10 - INFO - __main__ -   Batch number = 6
01/10/2022 16:20:10 - INFO - __main__ -   Batch number = 7
01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 8
01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 9
01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 10
01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 11
01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 12
01/10/2022 16:20:11 - INFO - __main__ -   Batch number = 13
01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 14
01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 15
01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 16
01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 17
01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 18
01/10/2022 16:20:12 - INFO - __main__ -   Batch number = 19
01/10/2022 16:20:13 - INFO - __main__ -   Batch number = 20
01/10/2022 16:20:13 - INFO - __main__ -   Batch number = 21
01/10/2022 16:20:13 - INFO - __main__ -   Batch number = 22
01/10/2022 16:20:14 - INFO - __main__ -   Batch number = 23
01/10/2022 16:20:14 - INFO - __main__ -   Batch number = 24
01/10/2022 16:20:14 - INFO - __main__ -   Batch number = 25
01/10/2022 16:20:15 - INFO - __main__ -   Batch number = 26
01/10/2022 16:20:15 - INFO - __main__ -   Batch number = 27
01/10/2022 16:20:15 - INFO - __main__ -   Batch number = 28
01/10/2022 16:20:16 - INFO - __main__ -   Batch number = 29
01/10/2022 16:20:16 - INFO - __main__ -   Batch number = 30
01/10/2022 16:20:16 - INFO - __main__ -   Batch number = 31
01/10/2022 16:20:17 - INFO - __main__ -   Batch number = 32
01/10/2022 16:20:17 - INFO - __main__ -   Batch number = 33
01/10/2022 16:20:17 - INFO - __main__ -   Batch number = 34
01/10/2022 16:20:18 - INFO - __main__ -   Batch number = 35
01/10/2022 16:20:18 - INFO - __main__ -   Batch number = 36
01/10/2022 16:20:18 - INFO - __main__ -   Batch number = 37
01/10/2022 16:20:18 - INFO - __main__ -   Batch number = 38
01/10/2022 16:20:19 - INFO - __main__ -   Batch number = 39
01/10/2022 16:20:19 - INFO - __main__ -   Batch number = 40
01/10/2022 16:20:19 - INFO - __main__ -   Batch number = 41
01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 42
01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 43
01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 44
01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 45
01/10/2022 16:20:20 - INFO - __main__ -   Batch number = 46
01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 47
01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 48
01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 49
01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 50
01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 51
01/10/2022 16:20:21 - INFO - __main__ -   Batch number = 52
01/10/2022 16:20:23 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:20:23 - INFO - __main__ -     f1 = 0.6480516095399453
01/10/2022 16:20:23 - INFO - __main__ -     loss = 1.0889393905034432
01/10/2022 16:20:23 - INFO - __main__ -     precision = 0.6491090659878598
01/10/2022 16:20:23 - INFO - __main__ -     recall = 0.6469975928696897
01/10/2022 16:20:25 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:20:25 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/10/2022 16:20:25 - INFO - __main__ -   Seed = 3
01/10/2022 16:20:25 - INFO - root -   save model
01/10/2022 16:20:25 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='hi', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/10/2022 16:20:25 - INFO - __main__ -   Loading pretrained model and tokenizer
01/10/2022 16:20:28 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/10/2022 16:20:34 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:20:34 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/10/2022 16:20:34 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/10/2022 16:20:34 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:20:34 - INFO - root -   loading task adapter
01/10/2022 16:20:34 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:20:34 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:20:34 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:20:34 - INFO - __main__ -   Language = hi
01/10/2022 16:20:34 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/10/2022 16:20:41 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:20:41 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:20:41 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:20:41 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:20:41 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_hi_bert-base-multilingual-cased_128
01/10/2022 16:20:41 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:20:41 - INFO - __main__ -     Num examples = 2685
01/10/2022 16:20:41 - INFO - __main__ -     Batch size = 32
01/10/2022 16:20:41 - INFO - __main__ -   Batch number = 1
01/10/2022 16:20:42 - INFO - __main__ -   Batch number = 2
01/10/2022 16:20:42 - INFO - __main__ -   Batch number = 3
01/10/2022 16:20:42 - INFO - __main__ -   Batch number = 4
01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 5
01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 6
01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 7
01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 8
01/10/2022 16:20:43 - INFO - __main__ -   Batch number = 9
01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 10
01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 11
01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 12
01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 13
01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 14
01/10/2022 16:20:44 - INFO - __main__ -   Batch number = 15
01/10/2022 16:20:45 - INFO - __main__ -   Batch number = 16
01/10/2022 16:20:45 - INFO - __main__ -   Batch number = 17
01/10/2022 16:20:45 - INFO - __main__ -   Batch number = 18
01/10/2022 16:20:45 - INFO - __main__ -   Batch number = 19
01/10/2022 16:20:46 - INFO - __main__ -   Batch number = 20
01/10/2022 16:20:46 - INFO - __main__ -   Batch number = 21
01/10/2022 16:20:46 - INFO - __main__ -   Batch number = 22
01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 23
01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 24
01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 25
01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 26
01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 27
01/10/2022 16:20:47 - INFO - __main__ -   Batch number = 28
01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 29
01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 30
01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 31
01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 32
01/10/2022 16:20:48 - INFO - __main__ -   Batch number = 33
01/10/2022 16:20:49 - INFO - __main__ -   Batch number = 34
01/10/2022 16:20:49 - INFO - __main__ -   Batch number = 35
01/10/2022 16:20:49 - INFO - __main__ -   Batch number = 36
01/10/2022 16:20:49 - INFO - __main__ -   Batch number = 37
01/10/2022 16:20:50 - INFO - __main__ -   Batch number = 38
01/10/2022 16:20:50 - INFO - __main__ -   Batch number = 39
01/10/2022 16:20:50 - INFO - __main__ -   Batch number = 40
01/10/2022 16:20:51 - INFO - __main__ -   Batch number = 41
01/10/2022 16:20:51 - INFO - __main__ -   Batch number = 42
01/10/2022 16:20:51 - INFO - __main__ -   Batch number = 43
01/10/2022 16:20:52 - INFO - __main__ -   Batch number = 44
01/10/2022 16:20:52 - INFO - __main__ -   Batch number = 45
01/10/2022 16:20:52 - INFO - __main__ -   Batch number = 46
01/10/2022 16:20:53 - INFO - __main__ -   Batch number = 47
01/10/2022 16:20:53 - INFO - __main__ -   Batch number = 48
01/10/2022 16:20:53 - INFO - __main__ -   Batch number = 49
01/10/2022 16:20:54 - INFO - __main__ -   Batch number = 50
01/10/2022 16:20:54 - INFO - __main__ -   Batch number = 51
01/10/2022 16:20:54 - INFO - __main__ -   Batch number = 52
01/10/2022 16:20:54 - INFO - __main__ -   Batch number = 53
01/10/2022 16:20:55 - INFO - __main__ -   Batch number = 54
01/10/2022 16:20:55 - INFO - __main__ -   Batch number = 55
01/10/2022 16:20:55 - INFO - __main__ -   Batch number = 56
01/10/2022 16:20:56 - INFO - __main__ -   Batch number = 57
01/10/2022 16:20:56 - INFO - __main__ -   Batch number = 58
01/10/2022 16:20:56 - INFO - __main__ -   Batch number = 59
01/10/2022 16:20:56 - INFO - __main__ -   Batch number = 60
01/10/2022 16:20:57 - INFO - __main__ -   Batch number = 61
01/10/2022 16:20:57 - INFO - __main__ -   Batch number = 62
01/10/2022 16:20:57 - INFO - __main__ -   Batch number = 63
01/10/2022 16:20:57 - INFO - __main__ -   Batch number = 64
01/10/2022 16:20:58 - INFO - __main__ -   Batch number = 65
01/10/2022 16:20:58 - INFO - __main__ -   Batch number = 66
01/10/2022 16:20:58 - INFO - __main__ -   Batch number = 67
01/10/2022 16:20:59 - INFO - __main__ -   Batch number = 68
01/10/2022 16:20:59 - INFO - __main__ -   Batch number = 69
01/10/2022 16:20:59 - INFO - __main__ -   Batch number = 70
01/10/2022 16:21:00 - INFO - __main__ -   Batch number = 71
01/10/2022 16:21:00 - INFO - __main__ -   Batch number = 72
01/10/2022 16:21:00 - INFO - __main__ -   Batch number = 73
01/10/2022 16:21:01 - INFO - __main__ -   Batch number = 74
01/10/2022 16:21:01 - INFO - __main__ -   Batch number = 75
01/10/2022 16:21:01 - INFO - __main__ -   Batch number = 76
01/10/2022 16:21:02 - INFO - __main__ -   Batch number = 77
01/10/2022 16:21:02 - INFO - __main__ -   Batch number = 78
01/10/2022 16:21:02 - INFO - __main__ -   Batch number = 79
01/10/2022 16:21:02 - INFO - __main__ -   Batch number = 80
01/10/2022 16:21:03 - INFO - __main__ -   Batch number = 81
01/10/2022 16:21:03 - INFO - __main__ -   Batch number = 82
01/10/2022 16:21:03 - INFO - __main__ -   Batch number = 83
01/10/2022 16:21:04 - INFO - __main__ -   Batch number = 84
01/10/2022 16:21:05 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:21:05 - INFO - __main__ -     f1 = 0.6698534220751741
01/10/2022 16:21:05 - INFO - __main__ -     loss = 1.0617101788520813
01/10/2022 16:21:05 - INFO - __main__ -     precision = 0.6727782071097372
01/10/2022 16:21:05 - INFO - __main__ -     recall = 0.6669539569447637
01/10/2022 16:21:05 - INFO - __main__ -   Loading pretrained model and tokenizer
01/10/2022 16:21:08 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/10/2022 16:21:13 - INFO - __main__ -   Using lang2id = None
01/10/2022 16:21:13 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/10/2022 16:21:13 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/10/2022 16:21:13 - INFO - root -   Trying to decide if add adapter
01/10/2022 16:21:13 - INFO - root -   loading task adapter
01/10/2022 16:21:14 - INFO - root -   loading lang adpater hi/wiki@ukp
01/10/2022 16:21:14 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/10/2022 16:21:14 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/10/2022 16:21:14 - INFO - __main__ -   Language = hi
01/10/2022 16:21:14 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/10/2022 16:21:15 - INFO - __main__ -   Language adapter for hi found
01/10/2022 16:21:15 - INFO - __main__ -   Set active language adapter to hi
01/10/2022 16:21:15 - INFO - __main__ -   Args Adapter Weight = None
01/10/2022 16:21:15 - INFO - __main__ -   Adapter Languages = ['hi']
01/10/2022 16:21:15 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_hi_bert-base-multilingual-cased_128
01/10/2022 16:21:15 - INFO - __main__ -   ***** Running evaluation  in hi *****
01/10/2022 16:21:15 - INFO - __main__ -     Num examples = 1664
01/10/2022 16:21:15 - INFO - __main__ -     Batch size = 32
01/10/2022 16:21:15 - INFO - __main__ -   Batch number = 1
01/10/2022 16:21:15 - INFO - __main__ -   Batch number = 2
01/10/2022 16:21:16 - INFO - __main__ -   Batch number = 3
01/10/2022 16:21:16 - INFO - __main__ -   Batch number = 4
01/10/2022 16:21:16 - INFO - __main__ -   Batch number = 5
01/10/2022 16:21:16 - INFO - __main__ -   Batch number = 6
01/10/2022 16:21:17 - INFO - __main__ -   Batch number = 7
01/10/2022 16:21:17 - INFO - __main__ -   Batch number = 8
01/10/2022 16:21:17 - INFO - __main__ -   Batch number = 9
01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 10
01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 11
01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 12
01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 13
01/10/2022 16:21:18 - INFO - __main__ -   Batch number = 14
01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 15
01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 16
01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 17
01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 18
01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 19
01/10/2022 16:21:19 - INFO - __main__ -   Batch number = 20
01/10/2022 16:21:20 - INFO - __main__ -   Batch number = 21
01/10/2022 16:21:20 - INFO - __main__ -   Batch number = 22
01/10/2022 16:21:20 - INFO - __main__ -   Batch number = 23
01/10/2022 16:21:20 - INFO - __main__ -   Batch number = 24
01/10/2022 16:21:21 - INFO - __main__ -   Batch number = 25
01/10/2022 16:21:21 - INFO - __main__ -   Batch number = 26
01/10/2022 16:21:21 - INFO - __main__ -   Batch number = 27
01/10/2022 16:21:22 - INFO - __main__ -   Batch number = 28
01/10/2022 16:21:22 - INFO - __main__ -   Batch number = 29
01/10/2022 16:21:22 - INFO - __main__ -   Batch number = 30
01/10/2022 16:21:23 - INFO - __main__ -   Batch number = 31
01/10/2022 16:21:23 - INFO - __main__ -   Batch number = 32
01/10/2022 16:21:23 - INFO - __main__ -   Batch number = 33
01/10/2022 16:21:24 - INFO - __main__ -   Batch number = 34
01/10/2022 16:21:24 - INFO - __main__ -   Batch number = 35
01/10/2022 16:21:24 - INFO - __main__ -   Batch number = 36
01/10/2022 16:21:25 - INFO - __main__ -   Batch number = 37
01/10/2022 16:21:25 - INFO - __main__ -   Batch number = 38
01/10/2022 16:21:25 - INFO - __main__ -   Batch number = 39
01/10/2022 16:21:25 - INFO - __main__ -   Batch number = 40
01/10/2022 16:21:26 - INFO - __main__ -   Batch number = 41
01/10/2022 16:21:26 - INFO - __main__ -   Batch number = 42
01/10/2022 16:21:26 - INFO - __main__ -   Batch number = 43
01/10/2022 16:21:27 - INFO - __main__ -   Batch number = 44
01/10/2022 16:21:27 - INFO - __main__ -   Batch number = 45
01/10/2022 16:21:27 - INFO - __main__ -   Batch number = 46
01/10/2022 16:21:27 - INFO - __main__ -   Batch number = 47
01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 48
01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 49
01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 50
01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 51
01/10/2022 16:21:28 - INFO - __main__ -   Batch number = 52
01/10/2022 16:21:29 - INFO - __main__ -   ***** Evaluation result  in hi *****
01/10/2022 16:21:29 - INFO - __main__ -     f1 = 0.6616311248575615
01/10/2022 16:21:29 - INFO - __main__ -     loss = 1.0752558650878759
01/10/2022 16:21:29 - INFO - __main__ -     precision = 0.6622132429614181
01/10/2022 16:21:29 - INFO - __main__ -     recall = 0.6610500292759092
01/15/2022 02:39:06 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:39:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 02:39:06 - INFO - __main__ -   Seed = 1
01/15/2022 02:39:06 - INFO - root -   save model
01/15/2022 02:39:06 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=1, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:39:06 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 02:39:09 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 02:39:14 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:39:14 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 02:39:14 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/15/2022 02:39:14 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:39:14 - INFO - root -   loading task adapter
01/15/2022 02:39:14 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:39:14 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:39:14 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:39:14 - INFO - __main__ -   Language = hi
01/15/2022 02:39:14 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/15/2022 02:39:19 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:39:19 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:19 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:19 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:19 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
01/15/2022 02:39:19 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:39:19 - INFO - __main__ -     Num examples = 47
01/15/2022 02:39:19 - INFO - __main__ -     Batch size = 32
01/15/2022 02:39:19 - INFO - __main__ -   Batch number = 1
01/15/2022 02:39:19 - INFO - __main__ -   Batch number = 2
01/15/2022 02:39:20 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:39:20 - INFO - __main__ -     f1 = 0.5079365079365079
01/15/2022 02:39:20 - INFO - __main__ -     loss = 1.494471788406372
01/15/2022 02:39:20 - INFO - __main__ -     precision = 0.5387205387205387
01/15/2022 02:39:20 - INFO - __main__ -     recall = 0.4804804804804805
01/15/2022 02:39:20 - INFO - __main__ -   Language adapter for bho not found, using hi instead
01/15/2022 02:39:20 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:20 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:20 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:20 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_bho_bert-base-multilingual-cased_128
01/15/2022 02:39:20 - INFO - __main__ -   ***** Running evaluation  in bho *****
01/15/2022 02:39:20 - INFO - __main__ -     Num examples = 361
01/15/2022 02:39:20 - INFO - __main__ -     Batch size = 32
01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 1
01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 2
01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 3
01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 4
01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 5
01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 6
01/15/2022 02:39:20 - INFO - __main__ -   Batch number = 7
01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 8
01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 9
01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 10
01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 11
01/15/2022 02:39:21 - INFO - __main__ -   Batch number = 12
01/15/2022 02:39:21 - INFO - __main__ -   ***** Evaluation result  in bho *****
01/15/2022 02:39:21 - INFO - __main__ -     f1 = 0.46695576756287943
01/15/2022 02:39:21 - INFO - __main__ -     loss = 2.092569281657537
01/15/2022 02:39:21 - INFO - __main__ -     precision = 0.48900999091734787
01/15/2022 02:39:21 - INFO - __main__ -     recall = 0.446804979253112
01/15/2022 02:39:22 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:39:22 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:22 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:22 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:22 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_ta_bert-base-multilingual-cased_128
01/15/2022 02:39:22 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:39:22 - INFO - __main__ -     Num examples = 656
01/15/2022 02:39:22 - INFO - __main__ -     Batch size = 32
01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 1
01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 2
01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 3
01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 4
01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 5
01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 6
01/15/2022 02:39:22 - INFO - __main__ -   Batch number = 7
01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 8
01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 9
01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 10
01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 11
01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 12
01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 13
01/15/2022 02:39:23 - INFO - __main__ -   Batch number = 14
01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 15
01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 16
01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 17
01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 18
01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 19
01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 20
01/15/2022 02:39:24 - INFO - __main__ -   Batch number = 21
01/15/2022 02:39:25 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:39:25 - INFO - __main__ -     f1 = 0.5443276744812718
01/15/2022 02:39:25 - INFO - __main__ -     loss = 1.3883723389534723
01/15/2022 02:39:25 - INFO - __main__ -     precision = 0.5732122587968218
01/15/2022 02:39:25 - INFO - __main__ -     recall = 0.5182144689584403
01/15/2022 02:39:25 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 02:39:27 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 02:39:34 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:39:34 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/15/2022 02:39:34 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s1/checkpoint-best/udpos/
01/15/2022 02:39:34 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:39:34 - INFO - root -   loading task adapter
01/15/2022 02:39:34 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:39:34 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:39:34 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:39:34 - INFO - __main__ -   Language = hi
01/15/2022 02:39:34 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/15/2022 02:39:35 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:39:35 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:35 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:35 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_mr_bert-base-multilingual-cased_128
01/15/2022 02:39:35 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:39:35 - INFO - __main__ -     Num examples = 46
01/15/2022 02:39:35 - INFO - __main__ -     Batch size = 32
01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 1
01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 2
01/15/2022 02:39:35 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:39:35 - INFO - __main__ -     f1 = 0.5152439024390244
01/15/2022 02:39:35 - INFO - __main__ -     loss = 1.5474462509155273
01/15/2022 02:39:35 - INFO - __main__ -     precision = 0.5504885993485342
01/15/2022 02:39:35 - INFO - __main__ -     recall = 0.48424068767908307
01/15/2022 02:39:35 - INFO - __main__ -   Language bho, split dev does not exist
01/15/2022 02:39:35 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:39:35 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:35 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:35 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_ta_bert-base-multilingual-cased_128
01/15/2022 02:39:35 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:39:35 - INFO - __main__ -     Num examples = 81
01/15/2022 02:39:35 - INFO - __main__ -     Batch size = 32
01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 1
01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 2
01/15/2022 02:39:35 - INFO - __main__ -   Batch number = 3
01/15/2022 02:39:35 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:39:35 - INFO - __main__ -     f1 = 0.5410628019323672
01/15/2022 02:39:35 - INFO - __main__ -     loss = 1.4334317843119304
01/15/2022 02:39:35 - INFO - __main__ -     precision = 0.5618729096989966
01/15/2022 02:39:35 - INFO - __main__ -     recall = 0.5217391304347826
01/15/2022 02:39:37 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:39:37 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 02:39:37 - INFO - __main__ -   Seed = 2
01/15/2022 02:39:37 - INFO - root -   save model
01/15/2022 02:39:37 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=2, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:39:37 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 02:39:40 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 02:39:46 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:39:46 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 02:39:46 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/15/2022 02:39:46 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:39:46 - INFO - root -   loading task adapter
01/15/2022 02:39:46 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:39:46 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:39:46 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:39:46 - INFO - __main__ -   Language = hi
01/15/2022 02:39:46 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/15/2022 02:39:50 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:39:50 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:50 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:50 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:50 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
01/15/2022 02:39:50 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:39:50 - INFO - __main__ -     Num examples = 47
01/15/2022 02:39:50 - INFO - __main__ -     Batch size = 32
01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 1
01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 2
01/15/2022 02:39:50 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:39:50 - INFO - __main__ -     f1 = 0.5297805642633229
01/15/2022 02:39:50 - INFO - __main__ -     loss = 1.4993797540664673
01/15/2022 02:39:50 - INFO - __main__ -     precision = 0.5540983606557377
01/15/2022 02:39:50 - INFO - __main__ -     recall = 0.5075075075075075
01/15/2022 02:39:50 - INFO - __main__ -   Language adapter for bho not found, using hi instead
01/15/2022 02:39:50 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:50 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:50 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:50 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_bho_bert-base-multilingual-cased_128
01/15/2022 02:39:50 - INFO - __main__ -   ***** Running evaluation  in bho *****
01/15/2022 02:39:50 - INFO - __main__ -     Num examples = 361
01/15/2022 02:39:50 - INFO - __main__ -     Batch size = 32
01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 1
01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 2
01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 3
01/15/2022 02:39:50 - INFO - __main__ -   Batch number = 4
01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 5
01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 6
01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 7
01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 8
01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 9
01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 10
01/15/2022 02:39:51 - INFO - __main__ -   Batch number = 11
01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 12
01/15/2022 02:39:52 - INFO - __main__ -   ***** Evaluation result  in bho *****
01/15/2022 02:39:52 - INFO - __main__ -     f1 = 0.44758029607826155
01/15/2022 02:39:52 - INFO - __main__ -     loss = 2.311605175336202
01/15/2022 02:39:52 - INFO - __main__ -     precision = 0.4677886355410785
01/15/2022 02:39:52 - INFO - __main__ -     recall = 0.42904564315352695
01/15/2022 02:39:52 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:39:52 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:39:52 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:39:52 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:39:52 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_ta_bert-base-multilingual-cased_128
01/15/2022 02:39:52 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:39:52 - INFO - __main__ -     Num examples = 656
01/15/2022 02:39:52 - INFO - __main__ -     Batch size = 32
01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 1
01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 2
01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 3
01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 4
01/15/2022 02:39:52 - INFO - __main__ -   Batch number = 5
01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 6
01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 7
01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 8
01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 9
01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 10
01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 11
01/15/2022 02:39:53 - INFO - __main__ -   Batch number = 12
01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 13
01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 14
01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 15
01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 16
01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 17
01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 18
01/15/2022 02:39:54 - INFO - __main__ -   Batch number = 19
01/15/2022 02:39:55 - INFO - __main__ -   Batch number = 20
01/15/2022 02:39:55 - INFO - __main__ -   Batch number = 21
01/15/2022 02:39:55 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:39:55 - INFO - __main__ -     f1 = 0.5581893665461364
01/15/2022 02:39:55 - INFO - __main__ -     loss = 1.3866249237741743
01/15/2022 02:39:55 - INFO - __main__ -     precision = 0.5839170636032502
01/15/2022 02:39:55 - INFO - __main__ -     recall = 0.534633145202668
01/15/2022 02:39:55 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 02:39:58 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 02:40:03 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:40:03 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/15/2022 02:40:03 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s2/checkpoint-best/udpos/
01/15/2022 02:40:03 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:40:03 - INFO - root -   loading task adapter
01/15/2022 02:40:03 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:40:03 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:40:03 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:40:03 - INFO - __main__ -   Language = hi
01/15/2022 02:40:03 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/15/2022 02:40:04 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:40:04 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:04 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:04 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:04 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_mr_bert-base-multilingual-cased_128
01/15/2022 02:40:04 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:40:04 - INFO - __main__ -     Num examples = 46
01/15/2022 02:40:04 - INFO - __main__ -     Batch size = 32
01/15/2022 02:40:04 - INFO - __main__ -   Batch number = 1
01/15/2022 02:40:05 - INFO - __main__ -   Batch number = 2
01/15/2022 02:40:05 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:40:05 - INFO - __main__ -     f1 = 0.5802650957290133
01/15/2022 02:40:05 - INFO - __main__ -     loss = 1.5113340616226196
01/15/2022 02:40:05 - INFO - __main__ -     precision = 0.5969696969696969
01/15/2022 02:40:05 - INFO - __main__ -     recall = 0.5644699140401146
01/15/2022 02:40:05 - INFO - __main__ -   Language bho, split dev does not exist
01/15/2022 02:40:05 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:40:05 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:05 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:05 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:05 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_ta_bert-base-multilingual-cased_128
01/15/2022 02:40:05 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:40:05 - INFO - __main__ -     Num examples = 81
01/15/2022 02:40:05 - INFO - __main__ -     Batch size = 32
01/15/2022 02:40:05 - INFO - __main__ -   Batch number = 1
01/15/2022 02:40:05 - INFO - __main__ -   Batch number = 2
01/15/2022 02:40:05 - INFO - __main__ -   Batch number = 3
01/15/2022 02:40:05 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:40:05 - INFO - __main__ -     f1 = 0.5151843817787418
01/15/2022 02:40:05 - INFO - __main__ -     loss = 1.5761994520823162
01/15/2022 02:40:05 - INFO - __main__ -     precision = 0.541002277904328
01/15/2022 02:40:05 - INFO - __main__ -     recall = 0.4917184265010352
01/15/2022 02:40:08 - INFO - root -   Input args: ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:40:08 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
01/15/2022 02:40:08 - INFO - __main__ -   Seed = 3
01/15/2022 02:40:08 - INFO - root -   save model
01/15/2022 02:40:08 - INFO - __main__ -   Training/evaluation parameters ModelArguments(model_name_or_path='bert-base-multilingual-cased', model_type='bert', config_name=None, tokenizer_name=None, cache_dir=None, labels='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128//labels.txt', data_dir='/home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/', output_dir='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi/', max_seq_length=128, do_train=False, do_eval=False, do_predict=True, do_adapter_predict=False, do_predict_dev=True, do_predict_train=False, init_checkpoint=None, evaluate_during_training=False, do_lower_case=False, few_shot=-1, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=32, gradient_accumulation_steps=4, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=50.0, max_steps=-1, save_steps=1000, warmup_steps=0, logging_steps=50, save_only_best_checkpoint=True, eval_all_checkpoints=True, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=3, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', predict_langs='mr,bho,ta', train_langs='en', log_file='/home/abhijeet/rohan/cloud-emea-copy/outputs//udpos/my-bert-base-multilingual-cased-MaxLen128_udpos_hi//train.log', eval_patience=-1, bpe_dropout=0, do_save_adapter_fusions=False, task_name='udpos', predict_task_adapter='output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/', predict_lang_adapter=None, test_adapter=True, adapter_weight=None, lang_to_vec=None, calc_weight_step=0, predict_save_prefix='', en_weight=None, temperature=1.0, get_attr=False, topk=1, task='udpos')
01/15/2022 02:40:08 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 02:40:10 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 02:40:16 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:40:16 - INFO - __main__ -   Evaluating the model on test set of all the languages specified
01/15/2022 02:40:16 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/15/2022 02:40:16 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:40:16 - INFO - root -   loading task adapter
01/15/2022 02:40:16 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:40:16 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:40:16 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:40:16 - INFO - __main__ -   Language = hi
01/15/2022 02:40:16 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/15/2022 02:40:20 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:40:20 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:20 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:20 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:20 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_mr_bert-base-multilingual-cased_128
01/15/2022 02:40:20 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:40:20 - INFO - __main__ -     Num examples = 47
01/15/2022 02:40:20 - INFO - __main__ -     Batch size = 32
01/15/2022 02:40:20 - INFO - __main__ -   Batch number = 1
01/15/2022 02:40:20 - INFO - __main__ -   Batch number = 2
01/15/2022 02:40:20 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:40:20 - INFO - __main__ -     f1 = 0.5795275590551181
01/15/2022 02:40:20 - INFO - __main__ -     loss = 1.4103432893753052
01/15/2022 02:40:20 - INFO - __main__ -     precision = 0.609271523178808
01/15/2022 02:40:20 - INFO - __main__ -     recall = 0.5525525525525525
01/15/2022 02:40:20 - INFO - __main__ -   Language adapter for bho not found, using hi instead
01/15/2022 02:40:20 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:20 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:20 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:20 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_bho_bert-base-multilingual-cased_128
01/15/2022 02:40:20 - INFO - __main__ -   ***** Running evaluation  in bho *****
01/15/2022 02:40:20 - INFO - __main__ -     Num examples = 361
01/15/2022 02:40:20 - INFO - __main__ -     Batch size = 32
01/15/2022 02:40:20 - INFO - __main__ -   Batch number = 1
01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 2
01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 3
01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 4
01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 5
01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 6
01/15/2022 02:40:21 - INFO - __main__ -   Batch number = 7
01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 8
01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 9
01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 10
01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 11
01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 12
01/15/2022 02:40:22 - INFO - __main__ -   ***** Evaluation result  in bho *****
01/15/2022 02:40:22 - INFO - __main__ -     f1 = 0.48433442963475853
01/15/2022 02:40:22 - INFO - __main__ -     loss = 2.09591473142306
01/15/2022 02:40:22 - INFO - __main__ -     precision = 0.5060589618375837
01/15/2022 02:40:22 - INFO - __main__ -     recall = 0.46439834024896265
01/15/2022 02:40:22 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:40:22 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:22 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:22 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:22 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_test_ta_bert-base-multilingual-cased_128
01/15/2022 02:40:22 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:40:22 - INFO - __main__ -     Num examples = 656
01/15/2022 02:40:22 - INFO - __main__ -     Batch size = 32
01/15/2022 02:40:22 - INFO - __main__ -   Batch number = 1
01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 2
01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 3
01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 4
01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 5
01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 6
01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 7
01/15/2022 02:40:23 - INFO - __main__ -   Batch number = 8
01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 9
01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 10
01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 11
01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 12
01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 13
01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 14
01/15/2022 02:40:24 - INFO - __main__ -   Batch number = 15
01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 16
01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 17
01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 18
01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 19
01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 20
01/15/2022 02:40:25 - INFO - __main__ -   Batch number = 21
01/15/2022 02:40:25 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:40:25 - INFO - __main__ -     f1 = 0.5879370162796905
01/15/2022 02:40:25 - INFO - __main__ -     loss = 1.2563766127540952
01/15/2022 02:40:25 - INFO - __main__ -     precision = 0.6126251390433816
01/15/2022 02:40:25 - INFO - __main__ -     recall = 0.5651616213442792
01/15/2022 02:40:26 - INFO - __main__ -   Loading pretrained model and tokenizer
01/15/2022 02:40:28 - INFO - __main__ -   loading from existing model bert-base-multilingual-cased
01/15/2022 02:40:34 - INFO - __main__ -   Using lang2id = None
01/15/2022 02:40:34 - INFO - __main__ -   Evaluating on the dev sets of all the specified languages
01/15/2022 02:40:34 - INFO - __main__ -   Task Adapter will be loaded from this path output/udpos/my-bert-base-multilingual-cased-LR1e-4-epoch50-MaxLen128-TrainLangen_en_s3/checkpoint-best/udpos/
01/15/2022 02:40:34 - INFO - root -   Trying to decide if add adapter
01/15/2022 02:40:34 - INFO - root -   loading task adapter
01/15/2022 02:40:34 - INFO - root -   loading lang adpater hi/wiki@ukp
01/15/2022 02:40:34 - INFO - __main__ -   Adapter Languages : ['hi'], Length : 1
01/15/2022 02:40:34 - INFO - __main__ -   Adapter Names ['hi/wiki@ukp'], Length : 1
01/15/2022 02:40:34 - INFO - __main__ -   Language = hi
01/15/2022 02:40:34 - INFO - __main__ -   Adapter Name = hi/wiki@ukp
01/15/2022 02:40:35 - INFO - __main__ -   Language adapter for mr not found, using hi instead
01/15/2022 02:40:35 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:35 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:35 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:35 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_mr_bert-base-multilingual-cased_128
01/15/2022 02:40:35 - INFO - __main__ -   ***** Running evaluation  in mr *****
01/15/2022 02:40:35 - INFO - __main__ -     Num examples = 46
01/15/2022 02:40:35 - INFO - __main__ -     Batch size = 32
01/15/2022 02:40:35 - INFO - __main__ -   Batch number = 1
01/15/2022 02:40:35 - INFO - __main__ -   Batch number = 2
01/15/2022 02:40:35 - INFO - __main__ -   ***** Evaluation result  in mr *****
01/15/2022 02:40:35 - INFO - __main__ -     f1 = 0.6005917159763314
01/15/2022 02:40:35 - INFO - __main__ -     loss = 1.369255542755127
01/15/2022 02:40:35 - INFO - __main__ -     precision = 0.6207951070336392
01/15/2022 02:40:35 - INFO - __main__ -     recall = 0.5816618911174785
01/15/2022 02:40:36 - INFO - __main__ -   Language bho, split dev does not exist
01/15/2022 02:40:36 - INFO - __main__ -   Language adapter for ta not found, using hi instead
01/15/2022 02:40:36 - INFO - __main__ -   Set active language adapter to hi
01/15/2022 02:40:36 - INFO - __main__ -   Args Adapter Weight = None
01/15/2022 02:40:36 - INFO - __main__ -   Adapter Languages = ['hi']
01/15/2022 02:40:36 - INFO - __main__ -   Loading features from cached file /home/abhijeet/rohan/cloud-emea-copy/data//udpos/udpos_processed_maxlen128/cached_dev_ta_bert-base-multilingual-cased_128
01/15/2022 02:40:36 - INFO - __main__ -   ***** Running evaluation  in ta *****
01/15/2022 02:40:36 - INFO - __main__ -     Num examples = 81
01/15/2022 02:40:36 - INFO - __main__ -     Batch size = 32
01/15/2022 02:40:36 - INFO - __main__ -   Batch number = 1
01/15/2022 02:40:36 - INFO - __main__ -   Batch number = 2
01/15/2022 02:40:36 - INFO - __main__ -   Batch number = 3
01/15/2022 02:40:36 - INFO - __main__ -   ***** Evaluation result  in ta *****
01/15/2022 02:40:36 - INFO - __main__ -     f1 = 0.5217391304347826
01/15/2022 02:40:36 - INFO - __main__ -     loss = 1.47808039188385
01/15/2022 02:40:36 - INFO - __main__ -     precision = 0.5491990846681922
01/15/2022 02:40:36 - INFO - __main__ -     recall = 0.4968944099378882
